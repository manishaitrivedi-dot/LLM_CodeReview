# from __future__ import annotations # <-- Must be first line. Added to support annotation: Quble.method(self, ...) -> Quble:
import sys
import time
import pathlib
import copy
import numpy as np
import statsmodels.api as models
from re import split
from io import StringIO
from typing import NewType
from itertools import product
from scipy.stats import norm
from snowflake.snowpark import functions as F
from snowflake.snowpark.window import Window
from qubles.core.jinja.jinja_utils import dquote_dot
from qubles.core.constants.coltypes import *
from qubles.core.constants.quble_consts import *
from qubles.core.utils.quble_utils import *
from qubles.core.exceptions.quble_exceptions import *
from qubles.core.iterators.quble_iterators import *
from qubles.core.classes.table_references import TableReferences
from qubles.core.classes.pandasDF import PandasDF
from qubles.core.classes.numpySA import NumpySA
from qubles.core.classes.daterange import Index, make_index
from qubles.core.classes.index_array_1d import IndexArray1D
from qubles.core.classes.amenable import Amenable
from qubles.core.functions import operators as op
from qubles.core.functions.typemap_functions import *
from qubles.core.functions.common import (
    isnull,
    unicode_arr_to_string_arr,
    pfixed,
    missing_val_by_dtype,
    min_val_by_type,
    max_val_by_type,
)
from qubles.io.base.rootlib import ControlContextManager
from qubles.io.base.datalib import DataLib
from qubles.io.util.table_utils import *
from qubles.io.util.libaddress import LibAddress
from qubles.io.util.snowpark_session_manager import SnowparkSessionManager
from qubles.io.snowflake.core import (
    execute,
    desc_table,
    generate_random_table_name,
    execute_snowalchemy,
    is_env_table,
)
from qubles.io.snowflake.env import (
    snowflake_set_quble,
    fill_value_based_on_data,
    convert_dtype,
)
from qubles.io.snowflake.qbl import (
    snowflake_quble_preview,
    snowflake_get_quble_timestamp,
    snowflake_set_quble_timestamp,
    snowflake_table_to_pandas,
)
from qubles.util.logger import init_logger

_logger = init_logger(__name__)

QUBLE_CONNECTION_TYPE = "snowflake"
Quble = NewType("Quble", int)


# ============================================= Quble Class ===============================================
class Quble(object, metaclass=Amenable):
    """
    **Quotient (table-based) data object.**

    Quble class represents a multi-dimensional, multi-variate keyed data object
    with intelligent arithmetic operations, slicing, reindexing, aggregation,etc.

    A Quble's structure is composed of an underlying SQL data table
    with two types of columns: "keyspaces" and "valuespaces"
    as well as some associated Python (meta-data) attributes.

    **keyspaces**

    "keyspaces" are index columns of the Quble table defining "dimensionality".
    For example: A Quble with 3 keyspaces reflects a "3-Dimensional" (3D) Quble.
    Each keyspace (column) holds a list of keys along that dimension.
    Users can access a Quble's keyspaces as: ``Quble.keyspaces``
    The combination of keys (across all the keyspaces) columns FOR A GIVEN ROW
    should be UNIQUE across the records of the Quble's data table.

    **valuespaces**

    "valuespaces" (value columns) can be thought of as the values of a Quble.
    Each valuespace describes the name and type of the value in a record.
    Valuespaces (value columns) provide the data values for the Quble
    [where as keyspaces (index columns) provide qualifiers for the data]
    Users can access a Quble's valuespaces (list) as: ``Quble.valuespaces``

    **(primary) valuespace**

    One specific valuespace can be annointed as the "primary valuespace".
    This "primary valuespace" will be used in ops requiring a single valuespace.
    For many Quble methods, single valuespace operations can be mandated
    by using the method argument: variate_mode = 'uni'
    For example, performing Quble additions (Ex: C=A+B)
    with a prevailing default user setting of variate_mode = 'uni'
    will yield a univariate (1V) result (C) that will reflect
    the sum of the primary valuespaces of A + B for each key-aligned record.
    Users can access a Quble's primary valuespace as: ``Quble.valuespace``

    **"Empty Quble"**

    A Quble's data table may have keyspaces and/or valuespaces but no records.
    Such Qubles are referred to as "Empty Qubles".
    This condition is identified using the ``Quble.is_empty`` class property.
    Qubles with records are NOT "empty" even if all their valuespace's values are null/missing

    **"Index Quble" (aka "Non-Variate Quble")**

    If a Quble's table has no valuespaces columns,
    the Quble is considered to be an "Index Quble" ("Non-Variate Quble").
    In this case, the class properties ``Quble.is_index`` will identify this condition.
    Similarly, class property ``Quble.is_nonvariate`` will also identify this condition.
    For "Index Qubles", the ``Quble.valuespace`` class property returns None,
    while the ``Quble.valuespaces`` class property will return an empty list.

    One can think of / treat / use an "Index Quble" as
    a compressed version of boolean-valued Quble where
    all the (imaginary) boolean values are assigned to True

    The methods ``Quble.index_to_bool()`` & ``Quble.bool_to_index()`` converts
    between boolean-univariate and index-only versions of Qubles.

    When converting from boolean-valued to index-only Quble,
    first, records with False values are removed
    then the valuespace is 'dropped' from the Quble's table

    **"Variate Quble"**

    A "Variate Quble"has a data table that contains
    one (or more) valuespaces (value columns).
    "Univariate Qubles" have only one valuespace column.
    "Multi-Variate Qubles" have multiple valuespaces (value columns).
    "Non-Variate" Qubles have no valuespaces (no value columns).
    For example, A Quble with 3 keyspaces and 2 valuespaces
    is referred to as a "3D-2V Quble" (or a "3-Dimensional, Bi-Variate Quble").
    The variate condition is identified using ``Quble.is_variate`` class property.
    Multi-variate Quble's may contain valuespaces of disparate data types.

    **"Scalar Quble"**

    A Quble with no keyspaces, a single valuespace and a SINGLE RECORD
    is referred to as a "scalar" Quble.
    "Scalar Qubles" can be identified using the ``Quble.is_scalar`` class property.
    A "Scalar Quble" is the only state that allows for no keyspaces
    Non-scalar Qubles require atleast one keyspace (even if no records present)
    A single-record Quble with one (or more) keyspaces is NOT a "Scalar Quble"
    For "Scalar Qubles", the ``Quble.keyspaces`` class property returns an empty list

    **"Multi-Scalar Quble"**

    A Quble with no keyspaces, but multiple valuespaces and a SINGLE RECORD
    is referred to as a "Multi-Scalar Quble".
    Multi-Scalar Qubles are identified using ``Quble.is_multiscalar`` class property

    **"Undefined Quble"**

    A Quble without an underlying data table is referred to as an "Undefined Quble".
    In this case, the Quble's table_name attribute is assigned to None.
    This condition is identified using the ``Quble.is_undefined`` class property.
    For "Undefined Qubles", the ``Quble.valuespace`` class property returns None,
    while the ``Quble.valuespaces`` and ``Quble.keyspaces`` class properties
    will return an empty list.

    **Info Types for Columns/Spaces:**

    Users can provide qualifying metadata for each Quble column.
    For example, users can specify the time-frequency of a time-column,
    or the currency (fx) for the values in a given (numeric) valuespace.
    The following "info types" are currently supported for Quble columns:

    * 'role': The role of the column with respect to the Quble (keyspace, valuespace)
    * 'fx': currency of a (numeric) column (using ISO 3-Character format)
    * 'freq': time-frequency of a given datetime (timestamp) column (system assigned)
    * 'time_basis': controls value-translations during frequency conversions
    * 'tdistribute_mode': controls time-period affiliations when converting from coarse to fine frequencies
    * 'tfill_method': default fill operation to use when filling values through time
    * 'tfill_max': default maximum fill range (in number of time-periods at freq)
    * 'tfill_end_mode': controls end-points for time-filling operations
    * 'tfill_honor_null': (default) flag to honor nulls when filling through time
    * 'keygroup': Used to group multiple keyspaces together into a common group
    * 'map_type': map type if/when using this (value) column to remap other content
    * 'map_basis': map basis if/when using this (value) column to remap other content
    * 'is_non_vantage': flag denoting a (time) column is a non-vantage column
    * 'is_rankspace': flag denoting this columns may/will be used a rankspace
    * 'is_primary': flag denoting a column as the primary value column

    Many of these info-type assignments represent optional column settings.
    In such cases, a global system setting may be substututed when needed.

    **Quble Construction:**

    To construct a Quble, you can specify any combination of the above components.
    For example, you can provide just keyspaces to create an "Index Quble".
    Or you can provide keyspaces, one valuespace and values to create an N-D,
    univariate data object. Or you can pass multiple valuespaces to create a
    multivariate data object.

    You can pass information to a Quble constructor a number of different ways.
    Data is presented to Quble constructor in a "folded" or "unfolded" form

    **"Unfolded" form for constructor args**

    The "unfolded" format reflects a multi-dimensional numpy-array format
    An N-D numpy array is an example of "unfolded" data. This form has information
    about every cell in the N-D matrix, and the structure is made up of nested arrays.

    **"Folded" form for constructor args**

    Folded data is more like a SQL table. Some of the columns are index columns
    (i.e. keyspaces) and some of the columns are data columns (i.e. valuespaces).
    There may not be a row for every possible cell in the N-D matrix.


    **Quble Constructor Arguments:**

    :type data: scalar or list or np.array or structured numpy array
    :param data:
      Values to store in the Quble.

    NOTE: For a variate-Quble constructor,
    user must provide atleast one of: data, dtype or valuespace
    Otherwise, an index-only non-valued Quble may result
    (provide hyper_index or indices are given)

    :type indices: dict or list or np.array
    :param indices:
      Describes the structure of the data passed to the Quble.

    :param space_map: (optional) dictionary allowing for selective remapping/renaming of space names
                      from names in struct_array to space names in resultant Quble
    :type space_map: None or dictionary

    :param freq_hint: (optional) frequency hint for frequency inference of time-keyspace(s)
        ==> NOTE: freq_hint should only be used if space_info arg
        ==> DOES NOT already contain frequency information for columns
    :type freq_hint: str, dictionary, None
        ==> None*: No hint
        ==> 'default_freq': use prevailing default frequency control from the RootLib()
        ==> str: will use the specified freq_hint for frequency inference against all time-keyspaces
        ==> dictionary: dictionary keys=(time) keyspaces, dictionary values=freq hint for a given keyspace
        NOTE: when dictionary value=None, frequency inference is still performed but with no freq_hint

    :param freq_hint_mode: (optional) handling for frequency hint failure
    :type freq_hint_mode: str, dictionary, None
        If dict: dict keys=(time) keyspaces, dict values=freq hint mode for each time-keyspace
        Valid freq hint modes...
        ==> None*: graceful inference of alternative frequency that matches data
        ==> 'pass': pass on frequency hint failure
        ==> 'raise': raises Exception if hint fails
        ==> 'force': forces frequency hint but uses no time-basis during force
        ==> 'force_honor_tb': forces frequency hint while honoring prevailing time-basis
        NOTE: Here, time-basis will be used to convert from intermediate inferred freq to hint freq

    :type fx: str or None or dict (keyed per valuespace) or list/tuple of strings across valuespaces
    :param fx:
      Currency ISO for given (numeric) valuespace(s)

    :type time_basis: str or None or dict (keyed per valuespace) or list/tuple of strings across valuespaces
    :param time_basis:
      Time-basis for given valuespace(s).
      Controls behavior of valuespace(s) when changing time-frequencies.

    :type valuespace: None or scalar string or list/tuple of strings
    :param valuespace:
      Identifies the valuespace(s) of the resultant Quble
      May be overriden/ignored when data is provided as structured numpy array
      If more than one valuespace is provided, first valuespace will be "primary"

    :type dtype: np.dtype
    :param dtype:
      Used to specify the dtype of an empty Quble.

    :type tfill_max: int or None or dict (keyed per valuespace) or list/tuple of ints across valuespaces
    :param tfill_max:
      The maximum allowable number time-periods for time-filling
    :param tfill_end_mode:
       Controls extension/limits beyond original dates
       if/when a fill operation is to be filled on this Quble's content
       ==> None or 'unconstrained': unconstrained filling
       ==> 'no_future': Do not fill beyond current date
       ==> 'in_progress': fill though the end of the current in-progress period
       ==> 'no_extension': Do not fill beyond the last date record for particlar orthogonal keys
       ==> 'full_extension': Do not fill beyond the last date record in the Quble's table

    :type tfill_honor_null: bool or None or dict (keyed per valuespace) or list/tuple of str across valuespaces
    :param tfill_honor_null:
      Flag to honor (dishonor) null records during a filling-operation

    :type tdistribute_mode: str or None or dict (keyed per valuespace) or list/tuple of str across valuespaces
    :param tdistribute_mode:

       ==> 'forward': distribute forward in time INCLUDING original end-point (no look-ahead bias)
                        [CEOM->DAILY Example: Apply the end-of-month values
                        TO original end-of-month point AND all intra-month days
                        in the NEXT-MONTH except the last day of next month]

       ==> 'xforward': distribute forward in time EXCLUDING original end-point (no look-ahead bias)
                        [CEOM->DAILY Example: Apply the end-of-month values
                        to all days in the NEXT-MONTH including the last day of next month
                        but do not apply to the original month-end date]

       ==> 'coincident': back-distribute (CAUTION: possible look ahead bias)
                          [CEOM->DAILY Example: Apply the end-of-month value
                          to all intra-month days DURING THE CURRENT month]

       ==> 'disallow': Do not allow converting from low-freq to high-freq (raises Exception)

    :type map_type: str or None or dict (keyed per valuespace) or list/tuple of str across valuespaces
    :param map_type: the type of mapping (if applicable)

            ==>  None: will perform a (simple) one-to-one or (simple) one-to-many mapping [will ignore map_basis arg]
                 [If a one-to-many keymap is provide, map_type=None, map_basis=None is equivalent to map_type='distribute', map_basis=None]
            ==> 'aggregate': many-to-one mapping [NOTE: non-trivial map_basis arg required]
            ==> 'distribute': one-to-many mapping [Both trivial & non-trivial map_basis arg supported]
            ==> 'aggregate_distribute': aggregate (N->1) then redistribute (1->N) [NOTE: non-trivial map_basis arg required]


    :type map_basis: str or None or dict (keyed per valuespace) or list/tuple of str across valuespaces
    :param map_basis: Aggregation/Distribution Basis (if applicable)

           For map_type='distribute' (non-basis/plain one-to-many):  ==> map_basis: None
           For map_type='distribute' (with binning):  ==> map_basis: 'min','max','mean','ave','avg','average'
           For map_type='distribute' (with binning):  ==> map_basis: 'median','sum','cume','prod'
           For map_type='distribute' (with binning):  ==> map_basis: 'geo_cume','geo_prod','geo_mean'
           For map_type='distribute' (with binning):  ==> map_basis: 'geo100_cume','geo100_prod','geo100_mean'
           For map_type='distribute' (with ranking):  ==> map_basis: 'first','first:<rankspace>','last',last:<rankspace>' [if no rankspace provided, then row number is used]

           For map_type='aggregate' (with ranking):  ==> map_basis: 'first','first:<rankspace>','last',last:<rankspace>' [if no rankspace provided, then row number is used]

           For map_type='aggregate' or 'aggregate_distribute':
                ==> map_basis: 'min','max','mean','ave','avg','average',
                               'median','sum','cume','prod',
                               'geo_cume','geo_prod','geo_mean',
                               'geo100_cume','geo100_prod','geo100_mean',
                               'skew','kurtosis','stddev_samp','stddev_pop',
                               'pos_std','neg_std','stddev','std','var_samp',
                               'var_pop','var','pos_var','neg_var'

           For map_type='aggregate' (valuespace ranking):  ==> map_basis: 'rank','pct_rank','uniform_rank','biuniform_rank'

    :type address: str or LibAddress
    :param address:
      Global address at which this Quble can be accessed.

    :type remove_duplicate_keys: bool (True*/False)
    :param remove_duplicate_keys: Flag to remove duplicate keys

    :type duplicate_key_grace: bool (False*/True)
    :param duplicate_key_grace: Grace for duplicate keys when remove_duplicate_keys=False

    :type table_name: str or None
    :param table_name: Existing table from which to contruct the new Quble
        ==> IMPORTANT: WHEN USING table_name != None,
        ==> following args must all be None: data, hyper_index, indices, space_info, dtype, fx, tfill_max, etc.
        ==> Only arg that can be non-None:
    """

    @RootLib.lazy_kwargs()
    def __init__(
        self,
        data=None,
        hyper_index=None,
        indices=None,
        space_info=None,
        space_map: dict = None,
        freq_hint=None,
        freq_hint_mode=None,
        fx=None,
        time_basis=None,
        valuespace=None,
        dtype=None,
        tfill_max=None,
        tfill_end_mode=None,
        tfill_honor_null=None,
        tdistribute_mode=None,
        map_type=None,
        map_basis=None,
        address=None,
        compress=False,
        import_false_as_null=RootLib().lazy_eval("import_false_as_null"),
        remove_duplicate_keys=False,
        duplicate_key_grace=False,
        table_name=None,
        exceptions_flag: bool = False,
        time_stamp=None,
    ):
        _logger.debug("~~~ Initializing Quble ~~~")
        # Basic initialization
        self.data = None
        self.input_data = data if data is not None else {}
        self.address = address
        self.exceptions = None
        self.table_name = None
        self._valuespace = None
        self._cache = {}
        self._column_info = {}
        self._spaces = []
        self._keyspaces = []
        self._valuespaces = []
        self._auxvalspaces = []

        # When inherting a pre-existing table, we consult/honor table's time-stamp
        # (when no data args provided but existing table_name is provided as input arg)
        if time_stamp == "inspect":
            if table_name is not None:
                time_stamp = snowflake_get_quble_timestamp(table_name)
            else:
                raise Exception(
                    "Recieved time_stamp value of: 'inspect', but table_name was None."
                )
        if time_stamp is not None and time_stamp != "now":
            self.time_stamp = time_stamp
        else:
            self.time_stamp = datetime.now()

        # Trap for trivial "undefined Quble"" case
        if (
            data is None
            and hyper_index is None
            and indices is None
            and valuespace is None
            and table_name is None
            and dtype == "undefined"
        ):
            return

        # ----------------------
        # Validate input args
        # ----------------------
        if (data is not None or hyper_index is not None or indices is not None) or (
            table_name is None and valuespace is None and dtype == "undefined"
        ):
            generate_table = True
            if table_name is None:
                # We will generate a random name for the table later on
                self.table_name = None
            else:
                self.table_name = table_name

        elif dtype is not None:
            # table is being provided here, so make sure non-trivial
            # dtype arg IS NOT being provided (otherwise ambiguious)
            if table_name is not None:
                raise Exception(
                    f"Quble Constructor Exception! table_name:{table_name} MUST NOT BE PROVIDED WHEN non-trivial dtype IS PROVIDED"
                )
            else:
                generate_table = True
        elif table_name is not None:
            generate_table = False
            self.table_name = table_name
        else:
            generate_table = True

        # ----------------------------------------
        # Try to substitute dtype as needed
        # OVERRIDE THIS WITH FOLLOWING LOGIC...
        # no dtype, no data, no table_name indicates user
        # intentionally wants index-only Quble
        # UNLESS NON-TRIVIAL valuespace provided
        # ----------------------------------------
        if (
            dtype is None
            and data is None
            and self.table_name is None
            and valuespace is not None
        ):
            dtype = RootLib().get_control("default_dtype")
            if dtype is None:
                dtype = np.float64

        # ---------------------------------------
        # Convert Dataframe to structured array
        # ---------------------------------------
        dtype_hints = {}
        if isinstance(data, PandasDF):
            # Attempt to merge space_info
            if space_info is not None:
                if not isinstance(space_info, dict):
                    raise Exception(
                        f"Quble Constructor Exception! Non-dict space_info:{space_info}"
                    )
                if data.space_info is not None:
                    # Make a copy of data.space_info arg (dict)
                    # so as not to contaminate the the calling context
                    tmp_space_info = deepcopy(data.space_info)
                    for info_type, sub_dict in space_info.items():
                        if not isinstance(sub_dict, dict):
                            raise Exception(
                                f"Quble Constructor Exception! For info_type:{info_type}...non-dict info_assignments:{sub_dict}"
                            )
                        if info_type in tmp_space_info:
                            for column, info_value in sub_dict.items():
                                tmp_space_info[info_type][column] = info_value
                        else:
                            tmp_space_info[info_type] = sub_dict
                    space_info = tmp_space_info
            elif data.space_info is not None:
                space_info = data.space_info
        # ----------------------------------------
        # Handling if data is already a dataframe
        # ----------------------------------------
        elif isinstance(data, pd.DataFrame):
            pass
        # --------------------------------------
        # Handling if data is struct_array case
        # --------------------------------------
        elif is_structured_array(data):
            # Reconstructing space info
            if space_info is None:
                space_info = {}

            dtype = data.dtype
            if hasattr(dtype, "names"):
                for column_name in dtype.names:
                    dtype_hints[column_name] = dtype.fields[column_name][0]

                    # Update column info if applicable
                    if len(dtype.fields[column_name]) >= 3:
                        titles = dtype.fields[column_name][2]
                        # The NPY format uses: np.save(...titles=json.dumps(custom_info))
                        # As such, we need to use np.load() then ...custom_info=json.loads(titles))
                        if titles is not None:
                            if isinstance(titles, str):
                                custom_info = loads(titles)
                            elif isinstance(titles, dict):
                                custom_info = titles
                            else:
                                raise Exception(
                                    "Quble Constructor Exception! Invalid titles:{0}...(json) string or dictionary expected"
                                )
                            for info_type, info_value in custom_info.items():
                                if info_type == DUMMY_INFO_TYPE_FOR_UNIQUE_NUMPY_TITLES:
                                    continue  # <-- This info_type is only used to make titles unique for numpy support
                                elif info_type == DUMMY_INFO_TYPE_FOR_DUMMY_DATA:
                                    # This info_type is only used to identify the presence of dummy data in the npy file
                                    # NOTE: It does not matter which column_name is used to communicate the dummy_data_flag
                                    dummy_data_flag = info_value
                                    continue
                                elif info_type not in space_info:
                                    space_info[info_type] = {}
                                space_info[info_type][column_name] = info_value
            data = pd.DataFrame(data)

        # -----------------------------------
        # Handle data is array_dict case
        # ----------------------------------
        elif isinstance(data, dict):
            data_df = pd.DataFrame()
            for column_name in data:
                if isinstance(data[column_name], np.ndarray):
                    dtype_hints[column_name] = data[column_name].dtype
                if isinstance(data[column_name], np.ma.masked_array):
                    arr = data[column_name].data
                    arr = convert_dtype(
                        data[column_name],
                        data[column_name].dtype,
                        fill_value_based_on_data(arr),
                    )
                    data_df[column_name] = arr
                else:
                    data_df[column_name] = pd.DataFrame({"col": data[column_name]})
            data = data_df
        # -----------------------------------
        # Handle index only case
        # ----------------------------------
        elif data is None and indices is not None:
            self._keyspaces = list(indices.keys())
            data = pd.DataFrame(indices)
        # -----------------------------------
        # Handle scalar case
        # Todo: create a helper isscalar()
        # ----------------------------------
        elif isinstance(data, (int, float, str, date, datetime)):
            col, valuespace = self._process_valuespace_param(valuespace)
            # For a scalar case, it's easier to create the table in pure sql
            self.table_name = (
                generate_random_table_name() if table_name is None else table_name
            )
            self.data = pd.DataFrame([data], columns=[DEFAULT_VALUESPACE])
            snowflake_set_quble(self)
            # As a result, clear data and don't generate below, we also don't have keys, so skip that check
            generate_table = False
            data = None
            remove_duplicate_keys = False
        elif isinstance(data, (list, np.ndarray)):
            col, valuespace = self._process_valuespace_param(valuespace)
            numpy_array = np.array(data)
            dim = len(numpy_array.shape)
            if dim == 1:
                data = pd.DataFrame({col: data})
            elif dim > 1:
                if hyper_index:
                    data = pd.DataFrame({col: numpy_array.flatten()})
                else:
                    raise Exception(
                        "Recieved a multidimentional numpy array without a hyper_index."
                    )
        elif data is not None:
            raise Exception(
                f"Quble Constructor Exception! Received incompatible data of type {type(data)}"
            )

        # ---------------------------------------------------------------------
        # data can come as df, dict, etc,
        # hyper_index needs to be processed at the end as augmentation to data
        # Process hyper_index keyspace(s) only
        # ---------------------------------------------------------------------
        if hyper_index is not None:
            cartesian_product_ndim = to_cartesian_ndim(hyper_keys=hyper_index.values())
            hyper_df = pd.DataFrame(cartesian_product_ndim, columns=hyper_index.keys())
            # -----------------------------------------------------------------
            # Process hyper_index keyspace(s) + dataspace(keyspace and/or
            # valuespace coming from data variable)
            # -----------------------------------------------------------------
            if data is not None:
                if hyper_df.shape[0] > 1 and data.shape[0] == 1:
                    repeated_data = pd.concat(
                        [data] * hyper_df.shape[0], ignore_index=True
                    )
                    data = pd.concat([hyper_df, repeated_data], axis=1)
                elif hyper_df.shape[0] != data.shape[0]:
                    raise ValueError(
                        f"Quble Constructor Exception! hyper index ({hyper_df.shape[0]}) and valuespace ({data.shape[0]}) size mismatch"
                    )
                else:
                    data = pd.concat(
                        [
                            hyper_df,
                            data,
                        ],
                        axis=1,
                    )
            # -----------------------------------------------------------------
            # Process hyper_index keyspace(s) only
            else:
                data = hyper_df

        # -----------------------------------
        # null-Quble
        # -----------------------------------
        if data is None and generate_table:
            valuespace = (
                valuespace
                if valuespace not in [None, "<inspect>"]
                else DEFAULT_VALUESPACE
            )
            # For a scalar case, it's easier to create the table in pure sql
            self.table_name = (
                generate_random_table_name() if table_name is None else table_name
            )
            execute(
                f'CREATE TABLE "{self.table_name}" AS SELECT NULL AS "{valuespace}";',
                interface="native_storage",
            )
            # As a result, clear data and don't generate below, we also don't have keys, so skip that check
            generate_table = False
            data = None
            remove_duplicate_keys = False

        # -----------------------------------
        # Handling np.inf case
        # -----------------------------------
        if data is not None:
            # Added following line to handle potential object dtypes
            resolve_pandas_df_object_dtypes(data, dtype_hints=dtype_hints)
            numeric_valuespaces = data.select_dtypes(include=[np.number]).columns
            if len(numeric_valuespaces) > 0:
                data.loc[:, numeric_valuespaces] = data[numeric_valuespaces].replace(
                    [np.inf, np.NINF], np.nan
                )

        # -----------------------------------
        # Apply space name remappings if provided and we have a df
        # ----------------------------------
        if space_map is not None and data is not None:
            data.rename(columns=space_map, inplace=True)

        # -------------------------------------------------------------
        # Augment column_info with additional space info (if provided)
        # -------------------------------------------------------------
        if space_info is None:
            pass
        elif not isinstance(space_info, dict):
            raise Exception(
                f"Quble Constructor Exception! Non-dict space_info:{space_info}"
            )
        else:
            # Loop through space_info input dict to augment column_info dict
            for info_type, info_assignments in space_info.items():
                if info_assignments is None:
                    continue
                elif not isinstance(info_assignments, dict):
                    raise Exception(
                        f"Quble Constructor Exception! For info_type:{info_type}...non-dict info_assignments:{info_assignments}"
                    )
                else:
                    if info_type not in self._column_info:
                        self._column_info[info_type] = {}
                    for space1, info_assignment1 in info_assignments.items():
                        self._column_info[info_type][space1] = info_assignment1

        # -----------------------------------
        # Establish valuespaces from params
        # -----------------------------------
        if isinstance(valuespace, (list, tuple)):
            # If it is a scalar quble and num_valuespaces > 1, throw an exception
            if (
                len(valuespace) > 1
                and len(self.input_data) == 1
                and valuespace[0] in data
                and len(data[valuespace[0]]) == 1
            ):
                raise Exception(
                    f"Uni-Scalar quble can't have more than one valuespaces, current valuepsace arg being passed: {valuespace}"
                )
            self._valuespaces = valuespace
        elif valuespace is not None and valuespace != "<inspect>":
            # Here, a non-trivial scalar valuespace has been provided
            self._valuespaces = [valuespace]
        else:
            self._valuespaces = []

        # Subcase where valuespace is provided via column info instead
        if "role" in self._column_info:
            for column_name, role in self._column_info["role"].items():
                if role == "valuespace" and column_name not in self._valuespaces:
                    self._valuespaces.append(column_name)
        else:
            self._column_info["role"] = {}

        # Translate back to col_info
        for space in self._valuespaces:
            self._column_info["role"][space] = "valuespace"

        # -----------------------------------
        # import_false_as_null
        # -----------------------------------
        # If there is a boolean valuespace, replace False with null
        if import_false_as_null and data is not None:
            for vs in self._valuespaces:
                if data[vs].dtype == "bool":
                    data.replace(False, pd.NA, inplace=True)

        # Add valuespaces self._column_info
        # -----------------------------
        column_info_inputs = {}
        column_info_inputs["fx"] = fx
        column_info_inputs["time_basis"] = time_basis
        column_info_inputs["tfill_max"] = tfill_max
        column_info_inputs["tfill_end_mode"] = tfill_end_mode
        column_info_inputs["tfill_honor_null"] = tfill_honor_null
        column_info_inputs["tdistribute_mode"] = tdistribute_mode
        column_info_inputs["map_type"] = map_type
        column_info_inputs["map_basis"] = map_basis
        # Validating custom info inputs dictionary for uni and multi variate cases
        # ------------------------------------------------------------------------
        for custom_info_type, custom_info_value in column_info_inputs.items():
            if custom_info_value is not None:
                if isinstance(custom_info_value, str):
                    # Custom info value is a string
                    if len(self._valuespaces) > 1:
                        raise Exception(
                            f"Quble Constructor Exception! custom_info_value for '{custom_info_type}' should be a dictionary for a multivariate Quble"
                        )
                elif isinstance(custom_info_value, dict):
                    # Custom info value is a dictionary
                    if len(self._valuespaces) == 1:
                        # Univariate case - Expected single valuespace
                        if len(list(custom_info_value.keys())) != 1:
                            raise Exception(
                                f"Quble Constructor Exception! Expected single valuespace but got multiple instead for info_type: '{custom_info_type}'"
                            )
                        elif self._valuespaces != list(custom_info_value.keys()):
                            raise Exception(
                                f"Quble Constructor Exception! Invalid column '{list(custom_info_value.keys())[0]}' for info_type: '{custom_info_type}'"
                            )
                    elif len(self._valuespaces) > 1:
                        # Multivariate case
                        for key in custom_info_value.keys():
                            if key not in self._valuespaces:
                                raise Exception(
                                    f"Quble Constructor Exception! info_type: '{custom_info_type}' provided for column ({key}) not contained in valuespaces: {self._valuespaces}"
                                )
                else:
                    raise Exception(
                        f"Quble Constructor Exception! custom_info_value for '{custom_info_type}' should be a string or a dictionary.\nRecieved '{custom_info_value}' of type: {type(custom_info_value)}"
                    )

        for vs_no, vs in enumerate(self._valuespaces):
            for column_info_type, column_info_value in column_info_inputs.items():
                # Update column_info[column_info_type]
                # --------------------------------------
                if column_info_value is None:
                    continue

                # ToDo: Commenting this for now, add ownership logic later
                # elif self.table_name is not None:
                #     # Column info assignments prohibited when table_name is not None
                #     # as the new Quble does not own the existing table in this case
                #     raise Exception(
                #         f"Quble Constructor Exception! Cannot assign column_info_type:{column_info_type} to column_info_value:{column_info_value} for existing table_name:{self.table_name}...no table ownership"
                #     )
                elif isinstance(column_info_value, (list, tuple)):
                    # column_info_value arg is a list/tuple
                    if len(column_info_value) != len(valuespace):
                        raise Exception(
                            f"Quble Constructor Exception! len({column_info_type}):{len(column_info_value)} != len(valuespaces):{len(valuespace)}"
                        )
                    if column_info_value[vs_no] is not None:
                        if column_info_type not in self._column_info:
                            self._column_info[column_info_type] = {}
                        self._column_info[column_info_type][vs] = column_info_value[
                            vs_no
                        ]
                elif isinstance(column_info_value, dict):
                    # column_info_value arg is a dictionary
                    if vs in column_info_value and column_info_value[vs] is not None:
                        if column_info_type not in self._column_info:
                            self._column_info[column_info_type] = {}
                        self._column_info[column_info_type][vs] = column_info_value[vs]
                else:
                    # column_info_value is a scalar to be commonly applied to all valuespaces
                    if column_info_type not in self._column_info:
                        self._column_info[column_info_type] = {}
                    self._column_info[column_info_type][vs] = column_info_value

        # -----------------------------------------------
        # Generate and populate new table (if required)
        # -----------------------------------------------
        if generate_table:
            self.data = data
            self._process_valuespaces(self._valuespace)
            self._initialize_space_roles(self._valuespace, list(data.columns))

            # If data is non-scalar, perform compress and duplicate removal upfront
            if len(self.data) > 1:
                # Confirm presence of keyspace, we don't want to seed multi-row scalars
                if "keyspace" not in self._column_info["role"].values():
                    raise Exception(
                        "Quble init error! Recieved multi-row scalar data without a keyspace, this would result in ambiguous data."
                    )

                # Investigate/handle duplicate keys
                if remove_duplicate_keys and len(self.keyspaces) > 0:
                    self.data.sort_values(self.keyspaces, inplace=True)
                    if exceptions_flag:
                        self._extend_exceptions(
                            "Duplicate",
                            Quble(
                                self.data[
                                    self.data.duplicated(
                                        subset=self.keyspaces, keep="last"
                                    )
                                ],
                                space_info=self._column_info,
                            ),
                        )
                    self.data.drop_duplicates(
                        subset=self.keyspaces, keep="last", inplace=True
                    )
                    self._cache["has_duplicate_keys"] = False

            # Compress Logic
            if compress and len(self.valuespaces) > 0:
                if exceptions_flag:
                    self._extend_exceptions(
                        "Compress",
                        Quble(
                            self.data.loc[
                                self.data[self.valuespaces].isna().all(axis=1)
                            ],
                            space_info=self._column_info,
                        ),
                    )
                self.data.dropna(subset=self.valuespaces, how="all", inplace=True)

            self._cache["num_records"] = len(self.data)
            self.table_name = snowflake_set_quble(self)
        else:
            # If we are not generating a table, then go ahead and increment the table reference
            TableReferences().increment_table_reference(self.table_name)
            # Write the space_info to the new table in the case that updated column_info is passed to the Quble.from_table method
            self._synchronize_space_info()  # TODO: this should only be needed for env nodes that have comments
            self._process_valuespaces(self._valuespace)
            self._initialize_space_roles(self._valuespace)

            # Investigate/handle duplicate keys
            if remove_duplicate_keys:
                self.check_remove_duplicate_keys(
                    inplace=True,
                    exceptions_flag=exceptions_flag,
                    remove_duplicate_keys=remove_duplicate_keys,
                    duplicate_key_grace=duplicate_key_grace,
                )

            # Handle null_values / compression
            if compress:
                self.compress(exceptions_flag=exceptions_flag, inplace=True)

        #  ------------------------------------------------------
        #  NOW APPLY FREQ_HINT
        #  ------------------------------------------------------
        if freq_hint is not None:
            # Chosing not to infer frequencies here if no freq_hint provided NOTE: calling _infer_all_freqs() may add content to self._cache

            # Confirm freq_hint (if applicable)
            if freq_hint_mode is not None:
                freq = self._infer_all_freqs(
                    freq_hint=freq_hint,
                    assign_inferred=False,
                    force_reinfer=True,
                )
                self._confirm_freq_hint(
                    freq_hint=freq_hint,
                    freq_hint_mode=freq_hint_mode,
                    allow_shallow_copy=True,
                    exceptions_flag=exceptions_flag,
                    inplace=True,
                )
            else:
                freq = self._infer_all_freqs(
                    freq_hint=freq_hint,
                    assign_inferred=True,
                    force_reinfer=True,
                )
                for key, value in freq.items():
                    if "freq" not in self._column_info:
                        self._column_info["freq"] = {}

                    self._column_info["freq"][key] = value

        multi_col_info_custom_writer(self.table_name, self._column_info)
        _logger.debug("Return quble...")

    def __del__(self):
        TableReferences().decrement_table_reference(self.table_name)

    @staticmethod
    def undefined_instance():
        return Quble(dtype="undefined")

    def define_quble(self, table_name: str, col_info: dict = None):
        """
        Initializes a Quble object with the specified table name and optional column information.
        This method then swaps the table with the Quble's table name while preserving the current space information.
        It returns the current instance of the class, allowing for method chaining.

        Parameters:
        - table_name (str): The name of the table to be used in creating the Quble object.
        - col_info (dict, optional): A dictionary containing column information. Defaults to None.

        Returns:
        - self: The current instance of the class, enabling method chaining.

        Usage:
        >>> instance = Quble.undefined_instance()
        >>> instance = instance.define_quble("example_table", {"column1": "type1", "column2": "type2"})

        """
        self._swap_table(table_name=table_name, col_info=col_info)

        return self

    @classmethod
    def native_connection_type(cls, tolower=False, toupper=False):
        """
        Returns the 'native' SQL connection type for the Quble class
        """
        result = QUBLE_CONNECTION_TYPE
        if tolower:
            if toupper:
                raise Exception(
                    f"Inconsistent args: tolower:{tolower} and toupper:{toupper}"
                )
            return result.lower()
        elif toupper:
            return result.upper()
        else:
            return result

    @classmethod
    def is_native_connection_type(cls, connection_type, case_sensitive=False):
        """
        Evaluates whether the provided (SQL) connection type arg (str or None)
        correponds to the Quble class 'native' connection type
        [NOTE: by default, this test is case-insensitive]

        :param connection_type: candidate connection type to be tested
        :type str or None

        :param case_sensitive: flag specifying whether test is case-sensitive
        :type bool (False*/True)

        :returns: True when matches Quble class native connection type
        :rtype: bool
        """
        if connection_type is None:
            return False if QUBLE_CONNECTION_TYPE is not None else True
        elif not isinstance(connection_type, str):
            raise Exception(
                f"Invalid connection_type:{connection_type}...str or None expected"
            )
        elif QUBLE_CONNECTION_TYPE is None:
            # Should not happen
            return False
        elif case_sensitive:
            return connection_type == QUBLE_CONNECTION_TYPE
        else:
            return connection_type.lower() == QUBLE_CONNECTION_TYPE.lower()

    @classmethod
    def from_table(
        cls,
        table_name: str,
        address=None,
        valuespace: str | list[str] = "<inspect>",
        freq_hint=None,
        freq_hint_mode=None,
        col_info=None,
        remove_duplicate_keys=False,
        duplicate_key_grace=False,
        exceptions_flag: bool = False,
        time_stamp="now",
        **kwargs,
    ) -> Quble:
        """
        Builds a Quble instance from a table

        :param table_name: the underlying existing table
        :type str

        :param address: Quble's address in the addressing space
        :type str or LibAddress or None

        :param valuespace: the desired valuespace column
        :type str or LibAddress
           ==> if valuespace=='<inspect>'...will inspect existing column information
           ==> For proper behavior here, user is responsible for pre-setting
           column's info_type='role' either in column comments and/or through column_info dict of dicts]

        :param freq_hint: (optional) frequency hint for frequency inference of time-keyspace(s)
            ==> NOTE: freq_hint should only be used if
            ==> table's column meta data DO NOT already
            ==> contain frequency information in column comments
        :type freq_hint: str, dictionary, None
            ==> None*: No hint
            ==> 'default_freq': use prevailing default frequency control from the RootLib()
            ==> str: will use the specified freq_hint for frequency inference against all time-keyspaces
            ==> dictionary: dictionary keys=(time) keyspaces, dictionary values=freq hint for a given keyspace
            NOTE: when dictionary value=None, frequency inference is still performed but with no freq_hint

        :param freq_hint_mode: (optional) handling for frequency hint failure
        :type freq_hint_mode: str, dictionary, None
            If dict: dict keys=(time) keyspaces, dict values=freq hint mode for each time-keyspace
            Valid freq hint modes...
            ==> None*: graceful inference of alternative frequency that matches data
            ==> 'pass': pass on frequency hint failure
            ==> 'raise': raises Exception if hint fails
            ==> 'force': forces frequency hint but uses no time-basis during force
            ==> 'force_honor_tb': forces frequency hint while honoring prevailing time-basis
            NOTE: Here, time-basis will be used to convert from intermediate inferred freq to hint freq

        :param col_info: (optional) custom column/space info (meta data)
           ==> Use this option if meta data for the columns of specified table has not yet been cofigured
           NOTE: This feature will update comments on the table's columns
        :type None or (nested) dict of dicts
            ==> outer dictionary keys: info_type
            ==> outer dictionary values: inner dictionary
            ==> inner dictionary keys: column_name
            ==> inner dictionary values: associated info_type_assignment

        :type remove_duplicate_keys: bool (True*/False)
        :param remove_duplicate_keys: Flag to remove duplicate keys

        :type duplicate_key_grace: bool (False*/True)
        :param duplicate_key_grace: Grace for duplicate keys when remove_duplicate_keys=False

        :param exceptions_flag: flag whether to generate exceptions Quble
        :type exceptions_flag: (boolean) False*/True
                ==> exceptions_flag=False: returns modified Quble result
                ==> exceptions_flag=True: returns a tuple: (result,exceptions)

                In this latter case, exceptions may be None or a dict
                with dict keys: "freq", "dupes", "compress"

        :returns: A Quble populated with results of the specified query
        :rtype: qubles.core.quble.Quble
        """
        # Build the Quble using the source (and prepped) source table
        return Quble(
            address=address,
            table_name=table_name,
            space_info=col_info,
            valuespace=valuespace,
            freq_hint=freq_hint,
            freq_hint_mode=freq_hint_mode,
            remove_duplicate_keys=remove_duplicate_keys,
            duplicate_key_grace=duplicate_key_grace,
            exceptions_flag=exceptions_flag,
            time_stamp=time_stamp,
            **kwargs,
        )

    @classmethod
    def from_query(
        cls,
        query: str,
        table_name: str = None,
        address=None,
        valuespace: str = "<inspect>",
        freq_hint=None,
        freq_hint_mode=None,
        col_info=None,
        remove_duplicate_keys=False,
        duplicate_key_grace=False,
        exceptions_flag: bool = False,
        time_stamp="now",
        **kwargs,
    ) -> Quble:
        """
        Builds a Quble instance using a generic query
        (via default/native SQL connection and interface)

        :param query: sql query to be executed
        :type query: str

        :param table_name: (optional) table name
            ==> if None, then an arbitrary table name will be generated
        :type table_name: str or None

        :param address: Quble's address in the addressing space
        :type str or LibAddress or None

        :param valuespace: the desired valuespace column(s)
        :type str or None or list of strings
           ==> if valuespace=='<inspect>'...will inspect existing column information
           ==> For proper behavior here, user is responsible for pre-setting
               column's info_type='role' either in column comments and/or through column_info dict of dicts]

        :param freq_hint: (optional) frequency hint for frequency inference of time-keyspace(s)
            ==> NOTE: freq_hint should only be used if
            ==> table's column meta data DO NOT already
            ==> contain frequency information in column comments
        :type freq_hint: str, dictionary, None
            ==> None*: No hint
            ==> 'default_freq': use prevailing default frequency control from the RootLib()
            ==> str: will use the specified freq_hint for frequency inference against all time-keyspaces
            ==> dictionary: dictionary keys=(time) keyspaces, dictionary values=freq hint for a given keyspace
                            NOTE: when dictionary value=None, frequency inference is still performed but with no freq_hint

        :param freq_hint_mode: (optional) handling for frequency hint failure
        :type freq_hint_mode: str, dictionary, None
            If dict: dict keys=(time) keyspaces, dict values=freq hint mode for each time-keyspace
            Valid freq hint modes...
            ==> None*: graceful inference of alternative frequency that matches data
            ==> 'pass': pass on frequency hint failure
            ==> 'raise': raises Exception if hint fails
            ==> 'force': forces frequency hint but uses no time-basis during force
            ==> 'force_honor_tb': forces frequency hint while honoring prevailing time-basis
                              NOTE: Here, time-basis will be used to convert
                              from intermediate inferred freq to hint freq

        :param col_info: (optional) custom column/space info (meta data)
            ==> Use this option if meta data for the columns
                of specified table has not yet been cofigured
            ==> NOTE: This feature will update comments on the table's columns
        :type None or (nested) dict of dicts
            ==> outer dictionary keys: info_type
            ==> outer dictionary values: inner dictionary
            ==> inner dictionary keys: column_name
            ==> inner dictionary values: associated info_type_assignment

        :type remove_duplicate_keys: bool (True*/False)
        :param remove_duplicate_keys: Flag to remove duplicate keys

        :type duplicate_key_grace: bool (False*/True)
        :param duplicate_key_grace: Grace for duplicate keys when remove_duplicate_keys=False

        :param exceptions_flag: flag whether to generate exceptions Quble
        :type exceptions_flag: (boolean) False*/True
                ==> exceptions_flag=False: returns modified Quble result
                ==> exceptions_flag=True: returns a tuple: (result,exceptions)

                In this latter case, exceptions may be None or a dict
                with dict keys: "freq", "dupes", "compress"

        :param time_stamp: time-stamp to apply to new Quble
                ==> If None or 'now', will use currennt datetime
        :type time_stamp: datetime or 'now' or None

        :returns: A Quble populated with results of the specified query
        :rtype: qubles.core.quble.Quble
        """
        # Validate table_name
        if table_name is None:
            table_name = generate_random_table_name()

        # Execute query and redirect to populate the desired table
        sql_template = JINJA_ENV.get_template("generic_query.j2")
        sql_command = sql_template.render(
            query=query,
            tgt_table_name=table_name,
        )
        execute(sql_command)

        # Build Quble using newly populated table
        return Quble.from_table(
            table_name=table_name,
            address=address,
            col_info=col_info,
            valuespace=valuespace,
            freq_hint=freq_hint,
            freq_hint_mode=freq_hint_mode,
            remove_duplicate_keys=remove_duplicate_keys,
            duplicate_key_grace=duplicate_key_grace,
            exceptions_flag=exceptions_flag,
            time_stamp=time_stamp,
            **kwargs,
        )

    @classmethod
    @RootLib.lazy_kwargs()
    def from_array_dict(
        cls,
        array_dict: dict,
        valuespace=None,
        fx=None,
        time_basis=None,
        space_map=None,
        freq_hint: str = None,
        freq_hint_mode: str = None,
        space_info=None,
        tfill_max=None,
        tfill_end_mode=None,
        tfill_honor_null=None,
        tdistribute_mode=None,
        map_type=None,
        map_basis=None,
        import_false_as_null=RootLib().lazy_eval("import_false_as_null"),
        address=None,
        table_name=None,
        remove_duplicate_keys=True,
        duplicate_key_grace=False,
        compress: bool = False,
        exceptions_flag: bool = False,
        dtype=None,
        hyper_index=None,
        indices=None,
        time_stamp="now",
        **kwargs,
    ) -> Quble:
        """
        Composes Quble from a dictionary of numpy arrays

        :param array_dict: dictionary of column/space arrays
        :type struct_array: numpy structured array

        :param valuespace: valuespace column(s) (must be present in struct array)
        :type valuespace: str or None or list of strings

        :param fx: currency of valuespace(s)
        :type fx: str or dict or list or None

        :param time_basis: time_basis of valuespace(s)
        :type time_basis: str or dict or list or None

        NOTE: if valuespace/fx/time_basis is not None: may potentially override valuespace information in struct array's titles
        NOTE: if valuespace/fx/time_basis is None: valuespace information in struct array's titles (if present) will be honored

        :param space_map: (optional) dictionary allowing for selective
                          remapping/renaming of space names
                          from names in struct_array to space naems in resultant Quble
        :type space_map: None or dictionary

        :param freq_hint: (optional) frequency hint for frequency inference of time-keyspace(s)
        :type freq_hint: str, dict, None
            ==> None*: no (immediate) frequency inference (even if time-keyspaces exist)
            ==> str: will use the specified freq_hint for frequency inference against all time-keyspaces
            ==> 'default_freq': use prevailing default frequency control from the RootLib()
            ==> dictionary: dictionary keys=(time) keyspaces, dictionary values=freq hint for a given keyspace NOTE: when dictionary value=None, frequency inference is still performed but with no freq_hint

        :param freq_hint_mode: (optional) handling for frequency hint failure
        :type freq_hint_mode: str, dictionary, None
            If dict: dict keys=(time) keyspaces, dict values=freq hint mode for each time-keyspace
            Valid freq hint modes...
            ==> None*: graceful inference of alternative frequency that matches data
            ==> 'raise': raises Exception if hint fails
            ==> 'force': forces frequency hint but uses no time-basis during force
            ==> 'force_honor_tb': forces frequency hint while honoring prevailing time-basis
            NOTE: Here, time-basis will be used to convert from intermediate inferred freq to hint freq

        :param space_info: (custom) column/space information
                          (must not contain 'built'-in info_types)
        :type space_info: dictionary of dictionaries
            outer dictionary keys: info_type
            outer dictionary values: inner dictionary
            inner dictionary keys: column_name
            inner dictionary values: associated info_type_assignment

        :param tfill_max: The maximum allowable number time-periods for time-filling
        :type tfill_max: int or dict (keyed per valuespace) or list/tuple of ints or None

        :param tfill_end_mode:
        :type tfill_end_mode: str or dict (keyed per valuespace) or list/tuple of str
        Controls extension/limits beyond original dates
        if/when a fill operation is to be filled on this Quble's content
        ==> None or 'unconstrained': unconstrained filling
        ==> 'no_future': Do not fill beyond current date
        ==> 'in_progress': fill though the end of the current in-progress period
        ==> 'no_extension': Do not fill beyond the last date record for particular orthogonal keys
        ==> 'full_extension': Do not fill beyond the last date record in the Quble's table

        :param tfill_honor_null: Flag to honor (dishonor) null records during a filling-operation
        :type tfill_honor_null: bool or None

        :param tdistribute_mode:
        :type tdistribute_mode: str or None

              ==> 'forward': distribute forward in time INCLUDING original end-point (no look-ahead bias)
                             [CEOM->DAILY Example: Apply the end-of-month values
                             TO original end-of-month point AND all intra-month days
                             in the NEXT-MONTH except the last day of next month]

              ==> 'xforward': distribute forward in time EXCLUDING original end-point (no look-ahead bias)
                              [CEOM->DAILY Example: Apply the end-of-month values
                              to all days in the NEXT-MONTH including the last day of next month
                              but do not apply to the original month-end date]

            ==> 'coincident': back-distribute (CAUTION: possible look ahead bias)
                              [CEOM->DAILY Example: Apply the end-of-month value
                              to all intra-month days DURING THE CURRENT month]

            ==> 'disallow': Do not allow converting from low-freq to high-freq (raises Exception)

        :type map_type: str or None
        :param map_type: the type of mapping (if applicable)

            ==>  None: will perform a (simple) one-to-one or (simple) one-to-many mapping [will ignore map_basis arg]
                 [If a one-to-many keymap is provide, map_type=None, map_basis=None is equivalent to map_type='distribute', map_basis=None]
            ==> 'aggregate': many-to-one mapping [NOTE: non-trivial map_basis arg required]
            ==> 'distribute': one-to-many mapping [Both trivial & non-trivial map_basis arg supported]
            ==> 'aggregate_distribute': aggregate (N->1) then redistribute (1->N) [NOTE: non-trivial map_basis arg required]


        :type map_basis: str or None
        :param map_basis: Aggregation/Distribution Basis (if applicable)

           For map_type='distribute' (non-basis/plain one-to-many):  ==> map_basis: None
           For map_type='distribute' (with binning):  ==> map_basis: 'min','max','mean','ave','avg','average','median'
           For map_type='distribute' (with binning):  ==> map_basis: 'sum','cume','prod','geo_cume','geo_prod','geo_mean','geo100_cume','geo100_prod','geo100_mean'
           For map_type='distribute' (with ranking):  ==> map_basis: 'first','first:<rankspace>','last',last:<rankspace>' [if no rankspace provided, then row number is used]
           For map_type='aggregate' (with ranking):  ==> map_basis: 'first','first:<rankspace>','last',last:<rankspace>' [if no rankspace provided, then row number is used]

           For map_type='aggregate' or 'aggregate_distribute':
                ==> map_basis: 'min','max','mean','ave','avg','average','median',
                               'sum','cume','prod','geo_cume','geo_prod','geo_mean','geo100_cume','geo100_prod','geo100_mean',
                               'skew','kurtosis','stddev_samp','stddev_pop',
                               'pos_std','neg_std','stddev','std','var_samp',
                               'var_pop','var','pos_var','neg_var'

           For map_type='aggregate' (valuespace ranking):  ==> map_basis: 'rank','pct_rank'

        :param import_false_as_null: Flag to import False values as NULLs
                                     (applies to boolean arrays only)
        :type import_false_as_null: bool

        :type address: str or LibAddress
        :param address: Global address at which this Quble can be accessed.

        :param table_name: (Optional) table name
            ==> if None, then an arbitrary table name will be generated

        :param remove_duplicate_keys: Flag to remove duplicate keys
        :type remove_duplicate_keys: bool (True*/False)

        :param duplicate_key_grace: Grace for duplicate keys when remove_duplicate_keys=False
        :type duplicate_key_grace: bool (False*/True)

        :param exceptions_flag: flag whether to generate exceptions Quble
        :type exceptions_flag: (boolean) False*/True
                ==> exceptions_flag=False: returns modified Quble result
                ==> exceptions_flag=True: returns a tuple: (result,exceptions)

                In this latter case, exceptions may be None or a dict
                with dict keys: "freq", "dupes", "compress"

        :param time_stamp: time-stamp to apply to new Quble
                ==> If None or 'now', will use currennt datetime
        :type time_stamp: datetime or 'now' or None

        :returns: A Quble populated with data from the given structured array.
        :rtype: qubles.core.quble.Quble

        """
        # Validate array_dict arg and handle trivial cases
        if not isinstance(array_dict, dict):
            raise Exception("Invalid array_dict arg...dict required")
        elif array_dict is None or len(array_dict) == 0:
            return Quble()
        return Quble(
            data=array_dict,
            valuespace=valuespace,
            fx=fx,
            time_basis=time_basis,
            space_map=space_map,
            freq_hint=freq_hint,
            freq_hint_mode=freq_hint_mode,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_null=tfill_honor_null,
            tdistribute_mode=tdistribute_mode,
            map_type=map_type,
            map_basis=map_basis,
            import_false_as_null=import_false_as_null,
            address=address,
            table_name=table_name,
            remove_duplicate_keys=remove_duplicate_keys,
            duplicate_key_grace=duplicate_key_grace,
            compress=compress,
            exceptions_flag=exceptions_flag,
            space_info=space_info,
            dtype=dtype,
            hyper_index=hyper_index,
            indices=indices,
            time_stamp=time_stamp,
            **kwargs,
        )

    @classmethod
    @RootLib.lazy_kwargs()
    def from_struct_array(
        cls,
        struct_array,
        valuespace=None,
        fx=None,
        time_basis=None,
        space_map: dict = None,
        freq_hint: str = None,
        freq_hint_mode: str = None,
        tfill_max=None,
        tfill_end_mode=None,
        tfill_honor_null=None,
        tdistribute_mode=None,
        map_type=None,
        map_basis=None,
        import_false_as_null: bool = RootLib().lazy_eval("import_false_as_null"),
        address=None,
        table_name: str = None,
        remove_duplicate_keys=True,
        duplicate_key_grace=False,
        compress: bool = False,
        space_info=None,
        exceptions_flag: bool = False,
        dtype=None,
        hyper_index=None,
        indices=None,
        time_stamp="now",
        **kwargs,
    ) -> Quble:
        """
        Composes Quble from structured numpy array

        :param struct_array: The structured array subject
                         (struct array's titles may be used for custom info)
        :type struct_array: numpy structured array

        :param valuespace: valuespace column(s) (must be present in struct array)
        :type valuespace: str or None or list of strings

        :param fx: currency of valuespace(s)
        :type fx: str or dict or list or None

        :param time_basis: time_basis of valuespace(s)
        :type time_basis: str or dict or list or None

        NOTE: if valuespace/fx/time_basis is not None: may potentially override valuespace information in struct array's titles
        NOTE: if valuespace/fx/time_basis is None: valuespace information in struct array's titles (if present) will be honored

        :param space_map: (optional) dictionary allowing for selective
                          remapping/renaming of space names
                          from names in struct_array to space names in resultant Quble
        :type space_map: None or dictionary

        :param freq_hint: (optional) frequency hint for frequency inference of time-keyspace(s)
           NOTE: freq_hint should ONLY be used if struct_array DOES NOT already contain frequency information within struct array's title
        :type freq_hint: str, dict, None
            ==> None*: no (immediate) frequency inference (even if time-keyspaces exist)
            ==> str: will use the specified freq_hint for frequency inference against all time-keyspaces
            ==> 'default_freq': use prevailing default frequency control from the RootLib()
            ==> dictionary: dictionary keys=(time) keyspaces, dictionary values=freq hint for a given keyspace
            NOTE: when dictionary value=None, frequency inference is still performed but with no freq_hint

        :param freq_hint_mode: (optional) handling for frequency hint failure
        :type freq_hint_mode: str, dictionary, None
            If dict: dict keys=(time) keyspaces, dict values=freq hint mode for each time-keyspace
            Valid freq hint modes...
            ==> None*: graceful inference of alternative frequency that matches data
            ==> 'raise': raises Exception if hint fails
            ==> 'force': forces frequency hint but uses no time-basis during force
            ==> 'force_honor_tb': forces frequency hint while honoring prevailing time-basis
            NOTE: Here, time-basis will be used to convert from intermediate inferred freq to hint freq

        :param tfill_max: The maximum allowable number time-periods for time-filling
        :type tfill_max: int or dict (keyed per valuespace) or list/tuple of ints or None

        :param tfill_end_mode:
        :type tfill_end_mode: str or dict (keyed per valuespace) or list/tuple of str
        Controls extension/limits beyond original dates if/when a fill operation is to be filled on this Quble's content
        ==> None or 'unconstrained': unconstrained filling
        ==> 'no_future': Do not fill beyond current date
        ==> 'in_progress': fill though the end of the current in-progress period
        ==> 'no_extension': Do not fill beyond the last date record for particlar orthogonal keys
        ==> 'full_extension': Do not fill beyond the last date record in the Quble's table

        :param tfill_honor_null: Flag to honor (dishonor) null records during a filling-operation
        :type tfill_honor_null: bool or None

        :param tdistribute_mode:
        :type tdistribute_mode: str or None

              ==> 'forward': distribute forward in time INCLUDING original end-point (no look-ahead bias)
                             [CEOM->DAILY Example: Apply the end-of-month values
                             TO original end-of-month point AND all intra-month days
                             in the NEXT-MONTH except the last day of next month]

              ==> 'xforward': distribute forward in time EXCLUDING original end-point (no look-ahead bias)
                              [CEOM->DAILY Example: Apply the end-of-month values
                              to all days in the NEXT-MONTH including the last day of next month
                              but do not apply to the original month-end date]

            ==> 'coincident': back-distribute (CAUTION: possible look ahead bias)
                              [CEOM->DAILY Example: Apply the end-of-month value
                              to all intra-month days DURING THE CURRENT month]

            ==> 'disallow': Do not allow converting from low-freq to high-freq (raises Exception)

        :type map_type: str or None
        :param map_type: the type of mapping (if applicable)

            ==>  None: will perform a (simple) one-to-one or (simple) one-to-many mapping [will ignore map_basis arg]
                 [If a one-to-many keymap is provide, map_type=None, map_basis=None is equivalent to map_type='distribute', map_basis=None]
            ==> 'aggregate': many-to-one mapping [NOTE: non-trivial map_basis arg required]
            ==> 'distribute': one-to-many mapping [Both trivial & non-trivial map_basis arg supported]
            ==> 'aggregate_distribute': aggregate (N->1) then redistribute (1->N) [NOTE: non-trivial map_basis arg required]


        :type map_basis: str or None
        :param map_basis: Aggregation/Distribution Basis (if applicable)

           For map_type='distribute' (non-basis/plain one-to-many):  ==> map_basis: None
           For map_type='distribute' (with binning):  ==> map_basis: 'min','max','mean','ave','avg','average','median'
           For map_type='distribute' (with binning):  ==> map_basis: 'sum','cume','prod','geo_cume','geo_prod','geo_mean','geo100_cume','geo100_prod','geo100_mean',
           For map_type='distribute' (with ranking):  ==> map_basis: 'first','first:<rankspace>','last',last:<rankspace>' [if no rankspace provided, then row number is used]
           For map_type='aggregate' (with ranking):  ==> map_basis: 'first','first:<rankspace>','last',last:<rankspace>' [if no rankspace provided, then row number is used]

           For map_type='aggregate' or 'aggregate_distribute':
                ==> map_basis: 'min','max','mean','ave','avg','average','median',
                               'sum','cume','prod','geo_cume','geo_prod','geo_mean','geo_cume','geo_prod','geo_mean',','geo100_cume','geo100_prod','geo100_mean',
                               'skew','kurtosis','stddev_samp','stddev_pop',
                               'pos_std','neg_std','stddev','std','var_samp',
                               'var_pop','var','pos_var','neg_var'

           For map_type='aggregate' (valuespace ranking):  ==> map_basis: 'rank','pct_rank'

        :param import_false_as_null: Flag to import False values as NULLs (applies to boolean arrays only)
        :type import_false_as_null: bool

        :type address: str or LibAddress
        :param address: Global address at which this Quble can be accessed.

        :param table_name: (Optional) table name
            ==> if None, then an arbitrary table name will be generated

        :param remove_duplicate_keys: Flag to remove duplicate keys
        :type remove_duplicate_keys: bool (True*/False)

        :param duplicate_key_grace: Grace for duplicate keys when remove_duplicate_keys=False
        :type duplicate_key_grace: bool (False*/True)

        :param space_info: (optional) custom column/space info (meta data)
            ==> Use this option if meta data for the columns of specified table has not yet been cofigured
            ==> NOTE: This feature will update comments on the table's columns
            ==> NOTE: column name references here should be provided in remapped naming convention (when applicable)
        :type space_info: None or (nested) dict of dicts
            ==> outer dictionary keys: info_type
            ==> outer dictionary values: inner dictionary
            ==> inner dictionary keys: column_name (in remapped form when space_map present)
            ==> inner dictionary values: associated info_type_assignment

        :param exceptions_flag: flag whether to generate exceptions Quble
        :type exceptions_flag: (boolean) False*/True
                ==> exceptions_flag=False: returns modified Quble result
                ==> exceptions_flag=True: returns a tuple: (result,exceptions)

                In this latter case, exceptions may be None or a dict
                with dict keys: "freq", "dupes", "compress"

        :returns: A Quble populated with data from the given structured array.
        :rtype: qubles.core.quble.Quble

        """
        # Validating struct_array
        if not is_structured_array(struct_array):
            raise Exception("The input is not a structured array")

        return Quble(
            data=struct_array,
            valuespace=valuespace,
            fx=fx,
            time_basis=time_basis,
            freq_hint=freq_hint,
            freq_hint_mode=freq_hint_mode,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_null=tfill_honor_null,
            tdistribute_mode=tdistribute_mode,
            map_type=map_type,
            map_basis=map_basis,
            import_false_as_null=import_false_as_null,
            address=address,
            table_name=table_name,
            remove_duplicate_keys=remove_duplicate_keys,
            duplicate_key_grace=duplicate_key_grace,
            compress=compress,
            exceptions_flag=exceptions_flag,
            space_info=space_info,
            space_map=space_map,
            dtype=dtype,
            hyper_index=hyper_index,
            indices=indices,
            time_stamp=time_stamp,
            **kwargs,
        )

    @classmethod
    def from_pandas_df(
        cls,
        df,
        space_info=None,
        freq_hint: str = None,
        freq_hint_mode: str = None,
        fx=None,
        time_basis=None,
        space_map: dict = None,
        valuespace=None,
        dtype=None,
        tfill_max=None,
        tfill_end_mode=None,
        tfill_honor_null=None,
        tdistribute_mode=None,
        map_type=None,
        map_basis=None,
        address=None,
        compress=False,
        import_false_as_null=RootLib().lazy_eval("import_false_as_null"),
        remove_duplicate_keys=True,
        duplicate_key_grace=False,
        exceptions_flag: bool = False,
        table_name: str = None,
        hyper_index=None,
        indices=None,
        time_stamp="now",
        **kwargs,
    ):
        return Quble(
            data=df,
            space_info=space_info,
            table_name=table_name,
            freq_hint=freq_hint,
            freq_hint_mode=freq_hint_mode,
            fx=fx,
            time_basis=time_basis,
            space_map=space_map,
            valuespace=valuespace,
            dtype=dtype,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_null=tfill_honor_null,
            tdistribute_mode=tdistribute_mode,
            map_type=map_type,
            map_basis=map_basis,
            address=address,
            compress=compress,
            import_false_as_null=import_false_as_null,
            remove_duplicate_keys=remove_duplicate_keys,
            duplicate_key_grace=duplicate_key_grace,
            exceptions_flag=exceptions_flag,
            hyper_index=hyper_index,
            indices=indices,
            time_stamp=time_stamp,
            **kwargs,
        )

    @classmethod
    @RootLib.lazy_kwargs()
    def from_npy_file(
        cls,
        npyfile: str,
        coltype_map: dict = None,
        freq_hint: str = None,
        freq_hint_mode: str = None,
        object_import_mode="OBJECT",
        table_name: str = None,
        address=None,
        inherit_file_time_stamp: bool = True,
        windows_filename_adjust: bool = True,
        import_false_as_null: bool = RootLib().lazy_eval("import_false_as_null"),
        remove_duplicate_keys=True,
        duplicate_key_grace=False,
        compress: bool = False,
        space_info=None,
        exceptions_flag: bool = False,
        hyper_index=None,
        indices=None,
        space_map: dict = None,
        fx=None,
        time_basis=None,
        valuespace=None,
        tfill_max=None,
        tfill_end_mode=None,
        tfill_honor_null=None,
        tdistribute_mode=None,
        map_type=None,
        map_basis=None,
        dtype=None,
        time_stamp="now",
        **kwargs,
    ) -> Quble:
        """
        Read NPY file holding a structure (numpy array or records) into Quble
        We use this method as a back-end means for Quble.from_struct_array()

        :param npyfile: Path to the npy file containing data with which Quble will be created.
        :type npyfile: str

        :param coltype_map:dict: (optional) col_type per field name within npy file
        :type coltype_map: dictionary, None

        :param freq_hint: (optional) frequency hint for frequency inference of time-keyspace(s)
            => NOTE: freq_hint should ONLY be used if npy file DOES NOT already contain frequency information in npy file/struct array's title
        :type freq_hint: str, dictionary, None
            ==> None*: no (immediate) frequency inference (even if time-keyspaces exist)
            ==> str: will use the specified freq_hint for frequency inference against all time-keyspaces
            ==> 'default_freq': use prevailing default frequency control from the RootLib()
            ==> dictionary: dictionary keys=(time) keyspaces, dictionary values=freq hint for a given keyspace
            NOTE: when dictionary value=None, frequency inference is still performed but with no freq_hint

        :param freq_hint_mode: (optional) handling for frequency hint failure
        :type freq_hint_mode: str, dictionary, None
            If dict: dict keys=(time) keyspaces, dict values=freq hint mode for each time-keyspace
            Valid freq hint modes...
            ==> None*: graceful inference of alternative frequency that matches data
            ==> 'raise': raises Exception if hint fails
            ==> 'force': forces frequency hint but uses no time-basis during force
            ==> 'force_honor_tb': forces frequency hint while honoring prevailing time-basis
            NOTE: Here, time-basis will be used to convert from intermediate inferred freq to hint freq

        :param object_import_mode: col_type to use for dtype=object
                                    Example: 'CLOB':  assume object array holds variable length string
                                    Example: None:  No assumption...raise Exception
        :type object_import_mode: str or None

        :param inherit_file_time_stamp: Flag to inherit time_stamp of source file
        :type inherit_file_time_stamp: bool

        :param import_false_as_null: Flag to import False values as NULLs
                (applies to boolean arrays only)
        :type import_false_as_null: bool

        :param table_name: (Optional) table name
            ==> if None, then an arbitrary table name will be generated
        :type table_name: str or None

        :param remove_duplicate_keys: Flag to remove duplicate keys
        :type remove_duplicate_keys: bool (True*/False)

        :param duplicate_key_grace: Grace for duplicate keys when remove_duplicate_keys=False
        :type duplicate_key_grace: bool (False*/True)

        :param space_info: (optional) custom column/space info (meta data)
            ==> Use this option if meta data for the columns of specified table has not yet been cofigured
            ==> NOTE: This feature will update comments on the table's columns
        :type space_info: None or (nested) dict of dicts
            ==> outer dictionary keys: info_type
            ==> outer dictionary values: inner dictionary
            ==> inner dictionary keys: column_name
            ==> inner dictionary values: associated info_type_assignment

        :param exceptions_flag: flag whether to generate exceptions Quble
        :type exceptions_flag: (boolean) False*/True
                ==> exceptions_flag=False: returns modified Quble result
                ==> exceptions_flag=True: returns a tuple: (result,exceptions)

                In this latter case, exceptions may be None or a dict
                with dict keys: "freq", "dupes", "compress"

        :returns: A Quble populated with data from the given npy file.
        :rtype: qubles.core.quble.Quble

        """
        if npyfile is None:
            return Quble()
        elif not os.path.exists(npyfile):
            raise Exception(f"Absent npyfile:{npyfile}")

        fp = open(npyfile, "r")
        try:
            # For NON-MASKED structured numpy arrays, we can create npy file using numpy.save()
            # In this case, we can read the header using: np.lib.format._read_array_header(fp, version)
            # -------------------------------------------------
            version = np.lib.format.read_magic(fp)
            np.lib.format._check_version(version)
            shape, fortran_order, dtype = np.lib.format._read_array_header(fp, version)
            fp.close()
        except:
            fp.close()
            # However, to save and (re)load MASKED structured numpy arrays, we needed to store as a pickled file using numpy.load(...)
            # [since numpy.save() does not work for this case] This format is not conducive to reading the header only!!
            # ---------------------------------------------------------
            # In this case, to reload we need to use: numpy.load(filename, allow_pickle=True,...)
            # ---------------------------------------------------------
            # This approach is sub-optimal as we read the entire structured numpy array
            # simply to ascertain the dtype so that we can establish the target table signature
            dummy = np.load(npyfile, allow_pickle=True, mmap_mode=None)
            dtype = dummy.dtype
            del dummy

        # Verify structured numpy array provided
        if not hasattr(dtype, "names"):
            raise Exception("Structured numpy array required")

        # Establish col_type_dict (map from column names -> col_types)
        # and space_info (dictionary of dictionaries)...
        # ==> outer keys=info_type, inner keys=column_name values=info_value)
        col_type_dict = {}
        if space_info is None:
            space_info = {}
        for column_name in dtype.names:
            # -----------------------------------------------------------------------------------------
            # For speed & convenience, assume dtype=object correponds to variable length string array
            # Alternative: we would need to read (atleast one line of) data and inspect the specified dtype specific array element(s)
            # However, this alternative may require reading the entire array since structure numpy arrays with object dtypes seem to be saved as pickled ascii arrays
            # [If possible, We would like to avoid reading the entire numpy array data just to infer the underlying dtype for the object dtype]
            # -----------------------------------------------------------------------------------------
            if coltype_map is not None and column_name in coltype_map:
                col_type1 = coltype_map[column_name]
            else:
                col_type1 = dtype_to_coltype(
                    dtype.fields[column_name][0], object_import_mode=object_import_mode
                )

            col_type_dict[column_name] = col_type1

            # Update column info if applicable
            if len(dtype.fields[column_name]) >= 3:
                titles = dtype.fields[column_name][2]
                # The NPY format uses: np.save(...titles=json.dumps(custom_info))
                # As such, we need to use np.load() then ...custom_info=json.loads(titles))
                if titles is not None:
                    if isinstance(titles, str):
                        custom_info = loads(titles)
                    elif isinstance(titles, dict):
                        custom_info = titles
                    else:
                        raise Exception(
                            "Invalid titles:{0}...(json) string or dictionary expected"
                        )

                    for info_type, info_value in custom_info.items():
                        if info_type == DUMMY_INFO_TYPE_FOR_UNIQUE_NUMPY_TITLES:
                            continue  # <-- This info_type is only used to make titles unique for numpy support
                        elif info_type == DUMMY_INFO_TYPE_FOR_DUMMY_DATA:
                            # This info_type is only used to identify the presence of dummy data in the npy file
                            # NOTE: It does not matter which column_name is used to communicate the dummy_data_flag
                            continue
                        elif info_type not in space_info:
                            space_info[info_type] = {}
                        space_info[info_type][column_name] = info_value

        # Create the table from the csv
        if windows_filename_adjust and hasattr(sys, "getwindowsversion"):
            npyfile = npyfile.replace("\\", "\\\\")

        # inherit_file_time_stamp
        if inherit_file_time_stamp:
            time_stamp = datetime.fromtimestamp(pathlib.Path(npyfile).stat().st_mtime)

        # PRETTY SURE AT THIS POINT, WE SHOULD HAVE THE SPACE INFO FROM THE NPY FILE,
        # AND WE CAN CREATE A DATAFRAME AND PASS THROUGH ALL THE PARAMS TO FROM_PANDS_DF
        return cls.from_pandas_df(
            df=pd.DataFrame(np.load(npyfile)),
            space_info=space_info,
            freq_hint=freq_hint,
            freq_hint_mode=freq_hint_mode,
            address=address,
            import_false_as_null=import_false_as_null,
            remove_duplicate_keys=remove_duplicate_keys,
            duplicate_key_grace=duplicate_key_grace,
            exceptions_flag=exceptions_flag,
            compress=compress,
            hyper_index=hyper_index,
            indices=indices,
            space_map=space_map,
            fx=fx,
            time_basis=time_basis,
            valuespace=valuespace,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_null=tfill_honor_null,
            tdistribute_mode=tdistribute_mode,
            map_type=map_type,
            map_basis=map_basis,
            dtype=dtype,
            time_stamp=time_stamp,
            table_name=table_name,
            **kwargs,
        )

    @classmethod
    def from_csv(
        cls,
        csvfile: str,
        pivot_keyspace: str = None,
        pivot_valuespace: str = DEFAULT_VALUESPACE,
        non_pivot_columns: list = [0],
        valuespace=-1,
        fx=None,
        time_basis=None,
        space_map=None,
        freq_hint=None,
        freq_hint_mode: str = None,
        space_info=None,
        tfill_max=None,
        tfill_end_mode=None,
        tfill_honor_null=None,
        tdistribute_mode=None,
        map_type=None,
        map_basis=None,
        table_name: str = None,
        num_headers="infer",
        delimiter: str = ",",
        missing_values: str = ",n/a,NaN,nan,NA,na,#N/A,#n/a,N/A,n.a.",
        compress: bool = False,
        import_false_as_null: bool = RootLib().lazy_eval("import_false_as_null"),
        address=None,
        inherit_file_time_stamp: bool = True,
        time_stamp="now",
        remove_duplicate_keys=True,
        duplicate_key_grace=False,
        exceptions_flag: bool = False,
        dtype=None,
        hyper_index=None,
        indices=None,
        **kwargs,
    ) -> Quble:
        """
        Reads a delimited (text) file into Quble

        :param csvfile: Path to the csv file containing data with which Quble will be created.
        :type csvfile: str

        :type pivot_keyspace: str or None
        :param pivot_keyspace:
            The (hidden/pivot) keyspace when given a pivoted (unfolded) csvfile
            [When given a unpivoted (folded) csvfile, use pivot_keyspace=None]

        :type pivot_valuespace: str
        :param pivot_valuespace: The value column name to use of pre-pivoting the csv file...
            ==> NOTE: Only applicable when pivot_keyspace != None (otherwise ignored)

        :type non_pivot_columns: list of strings or ints or None
        :param non_pivot_columns: The non-pivot columns...
            ==> NOTE: Only applicable when pivot_keyspace != None (otherwise ignored)
            ==> List of columns not participating in the pivot process
            ==> Indicates non-pivot columns occuring before the pivot column's keys in the header
            ==> NOTE: when using strings, the original file column names convention is expected here

        :param coltype_map:dict: (optional) col_type per column name within csv file
        :type coltype_map: dictionary, None
        ==> NOTE: column name references here should be provided in remapped naming convention (when applicable)

        :param valuespace: column name(s) (or number(s)) corresponding to valuespace
        :type unfold: str, int or slice object or None
        if valuespace is None, then non-valuespace/index-only Quble will be returned
        if valuespace == -1 (default), the last column will be used a valuespace
        if valuespace is str, the specified (target) column will be the single/primary valuespace(will throw exception if not present)
        if valuespace is a list/tuple, the specified (target) columns will be the valuespaces(will throw exception if not present)
        ==> Convention: valuespace arg column string references use remapped target column names (when space_map provided)

        :param space_map: (optional) dictionary allowing for selective
                        remapping/renaming of space names
                        from file (src) column names to target space names in resultant Quble
        :type space_map: None or dictionary

        :param freq_hint: (optional) frequency hint for frequency inference of time-keyspace(s)
        :type freq_hint: str, dict, None
            ==> None*: no (immediate) frequency inference (even if time-keyspaces exist)
            ==> str: will use the specified freq_hint for frequency inference against all time-keyspaces
            ==> 'default_freq': use prevailing default frequency control from the RootLib()
            ==> dictionary: dictionary keys=(time) keyspaces, dictionary values=freq hint for a given keyspace
            NOTE: when dictionary value=None, frequency inference is still performed but with no freq_hint

        :param freq_hint_mode: (optional) handling for frequency hint failure
        :type freq_hint_mode: str, dictionary, None
            If dict: dict keys=(time) keyspaces, dict values=freq hint mode for each time-keyspace
            Valid freq hint modes...
            ==> None*: graceful inference of alternative frequency that matches data
            ==> 'raise': raises Exception if hint fails
            ==> 'force': forces frequency hint but uses no time-basis during force
            ==> 'force_honor_tb': forces frequency hint while honoring prevailing time-basis
            NOTE: Here, time-basis will be used to convert from intermediate inferred freq to hint freq

        :param space_info: (custom) space information (must not contain 'built'-in info_types)
        :type space_info: dictionary of dictionaries
            outer dictionary keys: info_type
            outer dictionary values: inner dictionary
            inner dictionary keys: column_name (in remapped form when space_map present)
            inner dictionary values: associated info_type_assignment

        :param num_headers: The number of header rows in the file
            (proccesses last header row...preceeding header rows skipped/ignored)
        :type header: int

        :param delimiter: The delimiter used in the seperated values file being read.
        :type delimiter: str, int

        :param index_col: The column(s) to use as index
        :type index_col: int (or list/tuple of ints) or 'folded' to use first (n-1) cols as a folded index

        :param delimiter: The string used to separate values.  By default, any consecutive
            whitespaces act as delimiter.  An integer or sequence of integers
            can also be provided as width(s) of each field.
        :type delimiter: str, int, or sequence

        :param skip_header: The numbers of lines to skip at the beginning of the file.
        :type skip_header: int

        :param missing_values: The set of strings corresponding to missing data.
        :type missing_values: sequence of strs (comma-delimited master string or a list/tuple)

        :param compress: flag for compressing resultant Quble
        :type compress: bool (True/False*)

        :param import_false_as_null: Flag to import False values as NULLs
                                    (applies to boolean arrays only)
        :type import_false_as_null: bool

        :param inherit_file_time_stamp: Flag to inherit time_stamp of source file
        :type inherit_file_time_stamp: bool

        :param table_name: (Optional) table name
            ==> if None, then an arbitrary table name will be generated
        :type table_name: str or None

        :param remove_duplicate_keys: Flag to remove duplicate keys
        :type remove_duplicate_keys: bool (True*/False)

        :param duplicate_key_grace: Grace for duplicate keys when remove_duplicate_keys=False
        :type duplicate_key_grace: bool (False*/True)

        :param exceptions_flag: flag whether to generate exceptions Quble
        :type exceptions_flag: (boolean) False*/True
                ==> exceptions_flag=False: returns modified Quble result
                ==> exceptions_flag=True: returns a tuple: (result,exceptions)

                In this latter case, exceptions may be None or a dict
                with dict keys: "freq", "dupes", "compress"

        :returns: A Quble populated with data from the given CSV file
        :rtype: qubles.core.quble.Quble

        """
        if csvfile is None:
            return Quble.undefined_instance()
        elif not os.path.exists(csvfile):
            raise Exception(f"Absent csvfile:{csvfile}")

        # Validating num_headers
        if isinstance(num_headers, str) and num_headers.lower() != "infer":
            raise Exception(f"Invalid num_headers arg : {num_headers}")
        elif not isinstance(num_headers, (int, list, str)):
            raise Exception(f"Invalid num_headers arg : {num_headers}")

        # Convert missing_values arg to a list/tuple of strings
        if missing_values is None:
            na_values = missing_values
        elif isinstance(missing_values, (tuple, list)):
            na_values = missing_values
        elif isinstance(missing_values, str):
            na_values = missing_values.split(",")
        else:
            # We could also just set: na_values = missing_values
            raise Exception(
                f"Invalid missing_values arg: {missing_values}...str,list,tuple or None expected"
            )

        if pivot_keyspace is not None:
            # Here, the csv has been provided in an unfolded/pivoted format
            # (with a single keyspace + multiple valuespaces)
            # Use min_columns=3...
            # Logic: For # columns <= 2: folded & unfolded format is same
            # ------------------------------------------------------------------
            # For # columns <= 2 & unpivoted_csvpath=None: will return pivoted_csvpath
            # For # columns <= 2 & unpivoted_csvpath not None: returns copy of pivoted_csvpath
            if pivot_valuespace is None:
                raise Exception(
                    f"pivot_valuespace required when using pivot_keyspace:{pivot_keyspace}"
                )

            if non_pivot_columns is None:
                raise Exception(f"non_pivot_columns required when unpivoting csv file")

            df = pd.read_csv(
                csvfile, sep=delimiter, na_values=na_values, header=num_headers
            )

            # Initialising variables needed for unpivot
            col_list = df.columns.tolist()
            id_vars = []
            if isinstance(non_pivot_columns, list):
                if isinstance(non_pivot_columns[0], int):
                    for i in non_pivot_columns:
                        id_vars.append(col_list[i])
                elif isinstance(non_pivot_columns[0], str):
                    for i in non_pivot_columns:
                        id_vars.append(i)
            else:
                raise Exception(
                    "non_pivot_columns should be a list of strings or integers"
                )
            df = df.melt(
                id_vars=id_vars, var_name=pivot_keyspace, value_name=pivot_valuespace
            )
        else:
            df = pd.read_csv(
                csvfile, sep=delimiter, na_values=na_values, header=num_headers
            )

        # Establishing valuespace
        if valuespace and not isinstance(valuespace, (list, tuple, str, int)):
            raise Exception(
                f"Invalid valuespace arg: {valuespace}...str,list,tuple,int or None expected"
            )
        elif isinstance(valuespace, int):
            valuespace = df.columns[valuespace]
        else:
            valuespace = valuespace

        # inherit_file_time_stamp
        if inherit_file_time_stamp:
            time_stamp = datetime.fromtimestamp(pathlib.Path(csvfile).stat().st_mtime)

        return Quble.from_pandas_df(
            df,
            space_info=space_info,
            freq_hint=freq_hint,
            freq_hint_mode=freq_hint_mode,
            fx=fx,
            time_basis=time_basis,
            space_map=space_map,
            valuespace=valuespace,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_null=tfill_honor_null,
            tdistribute_mode=tdistribute_mode,
            map_type=map_type,
            map_basis=map_basis,
            address=address,
            compress=compress,
            import_false_as_null=import_false_as_null,
            remove_duplicate_keys=remove_duplicate_keys,
            duplicate_key_grace=duplicate_key_grace,
            exceptions_flag=exceptions_flag,
            table_name=table_name,
            dtype=dtype,
            hyper_index=hyper_index,
            indices=indices,
            time_stamp=time_stamp,
            **kwargs,
        )

    def _synchronize_space_info(self):
        # Then collect the col_names and types (if not provided? - tbd)
        table_metadata = desc_table(self.table_name)

        self._column_info["type"] = {}
        self._column_info["role"] = {}

        # Retrieve formatted Metadata with optional column info
        table_comments, col_types = get_column_comments_and_types(table_metadata)

        self._spaces = []
        for column in col_types:
            self._spaces.append(column)
            self._column_info["type"][column] = col_types[column].split("(")[0]

        # Collect info types and spaces to remove in a separate structure
        spaces_to_remove = {}
        for info_type, spaces in self._column_info.items():
            for space in spaces:
                if space not in self._spaces:
                    if info_type not in spaces_to_remove:
                        spaces_to_remove[info_type] = []
                    spaces_to_remove[info_type].append(space)

        # Remove the collected spaces
        for info_type, spaces in spaces_to_remove.items():
            for space in spaces:
                del self._column_info[info_type][space]

                # If removing a space results in an empty dictionary for the info_type, remove it
                if not self._column_info[info_type]:
                    del self._column_info[info_type]

        # Merge with comments in table
        for t_key in table_comments.keys():
            for t2_key in table_comments[t_key].keys():
                if t2_key not in self._column_info.keys():
                    self._column_info[t2_key] = {}
                if t_key not in self._column_info[t2_key].keys():
                    self._column_info[t2_key][t_key] = table_comments[t_key][t2_key]

        # Populate the col_info recordingly ---> required for space role initialization below
        for space, role in self._column_info["role"].items():
            if role == "valuespace" and space not in self._valuespaces:
                self._valuespaces.append(space)
        for val_space in self._valuespaces:
            self._column_info["role"][val_space] = "valuespace"

    def _initialize_space_roles(
        self, valuespace: str = "<inspect>", spaces: list = None
    ):
        # NOTE: due to legacy code, this is driven by valuespace logic
        # Setup all custom info_types
        if spaces is None:
            self._spaces = list(self._column_info["type"].keys())
        else:
            self._spaces = spaces

        # -----------------------------------
        # Establish valuespaces from params
        # -----------------------------------
        if isinstance(valuespace, (list, tuple)):
            self._valuespaces = valuespace
        elif valuespace is not None and valuespace != "<inspect>":
            # Here, a non-trivial scalar valuespace has been provided
            self._valuespaces = [valuespace]
        else:
            self._valuespaces = []

        if "role" in self._column_info:
            for col, val in self._column_info["role"].items():
                if val == "keyspace":
                    # processed below
                    pass
                elif val == "valuespace":
                    if col not in self._valuespaces:
                        self._valuespaces.append(col)
                else:
                    raise Exception(
                        f"Recieved invalid role assignment of '{val}' for col: '{col}'. Valid assignements: {VALID_ROLE_ASSIGNMENTS}"
                    )
        else:
            raise Exception("Role information is required for initialization!")

        # Apply preferred_vs
        self._valuespace = self._get_primary_valuespace(
            preferred_vs=valuespace, grace=False
        )

        # Assign remaining valuespaces to auxvalspaces
        self._auxvalspaces = [x for x in self._valuespaces if x != self.valuespace]
        self._keyspaces = [x for x in self._spaces if x not in self._valuespaces]

        # Finally, ensure all role assignments are persisted in self._column_info
        self._column_info["role"] = {}
        for space in self._spaces:
            if space in self._keyspaces:
                self._column_info["role"][space] = "keyspace"
            elif space in self._valuespaces:
                self._column_info["role"][space] = "valuespace"
            else:
                raise Exception(
                    f'Quble @table={self.table_name} recieved invalid role: {self._column_info["role"][space]} for col: {space}'
                )

    def _extend_exceptions(self, exception_type, exceptions_qbl):
        exceptions_qbl = exceptions_qbl.insert_keyspace(
            "Exception Type", exception_type
        )
        if self.exceptions is None:
            self.exceptions = exceptions_qbl
        else:
            self.exceptions.merge_inplace(exceptions_qbl)

    # ==================================== PRINTING ===================================

    def __repr__(self):
        return self.__str__()

    def __str__(self):
        buf = StringIO()
        self.toString(buffer=buf)
        return buf.getvalue()

    def toString(
        self,
        max_rows=30,
        key_ordering="ASC",
        display_column_info=True,
        default_col_width=16,
        apply_view=False,
        compress=False,
        missing_value_str=DEFAULT_MISSING_DATA_FORMAT,
        float_format=DEFAULT_FLOAT_FORMAT,
        date_format=DEFAULT_DATE_FORMAT,
        formatters=None,
        buffer=sys.stdout,
    ):

        if self.is_undefined:
            buffer.write("")
            return

        # Apply view operation and/or compress (if applicable)
        if self.is_scalar or self.is_empty:
            out_quble = self  # Shallow copy, but OK here
        elif apply_view and RootLib().get_control("view") is not None:
            out_quble = self.apply_view().compress(auto_squeeze=False)
        elif compress:
            out_quble = self.compress(auto_squeeze=False)
        else:
            out_quble = (
                self  # Shallow copy, but OK here (actually desired for speed & memory)
            )

        # Process key_ordering arg to generate order_by_clause
        if key_ordering is None:
            order_by_clause = None
        elif isinstance(key_ordering, str):
            order_by_terms = [f'"{ks}" {key_ordering}' for ks in self.keyspaces]
            order_by_clause = (
                "ORDER BY " + ",".join(order_by_terms) if order_by_terms else None
            )
        elif isinstance(key_ordering, dict):
            order_by_terms = [
                f'"{space1}" {ordering1}' for space1, ordering1 in key_ordering.items()
            ]
            order_by_clause = (
                "ORDER BY " + ",".join(order_by_terms) if order_by_terms else None
            )
        else:
            raise Exception(
                f"Invalid key_ordering:{key_ordering}...str or dict or None expected"
            )

        # Fetch data with row numbers
        data = snowflake_quble_preview(
            self.table_name, max_rows=max_rows + 1, order_by=order_by_clause
        )

        # Generate major headers
        subheader1 = f"table_name: {out_quble.table_name}"
        subheader2 = f"time_stamp: {out_quble.time_stamp}"
        if out_quble.valuespace is None:
            major_header = f"{out_quble.ndim}D-Quble: Index Only"
        else:
            if out_quble.is_scalar:
                major_header = f"Uni-Scalar Quble: {out_quble.valuespace}"
            elif out_quble.is_multiscalar:
                major_header = f"Multi-Scalar Quble: {out_quble.valuespace}"
            else:
                major_header = f"{out_quble.ndim}D-{out_quble.num_valuespaces}V Quble: {out_quble.valuespace}"

        if not out_quble.is_scalar:
            major_header += f" (#{out_quble.num_records:,})"

        major_dashes = "=" * max(len(major_header), len(subheader1), len(subheader2))
        major_margin = " " * int(
            (default_col_width * len(out_quble.column_names) - len(major_dashes)) / 2
        )

        buffer.write(f"\n{major_margin + major_dashes}\n")
        buffer.write(f"{major_margin + major_header}\n")
        buffer.write(f"{major_margin + subheader1}\n")
        buffer.write(f"{major_margin + subheader2}\n")
        buffer.write(f"{major_margin + major_dashes}\n")

        # Write column names
        for column_name in out_quble.column_names:
            text = (
                f"{column_name}*"
                if column_name == out_quble.valuespace
                else column_name
            )
            buffer.write(self._format_cell(text, default_col_width))
        buffer.write("\n")

        # Write header dashes
        for _ in out_quble.column_names:
            buffer.write("-" * (default_col_width - 2) + " ")
        buffer.write("\n")

        # Write space info
        if display_column_info:
            if self._column_info != {}:
                # Display column/space roles
                for column_name in out_quble.column_names:
                    if column_name in out_quble.keyspaces:
                        buffer.write(
                            self._format_cell(
                                "keyspace", default_col_width, missing_value=None
                            )
                        )
                    elif (
                        out_quble.valuespace is not None
                        and column_name == out_quble.valuespace
                    ):
                        buffer.write(
                            self._format_cell(
                                "valuespace*", default_col_width, missing_value=None
                            )
                        )
                    else:
                        buffer.write(
                            self._format_cell(
                                "auxvalspace", default_col_width, missing_value=None
                            )
                        )
                buffer.write(self._format_cell(" <-- role", 32))
                buffer.write("\n")

                # Display column info
                info_types_to_not_print = [
                    "table_id",
                    "id",
                    "default",
                    "null",
                    "storage",
                    "number",
                    "null",
                    "role",
                ]
                for info_type, info_assignments in self.column_info.items():
                    if info_type in info_types_to_not_print:
                        continue
                    if info_assignments is not None:
                        for column_name in out_quble.column_names:
                            if (
                                column_name in info_assignments
                                and info_assignments[column_name] is not None
                            ):
                                info_assignment1 = str(info_assignments[column_name])
                            else:
                                info_assignment1 = DEFAULT_MISSING_DATA_FORMAT
                            buffer.write(
                                self._format_cell(
                                    info_assignment1,
                                    default_col_width,
                                    missing_value=None,
                                )
                            )
                        buffer.write(self._format_cell(f" <-- {info_type}", 32))
                        buffer.write("\n")

                for column_name in out_quble.column_names:
                    buffer.write(
                        self._format_cell(
                            "-" * int(max(default_col_width - 3, 1)), default_col_width
                        )
                    )
                buffer.write("\n")

        # Formatters
        formatters = formatters or {}

        # Do not show bools using missing_value_str
        values_are_bools = {}
        missing_values = out_quble.missing_values
        valuespaces = out_quble.valuespaces
        for vs in valuespaces:
            values_are_bools[vs] = True if out_quble.is_bool(vs) else False

        # Write data
        if data is not None:
            for row_no, row in enumerate(data):
                if row_no >= max_rows:
                    break

                # Add a line break to mark the divide between start and end of preview
                if row_no == max_rows // 2:
                    for column_name in out_quble.column_names:
                        buffer.write(
                            self._format_cell(
                                "-" * int(max(default_col_width - 3, 2) / 2),
                                default_col_width,
                            )
                        )
                    buffer.write("\n")

                for i, val in enumerate(
                    row[:-2]
                ):  # Exclude the last two columns (row_num and total_rows)
                    column_name = out_quble.column_names[i]
                    formatter = formatters.get(column_name, lambda x: x)
                    formatted_val = formatter(val)
                    if (
                        missing_values is None
                        or column_name not in missing_values
                        or (
                            column_name in valuespaces and values_are_bools[column_name]
                        )
                    ):
                        buffer.write(
                            self._format_cell(
                                formatted_val,
                                default_col_width,
                                float_format=float_format,
                                date_format=date_format,
                                missing_value_str=missing_value_str,
                            )
                        )
                    else:
                        buffer.write(
                            self._format_cell(
                                formatted_val,
                                default_col_width,
                                float_format=float_format,
                                date_format=date_format,
                                missing_value_str=missing_value_str,
                                missing_value=missing_values[column_name],
                            )
                        )

                # Write the row number on the far right side, right-aligned
                row_num = row[-2]  # row_num is the second last column
                buffer.write(self._format_cell(f"({row_num:,}", 32) + "\n")

        # Indicate to user that more data exists than shown
        if len(data) > max_rows:
            buffer.write("...")

    def _format_cell(
        self,
        value,
        col_width,
        float_format=None,
        missing_value_str=None,
        date_format=None,
        missing_value=None,
    ):
        if value is None:
            text = missing_value or missing_value_str
        elif isinstance(value, (datetime, date)):
            text = value.strftime(date_format or "%Y-%m-%d %H:%M:%S")
        elif isinstance(value, float):
            text = f"{value:,.3f}" if float_format else str(value)
        else:
            text = str(value)

        available_width = col_width - 2  # for buffer space
        if len(text) > available_width:
            text = text[: available_width - 3].strip() + ".."
        return f"{text:<{available_width}} "

    # ==================================== COPYING ====================================

    def deep_copy(self, retain_address=False, copy_cache=True) -> Quble:
        return self.copy(
            deep_copy=True, retain_address=retain_address, copy_cache=copy_cache
        )

    def shallow_copy(self, retain_address=False, copy_cache=True) -> Quble:
        return self.copy(
            deep_copy=False, retain_address=retain_address, copy_cache=copy_cache
        )

    def copy(self, deep_copy=True, retain_address=False, copy_cache=True) -> Quble:
        """
        For deep copy=True, creates and populates a new table
        For shallow copy (deep copy=False), retains self.table_name

        NOTE: For deep_copy, don't forget to record column info for new table (based on old table)
        """
        if deep_copy:
            result = self.select(deep_copy=deep_copy)
        elif retain_address:
            return self
        else:
            result = Quble.from_table(
                self.table_name, col_info=self.column_info, time_stamp=self.time_stamp
            )

        result.address = self.address if retain_address else None

        # Make a deep copy of the associated cache (if directed)
        if copy_cache:
            result._cache = deepcopy(self._cache)
            result._column_info = deepcopy(self._column_info)
            result._spaces = self.spaces
            result._keyspaces = self.keyspaces
            result._valuespaces = self.valuespaces
            result._auxvalspaces = self.auxvalspaces
            result.exceptions = self.exceptions
        else:
            result._cache = {}
            result._column_info = {}
            result._spaces = []
            result._keyspaces = []
            result._valuespaces = []
            result._auxvalspaces = []
            result.exceptions = None

        return result

    def change_type(
        self,
        new_type="float",
        space="<valuespace>",
        index_support=False,
        deep_copy=True,
    ) -> Quble:
        """
        Changes the specified space/column to the specified type.
        If self is a index Quble, will create a new valuespace

        NOTE: new_type format is assumed to

        :param new_type: desired (sql) type for the space (column name)
        :type new_type: str or dict (map from specific spaces to desired types)
            ==> when new_type is dict, will loop through space(s) in space arg
            ==> and apply only those casts where space is supported as a key in the new_type dict

        :param space: space(s) / column(s) to change
        :type space: str or list of strings
                      (keywords may be used such as '<valuespaces>', '<valuespace>', etc.
                      [See: :meth:`~qubles.core.quble.Quble.validate_space`]

        :param index_support: support for index Quble object
                              when space arg uses valuespaces_shorthands
                        ==> will introduce new valuespace column
                        ==> new type must be a string (not a dictionary) in index case
        :type index_support: bool (False*/True)

        :param deep_copy: Flag to operator on self or return a modified copy
        :type deep_copy: bool (True*/False)
        """
        if (
            self.is_index
            and isinstance(space, str)
            and (space in self.valuespaces_shorthands)
        ):
            # -------------------------------------------
            # Special logic for index support when space
            # corresponds to valuespaces_shorthands
            # -------------------------------------------
            if not index_support:
                raise Exception(
                    f"valued Quble expected when arg index_support={index_support}"
                )
            elif not isinstance(new_type, str):
                raise Exception(
                    "Invalid new_type:{0}...str required when applying to index (non-variate) Quble"
                )
            else:
                # When authorized, convert index Quble subject to a valued Quble
                space = DEFAULT_VALUESPACE
                return self.index_to_valued(valuespace=space, valuespace_type=new_type)
        else:
            space = self.validate_space(space, coerce_to_list=True)
            # Constructing cast dict based on space and new_type params. This dict is passed down to change_types method
            new_types = {}
            for space1 in space:
                # Access new_type1 as a lower-case string
                if isinstance(new_type, str):
                    new_type1 = new_type.lower()
                elif not isinstance(new_type, dict):
                    raise Exception("Invalid new_type:{0}...str/dict expected")
                elif space1 not in new_type:
                    new_type1 = None
                elif new_type[space1] is None:
                    new_type1 = None
                elif not isinstance(new_type[space1], str):
                    raise Exception(
                        f"String expected, yet type(new_type[{space1}]):{type(new_type[space1])}"
                    )
                else:
                    new_type1 = new_type[space1].lower()

                if new_type1 is not None:
                    new_types[space1] = new_type1

            return self.change_types(new_types=new_types, deep_copy=deep_copy)

    def change_types(self, new_types: dict, deep_copy=True) -> Quble:
        """
        Changes the specified source_tables/columns
        as specified in the new_types arg (dictionary)
        Will preserve the Quble's original column order and roles

        :param new_types: mapping from space (column name) to desired (sql) type
        :type new_types: dict

        :param deep_copy: Flag to operator on self or return a modified copy
        :type deep_copy: bool (True*/False)

        """
        # Qualify new_types arg as dict
        if new_types is None:
            return self.copy()
        elif not isinstance(new_types, dict):
            raise Exception("Invalid new_types...dictionary expected ")
        elif len(new_types) == 0:
            return self.copy()

        return self.select(cast_dict=new_types, deep_copy=deep_copy)

    def change_dtype(self, new_dtype=np.float64, space="<valuespace>") -> Quble:
        """
        Changes the specified space/column
        to the specified dtype's equivalent in sql
        """
        new_type = dtype_to_coltype(new_dtype)
        return self.change_type(new_type=new_type, space=space)

    def change_dtypes(self, new_dtypes) -> Quble:
        """
        Changes the specified source_tables/columns
        as specified in the new_dtypes arg (dictionary)

        :param new_dtypes: mapping from space (column name) to desired dtype
        :type new_dtypes: dict

        """
        if new_dtypes is None:
            return self.copy()
        elif not isinstance(new_dtypes, dict):
            raise Exception("Invalid new_dtypes...dictionary expected ")
        elif len(new_dtypes) == 0:
            return self.copy()

        new_types = {}
        for space1, new_dtype1 in new_dtypes.items():
            space = self.validate_space(space1)
            new_types[space] = dtype_to_coltype(new_dtype1)

        return self.change_types(new_types=new_types)

    def sort1d(
        self,
        keyspace,
        value_ordering="asc",
        key_ordering="asc",
        valuespace="<valuespace>",
        null_placement="bottom",
        deep_copy=True,
    ) -> Quble:
        """
        See :meth:`~qubles.core.quble.Quble.value_sort`
        """
        return self.value_sort1d(
            keyspace=keyspace,
            value_ordering=value_ordering,
            key_ordering=key_ordering,
            valuespace=valuespace,
            null_placement=null_placement,
            deep_copy=deep_copy,
        )

    def value_sort1d(
        self,
        keyspace,
        value_ordering="asc",
        key_ordering="asc",
        valuespace="<valuespace>",
        null_placement="bottom",
        deep_copy=True,
    ) -> Quble:
        """
        See :meth:`~qubles.core.quble.Quble.value_sort`
        """
        keyspace = self.validate_keyspace(keyspace)
        return self.value_sort(
            sorting_keyspaces=keyspace,
            value_ordering=value_ordering,
            key_ordering=key_ordering,
            valuespace=valuespace,
            null_placement=null_placement,
            deep_copy=deep_copy,
        )

    def sortx1d(
        self,
        keyspace,
        value_ordering="asc",
        key_ordering="asc",
        valuespace="<valuespace>",
        deep_copy=True,
    ) -> Quble:
        """
        See :meth:`~qubles.core.quble.Quble.value_sort`
        """
        return self.value_sortx1d(
            keyspace=keyspace,
            value_ordering=value_ordering,
            key_ordering=key_ordering,
            valuespace=valuespace,
            deep_copy=deep_copy,
        )

    def value_sortx1d(
        self,
        keyspace,
        value_ordering="asc",
        key_ordering="asc",
        valuespace="<valuespace>",
        null_placement="bottom",
        deep_copy=True,
    ) -> Quble:
        """
        See :meth:`~qubles.core.quble.Quble.value_sort`
        """
        keyspace = self.validate_keyspace(keyspace)
        sorting_keyspaces = self.ortho_keyspaces(keyspace)
        return self.value_sort(
            sorting_keyspaces=sorting_keyspaces,
            value_ordering=value_ordering,
            key_ordering=key_ordering,
            valuespace=valuespace,
            null_placement=null_placement,
            deep_copy=deep_copy,
        )

    def sort(
        self,
        sorting_keyspaces="<keyspaces>",
        value_ordering="asc",
        key_ordering="asc",
        valuespace="<valuespace>",
        null_placement="bottom",
        deep_copy=True,
    ) -> Quble:
        """
        See :meth:`~qubles.core.quble.Quble.value_sort`
        """
        return self.value_sort(
            sorting_keyspaces=sorting_keyspaces,
            value_ordering=value_ordering,
            key_ordering=key_ordering,
            valuespace=valuespace,
            null_placement=null_placement,
            deep_copy=deep_copy,
        )

    def value_sort(
        self,
        sorting_keyspaces="<keyspaces>",
        value_ordering="asc",
        key_ordering="asc",
        valuespace="<valuespace>",
        null_placement="bottom",
        deep_copy=True,
        return_type="Quble",
    ) -> Quble:
        """
        Reorders the Quble by valuespace's records across the
        sorting_keyspaces according to the value_ordering, then
        sorts orthogonal keyspaces or duplicate keys (if any) by key_ordering

        :param sorting_keyspaces: keyspace(s) to sort valuespace across
        :type sorting_keyspaces: str or list of strings

        :param key_ordering: Sorting order for sorting_keyspaces
        :type key_ordering: 'asc' or 'desc'

        :param key_ordering: Sorting order for orthogonal keyspaces
        :type key_ordering: 'asc' or 'desc'

        :param valuespace: the valuespace to be sorted
        :type valuespace: valuespace name

        :param null_placement: controls placement for null keys
        :type null_placement: str
                ==> 'bottom': null keys/values are ordered at bottom
                ==> 'top': null keys/values are ordered at top

        :param deep_copy: Flag to indicate whether the existing Quble should be
            copied (and thus left unchanged) or changed in-place.
        :type deep_copy: bool
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate sorting_keyspaces
        sorting_keyspaces = self.validate_keyspace(
            sorting_keyspaces, coerce_to_list=True
        )
        ortho_keyspaces = self.ortho_keyspaces(sorting_keyspaces, grace=True)

        # Validate valuespace (use grace=False ==> valuespace required)
        sorting_valuespace = self.validate_valuespace(
            valuespace=valuespace, grace=False
        )

        # Initialize space_ordering dictionary
        # with key_ordering information
        if key_ordering is None:
            key_ordering = "asc"

        if not isinstance(key_ordering, str):
            raise Exception(
                f"Invalid key_ordering:{key_ordering}...asc or desc required"
            )
        elif key_ordering.lower() not in ("asc", "desc"):
            raise Exception(
                f"Invalid key_ordering:{key_ordering}...asc or desc required"
            )
        elif not isinstance(ortho_keyspaces, (list, tuple)):
            raise Exception(
                "Invalid ortho_keyspaces:{0}...list/tuple of str expected".format(
                    ortho_keyspaces
                )
            )

        space_ordering = {}
        for ks in ortho_keyspaces:
            space_ordering[ks] = key_ordering

        # Augment space_ordering dictionary
        # with value_ordering information
        if not isinstance(value_ordering, str):
            raise Exception(f"Invalid value_ordering:{value_ordering}")
        elif value_ordering.lower() not in ("asc", "desc"):
            raise Exception(
                f"Invalid value_ordering:{value_ordering}...asc or desc required"
            )

        space_ordering[sorting_valuespace] = value_ordering

        if deep_copy:
            table_name = generate_random_table_name()
        else:
            table_name = self.table_name

        col_info = self.get_space_info(
            info_type=CUSTOM_INFO_TYPES,
            space=self.spaces,
            omit_unassigned=True,
        )

        session = SnowparkSessionManager.get_snowpark_session()
        df = session.table(dquote_dot(self.table_name))
        sorting_exprs = [
            (
                F.col(f'"{col_name}"').asc_nulls_first()
                if sort_order == "asc" and null_placement == "top"
                else (
                    F.col(f'"{col_name}"').asc_nulls_last()
                    if sort_order == "asc" and null_placement == "bottom"
                    else (
                        F.col(f'"{col_name}"').desc_nulls_first()
                        if sort_order == "desc" and null_placement == "top"
                        else F.col(f'"{col_name}"').desc_nulls_last()
                    )
                )
            )
            for col_name, sort_order in space_ordering.items()
        ]
        sorted_df = df.sort(sorting_exprs)
        if return_type == "snowpark_df":
            return sorted_df
        else:
            sorted_df.write.mode("overwrite").save_as_table(table_name)

            # Finally, build new Quble using new table_name
            result = Quble.from_table(
                table_name,
                col_info=col_info,
                time_stamp=datetime.now() if deep_copy else self.time_stamp,
            )

            # valuespace handling via result.valuespace if necessary
            if self.valuespace is not None and len(self.valuespaces) > 1:
                result.valuespace = result._get_primary_valuespace(
                    preferred_vs=self.valuespace, grace=True
                )

            return result

    def key_sort(
        self, key_ordering="asc", null_placement="bottom", num_keys=None, deep_copy=True
    ) -> Quble:
        """
        Reorders the Quble records by keyspaces according to the key_ordering

        :param key_ordering: (optional) controls row ordering by key
        :type key_ordering: None (no keyspace sorting), 'asc' or 'desc', dict

           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace
           dictionary: dict keys (str): keyspaces, dict values (str): 'asc' or 'desc'
           ==> allows for assigning key ordering (ascending/descending)
           ==> (and relative priority) for each keyspace individually

        :param null_placement: controls placement for null keys
        :type null_placement: str
                ==> 'bottom': null keys are ordered at bottom
                ==> 'top': null keys are ordered at top

        :param num_keys: controls number of keys to be returned in the output
        :type num_keys: int
                ==> num_keys = 5 will result in quble containing top 5 keys based on key_ordering

        :param deep_copy: Flag to indicate whether the existing Quble should be
            copied (and thus left unchanged) or changed in-place.
        :type deep_copy: bool
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        # Build build_key_ordering_dict when applicable
        if key_ordering is not None:
            key_ordering = build_key_ordering_dict(
                key_ordering, keyspaces=self.keyspaces
            )

        # Validate null_placement arg
        if null_placement not in (None, "bottom", "BOTTOM", "top", "TOP"):
            raise Exception(f"Invalid null_placement:{null_placement}")

        if deep_copy:
            table_name = generate_random_table_name()
            col_info = self.get_space_info(
                info_type=CUSTOM_INFO_TYPES,
                space=self.spaces,
                omit_unassigned=True,
            )
        else:
            table_name = self.table_name
            col_info = None

        sql_template = JINJA_ENV.get_template("space_sort.j2")
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            tgt_table_name=table_name,
            spaces=self.spaces,
            space_ordering=key_ordering,
            null_placement=null_placement,
            num_keys=num_keys,
        )
        session = SnowparkSessionManager.get_snowpark_session()
        sql_command = sql_command.replace("\n", " ")
        sql_command = (
            "WITH " + sql_command.split("; COMMIT;")[0].split("WITH")[1].strip()[:-1]
        )
        snowpark_dataframe = session.sql(sql_command)
        snowpark_dataframe.write.mode("overwrite").save_as_table(table_name)

        # Finally, build new Quble using new table_name
        result = Quble.from_table(
            table_name,
            col_info=col_info,
            time_stamp=datetime.now() if deep_copy else self.time_stamp,
        )

        # valuespace handling via result.valuespace if necessary
        if self.valuespace is not None and len(self.valuespaces) > 1:
            result.valuespace = result._get_primary_valuespace(
                preferred_vs=self.valuespace, grace=True
            )

        return result

    def head(self, num_rows=5) -> Quble:
        """
        Returns the first n rows of a Quble

        :param num_rows: number of rows to return
        :type num_rows: int (>0)
        """
        if self.is_undefined:
            return Quble.undefined_instance()
        elif not isinstance(num_rows, int) or (num_rows <= 0):
            raise Exception(f"Invalid num_rows:{num_rows}...positive integer required")
        else:
            return self.top_keys(num_keys=num_rows, key_ordering=None)

    def top_keys(self, num_keys: int = 25, key_ordering="asc") -> Quble:
        return self.key_sort(key_ordering=key_ordering, num_keys=num_keys)

    def num_col_pages(self, col_page_size: int, force_keyspaces=True) -> Quble:
        """
        Determines the total column pages (int)
        given the col_page_size and force_keyspaces flag
        """
        if force_keyspaces:
            return int(
                np.ceil(
                    (1.0 * len(self.valuespaces))
                    / (col_page_size - len(self.valuespaces))
                )
            )
        else:
            return int(np.ceil((1.0 * len(self.spaces)) / col_page_size))

    def col_page(
        self,
        col_page_no,
        col_page_size: int,
        zero_base: bool = False,
        force_keyspaces: bool = True,
        quble_flag: bool = True,
    ) -> Quble:
        """
        col_page_no: which page (see zero_base)
        col_page_size: page size (# of columns per page)

        zero_base:True ==> first col_page_no is zero & first col_no is zero
        zero_base:False ==> first col_page_no is one & first col_no is one

        NOTE: zero_base applies to BOTH page numbers & column numbers

        force_keyspaces: flag to force keyspaces into every page
        """
        if force_keyspaces:
            # Make sure col_page_size is covers keyspaces to be forced
            if len(self.keyspaces) >= col_page_size:
                raise Exception(
                    "force_keyspaces yet col_page_size:{0} <= len(self.keyspaces):{1}".format(
                        col_page_size, len(self.keyspaces)
                    )
                )

            # Use start_col_number=list and end_col_number=None
            start_cols_tmp = list(range(len(self.keyspaces)))

            # Build start_col_number as a list in appropriate base format
            if zero_base:
                # Here, col_page_no starts at 0 for the 'first' page
                start_col_number_tmp = (col_page_no) * (
                    col_page_size - len(self.keyspaces)
                ) + len(self.keyspaces)
                end_col_number_tmp = start_col_number_tmp + (
                    col_page_size - len(self.keyspaces)
                )
                start_col_number = start_cols_tmp + list(
                    range(start_col_number_tmp, end_col_number_tmp)
                )
            else:
                # Here, col_page_no starts at 1 for the 'first' page (when zero_base=False)
                start_col_number_tmp = (col_page_no - 1) * (
                    col_page_size - len(self.keyspaces)
                ) + len(self.keyspaces)
                end_col_number_tmp = start_col_number_tmp + (
                    col_page_size - len(self.keyspaces)
                )
                start_cols_tmp = start_cols_tmp + list(
                    range(start_col_number_tmp, end_col_number_tmp)
                )
                # NOTE: start_cols_tmp (list) is currently in zero_base format
                # Convert to non-zero-base format by adding one to each element
                start_col_number = []
                for start_col0 in start_cols_tmp:
                    start_col_number.append(start_col0 + 1)

            end_col_number = None
        elif zero_base:
            start_col_number = (col_page_no) * (col_page_size)
            end_col_number = start_col_number + col_page_size
        else:
            start_col_number = (col_page_no - 1) * (col_page_size) + 1
            end_col_number = start_col_number + col_page_size

        # Generate col_number_slice
        return (
            self.slice_by_col_num(
                start_col_number=start_col_number,
                end_col_number=end_col_number,
                include_start_col_number=True,
                include_end_col_number=False,
                zero_base=zero_base,
            )
            if quble_flag
            else self.col_page_columns(
                start_col_number=start_col_number,
                end_col_number=end_col_number,
                include_start_col_number=True,
                include_end_col_number=False,
                zero_base=zero_base,
            )
        )

    def col_page_columns(
        self,
        start_col_number: int = 1,
        end_col_number: int = None,
        include_start_col_number: bool = True,
        include_end_col_number: bool = False,
        zero_base: bool = False,
    ) -> list:
        """
        Selects a subset of columns based on column number slice

        start_row_number: starting column number or a list/tuple or a column slice (latter requires end_col_number=None)
        end_row_number: ending column number (None for no end restriction)

        zero_base:True ==> first column number is zero (Python list convention)
        zero_base:False ==> first first column number is one (SQL convention)

        By default, includes start_row_number, excludes end_row_number
        """
        # Validate start_col_number
        if start_col_number is None:
            raise Exception(f"Invalid start_col_number:{start_col_number} <= 0")
        # Slice case (requires zero_base)
        elif isinstance(start_col_number, slice):
            if end_col_number is not None:
                raise Exception(
                    "end_col_number must be None when start_col_number is a slice"
                )
            elif not zero_base:
                raise Exception("zero_base required when start_col_number is a slice")
            else:
                columns_to_keep = self.spaces[start_col_number]
        # List/tuple case
        elif isinstance(start_col_number, (list, tuple)):
            if end_col_number is not None:
                raise Exception(
                    "end_col_number must be None when start_col_number is a list/tuple"
                )
            elif not zero_base:
                columns_to_keep = []
                for col_number in start_col_number:
                    col_number_minus_one = col_number - 1
                    if col_number_minus_one >= 0 and col_number_minus_one < len(
                        self.spaces
                    ):
                        columns_to_keep.append(self.spaces[col_number_minus_one])
            else:
                columns_to_keep = []
                for col_number in start_col_number:
                    if col_number >= 0 and col_number < len(self.spaces):
                        columns_to_keep.append(self.spaces[col_number])
        # Zero-Base case (aka Column Numbers Start At Zero)
        elif zero_base:
            if start_col_number < 0:
                raise Exception(
                    "Invalid start_col_number:{0} < 0 w/zero_base:{1}".format(
                        start_col_number, zero_base
                    )
                )
            start_col_number0 = (
                start_col_number if include_start_col_number else (start_col_number + 1)
            )
            if end_col_number is None:
                end_col_number0 = None
            else:
                # self.spaces[start_col_number0 : end_col_number0] slicing will NOT include end_col_number0
                # So we need to assign start_col_number0 accordingly
                end_col_number0 = (
                    (end_col_number + 1) if include_end_col_number else end_col_number
                )
            columns_to_keep = self.spaces[start_col_number0:end_col_number0]
        # Non-Zero-Base case (aka Column Numbers Start At One)
        else:
            if start_col_number <= 0:
                raise Exception(
                    "Invalid start_col_number:{0} <= 0 w/zero_base:{1}".format(
                        start_col_number, zero_base
                    )
                )
            start_col_number0 = (
                (start_col_number - 1)
                if include_start_col_number
                else (start_col_number)
            )
            if end_col_number is None:
                end_col_number0 = None
            else:
                end_col_number0 = (
                    end_col_number if include_end_col_number else (end_col_number - 1)
                )
            columns_to_keep = self.spaces[start_col_number0:end_col_number0]

        # Select the columns
        return columns_to_keep

    def slice_by_col_num(
        self,
        start_col_number: int = 1,
        end_col_number: int = None,
        include_start_col_number: bool = True,
        include_end_col_number: bool = False,
        zero_base: bool = False,
    ) -> Quble:
        """
        Selects a subset of columns based on column number slice

        start_row_number: starting column number or a list/tuple or a column slice (latter requires end_col_number=None)
        end_row_number: ending column number (None for no end restriction)

        zero_base:True ==> first column number is zero (Python list convention)
        zero_base:False ==> first first column number is one (SQL convention)

        By default, includes start_row_number, excludes end_row_number
        """
        result = self.select(
            column_names=self.col_page_columns(
                start_col_number=start_col_number,
                end_col_number=end_col_number,
                include_start_col_number=include_start_col_number,
                include_end_col_number=include_end_col_number,
                zero_base=zero_base,
            )
        )

        # Annoint valuespace
        # [NOTE: Previous valuespace may not be present in columns_to_keep]
        result.valuespace = result._get_primary_valuespace(
            preferred_vs=self.valuespace, grace=True
        )

        return result

    def num_row_pages(self, row_page_size: int) -> int:
        """
        Determines the total row pages (int) given row_page_size
        """
        return int(np.ceil((1.0 * self.num_records) / row_page_size))

    def row_page(
        self,
        row_page_no: int,
        row_page_size: int,
        zero_base: bool = False,
        keep_row_number_keyspace: bool = False,
        row_number_keyspace: str = "row_number",
        allow_shallow_copy: bool = True,
        column_names: str = None,
    ) -> Quble:
        """
        row_page_no: which page (see zero_base)
        row_page_size: page size (# of columns per page)

        zero_base:True ==> first row_page_no is zero & first col_no is zero
        zero_base:False ==> first row_page_no is one & first col_no is one
        """
        if zero_base:
            # Handle large page case
            if row_page_no == 0 and row_page_size > self.num_records:
                if keep_row_number_keyspace:
                    return self.slice_by_row_num(
                        row_number_keyspace=row_number_keyspace,
                        zero_base=zero_base,
                        keep_row_number_keyspace=keep_row_number_keyspace,
                        return_query_results=True,
                    )
                else:
                    return self if allow_shallow_copy else self.copy()

            start_row_number = (row_page_no) * (row_page_size)
        else:
            # Handle large page case
            if row_page_no <= 1 and row_page_size > self.num_records:
                if keep_row_number_keyspace:
                    return self.slice_by_row_num(
                        row_number_keyspace=row_number_keyspace,
                        zero_base=zero_base,
                        keep_row_number_keyspace=keep_row_number_keyspace,
                        return_query_results=True,
                    )
                else:
                    return self if allow_shallow_copy else self.copy()

            start_row_number = (row_page_no - 1) * (row_page_size) + 1

        return self.slice_by_row_num(
            start_row_number=start_row_number,
            end_row_number=start_row_number + row_page_size,
            include_start_row_number=True,
            include_end_row_number=False,
            zero_base=zero_base,
            keep_row_number_keyspace=keep_row_number_keyspace,
            row_number_keyspace=row_number_keyspace,
            return_query_results=True,
            column_names=column_names,
        )

    def slice_by_row_num(
        self,
        start_row_number: int = 1,
        end_row_number: int = None,
        include_start_row_number: bool = True,
        include_end_row_number: bool = False,
        zero_base: bool = False,
        keep_row_number_keyspace: bool = False,
        row_number_keyspace: str = "row_number",
        return_query_results: bool = False,
        column_names: str = None,
    ) -> Quble:
        """
        Selects a subset of rows based on row number slice

        start_row_number: starting row number or a row slice (latter requires end_row_number=None)
        end_row_number: ending row number (None for no end restriction)

        zero_base:True ==> first row number is zero (Python list convention)
        zero_base:False ==> first row column number is one (SQL convention)

        By default, includes start_row_number, excludes end_row_number
        NOTE: row_number_keyspace is arbitrary as will not show up in result
        """
        row_number_keyspace_with_quotes = f'"{row_number_keyspace}"'
        # numbered_quble = self.add_row_numbers(
        #     row_number_keyspace=row_number_keyspace, zero_base=zero_base
        # )

        # Apply start_row_number condition
        if start_row_number is None:
            raise Exception("start_row_number required")
        elif start_row_number <= 0 and not zero_base:
            raise Exception(
                "Invalid start_row_number:{0} <= 0 w/zero_base:{1}".format(
                    start_row_number, zero_base
                )
            )
        elif start_row_number < 0 and zero_base:
            raise Exception(
                "Invalid start_row_number:{0} < 0 w/zero_base:{1}".format(
                    start_row_number, zero_base
                )
            )
        elif include_start_row_number:
            where_clause = (
                f"WHERE {row_number_keyspace_with_quotes} >= {str(start_row_number)}"
            )
        else:
            where_clause = (
                f"WHERE {row_number_keyspace_with_quotes} > {str(start_row_number)}"
            )

        # Apply end_row_number condition
        if end_row_number is None:
            # No end condition
            pass
        elif start_row_number > end_row_number:
            raise Exception(
                "start_row_number:{0} > end_row_number:{1}".format(
                    start_row_number, end_row_number
                )
            )
        elif include_end_row_number:
            where_clause += (
                f" AND {row_number_keyspace_with_quotes} <= {str(end_row_number)}"
            )
        else:
            where_clause += (
                f" AND {row_number_keyspace_with_quotes} < {str(end_row_number)}"
            )

        if column_names is None:
            final_spaces = self.spaces.copy()
            if keep_row_number_keyspace:
                final_spaces.insert(0, row_number_keyspace)
        else:
            final_spaces = column_names

        return self.select(
            column_names=final_spaces,
            where_clause=where_clause,
            row_number_keyspace=row_number_keyspace,
            keep_row_number_keyspace=keep_row_number_keyspace,
            zero_base=zero_base,
            return_query_results=return_query_results,
        )

    def add_row_numbers(
        self,
        row_number_keyspace: str = "row_number",
        zero_base: bool = False,
    ) -> Quble:
        """
        Adds row number keyspace / column
        and populates with row numbers accordingly

        :param row_number_keyspace: (new) row number keyspace to be created & populated
        :type row_number_keyspace: string

        :param zero_base: Flag to start row numbers at zero (Python list convention)
                          otherwise start row numbers at one (SQL convention)
        :type zero_base: boolean (True/False*)
        """
        # Make sure the Quble is defined
        # [NOTE: defined yet empty Qubles (no records) are acceptable]
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate row_number_keyspace
        if row_number_keyspace is None:
            raise Exception("row_number_keyspace arg required")
        elif not isinstance(row_number_keyspace, str):
            raise Exception("row_number_keyspace arg must be a string")
        elif len(row_number_keyspace) == 0:
            raise Exception("row_number_keyspace arg is an empty string")
        elif row_number_keyspace in self.spaces:
            raise Exception(
                f"row_number_keyspace:{row_number_keyspace} already exists in Quble"
            )

        table_name = generate_random_table_name()

        sql_template = JINJA_ENV.get_template("add_row_numbers.j2")
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            tgt_table_name=table_name,
            row_number_keyspace=row_number_keyspace,
            spaces=self.spaces,
            zero_base=zero_base,
        )
        execute(sql_command)

        # Establish col_info for copy
        if table_name == self.table_name:
            col_info = None
        else:
            col_info = self.get_space_info(
                info_type=CUSTOM_INFO_TYPES,
                space=self.column_names,
                omit_unassigned=True,
            )

        # Finally, build new Quble using new table_name
        result = Quble.from_table(
            table_name,
            col_info=col_info,
        )

        # valuespace handling via result.valuespace
        result.valuespace = self._get_primary_valuespace(
            preferred_vs=self.valuespace, grace=True
        )

        return result

    def select_query(
        self,
        key_ordering=None,
        tgt_keyspaces=None,
        column_names="<all>",
        column_expressions=None,
        where_clause=None,
        cast_dict=None,
        tgt_insertions=None,
        data_exclusion=None,
        row_number_keyspace=None,
        keep_row_number_keyspace=None,
        zero_base=None,
        max_rows: int = None,
        tgt_table_name: str = None,
        return_query_results: bool = False,
    ) -> str:
        """
        Generates a SQL selection query against the Quble's table
        based on the arguments provided

        Query may be redirected to populate table: tgt_table_name (if provided)
        Set tgt_table_name=None for non-directed query

        See :meth:`~qubles.core.quble.Quble.select`
        """
        if where_clause is None:
            pass
        elif not isinstance(where_clause, str):
            raise Exception("Invalid where_clause:{0}...str required")
        else:
            # Here, where_clause is a string
            if (
                where_clause.lower().strip()[0:5] != "where"
                and where_clause.lower().strip()[0:5] != "limit"
            ):
                # Add 'where ' prefix (if needed)
                # so long as we are not merely applying a limit construct
                where_clause = f"where {where_clause}"

        # Establish column_names
        if not column_names or column_names == "<all>":
            column_names = self.column_names
        elif column_names == "<keyspaces>":
            column_names = self.keyspaces
        elif column_names == "<valuespace>":
            if self.valuespace:
                column_names = [self.valuespace]
            else:
                column_names = []
        elif isinstance(column_names, str):
            column_names = [column_names]
        elif not isinstance(column_names, (tuple, list, dict)):
            raise Exception(
                f"Invalid column names param type passed to select method : {type(column_names)}"
            )

        # Deep copying cast dict (to prevent possible corruption below)
        cast_dict2 = deepcopy(cast_dict) if cast_dict is not None else None

        # Validate cast_dict2
        if cast_dict2 is not None:
            if not isinstance(cast_dict2, dict):
                raise Exception("Cast dict should be a dictionary")
            else:
                for key, value in cast_dict2.items():
                    if key not in self.spaces:
                        raise Exception(
                            f"Unknown column name: {key} in cast dictionary"
                        )
                    elif not isinstance(value, str):
                        raise Exception(
                            f"Cast value should be a string for column : {key}"
                        )

        # Establish slice_spaces
        slice_spaces = None
        if row_number_keyspace is not None:
            slice_spaces = [col for col in column_names if col != row_number_keyspace]

            if not keep_row_number_keyspace:
                if row_number_keyspace in column_names:
                    column_names.remove(row_number_keyspace)

        # Identify the requesite query template
        if return_query_results or tgt_table_name is None:
            # Excludes support for tgt_table_name logic
            sql_template = JINJA_ENV.get_template("select_body.j2")
        elif tgt_table_name:
            sql_template = JINJA_ENV.get_template("select.j2")

        # Render the query template with proper args
        sql_command = sql_template.render(
            key_ordering=key_ordering,
            tgt_keyspaces=tgt_keyspaces,
            src_table_name=self.table_name,
            tgt_table_name=tgt_table_name,  # <-- Will be ignored for "select_body.j2"
            column_names=column_names,
            column_expressions=column_expressions,
            where_clause=where_clause,
            cast_dict=cast_dict2,
            data_exclusion=data_exclusion,
            tgt_insertions=tgt_insertions,
            row_number_keyspace=row_number_keyspace,
            zero_base=zero_base,
            slice_spaces=slice_spaces,
            max_rows=max_rows,
            type_info=self._column_info["type"],
        )
        # Return the query sql command
        if return_query_results:
            df = execute_snowalchemy(sql_command)
            df.columns = column_names
            return df

        return sql_command

    def select(
        self,
        key_ordering=None,
        tgt_keyspaces=None,
        column_names="<all>",
        column_expressions=None,
        where_clause=None,
        custom_info_overrides=None,
        cast_dict=None,
        tgt_insertions=None,
        data_exclusion=None,
        info_type_exclusions=None,
        deep_copy=True,
        preferred_vs="<valuespace>",
        row_number_keyspace: str = None,
        keep_row_number_keyspace: bool = False,
        zero_base: bool = False,
        max_rows: int = None,
        return_query_results: bool = False,
        exceptions_flag: bool = False,
    ) -> Quble:
        """
        Selects specified columns from from an existing table using an optional 'where clause' and returns a new Quble.
        Supports column renaming, type casting, data exclusion, etc.

        :param column_names: column name(s) to select from
        :type column_names: string, list/tuple (of strings), or dictionary
                ==> string: a specific column or '<all>' (default) for selecting all columns
                ==> list: a list of the specific columns to be selected
                ==> dictionary: map of original/source columns to select as well as their respective new/target columns [original column_name is retained if/where dictionary values are None]

        :param column_expressions: (optional) dictionary whereby expressions (or functions calls)
                    can be substituted for simple column references within select statement

                    NOTE: When using column_expressions (dict) to REDEFINE a pre-existing column,
                    this existing column CAN be either INCLUDED in or EXCLUDED from the column_names arg

                    1) INCLUSION IN BOTH column_expressions AND column_names args:
                        ==> BENEFITS FROM existing column maintaining/control column order per the column_names (list or dict keys order) arg,
                            but column content will reflect the refined content per expression provided
                        ==> WHEN INCLUSION IN BOTH column_expressions AND column_names
                            AND column_names is provided in a dictionary form (dict key:old/existing column name -> dict value:new/renamed column name)
                            the column_expressions dict keys should be coordinated/entered using the old/existing form of the columns
                    2) INCLUSION IN column_expresions ONLY AND EXCLUSION FROM column_names:
                        this column's location will appear the end of the column_names list

                    NOTE: Non-trivial column_names arg is RECOMMENDED when using column_expressions
                    Dictionary keys of column_expressions can be either EXISTING SPACES OR NEW SPACES...

                    In the case of existing, then expression will be applied instead of existing column
                        ==> dictionary keys corresponding to existing spaces:
                            that space's column content will be replaced with result of expression
                        ==> dictionary keys corresponding to new/introduced spaces that are also listed in column_names:
                            new space's column placement controlled by it's location in the column_names
                        ==> dictionary keys corresponding to new/introduced spaces that are NOT listed in column_names:
                            new space's column will be placed at end of existing columns
        :type column_expressions: dict or None

        :param where_clause: (optional) where clause (NOTE: the word 'where' should be provided/included by the caller)
        :type where_clause: str or None

        :param address: (optional) address
        :type address: str or LibAdress or None

        :param custom_info_overrides: Overrides to custom column info assignments
        :type custom_info_overrides: dictionary of dictionaries

            outer dictionary keys: info_type
            outer dictionary values: inner dictionary
            inner dictionary keys: column_name (post-renamed convention when applicable)
            inner dictionary values: associated info_type_assignment

            ==> NOTE: when using custom_info_overrides arg in conjunction with dict version of column_names (for column renaming)
                the custom_info_overrides should be specified using new/target column names

        :param cast_dict: (optional) data type casting dictionary from space (dictionary keys) to new type (dictionary values)
        :type cast_dict: dict or None

        tgt_insertions: list of list of insertions across the columns of the target table

        :param data_exclusion: controls whether to include/exclude data in query data_exclusion: None or 'WITH DATA' or 'WITH NO DATA'
        :type data_exclusion: str or None

        :param info_type_exclusions: (optional) list of info type(s) to be excluded from result
        :type info_type_exclusions: list or tuple or None

        :param deep_copy: If true, generate and return a new table
        :type deep_copy: bool (True*/False)

        :param preferred_vs: The preferred resultant primary valuespace
                    If preferred_vs == '<valuespace>': orginal primary valuespace is preferred
        :type preferred_vs: str

        :param row_number_keyspace: optional (new) column name for row numbers
        :type row_number_keyspace: str or None

        :param keep_row_number_keyspace: (optional) flag to keep row_number_keyspace (if row_number_keyspace arg provided)
        :type keep_row_number_keyspace: bool (False*/True)

        :param zero_base: (optional) flag to start row numbers at zero (if row_number_keyspace arg provided)
        :type zero_base: bool (False*/True

        :param max_rows: maximum number of rows in the output (use None for no limit)
        :type max_rows: int or None

        :param return_query_results: (optional) flag which indicates the return value (either Quble or query results)
                                    (if True returns the results in the form of a pandas dataframe else returns a Quble)
        :type return_query_results: bool (False*/True)

        """
        if column_expressions is None:
            pass
        elif not isinstance(column_expressions, dict):
            raise Exception(
                f"Invalid column_expressions:{column_expressions}...None/dict expected"
            )

        if self.is_undefined:
            return Quble.undefined_instance()

        if deep_copy:
            tgt_table_name = generate_random_table_name()
        else:
            tgt_table_name = self.table_name

        # -----------------------------------------------------------------
        # Establish column_names as a list (or tuple)
        # [Although this logic is present in self.select_query() method, we need to also apply here as we use column_names as list below]
        # -----------------------------------------------------------------
        if not column_names or column_names == "<all>":
            column_names = self.column_names
        elif column_names == "<keyspaces>":
            column_names = self.keyspaces
        elif column_names == "<valuespace>":
            if self.valuespace:
                column_names = [self.valuespace]
            else:
                column_names = []
        elif isinstance(column_names, str):
            column_names = [column_names]
        elif not isinstance(column_names, (tuple, list, dict)):
            raise Exception(
                f"Invalid column names param type passed to select method : {type(column_names)}"
            )

        # ------------------------------------------
        # Generate the selection query or dataframe as per return_query_results param
        # ------------------------------------------
        query = self.select_query(
            key_ordering=key_ordering,
            tgt_keyspaces=tgt_keyspaces,
            column_names=column_names,
            column_expressions=column_expressions,
            where_clause=where_clause,
            cast_dict=cast_dict,
            tgt_insertions=tgt_insertions,
            data_exclusion=data_exclusion,
            row_number_keyspace=row_number_keyspace,
            keep_row_number_keyspace=keep_row_number_keyspace,
            zero_base=zero_base,
            max_rows=max_rows,
            tgt_table_name=tgt_table_name,
            return_query_results=return_query_results,
        )
        if return_query_results:
            return query
        else:
            execute(query, format_flag=False)

        # Establish col_info for the column_names_to_copy
        col_info = self.column_info

        # Column names param can be a variety of types, dict indicating a rename request
        if column_names is None:
            new_cols = self.column_names
        elif isinstance(column_names, (list, tuple)):
            new_cols = column_names
        elif isinstance(column_names, str):
            new_cols = [column_names]
        elif isinstance(column_names, dict):
            new_cols = list(column_names.values())
            # Apply column renames
            for info_type1 in col_info:
                # Create a copy of the current inner dictionary to iterate over
                # This is necessary because we are modifying the dictionary while iterating
                current_inner_dict = col_info[info_type1].copy()

                # Iterate through each key-value pair in the inner dictionary
                for key, value in current_inner_dict.items():
                    # Check if the current key is in the rename requests
                    if key in column_names:
                        # Rename the key by deleting the old key-value pair and adding the new one
                        del col_info[info_type1][key]
                        new_key = column_names[key]
                        col_info[info_type1][new_key] = value
        else:
            raise Exception("Invalid column_names.p..None/str/list/dict expected")

        # If cast_dict was applied, update col_info
        if cast_dict:
            for space1 in col_info["type"]:
                if space1 in cast_dict and cast_dict[space1]:
                    # Need to convert from a pandas/python dtype to a SNOWFLAKE one
                    # cast_dict[space1] will have multiple elements due to the need
                    # for an intermediate translation to int for boolean to float castings and vice versa.
                    # See Quble.change_types for more information.
                    col_info["type"][space1] = cast_dict[space1].upper()

        # Remove info types if requested
        if info_type_exclusions:
            col_info = {
                k: v for k, v in col_info.items() if k not in info_type_exclusions
            }
        if "role" not in col_info:
            col_info["role"] = {}

        # CASE #1: Next, see if custom_info_overrides can help with oustanding resolution of preferred_vs
        if (
            isinstance(custom_info_overrides, dict)
            and "role" in custom_info_overrides
            and isinstance(custom_info_overrides["role"], dict)
        ):
            # Iterate over all assignments to identify a valuespace preference
            for space1, role1 in custom_info_overrides["role"].items():
                col_info["role"][space1] = role1
                # Only set preferred_vs if we find a role assignment, and don't reset it
                if (
                    role1 == "valuespace"
                    and space1 is not None
                    and preferred_vs == "<valuespace>"
                ):
                    preferred_vs = space1
                    break
                elif role1 == "keyspace" and space1 is not None:
                    # when changing the role of a valuespace to a keyspace
                    # preclude that column name from being used as preferred vs
                    if preferred_vs == "<valuespace>" and self.valuespace == space1:
                        _logger.warning(
                            "Received ambiguous information, trying to change role of a VS to KS and that is also a preferred VS"
                        )
                        preferred_vs = None
                    elif preferred_vs is not None and preferred_vs == space1:
                        _logger.warning(
                            "Received ambiguous information, trying to change role of a VS to KS and that is also a preferred VS"
                        )
                        preferred_vs = None

        # Infer preferred_vs if needed
        # --------------------------------
        if preferred_vs == "<valuespace>" and self.valuespace is not None:
            # CASE #2: First, try to confirm self.valuespace is being retained be inspecting the column_names arg
            if isinstance(column_names, dict) and self.valuespace in column_names:
                preferred_vs = column_names[self.valuespace]
            elif self.valuespace in new_cols:
                preferred_vs = self.valuespace

        if preferred_vs == "<valuespace>":
            # -----------------------------------------------------------
            # CASE #3: the logic above did not resolve the preferred_vs
            # In these cases, self.valuespace was either:
            #     1) originally None
            # OR  2) a) it is being dropped from result
            #    AND b) no alternative valuespace is being designated
            # -----------------------------------------------------------
            # In these cases, we choose to allow no preferred valuespace (as might be approriate for a non-variate result)
            # -----------------------------------------------------------
            preferred_vs = None

        # -----------------------------------
        # Populate the valuespace array to be used for Quble construction
        # -----------------------------------
        valuespace = []
        if preferred_vs is not None:
            # Hopefully already consistent, but reassign for integrity
            col_info["role"][preferred_vs] = "valuespace"
            valuespace.append(preferred_vs)
            if preferred_vs not in new_cols:
                new_cols.append(preferred_vs)

        # Remember here that user may intentionally be:
        #    1) moving the role of the original self.valuespace from "valuespace" to "keyspace" [via custom_info_overrides]
        # OR 2) (intentionally) dropping original valuespace from result
        for space1, role1 in col_info["role"].items():
            if (
                space1 in new_cols
                and role1 == "valuespace"
                and space1 not in valuespace
            ):
                valuespace.append(space1)

        # Is column_expressions redefining any existing column names?
        if column_expressions:
            for space1 in column_expressions:
                if space1 not in self.spaces:
                    # If inserting a new space and we don't have role info, assume valuespace
                    if space1 not in col_info["role"]:
                        col_info["role"][space1] = "valuespace"

                    if (
                        col_info["role"][space1] == "valuespace"
                        and space1 not in valuespace
                    ):
                        valuespace.append(space1)
                    if space1 not in new_cols:
                        new_cols.append(space1)

        # Apply custom_info_overrides to col_info
        # For integrity reasons, we validate column name references in custom_info_overrides against target column names in the new table
        if custom_info_overrides:
            validate_col_info(col_info=custom_info_overrides, column_names=new_cols)
            col_info = update_column_info(col_info, custom_info_overrides)

        # Now that we've moved over all the state, make sure there isn't anything left over in col_info
        cols_to_remove = list(set(self.column_names) - set(new_cols))
        if len(cols_to_remove) > 0:
            col_info = remove_columns_from_info(col_info, cols_to_remove)

        # Finally, build new Quble using new tgt_table_name
        if deep_copy:
            return Quble.from_table(
                tgt_table_name,
                col_info=col_info,
                exceptions_flag=exceptions_flag,
                valuespace=valuespace,
            )
        else:
            # TODO: Replace this with more careful approach...
            # but if selecting without deep_copy on an env node, we need to write the timestamp back
            self.table_name = tgt_table_name
            self.touch()

            # Clear previous state, update with new col_info
            self._clear_cache()
            update_column_info(self._column_info, col_info)

            # If we removed a column, remove it from the column_info
            cols_to_remove = []
            for col in self.column_names:
                if col not in new_cols:
                    cols_to_remove.append(col)
            self._column_info = remove_columns_from_info(
                self._column_info, cols_to_remove
            )

            # First, write back the new col_info
            if is_env_table(self.table_name):
                multi_col_info_custom_writer(self.table_name, self._column_info)

            # If we added a column, resync to verify and collect types
            # TODO: this can likely be avoided if we collect the information reliably above
            for col in column_names:
                if col not in self.column_names:
                    self._synchronize_space_info()
                    break

            # Finally, re-initialize space assignments as things may have changed
            self._initialize_space_roles(valuespace)

            return self

    def drop_auxvalspaces(self, allow_shallow_copy: bool = True) -> Quble:
        """
        Drops any auxillary (secondary) valuespaces
        """
        if len(self.auxvalspaces) > 0:
            spaces_to_keep = []
            for space in self.spaces:
                if space not in self.auxvalspaces:
                    spaces_to_keep.append(space)
            return self.select(column_names=spaces_to_keep)
        else:
            return self if allow_shallow_copy else self.copy()

    def remove_duplicate_keys(
        self,
        rankspace: str = None,
        rank_direction: str = "desc",
        key_ordering=None,
        inplace: bool = False,
        exceptions_flag: bool = False,
    ):
        """
        Shortcut for check_remove_duplicate_keys with remove=True
        """
        return self.check_remove_duplicate_keys(
            rankspace,
            rank_direction,
            key_ordering,
            inplace,
            exceptions_flag,
            remove_duplicate_keys=True,
        )

    def check_remove_duplicate_keys(
        self,
        rankspace: str = None,
        rank_direction: str = "desc",
        key_ordering=None,
        inplace: bool = True,
        exceptions_flag: bool = False,
        remove_duplicate_keys=True,
        duplicate_key_grace=False,
    ):
        """
        Checks for the presence of records with duplicate keys
        across the keyspaces columns of the Quble's table and
        removes records with duplicate keys (key combinations)

        :param rankspace: (non-keyspace) space/column for
                    duplicate keys sorting/differentiation (Example: None or '<valuespace>)
        :type rankspace: None or string

        :param rank_direction: direction for duplicate record sorting
        :type rank_direction: 'asc' or 'desc'

        :param key_ordering: (optional) controls row ordering by key
        :type key_ordering: None (no keyspace sorting), 'asc' or 'desc', dict

        :param inplace: Flag for changing self directly inplace
        :type inplace: boolean (True/False*)
            inplace=True: modifies self Quble directly and returns self
            inplace=False: returns a modified Quble (leaves self unchanged)

        :param exceptions_flag: flag whether to generate exceptions Quble
        :type exceptions_flag: (boolean) False*/True

        :param remove_duplicate_keys: Flag to remove duplicate keys
        :type remove_duplicate_keys: bool (True*/False)

        :param duplicate_key_grace: Grace for duplicate keys when remove_duplicate_keys=False
        :type duplicate_key_grace: bool (False*/True)

        :rtype: Quble
        :returns: Quble with duplicate keys removed

        NOTE: Ranking with be performed using partitioned by the keyspaces columns
            we will keep the duplicate key (key combinations) records with rank=1

        For non-trivial rankspace=None, we sort by table's row number across the keyspaces partitions
        For non-trivial rankspace, we must use a non-keyspace rankspace (such as the valuespace)

            Example #1: rankspace=None and rank_direction='desc'
                    ==> retains the last duplicate (keyspaces) record in the table

            Example #2: rankspace=None and rank_direction='asc'
                    ==> retains the first duplicate (keyspaces) record in the table

            Example #3: rankspace='<valuespace>' and rank_direction='asc'
                    ==> retains the duplicate (keyspaces) record with LOWEST VALUE (rank=1) in valuespace

            Example #4: rankspace='<valuespace>' and rank_direction='desc'
                    ==> retains the duplicate (keyspaces) record with HIGHEST VALUE (rank=1) in valuespace
        """
        # validating key_ordering
        if key_ordering is not None:
            if isinstance(key_ordering, dict):
                for key, value in key_ordering.items():
                    if not isinstance(key, str) or not isinstance(value, str):
                        raise Exception(
                            "Incorrect key or order datatype provided in key ordering dict"
                        )
                    elif key not in self.keyspaces:
                        raise Exception(
                            f"Column name {key} is not present in column_names list"
                        )
                    elif value.lower() not in ["asc", "desc"]:
                        raise Exception(
                            f"Incorrect order {value} provided in key ordering dict for column {key}"
                        )
            elif isinstance(key_ordering, str):
                if key_ordering.lower() not in ["asc", "desc"]:
                    raise Exception("Incorrect order provided in key ordering dict")
            else:
                raise Exception("Incorrect value provided for key ordering parameter")

        # For scalar/trivial case, simply return self (no duplicates present)
        if self.has_duplicate_keys():
            if not remove_duplicate_keys and not duplicate_key_grace:
                raise Exception(
                    f"Encountered duplicate keys for quble w/ address = '{self.address}' and remove_duplicate_keys/duplicate_key_grace are both false!"
                )
            pass
        elif inplace:
            return self
        else:
            return self.copy()

        # Procure/validate the rankspace
        if rankspace is not None:
            rankspace = self.validate_space(rankspace, grace=False)

        # Generate the new (target) table name
        if not inplace:
            table_name = generate_random_table_name()
        else:
            table_name = self.table_name
        # Generate the exceptions table name
        if exceptions_flag:
            exceptions_table_name = generate_random_table_name()

        # params needed for SP
        input_param_dict = {
            "src_table": self.table_name,
            "tgt_table": table_name,
            "exceptions_table_name": exceptions_table_name if exceptions_flag else "",
            "keyspaces": self.keyspaces,
            "all_spaces": self.spaces,
            "rank_space": "" if rankspace is None else rankspace,
            "rank_direction": rank_direction,
            "key_ordering": {} if key_ordering is None else key_ordering,
            "exceptions_flag": exceptions_flag,
            "remove_duplicate_keys": remove_duplicate_keys,
            "duplicate_key_grace": duplicate_key_grace,
            "table_timestamp": str(self.time_stamp),
        }
        # creating session and calling _dupe_keys_runner
        session = SnowparkSessionManager.get_snowpark_session()
        return_value = self._dupe_keys_runner(session, input_param_dict)
        if return_value is False:
            # -----------------------
            # Handle trivial cases
            # -----------------------
            if self.is_undefined:
                return None if inplace else Quble.undefined_instance()

            no_keyspaces = not self.keyspaces or len(self.keyspaces) == 0
            no_spaces = not self.spaces or len(self.spaces) == 0

            if no_keyspaces or self.is_scalar or no_spaces:
                return self if inplace else self.copy()

            if not inplace:
                return self
        else:
            # ------------------------------------
            # Generate exceptions (if requested)
            # ------------------------------------
            exceptions = None
            if exceptions_flag:
                # Instantiate exceptions Quble from the new table
                exceptions = Quble.from_table(
                    exceptions_table_name,
                    col_info=self._column_info,
                    exceptions_flag=False,
                )
            if not inplace:
                # Instantiate Quble from the new table
                result = Quble.from_table(
                    table_name,
                    col_info=self._column_info,
                    remove_duplicate_keys=False,
                    duplicate_key_grace=True,
                    exceptions_flag=exceptions_flag,
                )
                result.exceptions = self.exceptions
            else:
                self._clear_num_records_caches()
                result = self

            if exceptions:
                self._extend_exceptions("Duplicate", exceptions)

            return result

    def _dupe_keys_runner(self, session, input_params_dict):
        # Validating allspaces,keyspaces
        if len(input_params_dict["all_spaces"]) == 0:
            raise "allspaces empty or not provided"
        if len(input_params_dict["keyspaces"]) == 0:
            raise "keyspaces empty or not provided"

        keyspaces = ['"' + i + '"' for i in input_params_dict["keyspaces"]]
        allspaces = ['"' + i + '"' for i in input_params_dict["all_spaces"]]

        if len(input_params_dict["key_ordering"]) > 0:
            if isinstance(input_params_dict["key_ordering"], str):
                sort_order = [
                    (
                        True
                        if input_params_dict["key_ordering"].lower() == "asc"
                        else False
                    )
                ] * len(keyspaces)
                sort_cols = keyspaces
            elif isinstance(input_params_dict["key_ordering"], dict):
                sort_cols = [
                    '"' + col + '"' for col in input_params_dict["key_ordering"].keys()
                ]
                sort_order = [
                    True if order.lower() == "asc" else False
                    for col, order in input_params_dict["key_ordering"].items()
                ]
            else:
                raise Exception("Incorrect value provided for key ordering parameter")

        ##################################
        # Reading the table and comments #
        ##################################
        src_df = session.sql(f"""select * from "{input_params_dict['src_table']}" """)
        src_tbl_comments = session.sql(
            f""" desc table "{input_params_dict['src_table']}" """
        ).collect()

        #######################
        # Removing Duplicates #
        #######################
        # case -1 (No rankspace provided)
        if input_params_dict["rank_space"] == "":
            src_df = src_df.withColumn(
                "row_number",
                F.row_number().over(Window.partitionBy(keyspaces).orderBy(keyspaces)),
            )
            if input_params_dict["rank_direction"].lower() == "desc":
                src_df = src_df.withColumn(
                    "row_number2",
                    F.row_number().over(
                        Window.partitionBy(keyspaces).orderBy(
                            F.col("row_number").desc()
                        )
                    ),
                )
            else:
                src_df = src_df.withColumn(
                    "row_number2",
                    F.row_number().over(
                        Window.partitionBy(keyspaces).orderBy(F.col("row_number").asc())
                    ),
                )

            # Populate exceptions df if needed
            if input_params_dict["exceptions_flag"]:
                exceptions_df = src_df.filter(F.col("row_number2") > 1).select(
                    allspaces
                )
                # Writing output to exceptions table
                exceptions_df.write.mode("overwrite").save_as_table(
                    f'"{input_params_dict["""exceptions_table_name"""]}"'
                )
            # Populating target df
            tgt_df = src_df.filter(F.col("row_number2") == 1).select(allspaces)
            # Applying key_ordering
            if len(input_params_dict["key_ordering"]) > 0:
                tgt_df = tgt_df.orderBy(sort_cols, ascending=sort_order)
            # Writing output to tgt table
            tgt_df.write.mode("overwrite").save_as_table(
                f'"{input_params_dict["""tgt_table"""]}"',
                table_type="",
            )
            session.sql(
                f"""comment on table "{input_params_dict['tgt_table']}" is '{input_params_dict["table_timestamp"]}' """
            ).collect()
            # Adding column comments
            for row in src_tbl_comments:
                if row[9] is not None:
                    session.sql(
                        f""" comment on column "{input_params_dict['tgt_table']}"."{row[0]}" is '{row[9]}' """
                    ).collect()
        # case -2 (With rankspace)
        else:
            if input_params_dict["rank_direction"].lower() == "desc":
                src_df = src_df.withColumn(
                    "row_number2",
                    F.row_number().over(
                        Window.partitionBy(keyspaces).orderBy(
                            F.col(f'"{input_params_dict["rank_space"]}"').desc()
                        )
                    ),
                )
            else:
                src_df = src_df.withColumn(
                    "row_number2",
                    F.row_number().over(
                        Window.partitionBy(keyspaces).orderBy(
                            F.col(f'"{input_params_dict["rank_space"]}"').asc()
                        )
                    ),
                )
            # Populate exceptions df if needed
            if input_params_dict["exceptions_flag"]:
                exceptions_df = src_df.filter(F.col("row_number2") > 1).select(
                    allspaces
                )
                # Writing output to exceptions table
                exceptions_df.write.mode("overwrite").save_as_table(
                    f'"{input_params_dict["""exceptions_table_name"""]}"'
                )
            # Populating target df
            tgt_df = src_df.filter(F.col("row_number2") == 1).select(allspaces)
            # Applying key_ordering
            if len(input_params_dict["key_ordering"]) > 0:
                tgt_df = tgt_df.orderBy(sort_cols, ascending=sort_order)
            # we need to write the data to a temp table because snowpark df.write.mode('overwrite') first creates a table
            # then it tries to run a insert command on the table created previously

            # Create table ABCDE (c1 INT, c2 timestamp, c3 number); <- step - 1
            # Insert into ABCDE as select * from ABCDE; <- step - 2
            # When the table gets created in step-1, it has 0 records
            # Insert command in step -2 is inserting data by selecting from table with 0 records
            tgt_df.write.mode("overwrite").save_as_table(
                f'"{input_params_dict["""tgt_table"""]}"',
                table_type="",
            )
            session.sql(
                f"""comment on table "{input_params_dict['tgt_table']}" is '{input_params_dict["table_timestamp"]}' """
            ).collect()
            # Adding column comments
            for row in src_tbl_comments:
                if row[9] is not None:
                    session.sql(
                        f""" comment on column "{input_params_dict['tgt_table']}"."{row[0]}" is '{row[9]}' """
                    ).collect()
        return True

    # There is a snowpark Alternative of this method (remove_duplicate_keys), Hence renaming it as remove_duplicate_keys_sql
    def remove_duplicate_keys_sql(
        self,
        rankspace: str = None,
        rank_direction: str = "desc",
        inplace: bool = False,
        exceptions_flag: bool = False,
        has_duplicate_keys=None,
    ) -> Quble:
        """
        Removes records with duplicate keys (key combinations)
        across the keyspaces columns from the Quble

        :param rankspace: (non-keyspace) space/column for
                    duplicate keys sorting/differentiation (Example: None or '<valuespace>)
        :type rankspace: None or string

        :param rank_direction: direction for duplicate record sorting
        :type rank_direction: 'asc' or 'desc'

        :param key_ordering: (optional) controls row ordering by key
        :type key_ordering: None (no keyspace sorting), 'asc' or 'desc', dict

        :param inplace: Flag for changing self directly inplace
        :type inplace: boolean (True/False*)
            inplace=True: modifies self Quble directly and returns self
            inplace=False: returns a modified Quble (leaves self unchanged)

        :param exceptions_flag: flag whether to generate exceptions Quble
        :type exceptions_flag: (boolean) False*/True

        :param has_duplicate_keys: OPTIONAL shortcut if we know there are duplicate keys, if None call is_duplicate_keys()
        :type has_duplicate_keys: (boolean) Defaults to None

        :rtype: Quble
        :returns: Quble with duplicate keys removed

        NOTE: Ranking with be performed using partitioned by the keyspaces columns
              we will keep the duplicate key (key combinations) records with rank=1

        For non-trivial rankspace=None, we sort by table's row number across the keyspaces partitions
        For non-trivial rankspace, we must use a non-keyspace rankspace (such as the valuespace)

               Example #1: rankspace=None and rank_direction='desc'
                    ==> retains the last duplicate (keyspaces) record in the table

               Example #2: rankspace=None and rank_direction='asc'
                    ==> retains the first duplicate (keyspaces) record in the table

               Example #3: rankspace='<valuespace>' and rank_direction='asc'
                    ==> retains the duplicate (keyspaces) record with LOWEST VALUE (rank=1) in valuespace

               Example #4: rankspace='<valuespace>' and rank_direction='desc'
                    ==> retains the duplicate (keyspaces) record with HIGHEST VALUE (rank=1) in valuespace
        """
        if has_duplicate_keys is None:
            has_duplicate_keys = self.has_duplicate_keys()
        # ----------------------------------------------------------------
        #  inplace logic: modifies self (if applicable) and returns None
        # ----------------------------------------------------------------
        if inplace and not has_duplicate_keys:
            # For inplace case when no dupes exist, do nothing and simply return None
            return

        # -----------------------
        # Handle trivial cases
        # -----------------------
        if self.is_undefined:
            if inplace:
                return self
            else:
                return Quble.undefined_instance()
        elif (
            self.keyspaces is None
            or len(self.keyspaces) == 0
            or self.is_scalar
            or self.spaces is None
            or len(self.spaces) == 0
        ):
            if inplace:
                return self
            else:
                return self.copy()

        # Procure/validate the rankspace
        if rankspace is not None:
            rankspace = self.validate_space(rankspace, grace=False)
        # -------------------------------------------------------
        # Template arguments:
        # -------------------------------------------------------
        # keyspaces: list of all keyspaces
        # allspaces: all the spaces of the table
        # rankspace: (optional) space (non-keyspace) for ranking
        # rank_direction: (optional) direction for ranking ('asc' or 'desc')
        # src_table_name: the original table name
        # tgt_table_name: the new table name
        # key_ordering: (Common) direction for record ordering
        #               of keyspace columns in result (None or 'asc' or 'desc')
        # -------------------------------------------------------

        # ------------------------------------
        # Generate exceptions (if requested)
        # ------------------------------------
        exceptions = None
        if exceptions_flag:
            exceptions_table_name = generate_random_table_name()

            sql_template = JINJA_ENV.get_template("remove_duplicate_keys.j2")
            sql_command = sql_template.render(
                src_table_name=self.table_name,
                tgt_table_name=exceptions_table_name,
                keyspaces=self.keyspaces,
                allspaces=self.spaces,
                rankspace=rankspace,
                rank_direction=rank_direction,
                keep_dupes_flag=True,
            )
            execute(sql_command, format_flag=False)

            # Instantiate exceptions Quble from the new table
            exceptions = Quble.from_table(
                exceptions_table_name,
                col_info=self._column_info,
                exceptions_flag=False,
            )

        # Generate the new (target) table name
        if not inplace:
            tgt_table_name = generate_random_table_name()
        else:
            tgt_table_name = self.table_name

        sql_template = JINJA_ENV.get_template("remove_duplicate_keys.j2")
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            tgt_table_name=tgt_table_name,
            keyspaces=self.keyspaces,
            allspaces=self.spaces,
            rankspace=rankspace,
            rank_direction=rank_direction,
        )
        execute(sql_command)

        if not inplace:
            # Instantiate Quble from the new table
            result = Quble.from_table(
                tgt_table_name,
                col_info=self._column_info,
                remove_duplicate_keys=False,
                duplicate_key_grace=True,
                exceptions_flag=exceptions_flag,
            )
            result.exceptions = self.exceptions
        else:
            self._clear_num_records_caches()
            result = self

        if exceptions:
            self._extend_exceptions("Duplicate", exceptions)

        return result

    def has_duplicate_keys(self) -> bool:
        """
        Indicates the presence of records with duplicate keys
        across the keyspaces columns of the Quble's table
        """
        if "has_duplicate_keys" not in self._cache:
            if self.is_undefined:
                self._cache["has_duplicate_keys"] = False
                return self._cache["has_duplicate_keys"]
            elif self.is_empty:
                self._cache["has_duplicate_keys"] = False
                return self._cache["has_duplicate_keys"]
            elif self.spaces is None or len(self.spaces) == 0:
                self._cache["has_duplicate_keys"] = False
                return self._cache["has_duplicate_keys"]
            # For scalar/trivial case, simply return False (no duplicates present)
            elif (
                self.keyspaces is None
                or len(self.keyspaces) == 0
                or self.is_scalar
                or self.is_multiscalar
            ):
                self._cache["has_duplicate_keys"] = False
                return self._cache["has_duplicate_keys"]

            # -------------------------------------------------------
            # Template arguments:
            # -------------------------------------------------------
            # keyspaces: list of all keyspaces
            # src_table_name: the original table name
            # -------------------------------------------------------
            sql_template = JINJA_ENV.get_template("has_duplicate_keys.j2")
            sql_command = sql_template.render(
                src_table_name=self.table_name,
                tgt_table_name=None,
                keyspaces=self.keyspaces,
            )

            result = execute(sql_command, fetch="one", format_flag=False)

            self._cache["has_duplicate_keys"] = False if not result else result[0]
        return self._cache["has_duplicate_keys"]

    def pct_duplicated_keys(self, keyspaces="<keyspaces>"):
        """
        Returns percentage of keys in specified "key structure" (keyspaces)
        of the Quble that have duplicates
        Here, percentage is defined by the num of duplicated keys
        divided by the total number of records in the Quble's table

        ==> If all keys have duplicates, this method will return 1.0
        ==> If no keys are duplicated, this method will return 0.0
        ==> If no keyspaces are present or specified, returns 0.0
        [For example, for a scalar Quble with no keyspaces yields 0.0]

        :param keyspaces: (optional) keyspaces across which to check
        :type keyspaces: str or list/tuple of strings
           ==> Will default to all keyspaces of the Quble
           see ~qubles.core.quble.validate_keyspaces for a list of valid keyspace proxies

        :returns percentage of keys that have duplicates
        :rtype bool
        """
        # Handle trivial case
        if self.is_undefined:
            return None  # <-- Could also return 0.0 here
        elif (self.num_records is None) or (self.num_records == 0):
            return 0.0

        # Establish num_duplicated_keys
        num_duplicated_keys = self.num_duplicated_keys(keyspaces=keyspaces)
        if (num_duplicated_keys is None) or (num_duplicated_keys == 0):
            return 0.0
        elif not isinstance(num_duplicated_keys, int):
            num_duplicated_keys = int(num_duplicated_keys)

        # Determine under-qualified state
        try:
            pct_duplicates = float(num_duplicated_keys) / float(self.num_records)
        except ZeroDivisionError:
            raise (
                f"Division by zero: num_duplicated_keys:{num_duplicated_keys} / self.num_records:{self.num_records}"
            )
        except:
            raise (f"pct_duplicates calculation failed")

        # Return the computed pct_duplicates
        return pct_duplicates

    def num_duplicated_keys(self, keyspaces="<keyspaces>") -> bool:
        """
        Returns a Python scalar int representing
        the number of duplicated key combinations
        across the specified keyspaces

        IMPORTANT: The total number of duplicated keys
        returned here is computed as sum of the number of duplicates
        for each distinct duplicated key combination.

        Example:
        There are three total duplicated keys in following column
        [three duplicate 'B' keys and two duplicated 'C' keys]

        Code Column
           'A'
           'B'
           'B'
           'B'
           'C'
           'C'
           'D'
        InstanceCounts
           'A': 1
           'B': 3
           'C': 2
           'D': 1
        DuplicateCounts (excludes InstanceCounts <=1)
           'B': 3
           'C': 2

        ==> TotalDuplicated: 5

        The duplicates counted herein are defined
        analyzing key combinations across the multiple keyspaces
        as directed by the keyspaces arg
        """
        if self.is_undefined:
            return None
        elif (self.num_records is None) or (self.num_records == 0):
            return 0  # <-- Could also return None here

        # For scalar/trivial case, simply return False (no duplicates present)
        keyspaces = self.validate_keyspace(
            keyspace=keyspaces, grace=False, coerce_to_list=True
        )
        if keyspaces is None or len(keyspaces) == 0:
            return 0

        table_name = generate_random_table_name()

        # NOTE: tgt_valuespace arg below is chosen aribtrarily here
        sql_template = JINJA_ENV.get_template("num_duplicated_keys.j2")
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            tgt_table_name=table_name,
            keyspaces=keyspaces,
            tgt_valuespace="num_duplicates",
            aggregate_flag=True,
        )
        result = execute(sql_command, fetch="all")
        if result is None or len(result) == 0:
            return None
        else:
            # result should be a single-row, single-column
            # single value from SQL here should ideally be an integer
            return result[0][0]

    def get_duplicate_keys(
        self, tgt_valuespace="num_duplicates", keyspaces="<keyspaces>"
    ) -> Quble:
        """
        Returns either a:
              1) univariate,integer Quble (tgt_valuespace!=None)
           or 2) non-variate Quble (tgt_valuespace=None)

        providing the (number of mulitple instances of) duplicated key combinations
        for this Quble across the specified keyspaces
        The resultant records will be ordered with most duplicated keys in the top rows

        When tgt_valuespace is provided, the resultant value column will provide
        the actual duplication count for each duplicitous key combination

        NOTE: Records will only exist in result for those key combinations
              with more than one instance (i,e, "duplicates") in the original Quble

        :type tgt_valuespace: str or None
        :param tgt_valuespace: name given to newly created valuespace column
                  providing instance count for each duplicated key combination

          ==> NOTE: The key duplicates logic is agnostic to original valuespaces of the Quble
          ==> As such, this method applies equally to non-variate, univariate and multi-variate Qubles

           ==> NOTE: tgt_valuespace DOES NOT REFER TO ANY EXISTING valuespaces of the original Quble
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        # For scalar/trivial case, simply return False (no duplicates present)
        keyspaces = self.validate_keyspace(
            keyspace=keyspaces, grace=False, coerce_to_list=True
        )
        if (
            keyspaces is None
            or len(keyspaces) == 0
            or self.is_scalar
            or self.is_multiscalar
        ):
            return Quble.undefined_instance()

        # -------------------------------------------------------
        # Template arguments:
        # -------------------------------------------------------
        # keyspaces: list of all keyspaces
        # src_table_name: the original table name
        # -------------------------------------------------------
        table_name = generate_random_table_name()

        sql_template = JINJA_ENV.get_template("get_duplicate_keys.j2")
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            tgt_table_name=table_name,
            keyspaces=keyspaces,
            tgt_valuespace=tgt_valuespace,
        )
        execute(sql_command)

        col_info = self.get_space_info(
            info_type=CUSTOM_INFO_TYPES,
            space=self.keyspaces,
            omit_unassigned=True,
        )

        # Assign info_type:'role' to "valuespace" for the tgt_valuespace column
        if tgt_valuespace is not None:
            update_column_info(col_info, {"role": {tgt_valuespace: "valuespace"}})

        # Instantiate Quble from the new table
        return Quble.from_table(
            table_name,
            col_info=col_info,
        )

    def rename_space(self, space: str, tgt_space: str, inplace: bool = False):
        """
        Renames a space (column) of the Quble

        :param space: space (column name) to be renamed
        :type space: string

        :param tgt_space: target (new) space (column name)
        :type tgt_space: string

        :param inplace: Flag for changing self directly inplace
        :type inplace: boolean (True/False*)
            inplace=True: modifies self Quble directly and returns self
            inplace=False: returns a modified Quble (leaves self unchanged)

        """
        if self.is_undefined:
            raise UndefinedQubleError("Quble is undefined")

        # Validate the space to be renames
        space = self.validate_space(space, grace=False, solo_required=True)

        # Perform space renaming operation by calling rename_spaces() method
        space_map = {}
        space_map[space] = tgt_space
        return self.rename_spaces(space_map=space_map, inplace=inplace)

    def rename_spaces(self, space_map: dict, inplace: bool = False):
        """
        Renames mulitple spaces (columns) of the Quble

        :param space: space_map dictionary
            dictionary keys: original/source spaces (column names)
            dictionary values: target spaces (column names)
        :type space: dict

        :param inplace: Flag for changing self directly inplace
        :type inplace: boolean (True/False*)
            inplace=True: modifies self Quble directly and returns self
            inplace=False: returns a modified Quble (leaves self unchanged)

        """
        if self.is_undefined:
            raise UndefinedQubleError("Quble is undefined")

        # Validate space_map arg
        if space_map is None:
            return self if inplace else self.copy()
        elif not isinstance(space_map, dict):
            raise Exception(f"Invalid space_map:{space_map}...dict (or None) expected")
        elif len(space_map) == 0:
            # Trivial case...empty space_map
            return self if inplace else self.copy()

        # Validate tgt_space & handle trivial cases
        renaming_required = False  # Initialization (validate in loop below)
        for space, tgt_space in space_map.items():
            if tgt_space is None:
                raise Exception(f"Invalid space:{space}")
            elif space not in self.spaces:
                raise Exception(f"No such column {space} in the Quble")
            elif not isinstance(tgt_space, str):
                raise Exception(f"Invalid space:{space}...str expected")
            elif tgt_space == space:
                # ------------------------------------------------------------
                # Decided to allow for this (innocent but sub-optimal) case...
                # Here, the user is requesting to apply the SAME column name
                # One would hope that user would not intentionally apply
                # such superfluous actions, but this case may come up
                # inadvertantly through programmatic/variable-based args usage.
                # While this may cause additional overhead, we are choosing
                # not to yield an Exception here, but rather honor the request
                # whereby this column name will effectively not be changed.
                # ------------------------------------------------------------
                pass
            else:
                # Mark that atleast one of the columns is being renamed
                renaming_required = True

        # Handle simple case where no columns are being renamed
        if renaming_required:
            pass
        elif inplace:
            return self
        else:
            self.copy()

        # Build column_names (dict) for the select method
        column_names = {}
        valuespace = None

        for col_name in self.spaces:
            if (col_name not in space_map) or (space_map[col_name] == col_name):
                # We ARE NOT renaming this column
                column_names[col_name] = col_name
            else:
                # We ARE renaming this column: col_name -> space_map[col_name]
                column_names[col_name] = space_map[col_name]
                # Logic for dropping _spaces should be performed in self.select

            # Logic to check if primary valuespace is being renamed
            if col_name == self.valuespace:
                valuespace = column_names[col_name]
        if valuespace is None:
            valuespace = self.valuespace

        # Make sure there are no duplicates in the target column names
        tgt_column_names = list(column_names.values())
        if len(tgt_column_names) != len(set(tgt_column_names)):
            # Here, some tgt_column_names are being duplicated so raise an Exception accordingly
            raise Exception(
                f"Duplicates present in target column names:{tgt_column_names}"
            )

        query = ""
        new_column_info = copy.deepcopy(self._column_info)
        for old_name, new_name in column_names.items():
            if old_name != new_name:
                query += f'ALTER TABLE "{self.table_name}" RENAME COLUMN "{old_name}" TO "{new_name}";'
                for info_type in self._column_info:
                    if old_name in self._column_info[info_type]:
                        new_column_info[info_type][new_name] = self._column_info[
                            info_type
                        ][old_name]
                        del new_column_info[info_type][old_name]

        result = self
        if inplace:
            execute(query, interface="native_storage")

            result._spaces = []
            result._valuespaces = []
            result._keyspaces = []
            result._column_info = new_column_info
            result._initialize_space_roles(valuespace)
        else:
            result = self.select(column_names=column_names, deep_copy=not inplace)
            result._column_info = new_column_info

        return result

    def rename_space_inplace(self, space: str, tgt_space: str):
        """
        Renames a space (column) of the Quble in-place
        [Modifies self and returns None]
        In-place version of method: Quble.rename_space()
        See: :meth:`~qubles.core.quble.Quble.rename_space`
        """
        return self.rename_space(space=space, tgt_space=tgt_space, inplace=True)

    def rename_spaces_inplace(self, space_map: dict):
        """
        Renames multiple spaces (column) of the Quble in-place
        [Modifies self and returns None]
        In-place version of method: Quble.rename_spaces()
        See: :meth:`~qubles.core.quble.Quble.rename_spaces`
        """
        return self.rename_spaces(space_map, inplace=True)

    def rekeyspace(self, keyspace: str, tgt_keyspace: str, inplace: bool = False):
        """
        Renames a keyspace of the Quble
        Calls rename_space but included for legacy purposes
        """
        return self.rename_space(
            space=keyspace, tgt_space=tgt_keyspace, inplace=inplace
        )

    def rekeyspace_inplace(self, keyspace: str, tgt_keyspace: str):
        """
        Renames a keyspace of the Quble in-place
        [Modifies self and returns None]
        In-place version of method: Quble.rename_space()
        Calls rename_space but included for legacy purposes
        """
        return self.rename_space(space=keyspace, tgt_space=tgt_keyspace, inplace=True)

    def nullify_all(self) -> Quble:
        return self.nullify(space="<all>")

    def nullify(self, space="<valuespace>") -> Quble:
        """
        Nullifies the specified column(s) of a Quble

        :type space: string or list/tuple of strings
        :param space: The space(s) to be nullified
             space = '<all>' nullifies all columns
             space = '<valuespace>' nullifies primary valuespace column
        """
        # Validate space
        if space is None:
            return self.copy()

        spaces = self.validate_space(space, grace=False, coerce_to_list=True)

        # Create column_expressions
        for space1 in spaces:
            column_expressions = {}
            column_expressions[space1] = "NULL"

        # Generate new Quble
        result = self.select(
            column_names="<all>", column_expressions=column_expressions
        )

        # (Re)set freq info_type if applicable/present
        for space1 in spaces:
            if result.has_space_info(info_type="freq", space=space1):
                result.set_space_info(space=space1, info_type="freq", info_value=space1)

        return result

    def countdown_days(
        self, keyspace="<first_time_keyspace>", valuespace="<time_valuespaces>"
    ):
        """
        Returns "countdown" (in number of calendar days)
        to each time valuespace column from the base time-keyspace
        See: :meth:`~qubles.core.quble.Quble.countdown`
        """
        return self.countdown(keyspace=keyspace, valuespace=valuespace, time_unit="D")

    def countdown_busdays(
        self, keyspace="<first_time_keyspace>", valuespace="<time_valuespaces>"
    ):
        """
        Returns "countdown" (in number of business days)
        to each time valuespace column from the base time-keyspace
        See: :meth:`~qubles.core.quble.Quble.countdown`
        """
        return self.countdown(keyspace=keyspace, valuespace=valuespace, time_unit="B")

    def countdown_weeks(
        self, keyspace="<first_time_keyspace>", valuespace="<time_valuespaces>"
    ):
        """
        Returns "countdown" (in number of weeks)
        to each time valuespace column from the base time-keyspace
        See: :meth:`~qubles.core.quble.Quble.countdown`
        """
        return self.countdown(keyspace=keyspace, valuespace=valuespace, time_unit="W")

    def countdown_months(
        self, keyspace="<first_time_keyspace>", valuespace="<time_valuespaces>"
    ):
        """
        Returns "countdown" (in number of months)
        to each time valuespace column from the base time-keyspace
        See: :meth:`~qubles.core.quble.Quble.countdown`
        """
        return self.countdown(keyspace=keyspace, valuespace=valuespace, time_unit="M")

    def countdown_years(
        self, keyspace="<first_time_keyspace>", valuespace="<time_valuespaces>"
    ):
        """
        Returns "countdown" (in number of months)
        to each time valuespace column from the base time-keyspace
        See: :meth:`~qubles.core.quble.Quble.countdown`
        """
        return self.countdown(keyspace=keyspace, valuespace=valuespace, time_unit="Y")

    def countdown(
        self,
        keyspace="<first_time_keyspace>",
        valuespace="<time_valuespaces>",
        time_unit="D",
    ):
        """
        Returns "countdown" (in number of specified time period units)
        to each time valuespace column from the base time-keyspace

        Given a Quble with datetime values
        and a time-keyspace corresponding to a datetime index

        ==> Resultant valuspaces will retain valuespace names
        ==> but will become bigint column types

        NOTE: Where values (datetime) > keys (datetime), resultant countdown > 0
              [In otherwords, date values in the future (ahead of the observation/indexed date keys)
               correspond to positive countdown value]

        :param keyspace: base time keyspace to be used as starting timestamp
        :type keyspace: str (or shortcut thereof)

        :param valuespace: time valuespace(s) to be used as ending timestamp
        :type valuespace: str or list of strings (or shortcut thereof)

        :param time_unit: time unit code SCALAR(numpy timedelta64)
        :type time_unit: str

        **Valid time_unit:**
           ==> time_unit='Y': years elapsed
           ==> time_unit='M': months elapsed
           ==> time_unit='W': weeks elapsed
           ==> time_unit='B': business days elapsed (supported here)
           ==> time_unit='D': days elapsed (default setting)
           ==> time_unit='h': hours elapsed
           ==> time_unit='m': minutes elapsed
           ==> time_unit='s': seconds elapsed
           ==> time_unit='ms': milliseconds elapsed
           ==> time_unit='us': microseconds elapsed
           ==> time_unit='ns': nanoseconds elapsed
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        if valuespace is None or len(valuespace) == 0:
            # No time valuespaces to operate on: Simply return a copy of self
            return self.copy()

        # Validating keyspace and valuespace
        keyspace = self.validate_space(space=keyspace)
        valuespace = self.validate_space(space=valuespace)

        # Make sure (base) keyspace does not conflict with valuespace
        # [Recall valuespace is a list and keyspace is a validated scalar string]
        if keyspace in valuespace:
            raise Exception(
                f"keyspace:{keyspace} present in valuespace list:{valuespace}"
            )

        # Invoke time_elapsed udf to convert time valuespace columns
        column_expressions = {}
        if isinstance(valuespace, list):
            for vs in valuespace:
                # Here each vs as well as keyspace have been pre-validated as a time-spaces: Call the time_elapsed updf accordingly
                column_expressions[vs] = (
                    f'time_elapsed_udf("{keyspace}", "{vs}", \'{time_unit}\')'
                )
        else:
            column_expressions[valuespace] = (
                f'time_elapsed_udf("{keyspace}", "{valuespace}", \'{time_unit}\')'
            )

        # Apply column selections accorindgly
        result = self.select(
            column_names="<all>", column_expressions=column_expressions
        )
        # Clean-up any defunct freq info_type property assignments for each valuespace in list (if applicable)
        result.remove_space_info(space=valuespace, info_type="freq")

        return result

    @RootLib.lazy_kwargs()
    def convert_date_values(
        self,
        space: str = "<time_valuespaces>",
        freq: str = RootLib.lazy_eval("freq"),
        roll_direction: int = 1,
    ) -> Quble:
        """
        Return a Quble with the time-stamp values
        converted/rolled forward (backward) to the calendar/freq date
        AT OR ADJACENT TO the specified frequency.

        :type space: str or list of strings or '<valuespace>' or '<time_valuespaces>'
        :param space: The time-space(s) to be converted
             space = '<valuespace>' converts primary valuespace column
             space = '<time_valuespaces>' converts all time-valuespaces

        :type freq: string
        :param freq: frequency for rolling

        :type roll_direction: int
        :param roll_direction: direction for rolling

            roll_direction >= 0: roll to calendar/freq timestamp AT/AFTER each timestamp
            roll_direction < 0: roll to calendar/freq timestamp AT/BEFORE each timestamp
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        # Allow validation grace for non-specific space qualifications
        validate_grace = (
            True if space in ("<time_valuespaces>", "<valuespaces>") else False
        )
        space = self.validate_space(
            space, grace=validate_grace, coerce_to_list=True, time_space_required=True
        )
        if space is None or len(space) == 0:
            return self.copy()

        # Validate freq
        if freq is None:
            raise Exception("freq required")
        elif not isinstance(freq, str):
            raise Exception(f"Invalid freq:{freq}...str expected")
        elif freq not in FREQS:
            raise Exception(f"Invalid freq:{freq}")

        # Validate roll_direction
        if roll_direction is None:
            roll_direction = 1

        if not isinstance(roll_direction, int):
            raise Exception(
                f"Invalid roll_direction:{roll_direction}...integer expected"
            )

        table_name = generate_random_table_name()

        # Invoke template: roll_to_calendar.j2
        sql_template = JINJA_ENV.get_template("roll_to_calendar.j2")
        sql_command = sql_template.render(
            allspaces=self.spaces,
            roll_spaces=space,
            roll_freq=f"'{freq}'" if freq is not None else freq,
            roll_direction=roll_direction,
            src_table_name=self.table_name,
            tgt_table_name=table_name,
            calendar_table_name=RootLib().get_control("calendar_table_name"),
        )
        execute(sql_command)

        col_info = self.get_space_info(
            info_type=CUSTOM_INFO_TYPES,
            space="<all>",
            omit_unassigned=True,
        )
        # Remove 'freq' from col_info for rolled spaces
        if col_info is not None and "freq" in col_info and col_info["freq"] is not None:
            for space1 in list(col_info["freq"].keys()):
                if space1 in space:
                    # We do not want to copy freq for rolled spaces
                    # [Since freq will likely change for rolled spaces]
                    col_info["freq"].pop(space1)

        # Now, re-infer new freq for rolled spaces
        freq_hint1 = {}
        for roll_space in space:
            freq_hint1[roll_space] = freq

        # Instantiate Quble from the new table using the appropriate freq_hint
        result = Quble.from_table(
            table_name,
            col_info=col_info,
            freq_hint=freq_hint1,
        )

        return result

    def relativedelta(
        self,
        space: str = "<valuespace>",
        years: int = 0,
        months: int = 0,
        days: int = 0,
        weeks: int = 0,
        hours: int = 0,
        minutes: int = 0,
        seconds: int = 0,
        microseconds: int = 0,
        avoid_weekends: bool = False,
    ) -> Quble:
        """
        Given a Quble with datetime space, adds the specified number of time units
        years/months/days/weeks/hours/minutes/seconds/microsecconds (positive or negative)
        to each (non-missing) datetime value in the space / column.

        :type space: string
        :param space: The time-space to be converted
             space = '<valuespace>' converts primary valuespace column

        If avoid_weekends=None/False/integer=0: Any resultant weekend dates are honored
        If avoid_weekends=True or integer > 0: Will return a folllowing Monday for any resultant weekend date
        If avoid_weekends=integer < 0: Will return a preceeding Friday for any resultant weekend date
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate space
        space = self.validate_space(
            space, grace=False, solo_required=True, time_space_required=True
        )

        if not self.is_time_space(space=space, grace=True):
            raise Exception(f"Non-datetime/timestamp space:{space}")

        # Validate avoid_weekends and convert to integer for call to relativedelta_udf
        # -------------------------------
        if avoid_weekends is None or avoid_weekends == False:
            avoid_weekends = 0
        elif avoid_weekends == True:
            avoid_weekends = 1

        if not isinstance(avoid_weekends, int):
            raise Exception(
                f"Invalid avoid_weekends:{avoid_weekends}...integer expected"
            )

        # replace None time unit args w/zeros accordingly...
        # ----------------------------------------------------
        if years is None:
            years = 0
        if months is None:
            months = 0
        if days is None:
            days = 0
        if weeks is None:
            weeks = 0
        if hours is None:
            hours = 0
        if minutes is None:
            minutes = 0
        if seconds is None:
            seconds = 0
        if microseconds is None:
            microseconds = 0

        column_expressions = {}

        # BUILD COLUMN EXPRESSSION:
        #   relativedelta_udf(<column>, years, months, days, weeks, hours,
        #                 minutes, seconds, microseconds, avoid_weekends)
        # ------------------------------------------------------------------
        column_expressions[space] = (
            "relativedelta_udf("
            + '"'
            + space
            + '", '
            + str(years)
            + ", "
            + str(months)
            + ", "
            + str(days)
            + ", "
            + str(weeks)
            + ", "
            + str(hours)
            + ", "
            + str(minutes)
            + ", "
            + str(seconds)
            + ", "
            + str(microseconds)
            + ", "
            + str(avoid_weekends)
            + ")"
        )

        result = self.select(
            column_names="<all>",
            column_expressions=column_expressions,
        )
        # Remove the freq info for the designated space/column,
        # as this operation may have changed the time freq
        result._infer_freq(space=space, assign_inferred=True, force_reinfer=True)
        return result

    def increment_dates(
        self,
        periods: int,
        space: str = "<first_time_keyspace>",
        new_space: str = None,
        retain_orig_space: bool = False,
        retain_periods_column: bool = True,
        custom_info_overrides: dict = None,
    ) -> Quble:
        """
        Increments the specified time-space by the
        designated number of periods [Time-space required]
        according to the prevailing frequency

        :param periods: # periods to shift
            ==> periods (int) > 0: lag the data
            ==> periods (int) < 0: lead the data (Warning: may be non-causal)
            ==> periods (str): column (of integers/numbers) for shifting (on row-by-row basis)
        :type periods: int or str

        :param space: time-space to be incremented
        :type space: str

        :param new_space: (optional) new name for space column being incremented
        :type new_space: str or None
            ==> When new_space is None, the original space name will be retained

        :param retain_orig_space: (optional) flag to retain original column (when new_space is not None)
        :type retain_orig_space: bool (False*/True)
            ==> ONLY APPLICABLE when new_space is not None

        :param retain_periods_column: (optional) flag to retain periods_column (when periods arg is a str)
        :type retain_periods_column: bool (True*/False)
            ==> ONLY APPLICABLE when periods is a string!

        :param custom_info_overrides: Overrides to custom column info assignments
        :type custom_info_overrides: dictionary of dictionaries

        :returns: Quble with the specified column incremented accordingly
        :rtype: qubles.core.quble.Quble

        """
        # Validate table
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate space
        space = self.validate_space(
            space, grace=False, solo_required=True, time_space_required=True
        )

        # Handle empty Quble (or no incrementing) cases
        if self.is_empty or not periods:
            # Affect appropriate column selections accordingly
            column_names = {}
            for space1 in self.spaces:
                if (space1 == space) and new_space is not None:
                    column_names[space1] = new_space
                elif (
                    isinstance(periods, str)
                    and (space1 == periods)
                    and not retain_periods_column
                ):
                    pass
                else:
                    column_names[space1] = space1

            # Select the contents accordingly
            return self.select(column_names=column_names)

        # Establish and validate freq
        freq = self.get_freq(space, allow_infer=True, assign_inferred=True)

        if freq is None:
            raise Exception(
                f"Unable to establish existing freq for (time)space:{space}"
            )
        elif freq not in PPY:
            raise Exception(f"Invalid freq:{freq}")

        # Create target table
        table_name = generate_random_table_name()

        sql_template = JINJA_ENV.get_template("increment_dates.j2")
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            tgt_table_name=table_name,
            calendar_table_name=RootLib().get_control("calendar_table_name"),
            freq=freq,
            space=space,
            periods=periods,
            periods_column_flag=True if isinstance(periods, str) else False,
            spaces=self.spaces,
            new_space=new_space,
            retain_orig_space=retain_orig_space,
            retain_periods_column=retain_periods_column,
        )

        execute(sql_command, format_flag=False)

        # Establish col_info for copy
        col_info = self.get_space_info(
            info_type=CUSTOM_INFO_TYPES,
            space=self.spaces,
            omit_unassigned=True,
        )
        # Clean up col_info (if needed)
        if col_info is None:
            pass
        elif new_space is None and retain_periods_column:
            # Here, we do not need to perform any col_info cleaning/mods
            col_info = deepcopy(col_info) if custom_info_overrides else col_info
        else:
            # First, make a deep copy to avoid
            # potential contamination of self.col_info
            col_info = deepcopy(col_info)

            # Now, perform clean-up of col_info to acccommodate:
            #  1) new_space column (when applicable)
            #  2) possible droppage of original space (only when new_space is not None)
            #  3) possible droppage of periods_column
            # --------------------------------------------------
            for info_type, info_assignments in col_info.items():
                if not info_assignments:
                    continue
                elif (space in info_assignments and new_space is not None) or (
                    isinstance(periods, str)
                    and periods in info_assignments
                    and not retain_periods_column
                ):
                    # Here, we wish to modify the column entries
                    # in this info_assignments sub-dictionary accordingly
                    # NOTE: As written, the new_space (if applicable)
                    # will inherit original space column's info
                    info_assignments2 = {}
                    for col_name1, info_val in info_assignments.items():
                        if col_name1 != space:
                            if (
                                isinstance(periods, str)
                                and not retain_periods_column
                                and col_name1 == periods
                            ):
                                # HERE, we are dropping periods column
                                # so we want to exclude this column from info_assignments2
                                # ACTION: EXCLUDE from info_assignments2 for col_name1 == periods
                                pass
                            else:
                                # ACTION: RETAIN info_assignments references: col_name1
                                info_assignments2[col_name1] = info_val
                        elif new_space is None:
                            # HERE, we ARE NOT introducing a new_space
                            # [BUT IMPLICITLY AWAYS RETAINING original (yet modified) space column]
                            # ACTION: RETAIN info_assignments references: col_name1/space
                            info_assignments2[col_name1] = info_val
                        elif retain_orig_space:
                            # new_space is not None YET retain retain_orig_space
                            # HERE, we are introducing a new_space (w/modified dates)
                            # AND ALSO RETAINING original space column
                            # ACTION: RETAIN info_assignments references: col_name1/space
                            info_assignments2[col_name1] = info_val
                            # ACTION: COPY info_assignments references: col_name1/space -> new_space
                            info_assignments2[new_space] = info_val
                        else:
                            # new_space is not None AND NOT retain retain_orig_space
                            # HERE, we are introducing a new_space (w/modified dates)
                            # BUT DROPPING original space column
                            # ACION: RENAME info_assignments references: col_name1/space -> new_space
                            info_assignments2[new_space] = info_val
                    col_info[info_type] = info_assignments2

                elif (
                    isinstance(periods, str)
                    and periods in info_assignments
                    and not retain_periods_column
                ):
                    # Remove info_assignments references: periods
                    # [Here, periods references a integer/numeric column to be dropped]
                    info_assignments2 = {}
                    for col_name1, info_val in info_assignments.items():
                        if col_name1 != periods:
                            info_assignments2[col_name1] = info_val
                    col_info[info_type] = info_assignments2

        # Apply custom_info_overrides to col_info (if applicable)
        # [we consider this action independent of copy_custom_info arg]
        # For integrity reasons, we validate column name references
        # in custom_info_overrides against target column names in the new table
        if col_info and custom_info_overrides:
            if table_name:
                tgt_column_names = get_column_names(table_name)
                validate_col_info(
                    col_info=custom_info_overrides, column_names=tgt_column_names
                )
            col_info = update_column_info(col_info, custom_info_overrides)

        # Instantiate Quble from the new table
        result = Quble.from_table(
            table_name,
            col_info=col_info,
        )

        return result

    # =============================== TABLE MANAGEMENT ================================

    @property
    def _has_table(self) -> bool:
        return table_exists(self.table_name)

    def _drop_table(self):
        return drop_table(self.table_name)

    def _get_rows(self, key_ordering=None):
        sql_command = f'SELECT * FROM "{self.table_name}"'
        if key_ordering and len(self.keyspaces) > 0:
            sql_command += " ORDER BY "
            comma_str = ""
            for ks in self.keyspaces:
                sql_command += f'{comma_str}"{ks}"'
                comma_str = ", "
            if (
                isinstance(key_ordering, str) and key_ordering[0:4].lower() == "desc"
            ) or (isinstance(key_ordering, int) and key_ordering < 0):
                sql_command += " DESC"
        sql_command += ";"

        return execute(sql_command, fetch="all")

    def inspect_num_records(self, where_clause=None) -> int:
        if self.is_undefined:
            return None

        sql_command = f'SELECT COUNT(*) FROM "{self.table_name}"'
        if where_clause is not None:
            sql_command += where_clause
        sql_command += ";"

        result = execute(sql_command, fetch="one", format_flag=False)

        if not result:
            return None

        return result[0]

    @property
    def name(self):
        if self.address is not None:
            return self.address[-1]

    @property
    def num_records(self) -> int:
        """
        Number of records in Quble
        as a Python scalar int
        """
        if "num_records" not in self._cache:
            self._cache["num_records"] = self.inspect_num_records()
        return self._cache["num_records"]

    def _inspect_num_unique(self, space="<valuespace>", where_clause=None) -> int:
        """
        Returns the number of unique instances (as Python scalar int)
        in the specified column via column inspection
        (performs a distinct SQL count)
        """
        if self.is_undefined:
            return None

        space = self.validate_space(space, grace=False)
        sql_command = (
            f'SELECT COUNT(DISTINCT "{space}") FROM {dquote_dot(self.table_name)}'
        )
        # Augment sql_command with where_clause (if provided)
        if where_clause is not None:
            if where_clause[0:5].upper() != "WHERE":
                sql_command += f" WHERE {where_clause}"
            else:
                sql_command += f" {where_clause}"
        sql_command += ";"

        result = execute(sql_command, fetch="one")

        if not result:
            return None

        return result[0]

    def num_nulls_space(self, space: str = "<valuespace>") -> int:
        if self.is_undefined:
            return None

        space = self.validate_space(space, grace=False, solo_required=True)
        if space is None:
            # Should iedally not happen due to grace=False above
            return None

        num_nulls_all_spaces = self.num_nulls_all_spaces

        # Validate num_nulls_all_spaces
        if not isinstance(num_nulls_all_spaces, dict):
            raise Exception(
                f"dict expected but type(num_nulls_all_spaces):{type(num_nulls_all_spaces)}"
            )
        elif space not in num_nulls_all_spaces:
            raise Exception(
                f"space:{space} absent from num_nulls_all_spaces:{num_nulls_all_spaces}"
            )

        return num_nulls_all_spaces[space]

    def num_non_nulls_space(self, space: str = "<valuespace>") -> int:
        """
        Returns the number of non-nulls across a specific column/space
        """
        if self.is_undefined:
            return None

        space = self.validate_space(space, grace=False, solo_required=True)
        if space is None:
            # Should iedally not happen due to grace=False above
            return None

        num_non_nulls_all_spaces = self.num_non_nulls_all_spaces

        # Validate num_non_nulls_all_spaces
        if not isinstance(num_non_nulls_all_spaces, dict):
            raise Exception(
                f"dict expected but type(num_non_nulls_all_spaces):{type(num_non_nulls_all_spaces)}"
            )
        elif space not in num_non_nulls_all_spaces:
            raise Exception(
                f"space:{space} absent from num_non_nulls_all_spaces:{num_non_nulls_all_spaces}"
            )

        return num_non_nulls_all_spaces[space]

    def has_nulls(self, space: str = "<valuespace>") -> bool:
        """
        Tests whether the specified column/space has null values
        """
        num_nulls = self.num_nulls_space(space)
        if num_nulls is None:
            return False
        else:
            return True if (num_nulls > 0) else False

    def has_non_nulls(self, space: str = "<valuespace>") -> bool:
        """
        Tests whether the specified column/space has non-null values
        """
        num_non_nulls = self.num_non_nulls_space(space)
        if num_non_nulls is None:
            return False
        else:
            return True if (num_non_nulls > 0) else False

    @classmethod
    def _get_datetime_at_freq(cls, freq, mode="recent"):
        """
        Helper class method for following class methods:

        1) Quble.recent_datetime_at_freq(freq)
        2) Quble.in_progress_datetime_at_freq(freq)

        :params: freq: associated time-frequency
        :type freq: str

        :params: mode: mode
        :type freq: str in ("recent","in_progress")
        """
        if freq is None:
            freq = RootLib().get_control("freq")

        # Validate the frequency by ensuring it is present in the PPY map
        if freq not in PPY:
            # This should ideally not happen if freq is not None
            raise Exception(f"Unsupported freq:{freq}")

        # Generate now_str and comparison_op for use in SQL query
        # NOTE: Logic is different for
        # intraday versus non-intraday frequencies

        # TODO: Add formal support/construct to determine
        # if/when a given freq is "intra-day" resolution
        is_intraday_freq = False
        if is_intraday_freq:
            # For intra-day frequencies...
            now_str = "now()"
            comparison_op = "<=" if (mode == "recent") else ">"
        else:
            # For non-intra-day frequencies...
            # For latter convenience, add leading and trailing singe-quotes here
            now_str = "'" + datetime.now().strftime("%Y-%m-%d") + "'"
            comparison_op = "<" if (mode == "recent") else ">="

        # Craft the appropriate sql_command against the celndar table
        if mode == "recent":
            sql_command = (
                'SELECT MAX("Dates") AS "Dates" from "Calendar" WHERE "Freq" = '
                + "'"
                + freq
                + "'"
                + ' AND "Dates" '
                + comparison_op
                + " "
                + now_str
            )
        elif mode == "in_progress":
            sql_command = (
                'SELECT MIN("Dates") AS "Dates" from "Calendar" WHERE "Freq" = '
                + "'"
                + freq
                + "'"
                + ' AND "Dates" '
                + comparison_op
                + " "
                + now_str
            )
        else:
            raise Exception(f"Invalid mode:{mode}...'recent' or 'in_progress' required")

        # Execute the query against the calendar time
        result = execute(sql_command, fetch="all")

        # Here, query should yield a single row and single column
        if result is None or len(result) == 0:
            return None
        elif len(result) > 1:
            raise Exception(f"Single row expected but received # rows:{len(result)}")
        elif len(result[0]) != 1:
            raise Exception(
                f"Single column expected but received # columns:{len(result[0])}"
            )
        else:
            return result[0][0]

    @classmethod
    def recent_datetime_at_freq(cls, freq):
        """
        Returns the most recently completed datetime
        according to the time-profile of the specified freq

        :params: freq: associated time-frequency
        :type freq: str

        [NOTE: This is a Quble class method, and does not apply to a specific Quble]
        """
        return cls._get_datetime_at_freq(freq=freq, mode="recent")

    @classmethod
    def in_progress_datetime_at_freq(cls, freq):
        """
        Returns the in-progress datetime
        according to the time-profile of the specified freq

        :params: freq: associated time-frequency
        :type freq: str

        [NOTE: This is a Quble class method, and does not apply to a specific Quble]
        """
        return cls._get_datetime_at_freq(freq=freq, mode="in_progress")

    def recent_datetime1d(self, keyspace: str = "<first_time_keyspace>"):
        """
        Returns 'recent datetime' = max(max_datetime,recent_datetime_at_freq)
        across the time-keys across from the Quble's specified time-keyspace
        as a Python scalar with type as translated from column's sql type

        Here: max_datetime is max date key across the specified time-keyspace
        May be a date greater than now if last date in time-keyspace is greater than now

        Notes:
        Will return a datetime.datetime instance

        If there are no records OR no non-null records,
        this method will return None

        ~see qubles.core.quble.Quble.column_min_max
        """
        keyspace = self.validate_keyspace(
            keyspace=keyspace, grace=False, solo_required=True, time_space_required=True
        )
        max_datetime = self.column_min_max(space=keyspace, keyspace_required=True)[1]

        # Return the maximum of max_datetime & now()
        if max_datetime is None:
            return None
        elif not isinstance(max_datetime, datetime):
            raise Exception(
                f"column_min_max yielded type:{type(max_datetime)} but expected datetime.datetime"
            )
        else:
            # Access the frequency (freq) for this time-keyspace
            freq = self.get_space_info(
                info_type="freq",
                space=keyspace,
                grace=True,
                allow_infer=True,
                assign_inferred=True,
            )
            if freq is None:
                return max_datetime

            recent_datetime = Quble.recent_datetime_at_freq(freq)

            if recent_datetime is None:
                return max_datetime
            elif not isinstance(recent_datetime, datetime):
                raise Exception(
                    f"recent_datetime_at_freq yielded type:{type(recent_datetime)} but expected datetime.datetime"
                )
            else:
                return max(recent_datetime, max_datetime)

    def min_datetime1d(self, keyspace: str = "<first_time_keyspace>"):
        """
        Returns the minimum datetime from the specified time-keyspace as a
        Python scalar with type as translated from column's sql type

        **Notes:**
        Will return a datetime.datetime instance

        If there are no records OR no non-null records,
        this method will return None

        ~see qubles.core.quble.Quble.column_min_max
        """
        keyspace = self.validate_keyspace(
            keyspace=keyspace, grace=False, solo_required=True, time_space_required=True
        )
        return self.column_min_max(space=keyspace, keyspace_required=True)[0]

    def max_datetime1d(self, keyspace: str = "<first_time_keyspace>"):
        """
        Returns the maximum datetime from the specified keyspace as a
        Python scalar with type as translated from column's sql type

        **Notes:**
        Will return a datetime.datetime instance

        If there are no records OR no non-null records,
        this method will return None

        ~see qubles.core.quble.Quble.column_min_max
        """
        keyspace = self.validate_keyspace(
            keyspace=keyspace, grace=False, solo_required=True, time_space_required=True
        )
        return self.column_min_max(space=keyspace, keyspace_required=True)[1]

    def min_max_datetime1d(self, keyspace: str = "<first_time_keyspace>"):
        """
        Returns minimum and maximum datetime from the specified keyspace as a
        two-element tuple of Python scalars with types as translated from column's sql type

        **Notes:**
        Will return a tuple of datetime.datetime instances

        If there are no records OR no non-null records,
        this method will return (None,None)

        ~see qubles.core.quble.Quble.column_min_max
        """
        keyspace = self.validate_keyspace(
            keyspace=keyspace, grace=False, solo_required=True, time_space_required=True
        )
        return self.column_min_max(space=keyspace, keyspace_required=True)

    def min_key1d(self, keyspace: str = "<first_keyspace>"):
        """
        Returns the minimum key from the specified keyspace as a
        Python scalar with type as translated from column's sql type

        **Notes:**
        For time-spaces (datetime/timestamp column types in sql)
        Will return a datetime.datetime instance

        If there are no records OR no non-null records,
        this method will return None

        ~see qubles.core.quble.Quble.column_min_max
        """
        return self.column_min_max(space=keyspace, keyspace_required=True)[0]

    def max_key1d(self, keyspace: str = "<first_keyspace>"):
        """
        Returns the maximum key from the specified keyspace as a
        Python scalar with type as translated from column's sql type

        **Notes:**
        For time-spaces (datetime/timestamp column types in sql)
        Will return a datetime.datetime instance

        If there are no records OR no non-null records,
        this method will return None

        ~see qubles.core.quble.Quble.column_min_max
        """
        return self.column_min_max(space=keyspace, keyspace_required=True)[1]

    def min_max_key1d(self, keyspace: str = "<first_keyspace>"):
        """
        Returns minimum and maximum keys from the specified keyspace as a
        two-element tuple of Python scalars with types as translated from column's sql type

        **Notes:**
        For time-spaces (datetime/timestamp column types in sql)
        Will return a tuple of datetime.datetime instances

        If there are no records OR no non-null records,
        this method will return (None,None)

        ~see qubles.core.quble.Quble.column_min_max
        """
        return self.column_min_max(space=keyspace, keyspace_required=True)

    def column_min(self, space: str, keyspace_required=False):
        """
        Returns minimum value of a given column (space) as a
        Python scalar with type as translated from column's sql type

        **Notes:**
        For time-spaces (datetime/timestamp column types in sql)
        Will return a datetime.datetime instance

        If there are no records OR no non-null records,
        this method will return None

        ~see qubles.core.quble.Quble.column_min_max
        """
        return self.column_min_max(space=space, keyspace_required=keyspace_required)[0]

    def column_max(self, space: str, keyspace_required=False):
        """
        Returns maximum value of a given column (space)
        as a Python scalar with type as translated from column's sql type

        **Notes:**
        For time-spaces (datetime/timestamp column types in sql)
        Will return a datetime.datetime instance

        If there are no records OR no non-null records,
        this method will return None

        ~see qubles.core.quble.Quble.column_min_max
        """
        return self.column_min_max(space=space, keyspace_required=keyspace_required)[1]

    def column_min_max(self, space: str, keyspace_required=False) -> tuple:
        """
        Returns minimum and maximum values of a given column (space)
        and returns a two-element tuple (min,max)
        where each value represents the Python scalar
        of minimum value / maximum value respectively

        **Notes:**
        For time-spaces (datetime/timestamp column types in sql)
        Will return a tuple of datetime.datetime instances

        For undefined Qubles (no table), will throw an Exception

        If there are no records OR no non-null records,
        this method will return (None,None)

        **Args:**
        :param space: The column name
        :type space: str

        :param keyspace_required: flag requiring keyspace column be used
        :type keyspace_required: bool (False*/True)
          ==> if keyspace_required==False: column can be either keyspace or valuespace
          ==> if keyspace_required==True: column must be a keyspace of the Quble

        :returns: A tuple containing (min,max)
        :rtype param: tuple (two-elements)
        """
        # Validate space arg
        # [Is this a valid column of the table for this Quble?]
        # NOTE: This step will trap for undefined Quble (self)
        space = self.validate_space(
            space, keyspace_required=keyspace_required, grace=False
        )

        # Handle trivial case
        if self.is_empty:
            # [We can short-circuit here to avoid uncessary overhead]
            return (None, None)

        # Render appropriate sql command using the related template
        sql_template = JINJA_ENV.get_template("column_min_max.j2")
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            space=space,
        )
        result = execute(sql_command, fetch="all")

        # Here, result will be a list of tuples
        # Ideally, in this case, one-row (single-element list) with two columns (two-element tuple)
        if result is None or len(result) == 0:
            return (None, None)
        elif len(result) > 1:
            raise Exception(f"Single row expected but received # rows:{len(result)}")
        elif len(result[0]) != 2:
            raise Exception(
                f"Two columns expected but received # columns:{len(result[0])}"
            )
        else:
            # minimum is first column of first/only row in result: result[0][0]
            # maximum is second column of first/only row in result: result[0][1]
            min_key = result[0][0]
            max_key = result[0][1]
            return (min_key, max_key)

    @property
    def keyspaces_with_null_keys(self) -> list:
        ks_with_nulls = []

        if self.is_undefined:
            return ks_with_nulls

        for ks in self.keyspaces:
            if self.has_nulls(ks):
                ks_with_nulls.append(ks)

        return ks_with_nulls

    @property
    def keyspaces_without_null_keys(self) -> list:
        ks_without_nulls = []

        if self.is_undefined:
            return ks_without_nulls

        for ks in self.keyspaces:
            if not self.has_nulls(ks):
                ks_without_nulls.append(ks)

        return ks_without_nulls

    @property
    def keyspaces_with_non_null_keys(self) -> list:
        ks_with_non_nulls = []
        if self.is_undefined:
            return ks_with_non_nulls

        for ks in self.keyspaces:
            if self.has_non_nulls(ks):
                ks_with_non_nulls.append(ks)

        return ks_with_non_nulls

    @property
    def num_nulls_all_spaces(self) -> dict:
        """
        Returns a dictionary of the number of null records for each space in the Quble.
        :returns: dict
        """
        # Does a cache exist already?
        if "num_nulls_all_spaces" not in self._cache:
            if self.is_undefined or len(self.spaces) == 0 or self.table_name is None:
                # Case #2: undefined (trivial) Quble
                # Leave the cache as an empty dictionary here
                self._cache["num_nulls_all_spaces"] = {}
                pass
            elif self.is_empty:
                # Case #3: Empty Quble
                # NOTE: Handle special case of no records as the select query below will not work properly
                # (will yield null results) when there are no records
                self._cache["num_nulls_all_spaces"] = {}
                for space in self.spaces:
                    self._cache["num_nulls_all_spaces"][space] = 0
            else:
                # Case #4: non-trivial, non-empty Quble
                # Step 4A: Generate a query to count the number of nulls across each column/space
                selections = []
                for space in self.spaces:
                    selections.append(f'COUNT(*) - COUNT("{space}") AS "{space}"')

                # Step 4B: Submit the query
                sql_command = (
                    f"SELECT {', '.join(selections)} FROM {dquote_dot(self.table_name)}"
                )
                result = execute(sql_command, fetch="all")

                # Step 4C: Process the results of the query and populate cache dictionary
                # Here, result will be a list of tuples
                # Ideally, in this case, one-row (single-element list) with two columns (two-element tuple)
                if result is None:
                    raise Exception(f"No result from sql_command:{sql_command}")
                elif len(result) != 1:
                    raise Exception(
                        f"Single row expected but received # rows:{len(result)}"
                    )
                elif len(result[0]) != self.num_spaces:
                    raise Exception(
                        f"{self.num_spaces} columns expected but received # columns:{len(result[0])}"
                    )
                else:
                    # Waiting to declare down here to avoid race conditions
                    self._cache["num_nulls_all_spaces"] = {}
                    for i, space in enumerate(self.spaces):
                        self._cache["num_nulls_all_spaces"][space] = result[0][i]

        return deepcopy(self._cache["num_nulls_all_spaces"])

    @property
    def num_non_nulls_all_spaces(self) -> dict:
        """
        Returns a dictionary of the number of non-null records for each space in the Quble.
        :returns: dict
        """
        # Does a cache exist already?
        if "num_non_nulls_all_spaces" not in self._cache:
            # Handle various use cases...
            if self.is_undefined or len(self.spaces) == 0 or self.table_name is None:
                # Case #2: undefined (trivial) Quble
                # Leave the cache as an empty dictionary here
                self._cache["num_non_nulls_all_spaces"] = {}
                pass
            elif self.is_empty:
                # Case #3: empty Quble
                # NOTE: Handle special case of no records as the select query below will not work properly
                # (will yield null results) when there are no records
                self._cache["num_non_nulls_all_spaces"] = {}
                for space in self.spaces:
                    self._cache["num_non_nulls_all_spaces"][space] = 0
            else:
                # Case #4: non-trivial, non-empty Quble
                # Step 4A: Generate a query to count the number of non-nulls across each column/space
                selections = []
                for space in self.spaces:
                    selections.append(
                        'SUM(CASE WHEN "'
                        + space
                        + '" IS NOT NULL THEN 1 ELSE 0 END) AS "'
                        + space
                        + '"'
                    )
                sql_command = (
                    "SELECT "
                    + ", ".join(selections)
                    + " FROM "
                    + dquote_dot(self.table_name)
                    + ";"
                )

                # Step 4B: Submit the query
                result = execute(sql_command, fetch="all")

                # Step 4C: Process the results of the query and populate cache dictionary
                # Here, result will be a list of tuples
                # Ideally, in this case, one-row (single-element list) with two columns (two-element tuple)
                if result is None:
                    raise Exception(f"No result from sql_command:{sql_command}")
                elif len(result) != 1:
                    raise Exception(
                        f"Single row expected but received # rows:{len(result)}"
                    )
                elif len(result[0]) != self.num_spaces:
                    raise Exception(
                        f"{self.num_spaces} columns expected but received # columns:{len(result[0])}"
                    )
                else:
                    # Waiting to declare down here to avoid race conditions
                    self._cache["num_non_nulls_all_spaces"] = {}
                    for i, space in enumerate(self.spaces):
                        self._cache["num_non_nulls_all_spaces"][space] = result[0][i]

        return deepcopy(self._cache["num_non_nulls_all_spaces"])

    def expand_null_keys(
        self,
        expansion_keyspaces="<keyspaces_with_null_keys>",
        handle_multiple_replacees: bool = False,
        key_ordering: str = None,
    ) -> Quble:
        """
        Expands null keys by replacing with non-null crossers
        """
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_scalar or self.is_empty:
            return self.copy()
        elif len(self.keyspaces) == 0:
            return self.copy()

        # Establish expansion_keyspaces
        # --------------------------------
        keyspaces_with_null_keys = self.keyspaces_with_null_keys
        if (
            expansion_keyspaces is None
            or expansion_keyspaces == "<keyspaces_with_null_keys>"
            or expansion_keyspaces == "<keyspaces>"
            or expansion_keyspaces == "<all>"
        ):
            expansion_keyspaces = keyspaces_with_null_keys
        elif isinstance(expansion_keyspaces, (list, tuple)):
            # Only expand subset of specified expansion_keyspaces that have null keys
            expansion_keyspaces = [
                ks for ks in expansion_keyspaces if ks in keyspaces_with_null_keys
            ]
        elif isinstance(expansion_keyspaces, str):
            expansion_keyspaces = [
                ks for ks in [expansion_keyspaces] if ks in keyspaces_with_null_keys
            ]
        else:
            raise Exception(
                "Invalid expansion_keyspaces:{0}...None/list/tuple/str"
                + " or <keyspaces_with_null_keys> or <keyspaces> or <all> expected"
            )

        # Exit early for no expansion case
        if expansion_keyspaces is not None and len(expansion_keyspaces) == 0:
            return self.copy()

        table_name = generate_random_table_name()
        sql_template = JINJA_ENV.get_template("expand_null_keys.j2")
        # ----------------------------------------------------
        # Arguments for expand_null_keys template
        # ----------------------------------------------------
        # expansion_table_name: name of table to be expanded
        # tgt_table_name: target table name
        # keyspaces: list of the keyspaces of the table
        # nonkeyspaces: other non-keyspaces spaces (columns) (if present)
        # expansion_keyspaces: (optional) list of keyspaces for null expansion
        #     if none, then all keyspaces will be applied
        # handle_multiple_replacees: (Optional) flag for handling possible multiple replacees
        #      for a given complement key combination
        # key_ordering: controls ordering of result
        # ----------------------------------------------------
        sql_command = sql_template.render(
            expansion_table_name=self.table_name,
            tgt_table_name=table_name,
            keyspaces=self.keyspaces,
            nonkeyspaces=self.valuespaces,
            expansion_keyspaces=expansion_keyspaces,
            handle_multiple_replacees=handle_multiple_replacees,
            key_ordering=key_ordering,
        )
        execute(sql_command, format_flag=False)

        # Instantiate Quble from the new table
        result = Quble.from_table(
            table_name,
            col_info=self.get_space_info(
                info_type=CUSTOM_INFO_TYPES,
                space=self.column_names,
                omit_unassigned=True,
            ),
        )

        if self.valuespace is not None and len(self.valuespaces) > 1:
            result.valuespace = result._get_primary_valuespace(
                preferred_vs=self.valuespace, grace=False
            )

        return result

    def num_unique_non_missing(self, space: str = "<valuespace>") -> int:
        return self.num_unique(space=space, include_missing=False)

    def num_unique(self, space: str = "<valuespace>", include_missing=False) -> int:
        space = self.validate_space(space, solo_required=True, grace=False)
        if include_missing:
            return self._inspect_num_unique(space=space)
        else:
            return self._inspect_num_unique(
                space=space, where_clause=f'"{space}" IS NOT NULL'
            )

    def uniques(
        self,
        space: str = "<valuespace>",
        include_missing: bool = False,
        coerce_to_list: bool = False,
        ordering: str = None,
    ):
        """
        Yields a numpy-array (or list) of the unique values
        from the specified (key/value) space

        :param space: The categorical space/column of interest
        :type space: str

        :param include_missing: Flag to include null/missing instance in result
        :type include_missing: bool (False*/True)

        :param coerce_to_list: Flag to coerce result to list
                               (otherwise, a numpy array will be returned)
        :type coerce_to_list: bool (False*/True)

        :param ordering: (optional) control for ordering of results
        :type ordering: str ('asc' or 'desc')

        :rtype: numpy-array (or list)
        :returns: the unique values from the specified (key/value) space
        """
        if self.is_undefined:
            return None

        space = self.validate_space(space, solo_required=True, grace=False)

        # Implement main query
        sql_command = f'SELECT DISTINCT "{space}" FROM "{self.table_name}"'

        # Implement filtering (if applicable)
        if not include_missing:
            sql_command += (' WHERE "{0}" IS NOT NULL').format(space)

        # Implement ordering (if applicable)
        if ordering is None:
            pass
        elif not isinstance(ordering, str):
            raise Exception(f"Invalid ordering arg:{ordering}...None/str expected")
        else:
            sql_command += (' ORDER BY "{0}" {1}').format(space, ordering)

        result = execute(sql_command, fetch="all")

        if result is None:
            return None
        elif coerce_to_list:
            # [0] will isolate the first (and only) column from the query (post zip(*))
            return list(np.array(list(zip(*result))[0]))
        else:
            # [0] will isolate the first (and only) column from the query (post zip(*))
            return np.array(list(zip(*result))[0])

    def unique_counts(
        self, space: str = "<valuespace>", include_missing: bool = False
    ) -> dict:
        """
        Yields a dictionary where:
           ==> dictionary keys are unique elements of the specified column space
           ==> dictionary values are their respective counts
        NOTE: Here the dictionary keys are ordered in descending count order
        """
        if self.is_undefined:
            return None

        space = self.validate_space(space, solo_required=True, grace=False)
        if include_missing:
            sql_command = (
                'SELECT "{0}", COUNT("{0}") FROM "{1}" GROUP BY "{0}" ORDER BY COUNT("{0}") DESC'
            ).format(space, self.table_name)
        else:
            sql_command = (
                'SELECT "{0}", COUNT("{0}") FROM "{1}" WHERE "{0}" IS NOT NULL GROUP BY "{0}" ORDER BY COUNT("{0}") DESC'
            ).format(space, self.table_name)

        result = execute(sql_command, fetch="all")

        if not result:
            return None

        # Use the (two-column) query result to build a dictionary where:
        #    keys: (unique records from space column) (first column from query)
        #    values: the associated (group by) counts (second column from query)
        # -------------------------------------------------------------------------
        return dict(result)

    def non_contiguous_ortho_keys(
        self, keyspace: str = "<first_time_keyspace>"
    ) -> bool:
        """
        Returns an index (non-variate) Quble providing the
        'ortho' keys (orthognal, non-time keys) across the ortho keyspaces
        where each associated 'ortho time-series' in the self Quble
        is 'non-contiguous' (i.e., has 'non-contiguous' (time) keys)

        Where each associated ortho time-series has 'temporal gaps'
        according to the frequency profile of the time-calendar table

        Will raise Exception when specified (time) keyspace is absent

        Will return an undefined Quble in following scenarios:
            1) self Quble is undefined
            2) self Quble as a uni-scalar or multi-scalar
            3) No 'orthogonal' (non-time) keyspaces are present

        :param keyspace: (time) keypace to analyze contiguousness
        :type keyspace: str

        :rtype: (index) Quble
        :returns: (index) Quble where
            columns reflect orthogonal keyspaces and
            keys reflect orthogonal keys for which the
            associated time-series in self is non-contiguous
        """
        return self._contiguous_ortho_keys(keyspace=keyspace, non_contiguous_flag=True)

    def contiguous_ortho_keys(self, keyspace: str = "<first_time_keyspace>") -> bool:
        """
        Returns an index (non-variate) Quble providing the
        'ortho' keys (orthognal, non-time keys) across the ortho keyspaces
        where each associated 'ortho time-series' in the self Quble
        is 'contiguous' in time (i.e., has 'contiguous' (time) keys)

        Where each associated ortho time-series has NO 'temporal gaps'
        according to the frequency profile of the time-calendar table

        Will raise Exception when specified (time) keyspace is absent

        Will return an undefined Quble in following scenarios:
            1) self Quble is undefined
            2) self Quble as a uni-scalar or multi-scalar
            3) No 'orthogonal' (non-time) keyspaces present

        :param keyspace: (time) keypace to analyze contiguousness
        :type keyspace: str

        :rtype: (index) Quble
        :returns: (index) Quble where
            columns reflect orthogonal keyspaces and
            keys reflect orthogonal keys for which the
            associated time-series in self is contiguous
        """
        return self._contiguous_ortho_keys(keyspace=keyspace, non_contiguous_flag=False)

    def _contiguous_ortho_keys(self, keyspace, non_contiguous_flag) -> bool:
        """
        Helper method for (non)contiguous ortho keys
        """
        # Handle trivial cases
        if self.is_undefined:
            return Quble.undefined_instance()

        # Confirm that we have been given a valid time-keyspace
        keyspace = self.validate_keyspace(
            keyspace=keyspace, grace=False, solo_required=True, time_space_required=True
        )

        # Get the underlying time-frequency
        # for the specified time-keyspace
        frequency = self.get_space_info(
            info_type="freq",
            space=keyspace,
            grace=True,
            space_info_mode="space",
            allow_infer=True,
            assign_inferred=True,
        )

        # Establish ortho_keyspaces, and exit early
        # if/when no ortho_keyspaces present
        ortho_keyspaces = [ks for ks in self.keyspaces if ks != keyspace]
        if len(ortho_keyspaces) == 0:
            return Quble.undefined_instance()

        # -------------------------------------------------------
        # Template arguments:
        # -------------------------------------------------------
        #   time_keyspace: time keyspace to be checked
        #   src_table_name: the original table name
        #   frequency: the frequency of time keyspace in source table
        #   calendar_table_name: name of calendar table
        #   ortho_keyspaces: "orthogonal" (non-time) keyspaces
        # -------------------------------------------------------
        tgt_table_name = generate_random_table_name()
        sql_template = JINJA_ENV.get_template("contiguous_ortho_keys.j2")
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            tgt_table_name=tgt_table_name,
            calendar_table_name=RootLib().get_control("calendar_table_name"),
            time_keyspace=keyspace,
            frequency=frequency,
            ortho_keyspaces=ortho_keyspaces,
            non_contiguous_flag=non_contiguous_flag,
        )
        execute(sql_command, format_flag=False)

        # Build a index Quble from the new table that was
        # populated with the results of the sql_command
        # Also, copy over any meta-data for the ortho-keyspaces
        # from the original table (self)
        return Quble.from_table(
            tgt_table_name,
            valuespace=[],
            col_info=self.get_space_info(
                info_type=CUSTOM_INFO_TYPES,
                space=ortho_keyspaces,
                omit_unassigned=True,
            ),
        )

    def has_contiguous_keys(self, keyspace: str = "<first_time_keyspace>") -> bool:
        """
        Tests whether the Quble has contiguous representation
        across the specified time-keyspace
        for all orthogonal time-series

        In otherwords, are the time-keys for each/all orthogonal time-series
        for the specified time-keyspace 'contiguous' through time?
        """
        # Handle trivial cases
        if self.is_undefined:
            return False
        elif self.is_empty:
            return False
        elif self.is_scalar or self.is_multiscalar:
            return False

        # Confirm that we have been given a valid time-keyspace
        keyspace = self.validate_keyspace(
            keyspace=keyspace, grace=False, solo_required=True, time_space_required=True
        )

        # Get the underlying time-frequency
        # for the specified time-keyspace
        frequency = self.get_space_info(
            info_type="freq",
            space=keyspace,
            grace=True,
            space_info_mode="space",
            allow_infer=True,
            assign_inferred=True,
        )

        # -------------------------------------------------------
        # Template arguments:
        # -------------------------------------------------------
        #   time_keyspace: time keyspace to be checked
        #   src_table_name: the original table name
        #   frequency: the frequency of time keyspace in source table
        #   calendar_table_name: name of calendar table
        #   ortho_keyspaces: "orthogonal" (non-time) keyspaces
        # -------------------------------------------------------
        ortho_keyspaces = [ks for ks in self.keyspaces if ks != keyspace]
        sql_template = JINJA_ENV.get_template("has_contiguous_keys.j2")
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            calendar_table_name=RootLib().get_control("calendar_table_name"),
            time_keyspace=keyspace,
            frequency=frequency,
            ortho_keyspaces=ortho_keyspaces,
        )
        result = execute(sql_command, fetch="one", format_flag=False)[0]
        return result

    def _confirm_freq_hint(
        self,
        freq_hint=None,
        freq_hint_mode=None,
        tdistribute_mode="<space_root>",
        allow_shallow_copy=True,
        exceptions_flag: bool = False,
        inplace: bool = False,
    ) -> Quble:
        """
        Confirms whether the specified freq_hint was properly applied
        and handles unexpected frequency conflicts according to freq_hint_mode
        Returns Quble (possibly as a shallow-copy)

        :param freq_hint: (optional) frequency hint for frequency inference of time-keyspace(s)
            ==> NOTE: freq_hint should only be used if
            ==> table's column meta data DO NOT already
            ==> contain frequency information in column comments
        :type freq_hint: str, dictionary, None
            ==> None*: No hint
            ==> 'default_freq': use prevailing default frequency control from the RootLib()
            ==> str: will use the specified freq_hint for frequency inference against all time-keyspaces
            ==> dictionary: dictionary keys=(time) keyspaces, dictionary values=freq hint for a given keyspace
                            NOTE: when dictionary value=None, frequency inference is still performed but with no freq_hint

        :param freq_hint_mode: (optional) handling for frequency hint failure
        :type freq_hint_mode: str, dictionary, None
            If dict: dict keys=(time) keyspaces, dict values=freq hint mode for each time-keyspace
            Valid freq hint modes...
            ==> None*: graceful inference of alternative frequency that matches data
            ==> 'pass': pass on frequency hint failure
            ==> 'raise': raises Exception if hint fails
            ==> 'force': forces frequency hint but uses no time-basis during force
            ==> 'force_honor_tb': forces frequency hint while honoring prevailing time-basis
                              NOTE: Here, time-basis will be used to convert
                              from intermediate inferred freq to hint freq

        :param exceptions_flag: flag whether to generate exceptions Quble
        :type exceptions_flag: (boolean) False*/True

        :rtype: Quble
        :returns: Quble with confirmed freq hint
        """
        # Initialize subject
        # [Only refer to subject (not self) hereafter within this method]
        subject = self if allow_shallow_copy else self.copy()

        # Handle trivial cases
        if freq_hint is None or freq_hint_mode is None or subject.is_undefined:
            return subject

        # ===================== START: TIME-SPACE LOOP =====================
        for time_space1 in subject.time_spaces:
            # Access the frequency (freq1) for this time-space (time_space1)
            freq1 = subject.get_space_info(
                info_type="freq",
                space=time_space1,
                grace=True,
                allow_infer=True,
                assign_inferred=True,
            )
            if freq1 is None:
                # No frequency to validate...continue here?
                # [Could also consider throwing an Exception here]
                continue

            # Get freq_hint for this time-keyspace
            if freq_hint is None:
                # We likely already check for this case above
                freq_hint1 = None
            elif isinstance(freq_hint, str):
                freq_hint1 = freq_hint
            elif not isinstance(freq_hint, dict):
                raise Exception(
                    f"Invalid freq_hint:{freq_hint} w/type:{type(freq_hint)}...expected str, dict or None"
                )
            elif time_space1 not in freq_hint:
                freq_hint1 = None
            else:
                freq_hint1 = freq_hint[time_space1]

            # Continue to next time-keyspace if freq_hint1 is None
            if freq_hint1 is None:
                continue
            elif not (freq_hint1, str):
                # Require that freq_hint1 is str or None
                raise Exception(
                    f"Invalid freq_hint:{freq_hint1} for keyspace:{time_space1}...str or None expected"
                )

            # Continue to next time-keyspace if freq1 == freq_hint1
            if freq1 == freq_hint1:
                # frequency conforms to hint as suggested (no conflict)
                continue

            # Get freq_hint_mode for this time-keyspace
            if freq_hint_mode is None:
                # We likely already checked for this case above
                freq_hint_mode1 = None
            elif isinstance(freq_hint_mode, str):
                freq_hint_mode1 = freq_hint_mode
            elif not isinstance(freq_hint_mode, dict):
                raise Exception(
                    f"Invalid freq_hint_mode:{freq_hint_mode} w/type:{type(freq_hint_mode)}...expected str, dict or None"
                )
            elif time_space1 not in freq_hint_mode:
                freq_hint_mode1 = None
            else:
                freq_hint_mode1 = freq_hint_mode[time_space1]

            # -------------------------------------
            # Handle freq conflict with freq_hint
            # according to freq_hint_mode1
            # -------------------------------------
            if freq_hint_mode1 is None:
                # Continue to next time-keyspace if freq_hint_mode1 is None
                continue
            elif not (freq_hint_mode1, str):
                # Require that freq_hint_mode1 is str or None
                raise Exception(
                    f"Invalid freq_hint_mode:{freq_hint_mode1} for time-space:{time_space1}...str or None expected"
                )
            elif freq_hint_mode1 == "pass":
                continue
            elif freq_hint_mode1 == "raise":
                raise Exception(
                    f"time-space:{time_space1} freq:{freq1} conflicts with freq_hint:{freq_hint1} and freq_hint_mode:{freq_hint_mode1}"
                )
            elif freq_hint_mode1 in ("force", "force_honor_tb"):
                if time_space1 in subject.valuespaces:
                    # for valuespace frequency conversions
                    subject = subject.convert_date_values(
                        space=time_space1, freq=freq_hint1
                    )
                elif time_space1 not in subject.keyspaces:
                    raise Exception(
                        f"time_space1:{time_space1} absent from both keyspaces:{subject.keyspaces} and valuespaces:{subject.valuespaces}"
                    )
                else:
                    if freq_hint_mode1 == "force_honor_tb":
                        # for keyspace frequency conversions
                        # w/freq_hint_mode == 'force_honor_tb'
                        time_basis_override1 = "<no override>"
                    else:
                        # for keyspace frequency conversions
                        # w/freq_hint_mode == 'force'
                        # Use following syntax for imposing time_basis=None
                        time_basis_override1 = "<None>"

                    subject.asfreq(
                        freq=freq_hint1,
                        keyspace=time_space1,
                        time_basis_override=time_basis_override1,
                        tdistribute_mode=tdistribute_mode,
                        exceptions_flag=exceptions_flag,
                        inplace=inplace,
                    )
            else:
                raise Exception(
                    f"Invalid freq_hint_mode:{freq_hint_mode1} for time-space:{time_space1}"
                )

        # ====================== END: TIME-SPACE LOOP ======================

        return subject

    # ================================== COLUMN INFO ==================================

    def _column_is_string_variant(self, space="<all>", grace: bool = True):
        types = self.get_space_info(info_type="type", space=space, grace=grace)

        string_types = (
            "blob",
            "clob",
            "char",
            "character",
            "string",
            "varchar",
            "text",
        )

        if isinstance(types, (list, tuple)):
            is_string_variant = [t in string_types for t in types]
        else:
            is_string_variant = types in string_types

        return is_string_variant

    def get_column_type(self, space="<all>"):
        """
        Retreives column type(s) for the specified space(s)
        """
        if space == "<all>":
            space = self.spaces
        if isinstance(space, list):
            return {x: self.get_column_type(x) for x in space}
        else:
            if space in self._column_info["type"]:
                return self._column_info["type"][space]
            raise Exception(f"Column type is not present for column: {space}")

    def info_types(
        self,
        column_names="<all>",
        include_builtins: bool = True,
        include_custom: bool = True,
        info_type_exclusions: list = [],
    ) -> list:
        """
        Returns a list of all applicable info_types (both built-in and custom)
        assigned within any of the spaces (columns) of the Quble
        """
        if column_names == "<all>":
            column_names = self.column_names

        info_types = []
        for info_type in self._column_info.keys():
            if (
                info_type in info_type_exclusions
                or len(
                    [
                        value
                        for value in column_names
                        if value in self._column_info[info_type].keys()
                    ]
                )
                == 0
            ):
                continue
            elif (info_type in BUILTIN_INFO_TYPES and include_builtins) or (
                info_type in CUSTOM_INFO_TYPES and include_custom
            ):
                info_types.append(info_type)

        return info_types

    def custom_info_types(
        self, column_names="<all>", info_type_exclusions: list = []
    ) -> list:
        """
        Returns a list of all 'custom" (non-built-in) info_types
        assigned within any of the specified spaces (columns) of the Quble
        excluding any of the specified (custom) info types for exclusion
        """
        return self.info_types(
            column_names=column_names,
            include_builtins=False,
            include_custom=True,
            info_type_exclusions=info_type_exclusions,
        )

    @property
    def column_names(self) -> list:
        """
        Returns a list of column names (spaces) of the Quble
        """
        return self.spaces

    @property
    def column_info(self) -> dict:
        """
        Returns a dict of column info of the Quble
        """
        # NOTE: Need to return a deep copy here,
        # otherwise calling program can alter self._column_info
        return deepcopy(self._column_info)

    def set_multi_space_info(self, space_info):
        """
        Assign custom metadata space info where/as provided.
        Retains any pre-existing space info not being over-written
        Changes/modifies self (does not return a new Quble)

        :type space_info: dict
        :param space_info: new space info to be assigned

        outer dictionary keys: info_type
        outer dictionary values: inner dictionary
        inner dictionary keys: column_name
        inner dictionary values: associated info_type_assignment

        :returns: updated space info as a dictionary
            ==> INCLUDES NEW AS WELL AS PREVIOUS INFO ASSIGNMENTS PER SPECIFIED COLUMNS
        :rtype: nested dictionary (of dictionaries) keyed by info_type
        """
        # Handle trivial cases
        if self.is_undefined:
            return self
        elif space_info is None:
            # No changes provided
            return self
        elif not isinstance(space_info, dict):
            # Invalid arg
            raise Exception(
                f"Invalid type(space_info):{type(space_info)}...dict (or None) expected"
            )

        # Consolidate new space info into self._column_info (dict)
        change_flag = False
        orig_keyspaces = self.keyspaces  # <-- returns deepcopy of self._keyspaces
        for info_type, info_assignments in space_info.items():
            if info_type is None:
                continue
            elif info_assignments is None:
                continue

            if info_type not in self._column_info:
                self._column_info[info_type] = {}

            for column_name, info_value in info_assignments.items():
                if column_name not in self.column_names:
                    raise Exception(
                        f"column_name:{column_name} absent from self.column_names:{self.column_names}"
                    )
                if (
                    column_name not in self._column_info[info_type]
                    or info_value != self._column_info[info_type][column_name]
                ):
                    # This is a new or changed info assignment
                    change_flag = True
                    self._column_info[info_type][column_name] = info_value

        # Did any of the column info change?
        if change_flag:
            # Establish new primary valuespace
            # [Perhaps previous primary valuespace now has a keyspace role?]
            old_valuespace = self.valuespace
            if (
                old_valuespace is not None
                and "role" in self._column_info
                and old_valuespace in self._column_info["role"]
                and self._column_info["role"][old_valuespace] == "valuespace"
            ):
                # Retain existing valuespace when applicable
                new_valuespace = old_valuespace
            else:
                # Otherwise, establish new primary valuespace through inspection
                new_valuespace = "<inspect>"

            # self._clear_cache()
            self._initialize_space_roles(valuespace=new_valuespace)
            # For environment tables, apply multi_col_info_custom_writer
            # [This will persist the new column_info to table comments]
            if is_env_table(self.table_name):
                self.touch()
                multi_col_info_custom_writer(self.table_name, self._column_info)

            if orig_keyspaces != self.keyspaces:
                self._clear_cache(which_cache="has_duplicate_keys")

        # Return self
        return self

    def set_space_info(self, space, info_type: str, info_value=None):
        """Assign custom metadata scalar value to the specified space(s)/column(s).
            Changes/modifies self (does not return a new Quble)

            Only custom metadata can be written. The following metadata is supported:

                fx - An ISO currency code, meaning the column contains currency data
                time_basis - Controls behavior when changing time-frequencies
                freq - The frequency, used when the column contains time series data
                role - The role of the column with respect to the Quble (keyspace, valuespace)

            :type space: str or list/tuple of str
            :param space: Set metadata for this column (or columns).

            :type info_type: str
            :param info_type: The name of the metadata type to set.

            :type info_value: any
            :param info_value:
                The value to set as the column metadata.

        :returns: updated space info as a dictionary
            ==> INCLUDES NEW AS WELL AS PREVIOUS INFO ASSIGNMENTS PER SPECIFIED COLUMNS
        :rtype: nested dictionary (of dictionaries) keyed by info_type

            outer dictionary keys: info_type
            outer dictionary values: inner dictionary
            inner dictionary keys: column_name
            inner dictionary values: associated info_type_assignment
        """
        if info_type == DUMMY_INFO_TYPE_FOR_UNIQUE_NUMPY_TITLES:
            return  # <-- These were just added to make titles unique in numpy struct array
        if info_type in BUILTIN_INFO_TYPES:
            raise ValueError(
                "Cannot assign (built-in) info type: {0}".format(info_type)
            )

        column_names = self.validate_space(space=space, coerce_to_list=True)
        # clear the cache for 'info_types' if applicable
        if info_type in column_names:
            raise Exception(
                f"Cannot assign info_type that matches colname: {info_type}. Double check the order of your params."
            )

        if not isinstance(column_names, (list, tuple)):
            column_names = [column_names]

        orig_keyspaces = self.keyspaces  # <-- returns deepcopy of self._keyspaces
        write_changes = False
        if info_type not in self._column_info:
            self._column_info[info_type] = {}
        for column_name in column_names:
            if (
                column_name not in self._column_info[info_type]
                or info_value != self._column_info[info_type][column_name]
            ):
                write_changes = True
                self._column_info[info_type][column_name] = info_value

        self._initialize_space_roles(self.valuespace)
        if write_changes and is_env_table(self.table_name):
            self.touch()
            multi_col_info_custom_writer(self.table_name, self._column_info)

        if orig_keyspaces != self.keyspaces:
            self._clear_cache(which_cache="has_duplicate_keys")

        return self.column_info

    def remove_space_info(self, space, info_type: str):
        """Removes custom metadata to the specified space(s)/column(s).

        :type column_names: str or list of str
        :param column_names: set info type (metadata) for this column(s)

        :type info_type: str
        :param info_type: name of info type (metadata) type to set
        """
        if self.is_undefined:
            raise UndefinedQubleError("Undefined Quble (no table)")
        if info_type is None:
            raise Exception("info_type required")
        if info_type == "role":
            raise Exception(
                "Cannot remove space info assignment of 'role'. Each col must contain a role assignement (keyspace, valuespace)."
            )

        column_names = self.validate_space(space=space, coerce_to_list=True)

        write_changes = False
        for column_name in column_names:
            if column_name in self._column_info[info_type]:
                write_changes = True
                self._column_info[info_type].pop(column_name)
        if len(self._column_info[info_type]) == 0:
            self._column_info.pop(info_type)

        if write_changes and is_env_table(self.table_name):
            self.touch()
            multi_col_info_custom_writer(self.table_name, self._column_info)

        return self.column_info

    def has_space_info(
        self, info_type: str, space: str, freq_hint="default_freq"
    ) -> bool:
        """
        Returns True if the specified space/column
        has an associated info_type (meta data) assignment

        :param info_type: info type (column meta data) requested
        :type info_type: str

        :param space: space/column for which info type is being requested
        :type space: str

        :param freq_hint: (optional) hint for frequency inference of time-space(s)
        :type freq_hint: str
            ==> None: No hint
            ==> 'default_freq': use prevailing default frequency control from the RootLib()
            ==> str: a specific freq_hint for frequency inference
        """
        if space is None:
            return False

        if self.is_undefined:
            raise UndefinedQubleError("Undefined Quble (no table)")

        # Validate the space provided
        space = self.validate_space(space=space, solo_required=True, grace=False)

        if space not in self.column_names:
            raise Exception(f"Absent/invalid space:{space}")
        elif (
            info_type not in self._column_info
        ):  # <-- Can happen if (custom) info_type is not being used by any columns
            return False
        elif space in self.time_spaces:
            if freq_hint == "default_freq":
                freq_hint = RootLib().get_control("freq")
            if (
                space in self._column_info[info_type]
                and freq_hint in self._column_info[info_type].values()
            ):
                return True
            else:
                return False
        elif space in self._column_info[info_type]:
            return True
        else:
            return False

    def get_spaces_infos(
        self, grace: bool = True, allow_infer: bool = True, assign_inferred: bool = True
    ) -> dict:
        """
        Returns all space info for all spaces/columns
        in the form of a dictionary of dictionaries

           ==> Outer dictionary keys: info_type
           ==> Outer dictionary value: inner dictionary
           ==> Inner dictionary key: column_name
           ==> Inner dictionary value: info_assignment
        """
        return self.get_space_info(
            info_type=self.info_types(),
            space="<all>",
            grace=grace,
            allow_infer=allow_infer,
            assign_inferred=assign_inferred,
        )

    def get_space_info(
        self,
        info_type,
        space,
        grace=True,
        space_info_mode="space",
        allow_infer=True,
        assign_inferred=True,
        omit_unassigned=False,
        unassigned_value=None,
        freq_hint="default_freq",
    ):
        """Returns metadata about specified space(s)/column(s) and info_type(s)

        built-in info types

        info_type can include the following "built-in" info (metadata) types

            id, name, type, default, null, number, storage

        custom info types

        Also supports these "custom" info (metadata) types:

            fx: An ISO currency code, meaning the column contains currency data
            time_basis: Controls behavior when changing time-frequencies
            freq: The frequency, used when the column contains time series data
            role: The role of the column with respect to the Quble (keyspace, valuespace)
            is_rankspace: Indicates a column is to be used as a "rankspace"
            is_primary: Indicates a column is to be used as a "primary" valuespace
            tfill_method: (default) time-filling method for the content in this column
            tfill_max: (default) maximum time-filling for this column (# periods at this frequecy)
            tfill_end_mode: (default) time-filling "end-mode" for this column
            tfill_honor_null: (default) time-filling "honor null" setting for this column
            tdistribute_mode: (default) time-distribution mode (when converting from higher-freq to lower-freq)
            keygroup: keygroup assignment for this column
            map_type: default "map type" for this column (~see qubles.core.quble.remap1d)
            map_basis: default "map basis" for this column (~see qubles.core.quble.remap1d)

        arguments

        :type info_type: str or list/tuple of strings (None is not accepted)
        :param info_type:
            Info type(s) (metadata) being requested.
            Can be a list of multiple metadata info types.

        :type space: str or list of str or dict (remapping) (None is not accepted)
        :param space:
            Return metadata for this space (column or columns).

            Use "<all>", "<keyspaces>" or "<valuespace>" or "<spaces>" or "<valuespaces>"
            to return metadata for all columns, keyspace columns
            or valuespace columns respectively.
            When `None`, returns metadata for all columns.

            Can provide space as a dict to return space info using remapped column names [Typically, this feature is used when getting space info in conjuntion
            with creating a new Quble with remapped column names]

        :type grace: bool
        :param grace:
            When True, throw an Exception if
            the table or any given column doesn't exist

        :type space_info_mode: str or list/tuple of strings
        :param space_info_mode:
            Controls augmentation of space_info with default controls from RootLib()
            'space': reference only the space's explicit info
            'root': reference only the RootLib() property
            'space_root': Primary: space's explicit info, Secondary: RootLib() control
            'root_space': Primary: RootLib() control, Secondary: space's explicit info

        :type allow_infer: bool (True*/False)
        :param allow_infer: flag to allow inference of time-frequencies

        :type assign_inferred: bool (True*/False)
        :param assign_inferred: flag to assign inferred time-frequencies

        :type omit_unassigned: bool (False*/True)
        :param assign_inferred: flag omit unassigned entries
                                in/for dictionary return structures
              ==> This feature ony applies to cases when
              ==> space arg is a list/tuple and/or info_type arg is a list/tuple
              ==> [does not apply when space arg is scalar and info_type arg is scalar]

        :type unassigned_value: str or None
        :param unassigned_value: the value to provide when
                                no info_type assignment exists

        :param freq_hint: (optional) hint for frequency inference of time-space(s)
        :type freq_hint: str
            ==> None: No hint
            ==> 'default_freq': use prevailing default frequency control from the RootLib()
            ==> str: a specific freq_hint for frequency inference

        :returns: space info assignment(s)
        :rtype: scalar string or dictionary or dict of dictionaries

            Case #1: if (space is a string)
                     and (info_type is a string):
              ==> returns a string

            Case #2: if (space=='<all>'/'<keyspaces>'/'<valuespaces>' or space is a list/tuple)
                     and (info_type is a string):
              ==> returns a dict keyed-on space

            Case #3: if (space is a string)
                     and (info_type=='<all>' or info_type is a list/tuple)
              ==> dict keyed-on info type for the specified column

            Case #4: if (space=='<all>'/'<keyspaces>'/'<valuespaces>' or space is a list/tuple)
                     and (info_type=='<all>' or info_type is a list/tuple)

              ==> returns a dict of dictionaries as follows:
              ==> Outer dictionary keys: info_type
              ==> Outer dictionary value: inner dictionary
              ==> Inner dictionary key: column_name
              ==> Inner dictionary value: info_assignment
        """
        if self.is_undefined:
            raise UndefinedQubleError("Undefined Quble (no table)")

        # Validate info_type arg
        # (and convert to list/tuple if needed)
        scalar_info_type_flag = (
            False  # <-- Initialization (was info_type arg provided as a scalar?)
        )
        if info_type is None:
            raise Exception(f"No info_type provided")
        elif isinstance(info_type, (list, tuple)):
            pass
        elif not isinstance(info_type, str):
            raise Exception(
                f"Invalid info_type:{info_type}...str or list/tuple of strings expected"
            )
        elif info_type == "<all>":
            info_type = self.info_types(column_names=space)
        elif info_type == "<builtin>":
            info_type = BUILTIN_INFO_TYPES
        elif info_type == "<custom>":
            info_type = CUSTOM_INFO_TYPES
        else:
            scalar_info_type_flag = True
            info_type = [info_type]

        # Validate space arg
        # (and convert to list/tuple if needed)
        scalar_space_flag = (
            False  # <-- Initialization (was space arg provided as a scalar?)
        )
        if space is None:
            raise Exception(f"No space provided")
        elif isinstance(space, (list, tuple, dict)):
            pass
        elif not isinstance(space, str):
            raise Exception(
                f"Invalid space:{space}...str or list/tuple of strings expected"
            )
        elif space == "<all>":
            space = self.spaces
        elif space == "<valuespace>":
            scalar_space_flag = True
            if self.valuespace is None:
                return None if scalar_info_type_flag else {}
            space = [self.valuespace]
        elif space == "<keyspaces>":
            space = self.keyspaces
        elif space == "<valuespaces>":
            space = self.valuespaces
        elif space == "<numeric_valuespaces>":
            space = self.numeric_valuespaces
        elif space == "<non_numeric_valuespaces>":
            space = self.numeric_valuespaces
        else:
            scalar_space_flag = True
            space = [space]

        # Infer freq data if necessary
        if allow_infer:
            space_list = space if not isinstance(space, dict) else space.keys()
            for space1 in space_list:
                if self.is_time_space(space1):
                    if "freq" not in self._column_info:
                        self._column_info["freq"] = {}
                    if space1 not in self._column_info["freq"]:
                        self._column_info["freq"][space1] = self._infer_freq(
                            space=space1,
                            freq_hint=freq_hint,
                            assign_inferred=assign_inferred,
                        )

        # ------------------------------------------------
        # omit_unassigned is not possible when
        # scalar_info_type_flag and scalar_space_flag
        # [as we need/want to return a scalar result]
        # ------------------------------------------------
        # In this case, we set omit_unassigned to False
        # to assure a result is generated and returned
        # ------------------------------------------------
        if scalar_info_type_flag and scalar_space_flag:
            omit_unassigned = False

        # -----------------------------------
        # Trap for invalid space_info_mode
        # -----------------------------------
        if space_info_mode not in ("space", "space_root", "root", "root_space"):
            raise Exception(f"Invalid space_info_mode:{space_info_mode}")

        root_assignments = {}
        space_assignments = {}
        # ====================== START: ROOT ASSIGNMENTS =====================
        if space_info_mode in ("root", "root_space", "space_root"):
            # Handle primary root control consultation (if applicable)
            # -------------------------------------------
            # space_info_mode: "root" or "root_space"
            # -------------------------------------------
            for info_type1 in info_type:
                # Validate info_type1
                if info_type1 is None:
                    raise Exception(f"Invalid info_type:{info_type1}")
                elif info_type1 == "name":
                    raise Exception(
                        f"Cannot use get_space_info to request:{info_type1}"
                    )

                if info_type1 in RootLib().CONTROL_PROPERTY_LIST:
                    info_assignment1 = RootLib().get_control(
                        property_name=info_type1, grace=False
                    )

                    if info_type1 not in root_assignments:
                        root_assignments[info_type1] = {}

                    if isinstance(space, dict):
                        for old_space1, new_space1 in space.items():
                            root_assignments[info_type1][new_space1] = info_assignment1
                    else:
                        for space1 in space:
                            root_assignments[info_type1][space1] = info_assignment1

                # Raise Exception for case:
                # root only reference and root control absent and no grace
                elif space_info_mode == "root":
                    if grace:
                        if isinstance(space, dict):
                            for old_space1, new_space1 in space.items():
                                root_assignments[info_type1][new_space1] = None
                        else:
                            for space1 in space:
                                root_assignments[info_type1][space1] = None
                    else:
                        raise Exception(
                            "space_info_mode:{0} yet control:{0} is absent from RootLib() and grace:{1}".format(
                                space_info_mode, grace
                            )
                        )
        # ======================= END: ROOT ASSIGNMENTS ======================

        # ====================== START: SPACE ASSIGNMENTS =====================
        # IMPORTANT..NOT AN elif BELOW!!!!
        if space_info_mode in ("space", "space_root", "root_space"):
            # Copy over relevant info type components from self._column_info to space_assignments
            for info_type1 in info_type:
                if isinstance(space, dict):
                    for old_space1, new_space1 in space.items():
                        if (
                            info_type1 in self._column_info
                            and self._column_info[info_type1] is not None
                            and old_space1 in self._column_info[info_type1]
                        ):
                            if info_type1 not in space_assignments:
                                space_assignments[info_type1] = {}
                            space_assignments[info_type1][new_space1] = (
                                self._column_info[info_type1][old_space1]
                            )
                else:
                    for space1 in space:
                        if (
                            info_type1 in self._column_info
                            and self._column_info[info_type1] is not None
                            and space1 in self._column_info[info_type1]
                        ):
                            if info_type1 not in space_assignments:
                                space_assignments[info_type1] = {}
                            space_assignments[info_type1][space1] = self._column_info[
                                info_type1
                            ][space1]

        # ======================= END: SPACE ASSIGNMENTS ======================

        if space_info_mode in ("root", "space"):
            info_assignments = (
                root_assignments if space_info_mode == "root" else space_assignments
            )
            if not omit_unassigned:
                # Insert unassigned_value entries where unassigned
                for info_type1 in info_type:
                    if (
                        info_type1 not in info_assignments
                        or info_assignments[info_type1] is None
                    ):
                        info_assignments[info_type1] = {}
                    if isinstance(space, dict):
                        for old_space1, new_space1 in space.items():
                            if new_space1 not in info_assignments[info_type1]:
                                info_assignments[new_space1][space1] = unassigned_value
                    else:
                        for space1 in space:
                            if space1 not in info_assignments[info_type1]:
                                info_assignments[info_type1][space1] = unassigned_value
        elif space_info_mode in ("space_root", "root_space"):
            info_assignments = (
                root_assignments
                if space_info_mode == "root_space"
                else space_assignments
            )
            secondary_assignments = (
                space_assignments
                if space_info_mode == "root_space"
                else root_assignments
            )
            for info_type1 in info_type:
                if isinstance(space, dict):
                    for old_space1, new_space1 in space.items():
                        if (
                            info_type1 in info_assignments
                            and info_assignments[info_type1] is not None
                            and new_space1 in info_assignments[info_type1]
                        ):
                            continue
                        elif (
                            info_type1 in secondary_assignments
                            and secondary_assignments[info_type1] is not None
                            and new_space1 in secondary_assignments[info_type1]
                        ):
                            if info_type1 not in info_assignments:
                                info_assignments[info_type1] = {}
                            info_assignments[info_type1][new_space1] = (
                                secondary_assignments[info_type1][new_space1]
                            )
                        elif not omit_unassigned:
                            if (
                                info_type1 not in info_assignments
                                or info_assignments[info_type1] is None
                            ):
                                info_assignments[info_type1] = {}
                            info_assignments[info_type1][new_space1] = unassigned_value
                else:
                    for space1 in space:
                        if (
                            info_type1 in info_assignments
                            and info_assignments[info_type1] is not None
                            and space1 in info_assignments[info_type1]
                        ):
                            continue
                        elif (
                            info_type1 in secondary_assignments
                            and secondary_assignments[info_type1] is not None
                            and space1 in secondary_assignments[info_type1]
                        ):
                            if info_type1 not in info_assignments:
                                info_assignments[info_type1] = {}
                            info_assignments[info_type1][space1] = (
                                secondary_assignments[info_type1][space1]
                            )
                        elif not omit_unassigned:
                            if (
                                info_type1 not in info_assignments
                                or info_assignments[info_type1] is None
                            ):
                                info_assignments[info_type1] = {}
                            info_assignments[info_type1][space1] = unassigned_value
        else:
            raise Exception(f"Invalid space_info_mode:{space_info_mode}")

        # -------------------------------
        # Handle various scalar inputs
        # -------------------------------
        if info_assignments is None:
            # Should not happen
            return info_assignments
        elif scalar_info_type_flag:
            if scalar_space_flag:
                # scalar_info_type_flag and scalar_space_flag
                # return a scalar result here
                if len(info_assignments) != 1:
                    # In this case, omit_unassigned should be False (forced above)
                    # so that there is expected to be a (single) dictionary entry here
                    # If not, throw an Exception
                    raise Exception(
                        f"scalar_info_type_flag:{scalar_info_type_flag} yet len(info_assignments):{len(info_assignments)}"
                    )
                info_type1 = list(info_assignments.keys())[0]
                if len(info_assignments[info_type1]) != 1:
                    # In this case, omit_unassigned should be False (forced above)
                    # so that there is expected to be a (single) dictionary entry here
                    # If not, throw an Exception
                    raise Exception(
                        f"scalar_space_flag:{scalar_space_flag} yet len(info_assignments[{info_type1}]):{len(info_assignments[info_type1])}"
                    )
                space1 = list(info_assignments[info_type1].keys())[0]
                return info_assignments[info_type1][space1]
            else:
                # scalar_info_type_flag and not scalar_space_flag
                # return a (non-nested) dictionary keyed on space
                if len(info_assignments) == 0:
                    # No info assignments for this scalar info_type1 for all spaces
                    return info_assignments  # <-- return the empty dictionary
                elif len(info_assignments) != 1:
                    raise Exception(
                        f"scalar_info_type_flag:{scalar_info_type_flag} yet len(info_assignments):{len(info_assignments)}"
                    )
                else:
                    info_type1 = list(info_assignments.keys())[0]
                    return info_assignments[info_type1]

        elif scalar_space_flag:
            # not scalar_info_type_flag and scalar_space_flag
            # return a (non-nested) dictionary keyed on info_type
            info_assignments2 = {}
            for info_type1 in info_assignments:
                if (
                    info_assignments[info_type1] is None
                    or len(info_assignments[info_type1]) == 0
                ):
                    # No info assignments for this info_type1 for this (scalar) space
                    continue
                elif len(info_assignments[info_type1]) != 1:
                    # There should be no more than one
                    # inner dictionary (space-key) entry here
                    raise Exception(
                        f"scalar_space_flag:{scalar_space_flag} yet len(info_assignments[{info_type1}]):{len(info_assignments[info_type1])}"
                    )
                else:
                    space1 = list(info_assignments[info_type1].keys())[0]
                    info_assignments2[info_type1] = info_assignments[info_type1][space1]
            return info_assignments2

        else:
            # not scalar_info_type_flag and not scalar_space_flag
            # return a (nested) dictionary of dictionaries
            # w/outer key:info_type and inner key:space
            return info_assignments

    def _space_info_indirection(
        self,
        info_type,
        space,
        info_assignment,
        grace=True,
        allow_infer=True,
        assign_inferred=True,
    ):
        """
        Designed to handle indirection of an info_type request
        based on the info_assignment (sourcing mode) arg
        i.e., traps for cases when info_assignment in ('<space_root>','<root_space>','<space>','<root>')
        ==> In these cases, it calls self.get_space_info accordingly

        allow_infer: Allow inference when info_type = 'freq'
        assign_inferred: Allow inference when info_type = 'freq'
        """
        if info_assignment not in ("<space_root>", "<root_space>", "<space>", "<root>"):
            if info_type == "tfill_max" and isinstance(info_assignment, str):
                # Can also consider putting this in each method that handles tfill_max args
                info_assignment = self.validate_periods1d(
                    periods=info_assignment, keyspace=space
                )
            return info_assignment
        else:
            return self.get_space_info(
                info_type=info_type,
                space=space,
                grace=grace,
                space_info_mode=info_assignment[1:-1],
                allow_infer=allow_infer,
                assign_inferred=assign_inferred,
            )

    # ================================ STATE CHECKING =================================

    @property
    def ndim(self) -> int:
        """
        Returns the keyspace dimensionality of the Quble
        """
        return None if self._keyspaces is None else len(self._keyspaces)

    @property
    def is_undefined(self) -> bool:
        return self.table_name is None

    @property
    def is_defined(self) -> bool:
        return not self.is_undefined

    @property
    def is_empty(self) -> bool:
        # In general, a table will need atleast one column to be defined
        # Should we require a valuespace column?
        # Should we preclude presence of keyspaces columns?
        return self.num_records == 0

    @property
    def is_scalar(self) -> bool:
        """
        A scalar Quble has no keyspaces,
        a single valuespace and a single record
        """
        return (
            (self.keyspaces is None or len(self.keyspaces) == 0)
            and self.valuespace is not None
            and (len(self.valuespaces) == 1)
            and self.num_records == 1
        )

    @property
    def is_multiscalar(self) -> bool:
        """
        A multi-scalar Quble has no keyspaces,
        multiple valuespaces (>=2) and a single record
        """
        return (
            (self.keyspaces is None or len(self.keyspaces) == 0)
            and (len(self.valuespaces) > 1)
            and self.num_records == 1
        )

    @property
    def is_variate(self) -> bool:
        """Test whether the Quble has only any valuespaces"""
        return len(self.valuespaces) >= 1

    @property
    def is_univariate(self) -> bool:
        """Test whether the Quble has only one valuespace"""
        return len(self.valuespaces) == 1

    @property
    def is_multivariate(self) -> bool:
        """Test whether the Quble has more than one valuespace"""
        return len(self.valuespaces) > 1

    @property
    def is_not_multivariate(self) -> bool:
        return not self.is_multivariate

    @property
    def is_index(self) -> bool:
        """Test whether the Quble is an "index" (has no primary valuespace)"""
        return self.valuespace is None

    @property
    def is_nonvariate(self) -> bool:
        """Test whether the Quble has no valuespaces"""
        return self.valuespaces is None or len(self.valuespaces) == 0

    def _check_space_type(
        self, space: str, coltype_func, grace: bool = True, summarize="all"
    ) -> bool:
        """
        See: :meth:`~qubles.core.quble.Quble.is_numeric`
        """
        space = self.validate_space(space, grace=grace)
        # The type check must be False if no spaces could be resolved
        if not space:
            return False

        column_type = self.get_column_type(space)
        if not isinstance(column_type, (list, tuple, dict)):
            # column_type is a scalar here...summarize not applicable
            result = coltype_func(column_type)
        elif not summarize:
            # Here summarize is (nominally): False or None
            if isinstance(column_type, dict):
                result = [coltype_func(t) for t in list(column_type.values())]
            else:
                result = [coltype_func(t) for t in column_type]
        elif len(column_type) == 0:
            return None
        elif not isinstance(summarize, str):
            # Here summarize is (nominally): True
            # [We choose to apply ALL test in this case]
            if isinstance(column_type, dict):
                result = all([coltype_func(t) for t in list(column_type.values())])
            else:
                result = all([coltype_func(t) for t in column_type])
        elif summarize not in ("all", "any", "none"):
            # Validate str version of summarize arg
            raise Exception(
                "Invalid summarize arg:{0}...valid options: True,False,None,'all','any' or 'none'".format(
                    summarize
                )
            )
        elif summarize == "any":
            if isinstance(column_type, dict):
                result = any([coltype_func(t) for t in list(column_type.values())])
            else:
                result = any([coltype_func(t) for t in column_type])
        elif summarize == "none":
            if isinstance(column_type, dict):
                result = not any([coltype_func(t) for t in list(column_type.values())])
            else:
                result = not any([coltype_func(t) for t in column_type])
        else:
            # Here summarize is (nominally): 'all'
            if isinstance(column_type, dict):
                result = all([coltype_func(t) for t in list(column_type.values())])
            else:
                result = all([coltype_func(t) for t in column_type])

        return result

    def is_numeric(self, space="<valuespace>", grace: bool = True, summarize="all"):
        """Test for numeric space(s).
        For a single-space input: returns bool
        For a multi-space input and summarize=False/None: returns list of bools
        For a multi-space input and summarize=True/'any'/'none'/'all': returns bool (summary accordingly)

        The *space* argument can have the following values
        (per method: Quble.validate_space):

        +---------------------------+-----------------------------+
        | Value                     | Description                 |
        +---------------------------+-----------------------------+
        | ``<spaces>``              | Test all of the spaces      |
        +---------------------------+-----------------------------+
        | ``<keyspaces>``           | Test all of the keyspaces   |
        +---------------------------+-----------------------------+
        | ``<first_keyspace>``      | Test the first keyspace     |
        +---------------------------+-----------------------------+
        | ``<first_time_keyspace>`` | Test first time-keyspace    |
        +---------------------------+-----------------------------+
        | ``<valuespace>``          | Test the valuespace         |
        +---------------------------+-----------------------------+
        | ``<valuespaces>``         | Test all of the valuespaces |
        +---------------------------+-----------------------------+
        | *space name*              | Test a specific space       |
        +---------------------------+-----------------------------+
        | *list of space names*     | Test specific spaces        |
        +---------------------------+-----------------------------+

        :type space: str or list of str
        :param space: The space(s) to test

        :type grace: bool
        :param grace: Flag to allow for grace in validation of space arg
        ==> When grace=True and space arg is invalid/unsupported,
        ==> self._check_space_type call will return False

        :type summarize: str or bool
        :param summarize: control to summarize multi-space tests to a bool scalar result
            ==> summarize=False/None: result multi-space test result as a list/tuple
            ==> summarize='any': returns True (scalar bool) if ANY of the specified multi-spaces satisfy type test
            ==> summarize='none': returns True (scalar bool) if NONE of the specified multi-spaces satisfy type test
            ==> summarize='all'/True: returns True (scalar bool) if ALL of the specified multi-spaces satisfy type test

        :rtype: bool or list of bool
        :returns: ``True`` for each space that is numeric

        """
        return self._check_space_type(
            space, coltype_is_numeric, grace=grace, summarize=summarize
        )

    def is_numeric_or_bool(
        self, space="<valuespace>", grace: bool = True, summarize="all"
    ):
        """Test for numeric or bool space(s).

        See: :meth:`~qubles.core.quble.Quble.is_numeric`

        """
        return self._check_space_type(
            space, coltype_is_numeric_or_bool, grace=grace, summarize=summarize
        )

    def is_int(self, space="<valuespace>", grace: bool = True, summarize="all"):
        """Test for integer space(s).

        See: :meth:`~qubles.core.quble.Quble.is_numeric`

        """
        return self._check_space_type(
            space, coltype_is_int, grace=grace, summarize=summarize
        )

    def is_float(self, space="<valuespace>", grace: bool = True, summarize="all"):
        """Test for float space(s).

        See: :meth:`~qubles.core.quble.Quble.is_numeric`

        """
        return self._check_space_type(
            space, coltype_is_float, grace=grace, summarize=summarize
        )

    def is_bool(self, space="<valuespace>", grace=True, summarize="all"):
        """Test for boolean space(s).

        See: :meth:`~qubles.core.quble.Quble.is_numeric`

        """
        return self._check_space_type(
            space, coltype_is_bool, grace=grace, summarize=summarize
        )

    def is_str(self, space="<valuespace>", grace: bool = True, summarize="all"):
        """Test for string space(s).

        See: :meth:`~qubles.core.quble.Quble.is_numeric`

        """
        return self._check_space_type(
            space, coltype_is_str, grace=grace, summarize=summarize
        )

    def is_string(self, space="<valuespace>", grace: bool = True, summarize="all"):
        """Test for string space(s).

        See: :meth:`~qubles.core.quble.Quble.is_numeric`

        """
        return self._check_space_type(
            space, coltype_is_str, grace=grace, summarize=summarize
        )

    def is_binary(self, space="<valuespace>", grace: bool = True, summarize="all"):
        """Test for binary space(s).

        See: :meth:`~qubles.core.quble.Quble.is_numeric`

        """
        return self._check_space_type(
            space, coltype_is_binary, grace=grace, summarize=summarize
        )

    def is_date(self, space="<valuespace>", grace: bool = True, summarize="all"):
        """Test for date space(s).

        See: :meth:`~qubles.core.quble.Quble.is_numeric`

        """
        return self._check_space_type(
            space, coltype_is_date, grace=grace, summarize=summarize
        )

    def is_datetime(self, space="<valuespace>", grace=True, summarize="all"):
        """Test for datetime space(s).

        See: :meth:`~qubles.core.quble.Quble.is_numeric`

        """
        return self._check_space_type(
            space, coltype_is_datetime, grace=grace, summarize=summarize
        )

    @property
    def non_time_valuespaces(self) -> list:
        """
        List of non-time valuespaces of a Quble
        """

        return [vs for vs in self.valuespaces if not self.is_time_space(vs, grace=True)]

    @property
    def non_time_keyspaces(self) -> list:
        """
        List of all non-time-keyspaces present in the Quble
        """

        return [
            ks for ks in self.keyspaces if not self.is_time_space(space=ks, grace=True)
        ]

    def is_time_space(self, space="<valuespace>", grace: bool = True, summarize="all"):
        """Test for date or datetime spaces.

        See: :meth:`~qubles.core.quble.Quble.is_numeric`

        """
        return self._check_space_type(
            space, coltype_is_time_space, grace=grace, summarize=summarize
        )

    @property
    def time_valuespaces(self) -> list:
        """
        List of time valuespaces of a Quble
        """
        return [vs for vs in self.valuespaces if self.is_time_space(vs, grace=True)]

    @property
    def time_keyspaces(self) -> list:
        """
        List of all time-keyspaces present in the Quble
        """
        return [ks for ks in self.keyspaces if self.is_time_space(ks, grace=True)]

    def is_vantage_time_space(
        self, space="<valuespace>", grace: bool = True, summarize="all"
    ):
        """Test for vantage date or datetime space.
           FOR NOW, ONLY SINGLE SPACE INQUIRY IS SUPPORTED

        See: :meth:`~qubles.core.quble.Quble.is_numeric`

        """
        space = self.validate_space(space, solo_required=True, grace=grace)
        if space is None:
            return None
        elif not isinstance(space, str):
            # For now, cannot check multiple spaces at the same time
            raise Exception(f"Invalid space:{space}...single space required")
        elif space != "Vantage":
            # Eventually, we will get more sophisticated on how we define a Vantage space
            return False
        elif not self._check_space_type(
            space, coltype_is_time_space, grace=grace, summarize=summarize
        ):
            return False
        else:
            return True

    def is_non_vantage_time_space(
        self, space="<valuespace>", grace: bool = True, summarize="all"
    ):
        """Test for non-vantage date or datetime space.
           FOR NOW, ONLY SINGLE SPACE INQUIRY IS SUPPORTED

        See: :meth:`~qubles.core.quble.Quble.is_numeric`

        """
        space = self.validate_space(space, solo_required=True, grace=grace)
        if space is None:
            return None
        elif not isinstance(space, str):
            # For now, cannot check multiple spaces at the same time
            raise Exception(f"Invalid space:{space}...single space required")
        elif space == "Vantage":
            # Eventually, we will get more sophisticated on how we define a Vantage space
            return False
        elif not self._check_space_type(
            space, coltype_is_time_space, grace=grace, summarize=summarize
        ):
            return False
        else:
            return True

    @property
    def non_vantage_time_keyspaces(self) -> list:
        """
        List of all non-vantage time-keyspaces present in the Quble
        """

        return [
            ks
            for ks in self.time_keyspaces
            if self.is_non_vantage_time_space(space=ks, grace=True)
        ]

    @property
    def vantage_time_keyspaces(self) -> list:
        """
        List of all vantage time-keyspaces present in the Quble
        """

        return [
            ks
            for ks in self.time_keyspaces
            if self.is_vantage_time_space(space=ks, grace=True)
        ]

    @property
    def non_time_spaces(self) -> list:
        """
        List of all non-time-spaces present in the Quble
        """
        return [
            space1
            for space1 in self.spaces
            if not self.is_time_space(space=space1, grace=True)
        ]

    @property
    def has_non_time_keyspaces(self) -> bool:
        """
        Are any of the Quble's keyspaces not time/temporal?
        """
        for ks in self.keyspaces:
            if not self.is_time_space(space=ks, grace=True):
                return True
        return False

    @property
    def time_spaces(self) -> list:
        """
        List of all time-spaces present in the Quble
        """
        return [
            space1
            for space1 in self.spaces
            if self.is_time_space(space=space1, grace=True)
        ]

    @property
    def has_time_keyspaces(self) -> bool:
        """
        Are any of the Quble's keyspaces time/temporal?
        """
        for ks in self.keyspaces:
            if self.is_time_space(space=ks, grace=True):
                return True
        return False

    @property
    def has_non_vantage_time_keyspaces(self) -> bool:
        """
        Are any of the Quble's keyspaces non-vantage time/temporal?
        """
        for ks in self.keyspaces:
            if self.is_non_vantage_time_space(space=ks, grace=True):
                return True
        return False

    @property
    def has_vantage_time_keyspaces(self) -> bool:
        """
        Are any of the Quble's keyspaces vantage time/temporal?
        """
        for ks in self.keyspaces:
            if self.is_vantage_time_space(space=ks, grace=True):
                return True
        return False

    @property
    def has_time_spaces(self) -> bool:
        """
        Are any of the Quble's spaces time/temporal?
        """
        for space1 in self.spaces:
            if self.is_time_space(space=space1, grace=True):
                return True
        return False

    def is_resampling_space(
        self,
        space: str = "<valuespace>",
        tfill_max="<space_root>",
        tfill_method="<space_root>",
        grace: bool = True,
    ) -> bool:
        """
        Indicates whether a (key)space is a 'resampling' (fill-eligible) space
        Requirements:
        1) time-keyspace
        AND 2) tfill_max not None and != 0

        NOTE: For logical reasons, filling info (e.g., tfill_max, etc.) IS NOT sourced from / NOT associated with
        the time (key)space provided, rather the valuespace!!

        :type tfill_max: int or str (indirection case)
        :param tfill_max: The tfill_max parameter of the associated space

        :type tfill_method: str
        :param tfill_method: The tfill_method parameter of the associated space

        :type grace: bool
        :param grace: grace for invalid space parameter
        """
        # Make sure we have been given a valid space
        space = self.validate_space(space=space, grace=grace, solo_required=True)

        # Check for time-(key)space
        if not self.is_time_space(space=space, grace=grace):
            return False

        # valuespace is required for resampling
        if self.valuespace is None:
            return False

        # Implement 'Vantage' override
        if space == "Vantage":
            return True
        else:
            # NOTE: Procure valuespace's filling info: tfill_max, tfill_method, tfill_honor_nulls & tfill_end_mode
            # NOTE: For logical reasons, filling info IS NOT associated with the time-keyspace, rather the valuespace!!
            tfill_max = self._space_info_indirection(
                info_type="tfill_max",
                space=self.valuespace,
                info_assignment=tfill_max,
                grace=grace,
            )

        # Resampling requires valuespace to have non-trivial tfill_max
        if tfill_max is None:
            return False
        elif not isinstance(tfill_max, int):
            raise Exception("Invalid tfill_max:{0}...integer required")
        elif tfill_max == 0:
            return False
        else:
            return True

    def resampling_info(
        self,
        space: str = "<valuespace>",
        tfill_max="<space_root>",
        tfill_method="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_null="<space_root>",
        grace: bool = True,
    ) -> dict:
        """
        Returns the resampling info (dictionary) associated with a resampling (key)space
        If not a resampling keyspace, returns None
        Otherwise, returns a  dictionary with the following keys/information

        NOTE: For logical reasons, filling info (e.g., tfill_max, etc.)
              IS NOT sourced from / NOT associated with
              the time (key)space provided, rather the valuespace!!

        :type space: str
        :param space: The space to test

        :type tfill_max: int or str (indirection case)
        :param tfill_max: The tfill_max parameter of the associated space

        :type tfill_method: str
        :param tfill_method: The tfill_method parameter of the associated space

        :type tfill_end_mode: str
        :param tfill_end_mode: The tfill_end_mode parameter of the associated space

        :type tfill_honor_null: bool or str (indirection case)
        :param tfill_honor_null: The tfill_honor_null parameter of the associated space

        :type grace: bool
        :param grace: grace for invalid space parameter

        """
        # Make sure we have been given a valid space
        space = self.validate_space(space=space, grace=grace, solo_required=True)

        # Check for time-(key)space
        if not self.is_time_space(space=space, grace=grace):
            return None

        # valuespace is required for resampling
        if self.valuespace is None:
            return None

        # Implement 'Vantage' override
        if space == "Vantage":
            tfill_max = -1
            tfill_method = "pad"
        else:
            tfill_max = self._space_info_indirection(
                info_type="tfill_max",
                space=self.valuespace,
                info_assignment=tfill_max,
                grace=True,
            )
            tfill_method = self._space_info_indirection(
                info_type="tfill_method",
                space=self.valuespace,
                info_assignment=tfill_method,
                grace=True,
            )

        # NOTE: Procure valuespace's filling info: tfill_max, tfill_method, tfill_honor_nulls & tfill_end_mode
        # NOTE: For logical reasons, filling info IS NOT associated with the time-keyspace, rather the valuespace!!

        # Resampling requires valuespace to have non-trivial tfill_max
        if tfill_max is None:
            return None
        elif not isinstance(tfill_max, int):
            raise Exception("Invalid tfill_max:{0}...integer required")
        elif tfill_max == 0:
            return None

        # We have now verified that the space is indeed a resampling space
        # procure additional resampling information via self.valuespace
        tfill_end_mode = self._space_info_indirection(
            info_type="tfill_end_mode",
            space=self.valuespace,
            info_assignment=tfill_end_mode,
            grace=True,
        )
        tfill_honor_null = self._space_info_indirection(
            info_type="tfill_honor_null",
            space=self.valuespace,
            info_assignment=tfill_honor_null,
            grace=True,
        )

        resampling_info = {}
        resampling_info["tfill_max"] = tfill_max
        resampling_info["tfill_method"] = tfill_method
        resampling_info["tfill_end_mode"] = tfill_end_mode
        resampling_info["tfill_honor_null"] = tfill_honor_null

        return resampling_info

    @property
    def is_categorical(self) -> bool:
        """
        Determines whether the valuespace of a Quble contains categorical values.
        [Implemented as a class property specifically against valuespace for legacy purposes]
        Simply calls more generalized space method: Quble.is_categorical_space()
        """
        if self.is_undefined:
            return False
        elif self.valuespace is None:
            return False
        else:
            return self.is_categorical_space(space=self.valuespace)

    def is_categorical_space(self, space: str = "<valuespace>") -> bool:
        """
        Determines whether a space of a Quble contains categorical values.

        A Quble is categorical if it is determined that the values fall into a limited
        number of distinct categories. The result is heuristically determined based on
        a small number of unique values vs. a number of non-missing values

        :type space: str
        :param space: The tfill_end_mode parameter of the associated space

        :rtype: bool
        :returns: ``True`` for each valuespace that is categorical

        """

        # validate space
        space = self.validate_space(space, grace=False, solo_required=True)

        if "is_categorical" not in self._column_info:
            self._column_info["is_categorical"] = {}

        if space not in self._column_info["is_categorical"]:
            # Handle non-applicable cases
            if self.num_records == 0:
                return False
            elif self.is_empty:
                return False
            elif self.is_bool(space):
                return True
            elif self.is_float(space):
                return False

            # Determine Categorical State using #non-missing vs #unique
            # -----------------------------------------------------------
            if space in self.keyspaces:
                # For keyspaces, assume all keys in keyspace are not missing
                # NOTE: self.num_non_missing() method is not intended for use with keyspaces
                num_non_missing_values = self.num_records
            elif space not in self.valuespaces:
                raise Exception(
                    f"space absent from self.keyspaces:{self.keyspaces} AND self.valuespaces:{self.valuespaces}"
                )
            else:
                # Count # non-missing values in valuespace
                # NOTE: self.num_non_missing() method returns a scalar Quble (NOT A Python scalar)
                try:
                    num_non_missing_values = self.num_non_nulls_space(space)
                except ValueError as ve:
                    raise ve

            if num_non_missing_values is None or num_non_missing_values == 0:
                return False

            # --------------------------------------------------------
            # Heuristical Function:
            #    max_categorical_uniques = f(num_non_missing_values)
            # --------------------------------------------------------
            #     f(10) = 10
            #     f(100) = 30
            #     f(1000) = 130
            #     f(10000) = 180
            #     f(100000) = 205
            #     f(1000000) = 225
            #        ...
            # --------------------------------------------------------
            if num_non_missing_values < 10:
                threshold = 10
            # Range: f(10)=10 <= max_categorical_uniques <= f(100)=30
            elif num_non_missing_values <= 100:
                threshold = 10 + 20 * np.log10(num_non_missing_values / 10.0)
            # Range: f(100)=30 <= max_categorical_uniques <= f(1000)=130
            elif num_non_missing_values <= 1000:
                threshold = 30 + 100 * np.log10(num_non_missing_values / 100.0)
            # Increase another 50 for every factor of 10 above 1000
            # Range: f(1000)=130 <= max_categorical_uniques <= f(10000)=180
            elif num_non_missing_values <= 10000:
                threshold = 130 + 50 * np.log10(num_non_missing_values / 1000.0)
            # Increase another 25 for every factor of 10 above 10000
            # Range: f(10000)=180 <= max_categorical_uniques <= f(100000)=205...
            else:
                threshold = 180 + 25 * np.log10(num_non_missing_values / 10000.0)

            # Test #unique non-missing values against threshold
            # --------------------------------------------------
            self._column_info["is_categorical"][space] = bool(
                self.num_unique_non_missing(space) < threshold
            )

        return self._column_info["is_categorical"][space]

    def value_categories(
        self, include_missing: bool = False, coerce_to_list: bool = False
    ) -> list:
        """
        Provides a numpy array (or list) of the (unique) categories
        of the specified valuespace of a Quble
        Simply calls the general space method: Quble.space_categories()
        [Implemented for legacy purposes]
        See :meth:`~qubles.core.quble.Quble.space_categories`
        """
        return self.space_categories(
            space="<valuespace>",
            include_missing=include_missing,
            coerce_to_list=coerce_to_list,
        )

    def space_categories(
        self,
        space: str = "<valuespace>",
        include_missing: bool = False,
        coerce_to_list: bool = False,
    ) -> list:
        """
        Returns a numpy array (or list) of the (unique) categories
        of the specified valuespace for a 'categorical' Quble
        NOTE: returns an empty list of the Quble is not 'categorical'

        :param space: The categorical space/column of interest
        :type space: str

        :param include_missing: Flag to include null/missing instance in result
        :type include_missing: bool (False*/True)

        :param coerce_to_list: Flag to coerce result to list
                               (otherwise, a numpy array will be returned)
        :type coerce_to_list: bool (False*/True)
        """
        if not self.is_categorical_space(space=space):
            return []
        else:
            return self.uniques(
                space=space,
                include_missing=include_missing,
                coerce_to_list=coerce_to_list,
            )

    def value_category_counts(self, include_missing: bool = False) -> dict:
        """
        Provides a count of each unique category of the valuespace of a Quble
        Simply calls the general space method: Quble.space_category_counts()
        [Implemented for legacy purposes]
        """
        return self.space_category_counts(
            space="<valuespace>", include_missing=include_missing
        )

    def space_category_counts(
        self, space: str = "<valuespace>", include_missing: bool = False
    ) -> dict:
        """
        Returns a dictionary whereby:

           keys: unique categories for a 'categorical' Quble
           values: associated counts

        NOTE: returns an empty dictionary if the Quble is not 'categorical'

        """
        if not self.is_categorical_space(space=space):
            return {}
        else:
            return self.unique_counts(space=space, include_missing=include_missing)

    def context_freq(
        self,
        keyspace="<first_time_keyspace>",
        grace: bool = True,
        default_freq: str = "<freq>",
        as_dict: bool = False,
    ):
        """
        Returns the contextual frequency for a Quble
        Nominally, will return the frequency of the first time-keyspace or the root freq setting
        Returns either string or dict (keyed by time-keyspace) depending on as_dict

        If no time keyspaces present and grace=True and as_dict=False: returns default_freq
        If no time keyspaces present and grace=True and as_dict=True: returns {None:default_freq}
        If no time keyspaces present and grace=False: raise Exception

        :param keyspace: associated time-keyspace
        :type keyspace: str

            keyspace='<first_time_keyspace>' ==> resolves to first time-based keyspace
            keyspace='<first_non_vantage_time_keyspace>' ==> resolves to first non-vantage time-keyspace
            keyspace='<first_vantage_time_keyspace>' ==> resolves to first vantage time-keyspace

        :param grace: Flag for gracefulness when no time keyspaces present
        :type grace: bool (True*/False)

        :param default_freq: default freq to return when no time-keyspaces present and grace=True
        :type default_freq: ideally the RootLib() freq setting

        When default_freq='<freq>'  ==>  default_freq=RootLib().get_control('freq')

        :exclude_vantage: Flag to exclude vantage time keytspaces (if present)
        :type exclude_vantage: ideally the RootLib() freq

        :param as_dict: Flag to return a dictionary (else returns a string)
        :type as_dict: bool (False*/True)

        ==> Ideally, should only use as_dict=True with grace=False

        When as_dict=True & NOT USING default_freq: return { <first_time_keyspace> : <freq of first_time_keyspace>}
        When as_dict=True & grace=True & USING default_freq: return { None : <default_freq>}

        """
        time_keyspace = self.validate_keyspace(
            keyspace=keyspace, grace=grace, solo_required=True, time_space_required=True
        )

        if time_keyspace is None:
            # presumably there are no time_keyspaces present
            # and grace was likely True
            if default_freq == "<freq>":  # or default_freq is None
                # Think about desired behavior when default_freq=None
                result_freq = RootLib().get_control("freq")
            else:
                result_freq = default_freq

        # Make sure we have a valid/supported time_keyspace
        elif time_keyspace not in self.time_keyspaces:
            # This ideally should not occur
            raise Exception(
                f"time_keyspace:{time_keyspace} absent from self.time_keyspaces:{self.time_keyspaces}"
            )

        else:
            result_freq = self.get_space_info(
                info_type="freq",
                space=time_keyspace,
                grace=True,
                space_info_mode="space",
                allow_infer=True,
                assign_inferred=True,
            )

        return result_freq if not as_dict else {time_keyspace: result_freq}

    def first_time_keyspace_freq(
        self, grace: bool = True, exclude_vantage: bool = False, as_dict: bool = False
    ):
        """
        Returns the frequency of first time_keyspace (time column) in the Quble
        Returns either string or dict (keyed by time-keyspace) depending on as_dict

        If no time keyspaces present and grace=True and as_dict=False: returns None
        If no time keyspaces present and grace=True and as_dict=True: returns {None:None}
        If no time keyspaces present and grace=False: raise Exception

        :param grace: Flag for gracefulness when no time keyspaces present
        :type grace: bool (True*/False)

        :exclude_vantage: Flag to exclude vantage time keytspaces (if present)
        :type exclude_vantage: ideally the RootLib() freq

        :param as_dict: Flag to return a dictionary (else returns a string)
        :type as_dict: bool (False*/True)

        ==> Ideally, should only use as_dict=True with grace=False

        """
        first_time_keyspace = self.first_time_keyspace(
            grace=grace, exclude_vantage=exclude_vantage
        )

        if first_time_keyspace is None:
            result_freq = None

        # Make sure we have a valid/supported time_keyspace
        elif first_time_keyspace not in self.time_keyspaces:
            # This ideally should not occur
            raise Exception(
                f"first_time_keyspace:{first_time_keyspace} absent from self.time_keyspaces:{self.time_keyspaces}"
            )

        else:
            result_freq = self.get_space_info(
                info_type="freq",
                space=first_time_keyspace,
                grace=True,
                space_info_mode="space",
                allow_infer=True,
                assign_inferred=True,
            )

        return result_freq if not as_dict else {first_time_keyspace: result_freq}

    def first_time_keyspace(self, grace: bool = True, exclude_vantage=False) -> str:
        """
        Finds first time_keyspace in Quble
        If no time keyspaces present and grace=True: returns None
        If no time keyspaces present and grace=False raise Exception
        """
        time_keyspace = None
        for ks in self.keyspaces:
            if exclude_vantage and ks == "Vantage":
                continue
            elif self.is_time_space(space=ks, grace=True):
                time_keyspace = ks
                break

        if time_keyspace is not None or grace:
            return time_keyspace
        else:
            raise Exception("No time keyspaces present")

    def first_non_vantage_time_keyspace(self, grace: bool = True) -> str:
        """
        Finds first non-vantage time_keyspace in Quble
        If no non-vantage time keyspaces present and grace=True: returns None
        If no non-vantage time keyspaces present and grace=False raise Exception
        """
        non_vantage_time_keyspace = None
        for ks in self.keyspaces:
            if self.is_time_space(space=ks, grace=True) and (ks != "Vantage"):
                non_vantage_time_keyspace = ks
                break

        if non_vantage_time_keyspace is not None or grace:
            return non_vantage_time_keyspace
        else:
            raise Exception("No non-vantage time-keyspaces present")

    def first_vantage_time_keyspace(self, grace: bool = True) -> str:
        """
        Finds first 'vantage' time_keyspace in Quble
        If no vantage time keyspaces present and grace=True: returns None
        If no vantage time keyspaces present and grace=False raise Exception
        """
        vantage_time_keyspace = None
        for ks in self.keyspaces:
            if self.is_vantage_time_space(space=ks, grace=True):
                vantage_time_keyspace = ks
                break

        if vantage_time_keyspace is not None or grace:
            return vantage_time_keyspace
        else:
            raise Exception("No vantage time-keyspaces present")

    def freq_of_first_time_keyspace(self, grace: bool = True) -> str:
        """
        Returns the frequency of the first time_keyspace in Quble
        If no time keyspaces present and grace=True: returns None
        If no time keyspaces present and grace=False raise Exception
        """
        first_time_ks = self.first_time_keyspace(grace=grace)
        if first_time_ks is not None:
            return self.get_space_info(
                info_type="freq", space=first_time_ks, grace=True
            )
        else:
            return None

    @property
    def first_keyspace(self) -> str:
        """
        Returns the first keyspace of a Quble
        [Returns None when no time-keyspaces are present]
        """
        if self.keyspaces is None or len(self.keyspaces) == 0:
            return None
        else:
            return self.keyspaces[0]

    @property
    def pole_keyspace(self) -> str:
        """
        Returns the first keyspace of a Quble
        Included for legacy purposes
        See :meth:`~qubles.core.quble.Quble.first_keyspace`
        """
        return self.first_keyspace

    @property
    def last_keyspace(self) -> str:
        """
        Returns the last keyspace of a Quble
        """
        if self.keyspaces is None or len(self.keyspaces) == 0:
            return None
        else:
            return self.keyspaces[-1]

    def id_keyspace(
        self, hint: str = None, secmstr_inspection: bool = True, grace: bool = False
    ) -> str:
        """
        Deprecated...use Quble.security_keyspace method
        ~see qubles.core.quble.Quble.security_keyspace
        """
        return self.security_keyspace(
            hint=hint, secmstr_inspection=secmstr_inspection, grace=grace
        )

    def security_keyspace(
        self, hint: str = None, secmstr_inspection: bool = True, grace: bool = False
    ) -> str:
        """
        Tries to locate the Quble's (first)
        security identifier keyspace as follows:

           1) First try hint (if provided)
           2) Optionally consult fields of SECMSTR reference library
              (if available and secmstr_inspection=True)
           3) If no SECMSTR library present, allow single non-time keyspace

        NOTE: No keyspace linking is performed here...
              [Non-trivial results will be a keyspace of the Quble]
        """
        if hint is not None and hint in self.keyspaces:
            return hint

        secmstr_fields = []
        secmstr_found = False
        if secmstr_inspection:
            for reflib in RootLib().get_reflibs():
                if reflib.is_secmstr:
                    secmstr_found = True
                    secmstr_fields = reflib.fields()

                    if secmstr_fields is not None and reflib.master_id is not None:
                        secmstr_fields = list(secmstr_fields)
                        secmstr_fields.append(reflib.master_id)

                    for secmstr_field1 in secmstr_fields:
                        if secmstr_field1 in self.keyspaces:
                            return secmstr_field1

        # if not secmstr_found:
        default_security_id = RootLib().get_property("default_security_id", grace=True)
        if default_security_id is not None and default_security_id in self.keyspaces:
            return default_security_id

        # Hard coding 'DUMMY_ID' for trial deployments
        # that do not utilize a security master
        if not secmstr_found and "DUMMY_ID" in self.keyspaces:
            return "DUMMY_ID"

        # Handle failure according to grace
        if grace:
            return None
        elif len(secmstr_fields) > 0:
            raise Exception(
                "No security_keyspace in self.keyspaces:{0} w/hint={1} and secmstr_fields:{2}".format(
                    self.keyspaces, hint, secmstr_fields
                )
            )
        else:
            raise Exception(
                f"No security_keyspace in self.keyspaces:{self.keyspaces} w/hint={hint}"
            )

    def has_security_keyspace(self, secmstr_inspection: bool = True) -> bool:
        """
        Returns True/False reflecting whether specified
        one of the Quble's keyspaces corresponds to a 'security' keyspace
        according to the composition of the resident security master
        and/or the default_security_id of the RootLib()

        :type secmstr_inspection: bool (True*/False)
        :param secmstr_inspection: Allow inspection of secmstr library

        :rtype: bool
        :returns: ``True`` if specified space is a security space
        """
        sec_ks = self.security_keyspace(
            secmstr_inspection=secmstr_inspection, grace=True
        )
        return sec_ks is not None

    def is_security_space(
        self, space: str, grace: bool = True, secmstr_inspection: bool = True
    ) -> bool:
        """
        Returns True/False reflecting whether specified
        space (column) corresponds to a security space of the Quble
        according to the composition of the resident security master
        and/or the default_security_id of the RootLib()

        :type space: str
        :param space: The space to test

        :type grace: bool (True*/False)
        :param grace: Flag to allow for grace in validation of space arg

        :type secmstr_inspection: bool (True*/False)
        :param secmstr_inspection: Allow inspection of secmstr library

        :rtype: bool
        :returns: ``True`` if specified space is a security space
        """
        # Initial checks/validation
        if self.is_undefined:
            return False
        elif space is None:
            return False
        elif not isinstance(space, str):
            # For now, cannot check multiple spaces at the same time
            raise Exception(f"Invalid space:{space}...single space required")
        elif space in self.spaces:
            # Will proceed with checks below
            pass
        elif grace:
            # Here, space arg is not a valid space/column
            # Given the grace directive, we return False w/o exception
            return False
        else:
            # Here, we throw an Exception since no grace was given
            raise Exception(f"space:{space} is absent from self.spaces:{self.spaces}")

        secmstr_fields = []
        if secmstr_inspection:
            for reflib in RootLib().get_reflibs():
                if reflib.is_secmstr:
                    secmstr_fields = reflib.fields()
                    master_id = reflib.master_id

                    if secmstr_fields is not None and space in secmstr_fields:
                        return True

                    if master_id is not None and master_id == space:
                        return True
                    # Go ahead and exit the loop (assumes only one secmstr present)
                    break

        default_security_id = RootLib().get_property("default_security_id", grace=True)
        if default_security_id is not None and default_security_id == space:
            return True

        # Otherwise, security space was not confirmed
        return False

    # ============================= KEYSPACES/VALUESPACES =============================

    @property
    def freq(self) -> dict:
        """
        dictionary from keyspace to associated frequency
        NOTE: frequency (dict values) will be None for non-time keyspaces (dict keys)
        """
        freq_dict = {}
        for ks in self.keyspaces:
            freq1 = self.get_freq(
                ks,
                freq_hint="default_freq",
                allow_infer=True,
                assign_inferred=True,
                grace=True,
            )
            freq_dict[ks] = freq1
        return freq_dict

    def _get_valuespace_attr(
        self,
        vs_attr_name,
        valuespace="<valuespace>",
        grace=True,
        inspect_when_underscored_is_None=False,
    ):
        """
        Similar to self.get_space_info(info_type=vs_attr_name, space=self.valuespace, grace=grace)
        EXCEPT it will FIRST TRY TO FIND/PRIORITIZE the underscored Python attribute: self._<vs_attr_name>

        Gets a primary valuespace attribute from one of two sources in following priority:
           1) Python underscored attribute: self._<vs_attr_name>
           2) valuespace column's info
        """
        valuespace = self.validate_valuespace(valuespace=valuespace, grace=False)
        if valuespace is None:
            return None

        if vs_attr_name is None:
            return None
        elif not isinstance(vs_attr_name, str) or len(vs_attr_name) == 0:
            raise Exception(
                f"Invalid vs_attr_name: non-trivial str expected: {vs_attr_name}"
            )

        underscored_vs_attr_name = f"_{vs_attr_name}"

        # Is there a Python-based underscored attribute? self._<vs_attr_name>
        # If not, self._<vs_attr_name> is ABSENT
        #    BEHAVIOR:, "inspect" via self.get_space_info()
        # -------------------------------------------------------------------
        if not hasattr(self, underscored_vs_attr_name):
            # self._column_info[vs_attr_name] will be updated/managed by get_space_info method
            return self.get_space_info(
                info_type=vs_attr_name, space=valuespace, grace=grace
            )
        # Here, self._<vs_attr_name> is present but None
        #  AND (inspect_when_underscored_is_None == True)
        #   ==> BEHAVIOR: We "inspect" via self.get_space_info()
        # -------------------------------------------------
        elif inspect_when_underscored_is_None and (
            getattr(self, underscored_vs_attr_name) is None
        ):
            return self.get_space_info(
                info_type=vs_attr_name, space=valuespace, grace=grace
            )
        # Here, self._<vs_attr_name> is EITHER:
        #      1) present and not None
        #   OR 2) present but None AND (inspect_when_underscored_is_None == False)
        #   ==> BEHAVIOR: We return self._<vs_attr_name>
        # -----------------------------------------
        else:
            # We choose NOT to assign self._<vs_attr_name> -> self._column_info[vs_attr_name][self.valuespace]
            # [otherwise cache inconsistencies may result as inspect_when_underscored_is_None may differ on next call]
            return getattr(self, underscored_vs_attr_name)

    @property
    def fxs(self) -> dict:
        """
        dictionary from valuespace to associated currency
        NOTE: fxs (dict values) will be None for non-currency valuespaces (dict keys)
        """
        return self.get_space_info(info_type="fx", space="<valuespaces>", grace=True)

    @property
    def fx(self):
        """
        Gets the fx info type for the primary valuespace
        """
        return self._get_valuespace_attr(vs_attr_name="fx")

    @fx.setter
    def fx(self, new_fx):
        """
        Sets the fx info type for the primary valuespace
        """
        if self.is_undefined:
            raise UndefinedQubleError("Cannot set fx for an undefined (no table) Quble")
        elif self.valuespace is None:
            raise NoValuespaceError("valuespace required")

        self.set_space_info(space=self.valuespace, info_type="fx", info_value=new_fx)
        return

    @property
    def tfill_max(self):
        """
        Gets the tfill_max info type for the primary valuespace
        """
        return self._get_valuespace_attr(vs_attr_name="tfill_max")

    @tfill_max.setter
    def tfill_max(self, new_tfill_max):
        """
        Sets the tfill_max info type for the primary valuespace
        """
        if self.is_undefined:
            raise UndefinedQubleError(
                "Cannot set tfill_max for an undefined (no table) Quble"
            )
        elif self.valuespace is None:
            raise NoValuespaceError("valuespace required")

        self.set_space_info(
            space=self.valuespace, info_type="tfill_max", info_value=new_tfill_max
        )
        return

    @property
    def time_basis(self):
        """
        Gets the time_basis info type for the primary valuespace
        """
        return self._get_valuespace_attr(vs_attr_name="time_basis")

    @time_basis.setter
    def time_basis(self, new_time_basis):
        """
        Sets the time_basis info type for the primary valuespace
        """
        if self.is_undefined:
            raise UndefinedQubleError(
                "Cannot set time_basis for an undefined (no table) Quble"
            )
        elif self.valuespace is None:
            raise NoValuespaceError("valuespace required")

        self.set_space_info(
            space=self.valuespace, info_type="time_basis", info_value=new_time_basis
        )
        return

    @property
    def tfill_method(self):
        """
        Gets the tfill_method info type for the primary valuespace
        """
        return self._get_valuespace_attr(vs_attr_name="tfill_method")

    @tfill_method.setter
    def tfill_method(self, new_time_basis):
        """
        Sets the tfill_method info type for the primary valuespace
        """
        if self.is_undefined:
            raise UndefinedQubleError(
                "Cannot set tfill_method for an undefined (no table) Quble"
            )
        elif self.valuespace is None:
            raise NoValuespaceError("valuespace required")

        self.set_space_info(
            space=self.valuespace, info_type="tfill_method", info_value=new_time_basis
        )
        return

    @property
    def tfill_end_mode(self):
        """
        Gets the tfill_end_mode info type for the primary valuespace
        """
        return self._get_valuespace_attr(vs_attr_name="tfill_end_mode")

    @tfill_end_mode.setter
    def tfill_end_mode(self, new_time_basis):
        """
        Sets the tfill_end_mode info type for the primary valuespace
        """
        if self.is_undefined:
            raise UndefinedQubleError(
                "Cannot set tfill_end_mode for an undefined (no table) Quble"
            )
        elif self.valuespace is None:
            raise NoValuespaceError("valuespace required")

        self.set_space_info(
            space=self.valuespace, info_type="tfill_end_mode", info_value=new_time_basis
        )
        return

    @property
    def tfill_honor_nulls(self):
        """
        Gets the tfill_honor_nulls info type for the primary valuespace
        """
        return self._get_valuespace_attr(vs_attr_name="tfill_honor_nulls")

    @tfill_honor_nulls.setter
    def tfill_honor_nulls(self, new_time_basis):
        """
        Sets the tfill_honor_nulls info type for the primary valuespace
        """
        if self.is_undefined:
            raise UndefinedQubleError(
                "Cannot set tfill_honor_nulls for an undefined (no table) Quble"
            )
        elif self.valuespace is None:
            raise NoValuespaceError("valuespace required")

        self.set_space_info(
            space=self.valuespace,
            info_type="tfill_honor_nulls",
            info_value=new_time_basis,
        )
        return

    def _missing_value(self, space: str = "<valuespace>"):
        """
        Returns the missing value for the specified space
        [Generalized for any space/column]
        """
        space = self.validate_space(space=space, grace=False, solo_required=True)
        return self.get_space_info(info_type="missing_value", space=space)

    @property
    def missing_value(self):
        """
        Return the Numpy missing value representation for the Quble's primary valuespace.

        :param valuespace:
            See :meth:`~qubles.core.quble.Quble.validate_valuespace`

        :rtype: any or list of any
        :returns: The missing value representation.

        NOTE: For legacy reasons,
              implemented as a class property
              (not a class method with space arg)
        """
        if self.valuespace is None:
            return None
        else:
            return self.get_space_info(info_type="missing_value", space=self.valuespace)

    @property
    def missing_values(self) -> dict:
        """
        Return dictionary from spaces/column_names to (Python-based) missing_value
        :returns: The missing_value as a dictionary for each column.
        """
        return self.get_space_info(info_type="missing_value", space="<all>")

    @property
    def colType(self):
        """
        Returns the SQL type for the Quble's primary valuespace

        :rtype: str or list of str
        :returns: The Numpy dtype as a string.

        NOTE: For legacy reasons,
              implemented as a class property
              (not a class method with space arg)
        """
        if self.valuespace is None:
            return None
        else:
            colType1 = self.get_space_info(info_type="type", space=self.valuespace)
            return colType1

    @property
    def colTypes(self) -> dict:
        """
        Return dictionary from spaces/column_names to SQL column types.
        :returns: The SQL column types as a dictionary for each column.
        """
        return self.get_space_info(info_type="type", space="<all>")

    @property
    def dtype(self):
        """
        Returns the Numpy dtype for the Quble's primary valuespace.

        :rtype: str or list of str
        :returns: The Numpy dtype as a string.

        NOTE: For legacy reasons,
              implemented as a class property
              (not a class method with space arg)
        """
        if self.valuespace is None:
            return None
        else:
            dtype1 = self.get_space_info(info_type="dtype", space=self.valuespace)
            if isinstance(dtype1, str) and dtype1.lower() in ("bool", "boolean"):
                dtype1 = np.dtype(bool)
            return dtype1

    @property
    def dtypes(self) -> dict:
        """
        Return dictionary from spaces/column_names to dtypes.
        :returns: The Numpy dtype as a dictionary for each column.
        """
        return self.get_space_info(info_type="dtype", space="<all>")

    def _clear_cache(self, which_cache: str = "<all>"):
        """
        clears any performance-enhancing caches
        (such as keyspaces/valuespace/valuespaces/etc)
        """
        if which_cache == "<all>":
            self._clear_role_caches()
            self._clear_num_records_caches()
            self._cache = {}
            return

        if isinstance(which_cache, str):
            which_cache = [which_cache]

        if isinstance(which_cache, (list, tuple)):
            for which_cache1 in which_cache:
                if which_cache1 in self._cache:
                    self._cache.pop(which_cache1)

    # List of role-related cache items
    ROLE_CACHES = (
        "role",
        "keygroups",
        "basic_keygroups",
        "complex_keygroups",
        "is_vantage",
    )

    def _clear_role_caches(self):
        """
        Clears all caches related-to space roles
        [These caches are derived from info_type:'role', etc
        """
        self._keyspaces = []
        self._valuespace = None
        self._valuespaces = []
        self._auxvalspaces = []
        self._keygroups = {}
        if "basic_keygroups" in self._cache:
            self._cache.pop("basic_keygroups")
        if "complex_keygroups" in self._cache:
            self._cache.pop("complex_keygroups")
        if "has_duplicate_keys" in self._cache:
            self._cache.pop("has_duplicate_keys")

    def _set_data_to_none(self):
        self.data = None

    def _clear_num_records_caches(self):
        """
        Clears all caches related-to num_records (record counts)
        """
        for cache in [
            "has_duplicate_keys",
            "num_records",
            "num_nulls_all_spaces",
            "num_non_nulls_all_spaces",
        ]:
            if cache in self._cache:
                self._cache.pop(cache)
        self._set_data_to_none()

    @property
    def spaces(self) -> list:
        """
        spaces = all columns of the underlying table
        [includes both active/used and auxvalspaces/unused columns]
        """
        # NOTE: Need to return a deep copy here,
        # otherwise calling program can alter self._spaces
        return deepcopy(self._spaces)

    @property
    def has_spaces(self) -> bool:
        return True if len(self.spaces) > 0 else False

    @property
    def num_spaces(self) -> int:
        return len(self.spaces)

    @property
    def active_spaces(self) -> list:
        """
        active_spaces = keyspaces + [valuespace]
        [These are the spaces/columns that are being actively used by the Quble]
        [Auxillary valuespaces (auxvalspaces) are NOT included]
        """
        if self.valuespace is None:
            return self.keyspaces
        elif self.keyspaces is None:
            return [self.valuespace]
        else:
            return self.keyspaces + [self.valuespace]

    @property
    def num_active_spaces(self) -> int:
        return len(self.active_spaces)

    @property
    def nonkeyspaces(self) -> list:
        """
        nonkeyspaces = valuespaces
        nonkeyspaces = spaces - keyspaces
        nonkeyspaces = valuespace + [auxvalspaces]
        [May include auxvalspaces outside keyspaces and valuespace]
        """
        return self.valuespaces

    @property
    def has_active_spaces(self) -> bool:
        return True if len(self.active_spaces) > 0 else False

    def ortho_valuespaces(self, valuespace="<valuespace>", grace: bool = True) -> list:
        """
        Returns a (string) list of the Quble's valuespaces that are
        orthogonal to (outside of) the specified valuespace

        :param keyspace: keyspace(s) of the dimension to be aggregated
        :type keyspace: str or list of str

        :param grace: Graceful/ungraceful exception handling
        :type grace: boolean (True/False)

        """
        # Establish ortho_valuespace_list
        if valuespace is None:
            valuespaces_to_exclude = []
        elif isinstance(valuespace, list):
            valuespaces_to_exclude = valuespace
        elif isinstance(valuespace, tuple):
            # Will need to be mutable below
            valuespaces_to_exclude = list(valuespace)
        else:
            valuespaces_to_exclude = self.validate_valuespace(
                valuespace=valuespace,
                grace=False,
                coerce_to_list=True,
            )

        if self.has_valuespaces():
            ortho_valuespace_list = deepcopy(self.valuespaces)
            # Exclude valuespaces as directed
            for valuespace_to_exclude in valuespaces_to_exclude:
                if valuespace_to_exclude in ortho_valuespace_list:
                    ortho_valuespace_list.remove(valuespace_to_exclude)

            # Return the remaining (unexcluded/ortho) valuespaces
            return ortho_valuespace_list
        elif grace:
            return []
        else:
            raise Exception("Quble has no valuespaces")

    @property
    def auxvalspaces(self) -> list:
        """
        'auxvalspaces' are auxillary valuespaces of the underlying table that are not being used by this Quble
        ==> auxvalspaces typically exist when one table is being shared by multiple Qubles (e.g., coindexed Qubles)
        """
        # NOTE: Need to return a deep copy here,
        # otherwise calling program can alter self.auxvalspaces
        return deepcopy(self._auxvalspaces)

    @property
    def has_auxvalspaces(self) -> bool:
        return True if len(self._auxvalspaces) > 0 else False

    @property
    def num_auxvalspaces(self) -> int:
        return len(self._auxvalspaces)

    @property
    def keyspaces(self) -> list:
        """Quble's keyspaces"""
        # NOTE: Need to return a deep copy here,
        # otherwise calling program can alter self.keyspaces
        return deepcopy(self._keyspaces)

    @property
    def num_keyspaces(self) -> int:
        # Formerly returned None when keyspaces was None
        return 0 if self._keyspaces is None else len(self._keyspaces)

    @property
    def num_keygroups(self) -> int:
        return len(self.keygroups)

    @property
    def keygroups(self) -> dict:
        """
        Quble's keygroups: dictionary
        providing a map from keygroups to associated keyspaces (list)
        based on info_type assignments for space_info='keygroup'

        The order of the keygroups in result will be determined by their
        first appearance when resolving space_info during keyspace parsing

        Keyspaces without an explicit keygroup space info
        will have their own / dedicated synthetic keygroup

        NOTE: len(keygroups) <= len(keyspaces)

        Business Classification Example: 4-D keyspaces

           keyspace     keygroup (info_type) assignment
           --------     --------------------------------
           Sector        Business
           Industry      Business
           Ticker        Business
           Dates         <No keygroup assignment>

           keygroups: 2-D keygroups
           dict({'Business':['Sector', 'Industry', 'Ticker'], 'Dates':['Dates'] })

        """
        if "keygroups" not in self._cache:
            self._cache["keygroups"] = {}
            for ks in self.keyspaces:
                # Get this keyspace's keygroup assignment (if any)
                keygroup1 = self.get_space_info(
                    info_type="keygroup", space=ks, grace=True
                )

                if keygroup1 is None:
                    # This keyspace in not assigned to a keygroup
                    # so we create a keygroup (single-element list) exclusively for it
                    self._cache["keygroups"][ks] = [ks]
                elif keygroup1 in self.keyspaces:
                    # keygroup assignments must be distinct from keyspaces
                    # Otherwise, the keygroup integrity may be compromised
                    raise Exception(
                        f"Invalid assignment:keyspace:{ks} -> keygroup:{keygroup1}...redundant with keyspaces:{self.keyspaces}"
                    )
                elif keygroup1 not in self._cache["keygroups"]:
                    # First time this keygroup is encountered in keyspaces loop
                    # Seed the associated list with ks entry
                    self._cache["keygroups"][keygroup1] = [ks]
                elif ks not in self._cache["keygroups"][keygroup1]:
                    # Not the first time this keygroup is encountered in ks loop
                    # Append current ks to associated list
                    self._cache["keygroups"][keygroup1].append(ks)

        # NOTE: Need to return a deep copy here,
        # otherwise calling program can alter self._cache['keygroups']
        return deepcopy(self._cache["keygroups"])

    @property
    def num_basic_keygroups(self) -> int:
        return len(self.basic_keygroups)

    @property
    def basic_keygroups(self) -> dict:
        """
        Quble's basic-keygroups: dictionary
        providing a map from keygroups to keyspaces
        ONLY for those keygroups with that are BASIC

        ==> Here 'basic' means the keygroup is comprised of
        ==> merely a single, native keyspace of the Quble
        """
        if "basic_keygroups" not in self._cache:
            # if self.keygroups == {}:
            #     # Ideally should not happen
            #     self._cache["basic_keygroups"] = None
            # else:
            self._cache["basic_keygroups"] = dict(
                [
                    (ks, self.keygroups[ks])
                    for ks in self.keygroups
                    if ks in self.keyspaces
                ]
            )
            # Integrity check...make sure basic keygroups
            # only map to the proper, single, valid keyspace
            # Example: self._cache['basic_keygroups'] = { 'Dates': ['Dates'] }
            for keygroup_name, ks_list in self._cache["basic_keygroups"].items():
                # We know from command above
                # that keygroup_name is within self.keyspaces
                if ks_list != [keygroup_name]:
                    raise Exception(
                        f"Invalid basic_keygroups[{keygroup_name}]: {ks_list} != [{keygroup_name}]"
                    )

        return self._cache["basic_keygroups"]

    @property
    def num_complex_keygroups(self) -> int:
        return len(self.complex_keygroups)

    @property
    def complex_keygroups(self) -> dict:
        """
        Quble's complex-keygroups
        dictionary providing a map from keygroups to keyspaces
        ONLY for those keygroups with that are COMPLEX

        ==> Here 'complex' means the keygroup
        ==> is not merely a single, keyspace of the Quble
        """
        if "complex_keygroups" not in self._cache:
            if self.keygroups is None or self.basic_keygroups is None:
                # Ideally should not happen
                self._cache["complex_keygroups"] = None
            else:
                self._cache["complex_keygroups"] = dict(
                    [
                        (ks, self.keygroups[ks])
                        for ks in self.keygroups
                        if ks not in self.basic_keygroups
                    ]
                )
        return self._cache["complex_keygroups"]

    @property
    def num_valuespaces(self) -> int:
        return 0 if self.valuespaces is None else len(self.valuespaces)

    @property
    def numeric_valuespaces(self) -> list:
        """
        List of numeric valuespaces of a Quble
        """
        numeric_vs_list = [vs for vs in self.valuespaces if self.is_numeric(vs)]
        return numeric_vs_list

    @property
    def currency_valuespaces(self) -> list:
        """
        List of fx valuespaces of a Quble
        """
        fx_vs_list = [
            vs
            for vs in self.valuespaces
            if self.is_numeric(vs) and self.fxs[vs] is not None
        ]
        return fx_vs_list

    @property
    def non_numeric_valuespaces(self) -> list:
        """
        List of non-numeric valuespaces of a Quble
        """
        non_numeric_vs_list = [vs for vs in self.valuespaces if not self.is_numeric(vs)]
        return non_numeric_vs_list

    @property
    def float_valuespaces(self) -> list:
        """
        List of float valuespaces of a Quble
        """
        float_vs_list = []
        for vs in self.valuespaces:
            if self.is_float(vs):
                float_vs_list.append(vs)

        return float_vs_list

    @property
    def int_valuespaces(self) -> list:
        """
        List of integer valuespaces of a Quble
        """
        int_vs_list = []
        for vs in self.valuespaces:
            if self.is_int(vs):
                int_vs_list.append(vs)

        return int_vs_list

    @property
    def bool_valuespaces(self) -> list:
        """
        List of boolean valuespaces of a Quble
        """
        bool_vs_list = []
        for vs in self.valuespaces:
            if self.is_bool(vs):
                bool_vs_list.append(vs)

        return bool_vs_list

    @property
    def string_valuespaces(self) -> list:
        """
        List of string valuespaces of a Quble
        """
        str_vs_list = []
        for vs in self.valuespaces:
            if self.is_string(vs):
                str_vs_list.append(vs)

        return str_vs_list

    @property
    def categorical_valuespaces(self) -> list:
        """
        List of categorical valuespaces of a Quble
        """
        categorical_vs_list = [
            vs for vs in self.valuespaces if self.is_categorical_space(vs)
        ]
        return categorical_vs_list

    def unvaluespace(
        self,
        drop: bool = False,
        prevent_null_keys: bool = True,
        valuespace: str = "<valuespace>",
    ) -> Quble:
        """
        If no valuespaces exists, merely returns a copy (ignores valuespace arg),
        otherwise converts variate Quble to an index (non-variate) Quble as follows...

        :type drop: bool
        :param drop: Controls the droppage of Quble's valuespaces

           ==> drop=False*: converts specified valuespace (if present) to a keyspace
                            [drops/ignores any additonal valuespaces]
           ==> drop=True: drops valuespace(s) and only retains original keyspaces

        :type prevent_null_keys: bool
        :param drop: prevent_null_keys: Flag to control null key prevention method

           ==> prevent_null_keys=True*: prevents null index keys
                        (when carried over from valuespace, drop=False)
           ==> prevent_null_keys=False: allows for null index keys
                        (when carried over from valuespace, drop=False)

        :type valuespace: str or dict
        :param valuespace: valuespace to operate on
           ==> only applies when drop=False
           ==> str arg specifies which valuespace to use
           ==> dict arg must be one element dict
           ==> dict key identifies existing valuespace
           ==> dict value specifies the desired renamed valuespace
        """
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_nonvariate:
            return self.copy()
        elif drop or self.valuespace is None:
            # When self.valuespace is None but len(self.valuespaces) > 0,
            # Quble has auxillary valuespaces, but no primary valuespace
            return self.index(distinct=False, key_ordering=None)
        else:
            if not isinstance(valuespace, dict):
                # validate specified valuespace
                valuespace = self.validate_valuespace(valuespace, grace=False)
                old_valuespace = valuespace
                new_valuespace = valuespace
                # Convert specified valuespace to a keyspace, but do not keep any auxillary valuespaces
                spaces_to_keep = self.keyspaces + [new_valuespace]
            elif len(valuespace) != 1:
                raise Exception(
                    f"valuespace: {valuespace} dict must have only one entry"
                )
            else:
                old_valuespace = self.validate_valuespace(
                    list(valuespace.keys())[0], grace=False
                )
                new_valuespace = list(valuespace.values())[0]
                spaces_to_keep = {}
                for ks in self.keyspaces:
                    spaces_to_keep[ks] = ks
                spaces_to_keep[old_valuespace] = new_valuespace

            if prevent_null_keys:
                where_clause = f'WHERE "{old_valuespace}" IS NOT NULL'
            else:
                where_clause = None
            result = self.select(column_names=spaces_to_keep, where_clause=where_clause)
            result._column_info["role"][new_valuespace] = "keyspace"
            result._initialize_space_roles(valuespace=None)

            # Remove any explicit self.valuespace attribute
            if hasattr(result, "valuespace"):
                result._valuespace = None

            return result

    @property
    def valuespaces(self) -> list:
        # NOTE: Need to return a deep copy here,
        # otherwise calling program can alter self._valuespaces
        return deepcopy(self._valuespaces)

    def promote_valuespace_inplace(self, valuespace: str):
        return self.promote_valuespace(valuespace=valuespace, inplace=True)

    def promote_valuespace(
        self,
        valuespace: str,
        inplace: bool = False,
        deep_copy: bool = False,
        retain_address: bool = False,
    ):
        """
        Promotes the specified valuespace to the primary valuespace role
        Returns a new Quble retaining all original valuespaces

        :type valuespace: str
        :param valuespace: The (single) valuespace to promote
                           (must be a valid valuespace of the original Quble)

        :param inplace: Flag for changing self directly inplace
        :type inplace: boolean (True/False*)
            inplace=True: modifies self Quble directly and returns self
            inplace=False: returns a (possibly) modified Quble (leaves self unchanged)

        :type deep_copy: bool (False*/True)
        :param deep_copy: Controls new copy (vs sharing) of the original Quble table
             ==> Only applicable when inplace==False
             ==> False: The new Quble will share the original table (no content will be copied)
             ==> True: A new table will be created (with same data contents of original table)

        :type retain_address: bool (False*/True)
             ==> Only applicable when inplace==False
        :param retain_address: Flag to retain the address of the original Quble
        """
        # Validate valuespace arg
        valuespace = self.validate_valuespace(
            valuespace, grace=False, solo_required=True
        )

        # Copy the Quble
        if inplace:
            # Promote the specified valuespace (if needed)
            if self.valuespace != valuespace:
                self.valuespace = valuespace
            return self
        else:
            subject = self.copy(deep_copy=deep_copy, retain_address=retain_address)
            # Promote the specified valuespace (if needed)
            if subject.valuespace != valuespace:
                subject.valuespace = valuespace
            return subject

    def _process_valuespace_param(self, valuespace):
        if valuespace is None or isinstance(valuespace, str):
            if valuespace in [None, "<inspect>"]:
                col = DEFAULT_VALUESPACE
                valuespace = [DEFAULT_VALUESPACE]
            else:
                col = valuespace
            valuespace = [col]
        elif isinstance(valuespace, (list, tuple)):
            if len(valuespace) == 1:
                col = valuespace[0]
            else:
                raise Exception(
                    "Recieved multiple valuespace assignments for a single dimmensional dataset!"
                )
        else:
            raise Exception(
                f"Recieved bad valuespace param of type: {type(valuespace)}, expected str, list, or tuple."
            )

        return col, valuespace

    def _process_valuespaces(self, valuespace):
        # When more than one valuespace is present in result,
        # promote one of the valuespaces to primary status
        # -----------------------------------------------------
        if len(self._valuespaces) > 1:
            # Establish preferred_vs
            if valuespace is None:
                preferred_vs = self._valuespaces[0]
            elif isinstance(valuespace, str):
                preferred_vs = valuespace
            elif not isinstance(valuespace, (tuple, list)):
                raise Exception(
                    f"Invalid valuespace arg:{valuespace}...str/list/tuple/None required"
                )
            elif len(valuespace) == 0:
                preferred_vs = self._valuespaces[0]
            elif valuespace[0] not in self._valuespaces:
                raise Exception(
                    f"Invalid arg: valuespace[0]:{valuespace[0]} absent from self._valuespaces:{self._valuespaces}"
                )
            else:
                preferred_vs = valuespace[0]

            # Apply preferred_vs
            self._valuespace = self._get_primary_valuespace(
                preferred_vs=preferred_vs, grace=False
            )
        elif len(self._valuespaces) == 1:
            # If there is only one, make it valuespace by default, leave null if len == 0
            self._valuespace = self._valuespaces[0]

    def _get_primary_valuespace(
        self,
        preferred_vs: str = "<inspect>",
        grace: bool = True,
    ) -> str:
        """
        Finds the primary valuespace (non-index column) through table inspection
        Primary valuespace is the primary value column of a Quble.
        Makes use of (assumes pre-assignment of) self._valuespaces

        :type preferred_vs: str or None
        :param preferred_vs: preferred valuespace (may use None)
                             None ==> primary valuespace = None (makes index Quble)
                             '<inspect>' ==> no preference..inspect valuespaces

        : type grace: bool (True/False*)
        : param grace: handling when non-trivial preferred_vs
                       is absent from table's valuespace
        """
        if isinstance(preferred_vs, (list, tuple)):
            # Handle list/tuple arg case
            # by selecting first element if possible
            if len(preferred_vs) > 0:
                preferred_vs = preferred_vs[0]
            else:
                preferred_vs = None

        if (preferred_vs in self.spaces) and (preferred_vs not in self._valuespaces):
            # Handle case when we are annointing a former non-valuespace (but valid space)
            self._valuespaces.append(preferred_vs)
            if preferred_vs in self._keyspaces:
                self._keyspaces.remove(preferred_vs)
            self.set_space_info(
                space=preferred_vs, info_type="role", info_value="valuespace"
            )
            return preferred_vs

        # Next, try to honor preferred_vs if applicable
        elif preferred_vs == "<inspect>":
            pass
        # elif preferred_vs is None or preferred_vs in self._valuespaces:
        #     return preferred_vs
        elif preferred_vs is None:
            pass
        elif preferred_vs in self._valuespaces:
            return preferred_vs
        elif not grace:
            raise Exception(
                "Non-trivial preferred_vs:{0} is absent from valuespaces:{1}".format(
                    preferred_vs, self.valuespaces
                )
            )

        # --------------------------------------------------
        # At this point, preferred_vs in ('<inspect>',None)
        # --------------------------------------------------
        # Next, see if any valuespace is explicitly identified as primary
        for vs in self._valuespaces:
            if self.get_space_info(info_type="is_primary", space=vs, grace=True):
                return vs

        # Default to first valuespace
        if len(self._valuespaces) > 0:
            return self._valuespaces[0]
        else:
            return None

    def has_valuespace(self, grace: bool = True) -> bool:
        if self.valuespace is not None:
            return True
        elif grace:
            return False
        else:
            raise Exception("Quble has no primary valuespace")

    def has_valuespaces(self, grace: bool = True) -> bool:
        if len(self.valuespaces) > 0:
            return True
        elif grace:
            return False
        else:
            raise Exception("Quble has no valuespaces")

    @property
    def keyspaces_shorthands(cls):
        """
        List of all possible 'shorthands' for keyspaces
        Examples:
        """
        return [
            "<keyspaces>",
            "<time_keyspaces>",
            "<first_keyspace>",
            "<first_time_keyspace>",
            "<last_keyspace>",
            "<SECMSTR>",
            "<resampling_keyspaces>",
            "<vantage_time_keyspaces>",
            "<non_vantage_time_keyspaces>",
            "<keyspaces_with_null_keys>",
        ]

    @property
    def valuespaces_shorthands(cls):
        """
        List of all possible shorthands for valuespaces
        """
        return [
            "<valuespace>",
            "<valuespaces>",
            "<numeric_valuespaces>",
            "<float_valuespaces>",
            "<int_valuespaces>",
            "<bool_valuespaces>",
            "<time_valuespaces>",
            "<first_valuespace>",
            "<last_valuespace>",
            "<auxvalspaces>",
        ]

    @property
    def spaces_shorthands(cls):
        """
        List of all possible shorthands for any/all spaces
        """
        return (
            ["<all>", "<spaces>"]
            + cls.keyspaces_shorthands
            + cls.valuespaces_shorthands
        )

    def validate_space(
        self,
        space: str,
        grace: bool = False,
        coerce_to_list: bool = False,
        solo_required: bool = False,
        keyspace_required: bool = False,
        valuespace_required: bool = False,
        numeric_required: bool = False,
        time_space_required: bool = False,
    ):
        """Validates a general candidate space of a Quble

        Can provide following templated args for subsequent translation:
        '<valuespace>'
        ==> resolves to primary valuespace
        '<all>' or '<spaces>'
        ==> resolves to all spaces of the Quble
        ==> returns a list regardless of coerce_to_list arg
        '<keyspaces>'
        ==> resolves to all keyspaces of the Quble
        ==> returns a list regardless of coerce_to_list arg
        '<time_keyspaces>'
        ==> resolves to all time keyspaces of the Quble
        ==> returns a list regardless of coerce_to_list arg
        '<time_spaces>'
        ==> resolves to all time spaces of the Quble
        ==> returns a list regardless of coerce_to_list arg
        '<valuespaces>'
        ==> resolves to all valuespaces of the Quble
        ==> returns a list regardless of coerce_to_list arg
        '<auxvalspaces>'
        ==> resolves to all auxillary valuespaces of the Quble
        ==> returns a list regardless of coerce_to_list arg
        '<numeric_valuespaces>'
        ==> resolves to all numeric valuespaces of the Quble
        ==> returns a list regardless of coerce_to_list arg
        '<non_numeric_valuespaces>'
        ==> resolves to all non-numeric valuespaces of the Quble
        ==> returns a list regardless of coerce_to_list arg
        '<string_valuespaces>'
        ==> resolves to all string valuespaces of the Quble
        ==> returns a list regardless of coerce_to_list arg
        '<time_valuespaces>' ==> resolves to all time valuespaces of the Quble
        ==> returns a list regardless of coerce_to_list arg
        '<first_time_keyspace>'
        ==> resolves to first time-based keyspace
        '<first_non_vantage_time_keyspace>'
        ==> resolves to first non-vantage time-keyspace
        '<first_vantage_time_keyspace>'
        ==> resolves to first vantage time-keyspace
        '<first_keyspace>'
        ==> resolves to first keyspace

        :type space: str or list of str
        :param space: space(s) to be validated.

        :type grace: bool
        :param grace:
            Control for handling of non-validation [True: invalid gracfully
            return original keyspace(s), False: throw Exception]

        :type coerce_to_list: bool
        :param coerce_to_list:
            (optional) Will coerce (guarantee) a list output
            (when the calling context would like list form).
            ==> coerce_to_list=True: yields a list
            ==> coerce_to_list=False: yields either scalar or list  (depending on space arg input form and solo_required arg)

        :type solo_required: bool (False*/True)
        :param solo_required: Flag to requiring a single space result
        ==> If solo_required=True, will return result as scalar unless coerce_to_list=True (even if input was a provided as single element list/tuple)

        :type keyspace_required: bool (False*/True)
        :param keyspace_required: Flag for requiring only keyspaces

        :type valuespace_required: bool (False*/True)
        :param valuespace_required: Flag for requiring only valuespaces

        :type numeric_required: bool (False*/True)
        :param numeric_required: Flag for requiring only numeric valuespaces

        :type time_space_required: bool (False*/True)
        :param time_space_required: Flag to requiring time space
               ==> If time_space_required=True,
               ==> the resultant space(s) must be time-spaces

        :rtype: str (or list of str)
        :returns: The validated space name(s)
        """
        # Handle undefined Quble case
        if self.is_undefined:
            if not grace:
                raise UndefinedQubleError("Quble is undefined")
            elif space in self.spaces_shorthands:
                return None
            else:
                return space

        scalar_space_flag = False
        # (Temporarily) convert space to a list
        if isinstance(space, (list, tuple)):
            # Need deepcopy as we may actually
            # change some of the elements of
            # space below via auto_link
            if solo_required and len(space) > 1:
                raise Exception(f"solo required yet space:{space}")
            space = deepcopy(space)
        elif space in ("<all>", "<spaces>"):
            space = self.spaces
        elif space == "<keyspaces>":
            space = self.keyspaces
        elif space == "<time_keyspaces>":
            space = self.time_keyspaces
        elif space == "<time_spaces>":
            space = self.time_spaces
        elif space == "<valuespaces>":
            space = self.valuespaces
        elif space == "<auxvalspaces>":
            space = self.auxvalspaces
        elif space == "<numeric_valuespaces>":
            space = self.numeric_valuespaces
        elif space == "<non_numeric_valuespaces>":
            space = self.non_numeric_valuespaces
        elif space == "<string_valuespaces>":
            space = self.string_valuespaces
        elif space == "<time_valuespaces>":
            space = self.time_valuespaces
        elif space == "<valuespace>":
            scalar_space_flag = True
            space = [self.valuespace]
        elif space == "<first_time_keyspace>":
            scalar_space_flag = True
            ftk = self.first_time_keyspace(grace=grace)
            space = [ftk] if ftk is not None else []
        elif space == "<first_non_vantage_time_keyspace>":
            scalar_space_flag = True
            ftk = self.first_non_vantage_time_keyspace(grace=grace)
            space = [ftk] if ftk is not None else []
        elif space == "<first_vantage_time_keyspace>":
            scalar_space_flag = True
            ftk = self.first_vantage_time_keyspace(grace=grace)
            space = [ftk] if ftk is not None else []
        elif space == "<first_keyspace>":
            scalar_space_flag = True
            pks = self.first_keyspace
            space = [pks] if pks is not None else []
        elif not space in self.spaces:
            space = [space]
            scalar_space_flag = True
        else:
            scalar_space_flag = True
            space = [space]

        # Loop through space(s) to validate
        for i in range(len(space)):
            # Handle (key)space position/axis number was given
            if isinstance(space[i], int):
                if (space[i] >= 0) and (space[i] < self.ndim):
                    space[i] = self.spaces[space[i]]
                elif grace:
                    continue
                else:
                    if grace:
                        return None
                    raise SpaceRefError(f"Invalid space:{space[i]}")

            # Intentionally not an elif clause here
            if space[i] in self.spaces:
                # Check keyspace requirement (when applicable)
                if keyspace_required and space[i] not in self.keyspaces:
                    if grace:
                        return None
                    raise SpaceRefError(f"Non-keyspace: {space[i]}")
                # Check time-space requirement (when applicable)
                elif time_space_required and not self.is_time_space(space[i]):
                    if grace:
                        return None
                    raise SpaceRefError(f"Non-time space: {space[i]}")
                # Check valuespace requirement (when applicable)
                elif valuespace_required and space[i] not in self.valuespaces:
                    if grace:
                        return None
                    raise SpaceRefError(f"Non-valuespace: {space[i]}")
                # Check numeric requirement (when applicable)
                elif numeric_required and not self.is_numeric(space[i]):
                    if grace:
                        return None
                    raise Exception(
                        f"Invalid space:{space[i]}...numeric requirement violated"
                    )
            else:
                if grace:
                    return None
                raise SpaceRefError(f"Invalid space:{space[i]}")

            if space[i] not in self._column_info["role"]:
                if grace:
                    return None
                raise Exception(f"Invalid space:{space[i]}... missing role assignment")

        # Handle result: At this point, space is a list
        # -------------------
        if solo_required and len(space) > 1:
            if grace:
                return None
            raise Exception(f"solo space required yet result:{space}")
        elif coerce_to_list:
            return space
        elif scalar_space_flag or solo_required:
            # Was originally provided as a scalar or solo_required, return as scalar
            if len(space) > 0:
                return space[0]
            else:
                return None
        else:
            return space

    def validate_valuespace(
        self,
        valuespace,
        grace: bool = False,
        allow_auxvalspaces: bool = True,
        coerce_to_list: bool = False,
        solo_required: bool = False,
        numeric_required: bool = False,
        numeric_or_bool_required: bool = False,
    ):
        """
        Validate/resolve valuespace to ensure support within the Quble.
            The *valuespace* argument can have the following values:

            +----------------------------+---------------------------------------+
            | Value                      | Description                           |
            +----------------------------+---------------------------------------+
            | *valuespace name*          | Return the validated given valuespace |
            +----------------------------+---------------------------------------+
            | *list of valuespace names* | Return the validated given valuespaces|
            +----------------------------+---------------------------------------+
            | ``<valuespace>``           | Return the primary valuespace         |
            +----------------------------+---------------------------------------+
            | ``<valuespaces>``          | Return all valuespaces                |
            +----------------------------+---------------------------------------+
            | ``<auxvalspaces>``         | Return auxillary valuespaces          |
            +----------------------------+---------------------------------------+
            | ``<first_valuespace>``     | Return the first valuespace           |
            +----------------------------+---------------------------------------+
            | ``<last_valuespace>``      | Return the last valuespace            |
            +----------------------------+---------------------------------------+
            | ``<numeric_valuespaces>``  | Return numeric valuespaces            |
            +----------------------------+---------------------------------------+
            | ``<float_valuespaces>``    | Return float valuespaces              |
            +----------------------------+---------------------------------------+
            | ``<int_valuespaces>``      | Return integer valuespaces            |
            +----------------------------+---------------------------------------+
            | ``<bool_valuespaces>``     | Return boolean valuespaces            |
            +----------------------------+---------------------------------------+
            | ``<time_valuespaces>``     | Return time valuespaces               |
            +----------------------------+---------------------------------------+
            | ``<string_valuespaces>``   | Return string-type valuespaces        |
            +----------------------------+---------------------------------------+
            | ``<currency_valuespaces>`` | Return currency valuespaces           |
            +----------------------------+---------------------------------------+

        :type valuespace: str or list of str
        :param valuespace: Valuespace(s) to be validated. '<valuespace>' ==> resolves to primary valuespace

        :type grace: bool
        :param grace: Control for handling of non-validation.
            ==> If True, invalid gracfully returns original valuespace(s)
            ==> If False, throw Exception

        :type allow_auxvalspaces: bool (True*/False)
        :param allow_auxvalspaces: Allows for auxillary valuespace submissions (if present)

        :type coerce_to_list: bool
        :param coerce_to_list: (optional) Will coerce (guarantee) a list output (when the calling context would like list form).
            ==> coerce_to_list=True: yields a list
            ==> coerce_to_list=False: yields either scalar or list (depending on space arg input form and solo_required arg)

        :type solo_required: bool (False*/True)
        :param solo_required: Flag to requiring a single valuespace result
            ==> If solo_required=True,will return result as scalar unless coerce_to_list=True (even if input was a provided as single element list/tuple)

        :type numeric_required: bool (False*/True)
        :param numeric_required: Flag for requiring only numeric valuespaces

        :type numeric_or_bool_required: bool (False*/True)
        :param numeric_or_bool_required: Flag for requiring only numeric or boolean valuespaces

        :rtype: str (or list of str)
        :returns: The validated valuespace name(s)

        NOTE: Arguments numeric_required and numeric_or_bool_required SHOULD NOT BE USED SIMULTANEOUSLY
        """
        # Handle undefined Quble case
        if self.is_undefined:
            if not grace:
                raise UndefinedQubleError("Quble is undefined")
            elif valuespace in self.valuespaces_shorthands:
                # Trap for special keyword cases
                return None
            else:
                return valuespace

        # Handle trivial case
        if (self.valuespaces is None) or (valuespace is None):
            if grace:
                return valuespace
            else:
                raise ValuespaceRefError(f"Invalid valuespace:{valuespace}")
        elif valuespace in ("<all>", "<valuespaces>"):
            valuespace = self.valuespaces
        elif valuespace == "<auxvalspaces>":
            valuespace = self.auxvalspaces
        elif valuespace in ("<first>", "<first_valuespace>"):
            valuespace = self.valuespaces[0]
        elif valuespace in ("<last>", "<last_valuespace>"):
            valuespace = self.valuespaces[-1]
        elif valuespace == "<numeric_valuespaces>":
            valuespace = self.numeric_valuespaces
        elif valuespace == "<float_valuespaces>":
            valuespace = self.float_valuespaces
        elif valuespace == "<int_valuespaces>":
            valuespace = self.int_valuespaces
        elif valuespace == "<bool_valuespaces>":
            valuespace = self.bool_valuespaces
        elif valuespace == "<time_valuespaces>":
            valuespace = self.time_valuespaces
        elif valuespace == "<string_valuespaces>":
            valuespace = self.string_valuespaces
        elif valuespace == "<valuespace>":
            valuespace = self.valuespace
        elif valuespace == "<currency_valuespaces>":
            valuespace = self.currency_valuespaces

        # (Temporarily) convert valuespace to a list
        if isinstance(valuespace, (list, tuple)):
            # Need deepcopy as we may actually change some of the elements of valuespace below via auto_link
            if solo_required and len(valuespace) > 1:
                raise Exception(
                    f"Failed validation: solo required yet valuespace:{valuespace}"
                )
            valuespace = (
                deepcopy(list(valuespace))
                if not isinstance(valuespace, list)
                else deepcopy(valuespace)
            )
            scalar_valuespace_flag = False
        else:
            valuespace = [valuespace]
            scalar_valuespace_flag = True

        # Loop through valuespace(s) to validate
        for i in range(len(valuespace)):
            # Check numeric or bool requirement (when applicable)
            if (
                numeric_or_bool_required
                and valuespace[i] in self.valuespaces
                and not self.is_numeric_or_bool(valuespace[i])
            ):
                if grace:
                    return None
                raise Exception(
                    f"Failed validation: numeric or bool requirement violated for valuespace: {valuespace[i]}"
                )
            # Otherwise check numeric requirement (when applicable)
            elif (
                numeric_required
                and valuespace[i] in self.valuespaces
                and not self.is_numeric(valuespace[i])
            ):
                if grace:
                    return None
                raise Exception(
                    f"Failed validation: numeric requirement violated for valuespace: {valuespace[i]}"
                )

            # Check against allow_auxvalspaces flag
            if allow_auxvalspaces and valuespace[i] in self.valuespaces:
                pass
            elif not allow_auxvalspaces and valuespace[i] == self.valuespace:
                pass
            elif grace:
                pass
            else:
                raise Exception(
                    f"Failed validation: requested valuespace, '{valuespace[i]}', not contained in valuespaces = {self.valuespaces}"
                )

        # Handle result
        # At this point, valuespace is a list
        # ---------------------
        if solo_required and len(valuespace) > 1:
            raise Exception(
                f"Failed validation: solo valuespace required yet result:{valuespace}"
            )
        elif coerce_to_list:
            return valuespace
        elif scalar_valuespace_flag or solo_required:
            # Was originally provided as a scalar, return as scalar
            return valuespace[0]
        else:
            # Was originally provided as a scalar or solo_required, return as scalar
            return valuespace

    @RootLib.lazy_kwargs()
    def validate_keyspace(
        self,
        keyspace,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        grace: bool = False,
        coerce_to_list: bool = False,
        allow_keygroup: bool = False,
        expand_keygroups: bool = False,
        solo_required: bool = False,
        time_space_required: bool = False,
        resampling_space_required: bool = False,
        security_space_required: bool = False,
    ):
        """
        Validate/resolve keyspaces(s) to ensure support within the Quble.

        The *keyspace* argument can have the following values:

        +-----------------------------+--------------------------------------+
        | Value                       | Description                          |
        +-----------------------------+--------------------------------------+
        | *keyspace name*             | Return the validated given keyspace  |
        +-----------------------------+--------------------------------------+
        | *list of keyspace names*    | Return the validated given keyspaces |
        +-----------------------------+--------------------------------------+
        | *keygroup name*             | Return keyspaces in keygroup         |
        +-----------------------------+--------------------------------------+
        | ``<first_keyspace>``        | Return the first keyspace            |
        +-----------------------------+--------------------------------------+
        | ``<first_time_keyspace>``   | Return the first time-based keyspace |
        +-----------------------------+--------------------------------------+
        | ``<last_keyspace>``         | Return the last keyspace             |
        +-----------------------------+--------------------------------------+
        | ``<keyspaces>``             | Return all keyspaces                 |
        +-----------------------------+--------------------------------------+
        | ``<time_keyspaces>``        | Return all time-keyspaces            |
        +-----------------------------+--------------------------------------+
        | ``<resampling_keyspaces>``  | Return all resampling-keyspaces      |
        +-----------------------------+--------------------------------------+
        | ``<SECMSTR>``               | Return the (first) keyspace          |
        |                             | present in SECMSTR library fields    |
        +-----------------------------+--------------------------------------+
        |  keyspaces_with_null_keys   | Return keyspaces with null keys      |
        +-----------------------------+--------------------------------------+
        |  keyspaces_without_null_keys| Return keyspaces with null keys      |
        +-----------------------------+--------------------------------------+

        :type keyspace: str or list of str
        :param keyspace: keyspace(s) to be validated.

        :type auto_link: bool
        :param auto_link: Control for auto-linking (keyspace affiliation)

        :type grace: bool
        :param grace:
            Control for handling of non-validation [True: invalid gracefully
            return original keyspace(s), False: throw Exception]

        :type coerce_to_list: bool
        :param coerce_to_list:
            (optional) Will coerce (guarantee) a list output
            (when the calling context would like list form).
            ==> coerce_to_list=True: yields a list
            ==> coerce_to_list=False: yields either scalar or list (depending on space arg input form and solo_required arg)

        :type allow_keygroup: bool (True*/False)
        :param allow_keygroup:
            Control to allow keygroup to a validated

        :type expand_keygroups: bool (False*/True)
        :param expand_keygroups:
            Control to expand specified keygroups to their underlying keyspaces

        :type solo_required: bool (False*/True)
        :param solo_required: Flag to requiring a single keyspace result
               ==> If solo_required=True,will return result as scalar unless coerce_to_list=True (even if input was a provided as single element list/tuple)

        :type time_space_required: bool (False*/True)
        :param time_space_required: Flag to requiring time keyspace
               ==> If time_space_required=True,
               ==> the resultant keyspace(s) must be time-spaces

        :type security_space_required: bool (False*/True)
        :param security_space_required: Flag to requiring security keyspace
               ==> If security_space_required=True,
               ==> the resultant keyspace(s) must be security-spaces

        :rtype: str (or list of str)
        :returns: The validated keyspace name(s)
        """
        root_lib = RootLib()
        from qubles.io.ref.reflib import RefLib  # Avoids circular import

        # Set initial expectations for steps
        validation_required = True
        keygroup_inspection_required = True
        prevalidated_security_space = False

        # Handle undefined Quble case
        if self.is_undefined:
            if not grace:
                raise UndefinedQubleError("Quble is undefined")
            elif keyspace in self.keyspaces_shorthands:
                # Trap for special keyword cases
                return None
            else:
                return keyspace

        # Establish Quble's keyspaces
        keyspaces = self.keyspaces

        # ------------------------------------------
        # Initialize algo requirements...
        # [Will be reset below for general case]
        # ------------------------------------------
        validation_required = False
        keygroup_inspection_required = False

        # -----------------------------------
        # Handle special cases
        # [No validation_required]
        # [No keygroup_inspection_required]
        # -----------------------------------
        if (keyspaces is None) or (keyspace is None):
            if grace:
                return keyspace
            else:
                raise KeyspaceRefError(f"Invalid keyspace:{keyspace}")
        elif keyspace in ("<all>", "<keyspaces>"):
            keyspace = keyspaces
        elif keyspace in ("<first>", "<first_keyspace>"):
            keyspace = keyspaces[0]
        elif keyspace in ("<last>", "<last_keyspace>"):
            keyspace = keyspaces[-1]
        elif keyspace == "<time_keyspaces>":
            keyspace = self.time_keyspaces
        elif keyspace == "<vantage_time_keyspaces>":
            keyspace = self.vantage_time_keyspaces
        elif keyspace == "<non_vantage_time_keyspaces>":
            keyspace = self.non_vantage_time_keyspaces
        elif keyspace == "<first_time_keyspace>":
            keyspace = self.first_time_keyspace(grace=grace)
            if keyspace is None and grace:
                return keyspace
        elif keyspace == "<resampling_keyspaces>":
            keyspace = self.resampling_keyspaces()
        elif keyspace == "<keyspaces_with_null_keys>":
            keyspace = self.keyspaces_with_null_keys
        elif keyspace == "<keyspaces_without_null_keys>":
            keyspace = self.keyspaces_without_null_keys
        elif keyspace == "<SECMSTR>":
            if "SECMSTR" in root_lib.fields() and isinstance(
                root_lib["SECMSTR"], RefLib
            ):
                keyspace = root_lib["SECMSTR"].get_src_keyspace(self.keyspaces)
                prevalidated_security_space = True
            elif not grace:
                raise KeyspaceRefError("Invalid keyspace:{0}".format(keyspace))
        else:
            # ----------------
            # General case
            # ----------------
            validation_required = True
            keygroup_inspection_required = True

        # ----------------------------------------------------
        # Step 1A: Apply keygroup inspection (if applicable)
        # Step 1B: (Temporarily) convert keyspace to a list
        # ----------------------------------------------------
        if not keygroup_inspection_required:
            if isinstance(keyspace, (list, tuple)):
                # Nothing to do here
                pass
                scalar_keyspace_flag = False
            else:
                keyspace = [keyspace]
                scalar_keyspace_flag = True
        else:
            # ----------------------
            # keygroup inspection
            # ----------------------
            # Make a local copy of keygroups
            keygroups = self.keygroups

            if isinstance(keyspace, (list, tuple)):
                # Handle existence of keygroups
                keyspace2 = []
                for ks in keyspace:
                    if ks not in self.keyspaces and ks in keygroups:
                        if isinstance(ks, (list, tuple)):
                            keyspace2 += list(keygroups[ks])
                        else:
                            keyspace2 += [keygroups[ks]]
                    else:
                        keyspace2 += [ks]
                keyspace = keyspace2

                scalar_keyspace_flag = False
                if solo_required and len(keyspace) > 1:
                    if grace:
                        return None
                    raise Exception("solo required yet keyspace:{0}".format(keyspace))

            # Investigate keygroups sans keyspaces
            elif keyspace not in self.keyspaces and keyspace in keygroups:
                keyspace = keygroups[keyspace]
                if not isinstance(keyspace, (list, tuple)):
                    keyspace = [keyspace]
                    scalar_keyspace_flag = True
                else:
                    # Do not want to re-coerce to scalar at end
                    scalar_keyspace_flag = False if len(keyspace) > 1 else True
            else:
                keyspace = [keyspace]
                scalar_keyspace_flag = True

        # ---------------------------------------------------------
        # Validate each element of the keyspace list (if needed)
        # ---------------------------------------------------------
        # Loop through keyspace(s) to validate each
        keygroup_expansions = {}  # <-- Initialization
        if validation_required:
            for i in range(len(keyspace)):
                # Case #1: keyspace position/axis number was given
                if isinstance(keyspace[i], int):
                    if (keyspace[i] >= 0) and (keyspace[i] < self.ndim):
                        keyspace[i] = self.keyspaces[keyspace[i]]
                    elif grace:
                        continue
                    else:
                        raise KeyspaceRefError(
                            "Invalid keyspace:{0}".format(keyspace[i])
                        )
                # Case #2: keyspace was given (instead of a axis number)
                elif keyspace[i] in keyspaces:
                    # <-- pass here as we possibly want to check time-space requirement below
                    pass
                # Case #3: RefLib was given (instead of a axis number)
                elif isinstance(keyspace[i], RefLib):
                    keyspace[i] = keyspace[i].get_src_keyspace(self.keyspaces)
                # Case #4: auto-link authorized and a RefLib Address was given as either:
                #     a) LibAddress
                #  or b) string field of RootLib domain
                # -----------------------------------------
                elif auto_link and (
                    isinstance(keyspace[i], LibAddress)
                    or (
                        isinstance(keyspace[i], str)
                        and (keyspace[i] in root_lib.field_index)
                    )
                ):
                    if isinstance(keyspace[i], LibAddress):
                        # Here, keyspace[i] is LibAddress (Expected to yield a RefLib)
                        reflib = keyspace[i].deliver()
                    else:
                        # Here, keyspace[i] is str matching a field of the root_lib (Expected to yield a RefLib)
                        reflib = root_lib.get(keyspace[i], log=False)

                    if isinstance(reflib, RefLib):
                        keyspace[i] = reflib.get_src_keyspace(self.keyspaces)
                    elif grace:
                        continue
                    else:
                        raise KeyspaceRefError(
                            "Invalid keyspace:{0}".format(keyspace[i])
                        )
                # Case #5: Bracketed RefLib Address was given & auto_link authorized
                elif (
                    auto_link
                    and isinstance(keyspace[i], str)
                    and (len(keyspace[i]) > 2)
                    and (keyspace[i][0] == "<")
                    and (keyspace[i][-1] == ">")
                    and (keyspace[i][1:-1] in root_lib.field_index)
                ):
                    reflib = root_lib.get(keyspace[i][1:-1], log=False)
                    if isinstance(reflib, RefLib):
                        keyspace[i] = reflib.get_src_keyspace(self.keyspaces)
                    elif grace:
                        continue
                    else:
                        raise KeyspaceRefError(
                            "Invalid keyspace:{0}".format(keyspace[i])
                        )
                elif (
                    allow_keygroup
                    and self.keygroups is not None
                    and keyspace[i] in self.keygroups
                ):
                    if expand_keygroups:
                        keygroup_expansions[keyspace[i]] = self.keygroups[keyspace[i]]
                    # Recall (when not None) will be a dictionary
                    continue
                elif grace:
                    continue
                else:
                    raise KeyspaceRefError("Invalid keyspace:{0}".format(keyspace[i]))

                # If applicable, perform time-space check on the validated keyspace
                if (
                    time_space_required
                    and keyspace[i] in self.keyspaces
                    and not self.is_time_space(keyspace[i])
                ):
                    if grace:
                        return None
                    raise KeyspaceRefError("Non-time keyspace: {}".format(keyspace[i]))

                # If applicable, perform security-space check on the validated keyspace
                if (
                    security_space_required
                    and keyspace[i] in self.keyspaces
                    and not prevalidated_security_space
                    # Following method should not be called if prevalidated_security_space
                    and not self.is_security_space(keyspace[i])
                ):
                    if grace:
                        return None
                    raise KeyspaceRefError(
                        "Non-security keyspace: {}".format(keyspace[i])
                    )

                # If applicable, perform resampling-space check on the validated keyspace
                if (
                    resampling_space_required
                    and keyspace[i] in self.keyspaces
                    and not self.is_resampling_space(keyspace[i])
                ):
                    if grace:
                        return None
                    raise KeyspaceRefError(
                        "Non-resampling keyspace: {}".format(keyspace[i])
                    )

        # -------------------------------------------
        # Apply keygroup expansion (when applicable)
        # -------------------------------------------
        if len(keygroup_expansions) > 0:
            # Here, some self.keygroups were specified in the original keyspace arg and need to be expanded to their underlying keyspaces
            # Recall that keyspace variable is a list here. This exercise may recast/increase the length of keyspace (list)
            expanded_keyspaces = []
            for ks in keyspace:
                if ks in keygroup_expansions and keygroup_expansions[ks] is not None:
                    if not isinstance(keygroup_expansions[ks], (list, tuple)):
                        if grace:
                            return None
                        raise Exception(
                            "self.keygroups[{0}]:{1} is niot a list/tuple as expected".format(
                                ks, keygroup_expansions[ks]
                            )
                        )
                    expanded_keyspaces += keygroup_expansions[ks]
                else:
                    expanded_keyspaces.append(ks)
            # Reassign keyspaces to expanded_keyspaces
            keyspace = expanded_keyspaces

        # -------------------
        # Handle result. At this point, keyspace is a list
        # -------------------
        if solo_required and len(keyspace) > 1:
            raise Exception(f"solo keyspace required yet result:{keyspace}")
        elif coerce_to_list:
            return keyspace
        elif scalar_keyspace_flag or solo_required:
            # Was originally provided as a scalar or solo_required, return as scalar
            return keyspace[0]
        else:
            return keyspace

    def absent_keyspaces(self, tgt_keyspaces) -> list:
        """
        Given a list of candidate keyspaces,
        returns the subset of keyspaces that are absent
        [Gets absent keyspaces from a those supplied (tgt_keyspaces).]

        :param tgt_keyspaces: List of target keyspaces
        :type tgt_keyspaces: list or tuple

        :returns: list of absent (external) keyspaces
        :rtype: list
        """
        absent_keyspaces = []

        # Validate tgt_keyspaces arg
        if tgt_keyspaces is None:
            return absent_keyspaces

        elif not isinstance(tgt_keyspaces, list) and not isinstance(
            tgt_keyspaces, tuple
        ):
            raise Exception("Invalid tgt_keyspaces arg: list or tuple expected")

        # Populate the absent_kesypaces list
        keyspaces = self.keyspaces
        for ks in tgt_keyspaces:
            if ks not in keyspaces:
                absent_keyspaces.append(ks)
        return absent_keyspaces

    def ortho_keyspaces(self, keyspace, grace: bool = True) -> list:
        """
        Returns a (string) list of the Quble's keyspaces that are
        orthogonal to (outside of) the specified keyspace(s)

        :param keyspace: keyspace(s) of the dimension to be aggregated
        :type keyspace: str or list of str (or shorthand thereof)

        :param grace: Graceful/ungraceful exception handling
        :type grace: boolean (True/False)

        """
        # Validate the keyspace arg and convert to a list
        keyspaces_to_exclude = self.validate_keyspace(
            keyspace=keyspace, grace=grace, coerce_to_list=True
        )

        # Establish ortho_keyspace_list
        ortho_keyspace_list = deepcopy(self.keyspaces)

        # Exclude keyspaces as directed
        for keyspace_to_exclude in keyspaces_to_exclude:
            if keyspace_to_exclude in ortho_keyspace_list:
                ortho_keyspace_list.remove(keyspace_to_exclude)

        # Return the remaining (unexcluded/ortho) keyspaces
        return ortho_keyspace_list

    def has_resampling_keyspaces(self) -> bool:
        return True if len(self.resampling_keyspaces()) > 0 else False

    def resampling_keyspaces(self) -> list:
        """
        Returns a list of strings of the Quble's keyspaces
        that are resampling time-spaces
        """
        rs_ks_list = []
        for ks in self.keyspaces:
            if self.is_resampling_space(space=ks):
                rs_ks_list.append(ks)

        return rs_ks_list

    def has_ortho_resampling_keyspaces(self, keyspace, grace: bool = True) -> bool:
        return (
            True
            if len(self.ortho_resampling_keyspaces(keyspace=keyspace, grace=grace)) > 0
            else False
        )

    def ortho_resampling_keyspaces(self, keyspace, grace: bool = True) -> list:
        """
        Returns a list (of (strings) of Quble's keyspaces that are
        resampling time-spaces AND orthogonal to (outside of) the specified keyspace(s)

        :param keyspace: keyspace(s) of the dimension to be aggregated
        :type keyspace: str or list of str

        :param grace: Graceful/ungraceful exception handling
        :type grace: boolean (True/False)

        """
        # Establish ortho_keyspace_list
        if keyspace is None:
            keyspaces_to_exclude = []
        elif isinstance(keyspace, list):
            keyspaces_to_exclude = keyspace
        elif isinstance(keyspace, tuple):
            keyspaces_to_exclude = list(keyspace)  # <-- Will need to be mutable below
        else:
            keyspaces_to_exclude = [keyspace]

        if len(self.keyspaces) > 0:
            ortho_rs_list = []
            for ks in self.keyspaces:
                if ks in keyspaces_to_exclude:
                    continue
                elif not self.is_resampling_space(space=ks):
                    continue
                else:
                    ortho_rs_list.append(ks)

            # Return the remaining (unexcluded/ortho) resampling keyspace list
            return ortho_rs_list
        elif grace:
            return []
        else:
            raise Exception("Quble has no keyspaces")

    def _keyspaces_sort_clause(self, key_ordering: str, keyspaces=None) -> str:
        """
        Creates an keyspace sort SQL clause.

        If keyspaces=None, then the keyspaces will be requested/established internally
        Returns a string. Clause will be empty string for the non-sort case

        :param key_ordering: (optional) Indicates whether/how to order result records within the keyspaces (index columns)
        :type key_ordering: None (no keyspace sorting), 'asc' or 'desc'

        :param keyspaces: (optional) Bootsrapping for keyspaces of the associated table
        :type key_ordering: None or string list

        :returns: The associated SQL sort clause
        :rtype: str
        """
        keyspaces_sort_clause = ""  # <-- Initialize to empty string

        # Handle trivial cases
        if key_ordering is None:
            return keyspaces_sort_clause

        if keyspaces is None:
            keyspaces = self.keyspaces

        if keyspaces is None or len(keyspaces) == 0:
            return keyspaces_sort_clause

        # Validate key_ordering
        if not isinstance(key_ordering, str) or len(key_ordering) == 0:
            raise Exception(
                "Invalid key_ordering arg:{0}...None or 'asc' or 'desc' expected".format(
                    key_ordering
                )
            )
        elif key_ordering[0].lower() == "a":
            key_ordering = " asc"
        elif key_ordering[0].lower() == "d":
            key_ordering = " desc"
        else:
            raise Exception(
                "Invalid key_ordering arg:{0}...None or 'asc' or 'desc' expected".format(
                    key_ordering
                )
            )

        # Add each keyspace to keyspaces_sort_clause
        comma_str = ""
        for keyspace in keyspaces:
            if len(keyspaces_sort_clause) == 0:
                keyspaces_sort_clause = " ORDER BY "  # <-- Note intentional leading space for convenience of latter use
            keyspaces_sort_clause += comma_str + keyspace + key_ordering
            comma_str = ", "

        return keyspaces_sort_clause

    def _keyspaces_by_clause(self, keyspaces: list) -> str:
        """
        Creates a SQL "BY CLAUSE" (str)
        involving the specified keyspaces (list)
        for appropriate use within a SQL command.

        This method returns a string
        (Clause will be empty if no ortho_keyspaces exist)

        :param keyspaces: keyspaces (list of str or str) to be used in "by-clause"
        :type keyspaces: string list

        :rtype: str
        :returns: The associated SQL "by clause"
        """
        # Next, create orthogonal "by clause" for use partitioning clause within ortho_keyspaces (to be used within ranking)
        # [Example: partition_clause = ' BY Tickers, Dates']
        by_clause = ""
        if not isinstance(keyspaces, (list, tuple)):
            keyspaces = [keyspaces]

        if len(keyspaces) > 0:
            by_clause += " BY "  # <-- NOTE LEADING SPACE HERE
            comma_str2 = ""
            for ks in keyspaces:
                by_clause += comma_str2 + ks
                comma_str2 = ", "
        return by_clause

    # ===================================== STATS =====================================

    # ========================================= CROSS-COLUMN AGGREGATION =========================================

    @RootLib.lazy_kwargs()
    def aggregate_xcols(
        self,
        aggr_valuespaces="<numeric_valuespaces>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        new_valuespace: str = DEFAULT_VALUESPACE,
        keep_existing_valuespaces: bool = False,
        num_required: int = 0,
        pct_required: float = 0.0,
        weights: dict = None,
        wt_required: float = 0.0,
        view: Quble = RootLib.lazy_eval("view"),
        custom_info_overrides: dict = None,
        compress: bool = RootLib.lazy_eval("auto_compress"),
        key_ordering: str = "asc",
        inplace: bool = False,
    ):
        """
        Aggregates across the specified aggregation valuespaces
        according to the aggregation_method

        :param aggr_valuespaces: valuespace(s) to be aggregated
        :type aggr_valuespaces: str or list of strings
                (keywords may be used such as '<valuespaces>', '<numeric_valuespaces>', etc.
                [See: :meth:`~qubles.core.quble.Quble.validate_valuespace`]

        :param aggr_method: Aggregation method
                ==> 'sum','ave','avg','mean'
                ==> 'wtd_sum','wtd_ave','wtd_avg','wtd_mean'
                ==> 'stddev','var'
                ==> 'wtd_stddev','wtd_var'
        :type aggr_method: str

        :param ignore_missing:
            Control for whether to ignore the presence of null values in the aggregation
        :type ignore_missing: bool

        :param new_valuespace: new valuespace (column) of aggregated results
        :type new_valuespace: str

        :param keep_existing_valuespaces:
            Control for retaining the origical valuespaces
        :type keep_existing_valuespaces: bool (False*/True)

        :param num_required:
            Control for necessary data support across aggregation valuespaces
            Value must  either None or an int >= 0
        :type num_required: None or int (default:0)

        :param pct_required:
            Control for necessary data support across aggregation valuespaces
            Value must be: 0.0 <= pct_required <= 1.0
        :type pct_required: None or float (default:0.0)

        :param weights: (optional) map from valuespaces to associated weights
        ==> Only applicable for weighted aggregation methods
            [Ignored for non-weighted aggregation methods]
        :type weights: dict or None

        :param wt_required: Control for necessary weight data support
        ==> Only applicable for weighted aggregation methods
            [Ignored for non-weighted aggregation methods]
        :type wt_required: None or float (default:0.0)

        :param view: Quble indicating conditional elements
                     for which aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :param custom_info_overrides: Overrides to custom column info assignments
        :type custom_info_overrides: dictionary of dictionaries

            outer dictionary keys: info_type
            outer dictionary values: inner dictionary
            inner dictionary keys: column_name (post-renamed convention when applicable)
            inner dictionary values: associated info_type_assignment

            ==> NOTE: when using custom_info_overrides arg
                in conjunction with dict version of column_names (for column renaming)
                the custom_info_overrides should be specified using new/target column names

        :param compress: flag for compressing resultant Quble
        :type compress: bool (True/False)

        :param key_ordering: controls row ordering by key
        :type key_ordering: None, str or dictionary
           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace
           dictionary: dict keys (str): keyspaces, dict values (str): 'asc' or 'desc'
           ==> allows for assigning key ordering (ascending/descending)
           ==> (and relative priority) for each keyspace individually

        :param inplace: Flag for changing self directly inplace
        :type inplace: boolean (True/False*)
            inplace=True: modifies self Quble directly and returns self
            inplace=False: returns a (possibly) modified Quble (leaves self unchanged)

        :returns: The resultant Quble
        :rtype: qubles.core.quble.Quble
        """
        # Handle trivial cases
        # ---------------------
        if not self.is_undefined:
            pass
        elif inplace:
            return self
        else:
            return self.copy()

        # Validate aggr_valuespaces
        # [Require that aggr_valuespaces be numeric]
        # ------------------------------------------
        aggr_valuespaces = self.validate_valuespace(
            valuespace=aggr_valuespaces,
            numeric_required=True,
            grace=False,
            coerce_to_list=True,
        )

        # Validate aggregation method (aggr_method)
        # -----------------------------------------
        if aggr_method not in (
            "sum",
            "wtd_sum",
            "ave",
            "wtd_ave",
            "avg",
            "wtd_avg",
            "mean",
            "wtd_mean",
            "stddev",
            "wtd_stddev",
            "var",
            "wtd_var",
        ):
            raise Exception(f"Unsupported aggr_method:{aggr_method}")

        # When no weights are provided,
        # transition to non-weighted aggregation
        # ---------------------------------------
        if weights is not None:
            pass
        elif aggr_method == "wtd_sum":
            aggr_method = "sum"
        elif aggr_method == "wtd_ave":
            aggr_method = "ave"
        elif aggr_method == "wtd_avg":
            aggr_method = "avg"
        elif aggr_method == "wtd_mean":
            aggr_method = "mean"
        elif aggr_method == "wtd_stddev":
            aggr_method = "stddev"
        elif aggr_method == "wtd_var":
            aggr_method = "var"

        # Validate new_valuespace arg
        # ----------------------------
        if not isinstance(new_valuespace, str):
            raise Exception(f"Invalid new_valuespace:{new_valuespace}...str required")
        elif keep_existing_valuespaces and new_valuespace in self.valuespaces:
            raise Exception(
                f"new_valuespace:{new_valuespace} already present in self.valuespaces:{self.valuespaces}"
            )

        # Validate weights arg
        # NOTE: ALL aggr_valuespaces MUST HAVE A VALID WEIGHT ENTRY
        # NOTE: ALL weights ENTRIES MUST CORRESPOND TO A VALID VALUESPACE
        # ----------------------------------------------------------------
        if weights is None:
            pass
        elif not isinstance(weights, dict):
            raise Exception(f"Invalid new_valuespace:{new_valuespace}...dict required")
        else:
            wt_keys_without_valuespaces = [
                vs for vs in weights.keys() if vs not in self.valuespaces
            ]
            if len(wt_keys_without_valuespaces) > 0:
                raise Exception(
                    f"Some weight keys:{wt_keys_without_valuespaces} are absent from self.valuespaces:{self.valuespaces}"
                )

            aggr_vs_without_wts = [vs for vs in aggr_valuespaces if vs not in weights]
            if len(aggr_vs_without_wts) > 0:
                raise Exception(
                    f"Some aggregation valuespaces:{aggr_vs_without_wts} are absent from weights.keys():{weights.keys()}"
                )

        # Establish (comprehensive) num_required as:
        # max( num_required (arg), len(aggr_valuespaces)*pct_required )
        # -------------------------------------------------------------
        if num_required is None:
            num_required = 0

        if pct_required is None:
            pass
        elif (pct_required < 0.0) or (pct_required > 1.0):
            raise Exception(
                f"Invalid pct_required:{pct_required}...0.0 <= pct_required <= 1.0"
            )
        else:
            num_required2 = int(np.ceil(float(len(aggr_valuespaces)) * pct_required))
            if num_required2 > num_required:
                num_required = num_required2

        # When not ignore_missing, require ALL terms
        if not ignore_missing:
            num_required = len(aggr_valuespaces)

        if num_required > len(aggr_valuespaces):
            raise Exception(
                f"num_required:{num_required} > len(aggr_valuespaces):{len(aggr_valuespaces)}"
            )

        # Apply view to subject (if applicable)
        subject = self.apply_view(view, allow_shallow_copy=True)

        # Generate target table_name
        table_name = generate_random_table_name()

        # Access the proper SQL template
        sql_template = JINJA_ENV.get_template("aggregate_xcols.j2")

        valuespaces_to_keep = subject.valuespaces if keep_existing_valuespaces else None

        # Render the SQL template
        sql_command = sql_template.render(
            src_table_name=subject.table_name,
            tgt_table_name=table_name,  # <-- Used by query_base.j2
            aggr_method=aggr_method,
            tgt_keyspaces=subject.keyspaces,
            aggr_valuespaces=aggr_valuespaces,
            new_valuespace=new_valuespace,
            valuespaces_to_keep=valuespaces_to_keep,
            num_required=num_required,
            weights=weights,
            wt_required=wt_required,
            compress=compress,
            key_ordering=key_ordering,
        )
        execute(sql_command, format_flag=False)

        # Establish tgt_col_info
        tgt_col_info = subject.get_space_info(
            info_type=CUSTOM_INFO_TYPES,
            space=subject.keyspaces + valuespaces_to_keep,
            omit_unassigned=True,
        )
        # Ensure new_valuespace column is assigned a valuespace role
        if tgt_col_info is None:
            tgt_col_info = {}
        if "role" not in tgt_col_info:
            tgt_col_info["role"] = {}
        tgt_col_info["role"][new_valuespace] = "valuespace"

        # Reorder tgt_col_info["role"] so that new_valuespace appears as the first valuespace which will force
        # new_valuespace as primary valuespace in Quble.from_table()
        tgt_col_info_roles = {}
        for space1 in tgt_col_info["role"]:
            if tgt_col_info["role"][space1] == "valuespace":
                if new_valuespace not in tgt_col_info_roles:
                    # Assign new_valuespace first before other valuespaces
                    tgt_col_info_roles[new_valuespace] = tgt_col_info["role"][
                        new_valuespace
                    ]
                if space1 not in tgt_col_info_roles:
                    tgt_col_info_roles[space1] = tgt_col_info["role"][space1]
            else:
                tgt_col_info_roles[space1] = tgt_col_info["role"][space1]
        tgt_col_info["role"] = tgt_col_info_roles

        # Apply custom_info_overrides to col_info
        # For integrity reasons, we validate column name references in  custom_info_overrides against target column names in the new table
        if custom_info_overrides is not None:
            tgt_column_names = get_column_names(table_name)
            validate_col_info(
                col_info=custom_info_overrides, column_names=tgt_column_names
            )
            tgt_col_info = update_column_info(tgt_col_info, custom_info_overrides)

        # Handle inplace table operations (when applicable)
        if inplace:
            self._swap_table(
                table_name, col_info=tgt_col_info, valuespace=new_valuespace
            )
            return self
        else:
            return Quble.from_table(
                table_name, col_info=tgt_col_info, valuespace=new_valuespace
            )

    @RootLib.lazy_kwargs()
    def sum_xcols(
        self,
        aggr_valuespaces="<numeric_valuespaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        new_valuespace: str = DEFAULT_VALUESPACE,
        keep_existing_valuespaces: bool = False,
        num_required: int = 0,
        pct_required: float = 0.0,
        view: Quble = RootLib.lazy_eval("view"),
        custom_info_overrides: dict = None,
        compress: bool = RootLib.lazy_eval("auto_compress"),
        key_ordering: str = "asc",
        inplace: bool = False,
    ):
        """
        Computes sum across
        specified columns (aggregation valuespaces)
        see ~qubles.core.quble.aggregate_xcols
        """
        return self.aggregate_xcols(
            aggr_valuespaces=aggr_valuespaces,
            aggr_method="sum",
            ignore_missing=ignore_missing,
            new_valuespace=new_valuespace,
            keep_existing_valuespaces=keep_existing_valuespaces,
            num_required=num_required,
            pct_required=pct_required,
            view=view,
            custom_info_overrides=custom_info_overrides,
            compress=compress,
            key_ordering=key_ordering,
            inplace=inplace,
        )

    @RootLib.lazy_kwargs()
    def wtd_sum_xcols(
        self,
        aggr_valuespaces="<numeric_valuespaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        new_valuespace: str = DEFAULT_VALUESPACE,
        keep_existing_valuespaces: bool = False,
        num_required: int = 0,
        pct_required: float = 0.0,
        weights: dict = None,
        wt_required: float = 0.0,
        view: Quble = RootLib.lazy_eval("view"),
        custom_info_overrides: dict = None,
        compress: bool = RootLib.lazy_eval("auto_compress"),
        key_ordering: str = "asc",
        inplace: bool = False,
    ):
        """
        Computes weighted sum across
        specified columns (aggregation valuespaces)
        see ~qubles.core.quble.aggregate_xcols
        """
        return self.aggregate_xcols(
            aggr_valuespaces=aggr_valuespaces,
            aggr_method="wtd_sum",
            ignore_missing=ignore_missing,
            new_valuespace=new_valuespace,
            keep_existing_valuespaces=keep_existing_valuespaces,
            num_required=num_required,
            pct_required=pct_required,
            weights=weights,
            wt_required=wt_required,
            view=view,
            custom_info_overrides=custom_info_overrides,
            compress=compress,
            key_ordering=key_ordering,
            inplace=inplace,
        )

    @RootLib.lazy_kwargs()
    def ave_xcols(
        self,
        aggr_valuespaces="<numeric_valuespaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        new_valuespace: str = DEFAULT_VALUESPACE,
        keep_existing_valuespaces: bool = False,
        num_required: int = 0,
        pct_required: float = 0.0,
        view: Quble = RootLib.lazy_eval("view"),
        custom_info_overrides: dict = None,
        compress: bool = RootLib.lazy_eval("auto_compress"),
        key_ordering: str = "asc",
        inplace: bool = False,
    ):
        """
        Computes average across
        specified columns (aggregation valuespaces)
        see ~qubles.core.quble.aggregate_xcols
        """
        return self.aggregate_xcols(
            aggr_valuespaces=aggr_valuespaces,
            aggr_method="ave",
            ignore_missing=ignore_missing,
            new_valuespace=new_valuespace,
            keep_existing_valuespaces=keep_existing_valuespaces,
            num_required=num_required,
            pct_required=pct_required,
            # weights=weights,
            # wt_required=wt_required,
            view=view,
            custom_info_overrides=custom_info_overrides,
            compress=compress,
            key_ordering=key_ordering,
            inplace=inplace,
        )

    def wtd_ave_xcols(
        self,
        aggr_valuespaces="<numeric_valuespaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        new_valuespace: str = DEFAULT_VALUESPACE,
        keep_existing_valuespaces: bool = False,
        num_required: int = 0,
        pct_required: float = 0.0,
        weights: dict = None,
        wt_required: float = 0.0,
        view: Quble = RootLib.lazy_eval("view"),
        custom_info_overrides: dict = None,
        compress: bool = RootLib.lazy_eval("auto_compress"),
        key_ordering: str = "asc",
        inplace: bool = False,
    ):
        """
        Computes weighted average across
        specified columns (aggregation valuespaces)
        see ~qubles.core.quble.aggregate_xcols
        """
        return self.aggregate_xcols(
            aggr_valuespaces=aggr_valuespaces,
            aggr_method="wtd_ave",
            ignore_missing=ignore_missing,
            new_valuespace=new_valuespace,
            keep_existing_valuespaces=keep_existing_valuespaces,
            num_required=num_required,
            pct_required=pct_required,
            weights=weights,
            wt_required=wt_required,
            view=view,
            custom_info_overrides=custom_info_overrides,
            compress=compress,
            key_ordering=key_ordering,
            inplace=inplace,
        )

    def stddev_xcols(
        self,
        aggr_valuespaces="<numeric_valuespaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        new_valuespace: str = DEFAULT_VALUESPACE,
        keep_existing_valuespaces: bool = False,
        num_required: int = 0,
        pct_required: float = 0.0,
        view: Quble = RootLib.lazy_eval("view"),
        custom_info_overrides: dict = None,
        compress: bool = RootLib.lazy_eval("auto_compress"),
        key_ordering: str = "asc",
        inplace: bool = False,
    ):
        """
        Computes standard deviation across
        specified columns (aggregation valuespaces)
        see ~qubles.core.quble.aggregate_xcols
        """
        return self.aggregate_xcols(
            aggr_valuespaces=aggr_valuespaces,
            aggr_method="stddev",
            ignore_missing=ignore_missing,
            new_valuespace=new_valuespace,
            keep_existing_valuespaces=keep_existing_valuespaces,
            num_required=num_required,
            pct_required=pct_required,
            # weights=weights,
            # wt_required=wt_required,
            view=view,
            custom_info_overrides=custom_info_overrides,
            compress=compress,
            key_ordering=key_ordering,
            inplace=inplace,
        )

    def var_xcols(
        self,
        aggr_valuespaces="<numeric_valuespaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        new_valuespace: str = DEFAULT_VALUESPACE,
        keep_existing_valuespaces: bool = False,
        num_required: int = 0,
        pct_required: float = 0.0,
        view: Quble = RootLib.lazy_eval("view"),
        custom_info_overrides: dict = None,
        compress: bool = RootLib.lazy_eval("auto_compress"),
        key_ordering: str = "asc",
        inplace: bool = False,
    ):
        """
        Computes variance across
        specified columns (aggregation valuespaces)
        see ~qubles.core.quble.aggregate_xcols
        """
        return self.aggregate_xcols(
            aggr_valuespaces=aggr_valuespaces,
            aggr_method="var",
            ignore_missing=ignore_missing,
            new_valuespace=new_valuespace,
            keep_existing_valuespaces=keep_existing_valuespaces,
            num_required=num_required,
            pct_required=pct_required,
            # weights=weights,
            # wt_required=wt_required,
            view=view,
            custom_info_overrides=custom_info_overrides,
            compress=compress,
            key_ordering=key_ordering,
            inplace=inplace,
        )

    @RootLib.lazy_kwargs()
    def wtd_stddev_xcols(
        self,
        aggr_valuespaces="<numeric_valuespaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        new_valuespace: str = DEFAULT_VALUESPACE,
        keep_existing_valuespaces: bool = False,
        num_required: int = 0,
        pct_required: float = 0.0,
        weights: dict = None,
        wt_required: float = 0.0,
        view: Quble = RootLib.lazy_eval("view"),
        custom_info_overrides: dict = None,
        compress: bool = RootLib.lazy_eval("auto_compress"),
        key_ordering: str = "asc",
        inplace: bool = False,
    ):
        """
        Computes weighted standard deviation across
        specified columns (aggregation valuespaces)
        see ~qubles.core.quble.aggregate_xcols
        """
        return self.aggregate_xcols(
            aggr_valuespaces=aggr_valuespaces,
            aggr_method="wtd_stddev",
            ignore_missing=ignore_missing,
            new_valuespace=new_valuespace,
            keep_existing_valuespaces=keep_existing_valuespaces,
            num_required=num_required,
            pct_required=pct_required,
            weights=weights,
            wt_required=wt_required,
            view=view,
            custom_info_overrides=custom_info_overrides,
            compress=compress,
            key_ordering=key_ordering,
            inplace=inplace,
        )

    @RootLib.lazy_kwargs()
    def wtd_var_xcols(
        self,
        aggr_valuespaces="<numeric_valuespaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        new_valuespace: str = DEFAULT_VALUESPACE,
        keep_existing_valuespaces: bool = False,
        num_required: int = 0,
        pct_required: float = 0.0,
        weights: dict = None,
        wt_required: float = 0.0,
        view: Quble = RootLib.lazy_eval("view"),
        custom_info_overrides: dict = None,
        compress: bool = RootLib.lazy_eval("auto_compress"),
        key_ordering: str = "asc",
        inplace: bool = False,
    ):
        """
        Computes weighted variance across
        specified columns (aggregation valuespaces)
        see ~qubles.core.quble.aggregate_xcols
        """
        return self.aggregate_xcols(
            aggr_valuespaces=aggr_valuespaces,
            aggr_method="wtd_var",
            ignore_missing=ignore_missing,
            new_valuespace=new_valuespace,
            keep_existing_valuespaces=keep_existing_valuespaces,
            num_required=num_required,
            pct_required=pct_required,
            weights=weights,
            wt_required=wt_required,
            view=view,
            custom_info_overrides=custom_info_overrides,
            compress=compress,
            key_ordering=key_ordering,
            inplace=inplace,
        )

    @RootLib.lazy_kwargs()
    def zscore_xcols(
        self,
        aggr_valuespaces="<numeric_valuespaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        num_required: int = 0,
        pct_required: float = 0.0,
        view: Quble = RootLib.lazy_eval("view"),
        custom_info_overrides: dict = None,
        compress: bool = RootLib.lazy_eval("auto_compress"),
        key_ordering: str = "asc",
        inplace: bool = False,
    ):
        """
        Generates z-score values across
        specified columns (aggregation valuespaces)
        see ~qubles.core.quble.aggregate_xcols
        """
        # Validate aggr_valuespaces
        # --------------------------
        aggr_valuespaces = subject.validate_valuespace(
            valuespace=aggr_valuespaces, grace=False, coerce_to_list=True
        )

        # Handle trivial cases
        # ---------------------
        if aggr_valuespaces is None or len(aggr_valuespaces) == 0:
            if inplace:
                return self
            else:
                return self.copy()

        # Only keep the valuespaces that are
        # included in the z-score operation
        subject = self.sub_variate(aggr_valuespaces)

        # Apply view to subject (if applicable)
        if view:
            subject = subject.apply_view(view, allow_shallow_copy=True)

        # Append ave column ("__ave__")
        ave_xcols = self.aggregate_xcols(
            aggr_valuespaces=aggr_valuespaces,
            aggr_method="ave",
            ignore_missing=ignore_missing,
            new_valuespace="__ave__",
            keep_existing_valuespaces=True,
            num_required=num_required,
            pct_required=pct_required,
            # weights=weights,
            # wt_required=wt_required,
            view=None,
            custom_info_overrides=None,
            compress=compress,
            key_ordering=key_ordering,
            inplace=False,
        )
        # Append stddev column ("__stddev__")
        stddev_xcols = ave_xcols.aggregate_xcols(
            aggr_valuespaces=aggr_valuespaces,
            aggr_method="stddev",
            ignore_missing=ignore_missing,
            new_valuespace="__stddev__",
            keep_existing_valuespaces=True,
            num_required=num_required,
            pct_required=pct_required,
            # weights=weights,
            # wt_required=wt_required,
            view=None,
            custom_info_overrides=None,
            compress=compress,
            key_ordering=key_ordering,
            inplace=False,
        )
        # Compute z-score result by selecting
        column_expressions = {}
        for vs in aggr_valuespaces:
            column_expressions[vs] = '(("' + vs + '" - __ave__) / __stddev__)'

        # # Are there any ortho_valuespaces?
        # ortho_valuespaces = []
        # for vs in self.valuespaces:
        #     if vs not in aggr_valuespaces:
        #         ortho_valuespaces.append(vs)

        zscore = stddev_xcols.select(
            key_ordering=key_ordering,
            tgt_keyspaces=self.keyspaces,
            column_names=self.keyspaces,  # + ortho_valuespaces
            column_expressions=column_expressions,
            custom_info_overrides=custom_info_overrides,
        )

        # Handle inplace table operations (when applicable)
        if inplace:
            self._swap_table(zscore)
        else:
            return zscore

    # ========================================= SINGLE-DIMENSION AGGREGATION ===========================================

    @RootLib.lazy_kwargs()
    def aggregate1d(
        self,
        keyspace: str = "<first_keyspace>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view: Quble = RootLib.lazy_eval("view"),
        key_ordering="asc",
        percentile: float = 50.0,
        epsilon: float = None,
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Aggregates across the specified keyspace / dimension
        When auto_squeeze=True, result's dimensionality is reduced by one
        See: :meth:`~qubles.core.quble.Quble.aggregate`
        """
        return self.aggregate(
            aggr_keyspaces=keyspace,
            aggr_method=aggr_method,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            percentile=percentile,
            epsilon=epsilon,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def count1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        unfolded: bool = False,
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes the number of data points across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        # Quble.count() method contains special logic for unfolded case,
        # As such, we call Quble.count() here instead of calling aggregate1d(aggr_method='count',...)
        return self.count(
            aggr_keyspaces=keyspace,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            unfolded=unfolded,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def sum1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes a summation across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="sum",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_sum1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Perform a summation across a specified valuespace
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="wtd_sum",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def prod1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes a product of a sequence of factors across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="prod",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_prod1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes a weighted product of a sequence of factors across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="wtd_prod",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def mean1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes the mean across a specified valuespace
        [First moment about the origin]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="avg",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_mean1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering: str = "asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes a weighted mean across a specified valuespace
        [First moment about the origin]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="wtd_mean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def avg1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes a weighted mean across a specified valuespace
        [First moment about the origin]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="avg",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_avg1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes a weighted mean across a specified valuespace
        [First moment about the origin]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="wtd_mean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def average1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes a weighted mean across a specified valuespace
        [First moment about the origin]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="avg",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_average1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes a weighted mean across a specified valuespace
        [First moment about the origin]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="wtd_mean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def ave1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="avg",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_ave1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="wtd_mean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def median1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """

        Computes the median across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate

        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="median",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def wtd_median1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes a weighted median across a specified valuespace
        [The 50% weighted percentile]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="wtd_median",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            auto_squeeze=auto_squeeze,
            interpolate_flag=True,
        )

    @RootLib.lazy_kwargs()
    def min1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes the minimum value across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="min",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def max1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes the maximum value across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="max",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def stddev_samp1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="stddev_samp",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def stddev_pop1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="stddev_pop",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def var_samp1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="var_samp",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def var_pop1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="var_pop",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def std1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes the standard deviation across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="stddev_pop",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_std1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes a weighted standard deviation across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="wtd_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def stddev1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes the standard deviation across a specified valuespace with Bessel's correction (n - 1)
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="stddev_pop",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_stddev1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes a weighted standard deviation across a specified valuespace with an added factor of (n/n-1)
        to account for the number of degrees of freedom, similar to Bessel's correction. Useful when each
        data point's weight is inversely proportional to the square of its uncertainty.
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="wtd_stddev",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def var1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes the variance across a specified valuespace
        [The second moment about the mean]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="var_pop",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_var1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes a weighted variance across a specified valuespace
        [The second moment about the mean]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="wtd_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def iqr1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="iqr",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def first1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        See: :meth:`~qubles.core.quble.Quble.last1d`
        NOTE: first1d/last1d aggregation does not require a valuespace
        """
        return self.first(
            aggr_keyspaces=keyspace,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def last1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Yields the last record across across the aggregation keyspace
        for the specified valuespace(s)

        :type keyspace: str
        :param keyspace: Keyspace to be aggregated

        :type ignore_missing: bool
        :param ignore_missing:
            Control for whether to ignore the presence of null values in the count

        :param valuespace: the valuespace(s) to be aggregated
                           (only these valuespaces will remain in result)
        :type valuespace: str or list of strings
                      (keywords may be used such as '<valuespaces>', '<valuespace>', etc.
                      [See: :meth:`~qubles.core.quble.Quble.validate_valuespace`]

        :param view: Quble indicating conditional elements
                     for which aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :param key_ordering: controls row ordering by key
        :type key_ordering: None, str or dictionary
           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace
           dictionary: dict keys (str): keyspaces, dict values (str): 'asc' or 'desc'
           ==> allows for assigning key ordering (ascending/descending)
           ==> (and relative priority) for each keyspace individually

        :param auto_squeeze: Flag to auto_squeeze the columns keyspace
                             if there is only one value column
                             and the column space is not explicitly names
        :type auto_squeeze: boolean

        :param pre_cross_fill: flag to control whether to pre-cross-fill
                           when some keyspaces being aggregated are a time keyspaces
                           and ortho_resampling_keyspaces also exist
        :type pre_cross_fill: boolean (True*/False)

        :param pre_fill: flag to control whether to pre-fill
                         when some being aggregated are resampling keyspaces
        :type pre_fill: boolean (True/False*)

        NOTE: first1d/last1d aggregation does not require a valuespace
        """
        return self.last(
            aggr_keyspaces=keyspace,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def recent1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        tfill_max: int = "<space_root>",
        recent_key: str = "recent",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        valuespace="<valuespaces>",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        key_ordering=None,
        view=RootLib.lazy_eval("view"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Returns the 'most recent' values (for each valuespace) across the specified
        (time) keyspace for each set of 'ortho keys' within the 'orthogonal' keyspaces.

        Use this method (rather than last1d) for age restrictions on the 'last' value.

        A variate Quble is required for this operation,
        the specified valuespace(s) will be retained in the result.

        The specified keyspace will be dropped if auto_squeeze=True,
        or will be retained (with a NULL key) if auto_squeeze=False.

        The tfill_max parameter provides an 'age restriction' on recent records,
        and will exclude all records occurring
        this many periods prior to the specified recent key.

        For example, if tfill_max=5 is applied against a monthly time-keyspace,
        this method will exclude any records from consideration that are
        more than five (5) months earlier than the specified recent_key arg.

        :param keyspace: time-keyspace to apply the most recent value selection
        :type str
        ==> '<first_time_keyspace> will identify the first time-keyspace (if present)
        ==> This method will throw an Exception if the specified keyspace does not exist or does not correspond to a time-keyspace of subject Quble

        :param recent_key: nominal recent time-key for age determination or sql function (e.g., now())
        :type np.datetime64 or datetime or date or 'recent' or 'now' or 'now()' or datetime-coercible string

               If recent_key=='recent':

               will locate/apply the maximum datetime from specified time-keyspace
               [even if that datetime lies in the future from current time]

               If recent_key=='now' or 'now()':

               will locate/apply the current/now datetime
               and then limit the records to only those on/before current time
               [this option may drop/ignore records with dates after current time]

               If recent_key is None:

               sets recent_key='recent' (since recent_key is required)

        :param valuespace: the valuespace(s) against which recent logic is to be applied
                           (only these valuespace(s) will remain in result)
        :type valuespace: str or list of strings
                      (keywords may be used such as '<valuespaces>', '<valuespace>', etc.
                      [See: :meth:`~qubles.core.quble.Quble.validate_valuespace`]

        :param tfill_max: (optional) maximum number of lookback periods before recent time-key
            ==> The number of periods prior to specified recent_key to exclude 'old' records
        :type int or None
            Treat tfill_max > 0: finite filling
            Treat tfill_max < 0: Infinite tfill_max
            Treat tfill_max = None: NO filling
            Treat tfill_max = 0: NO filling

        :param auto_squeeze: flag to drop (or keep) the specified time-keyspace from the result
        :type bool

        :param key_ordering: controls row ordering by key
        :type key_ordering: None, str or dictionary
           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace
           dictionary: dict keys (str): keyspaces, dict values (str): 'asc' or 'desc'
           ==> allows for assigning key ordering (ascending/descending)
           ==> (and relative priority) for each keyspace individually

        :param view: Quble indicating conditional elements
                     for which aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or np.float)

        :param pre_cross_fill: flag to control whether to pre-cross-fill
                           when some keyspaces being aggregated are a time keyspaces
                           and ortho_resampling_keyspaces also exist
        :type pre_cross_fill: boolean (True*/False)

        :param pre_fill: flag to control whether to pre-fill
                         when some being aggregated are resampling keyspaces
        :type pre_fill: boolean (True/False*)
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        # Restrict Quble to only the valuespace(s) of interest
        # [valuespace arg is validated within sub_variate method]
        # (allow for shallow copy when valuespaces are unchanged)
        # ==> Only refer to subject (not self) hereafter
        # ------------------------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # Preclude ill-defined multivariate case where:
        #   ignore_missing==True & auto_squeeze==False
        if subject.is_multivariate and ignore_missing and not auto_squeeze:
            raise Exception(
                "Invalid/ill defined case: multi-variate Quble (# valuespaces:{0}) and ignore_missing:{1} and auto_squeeze:{2}".format(
                    len(self.valuespaces), ignore_missing, auto_squeeze
                )
            )

        # Validate keyspace
        keyspace = subject.validate_keyspace(
            keyspace, grace=False, solo_required=True, time_space_required=True
        )

        # List of all the extra keyspaces
        # (excluding the keyspace provided as an argument)
        ortho_keyspaces = subject.ortho_keyspaces(keyspace)
        tgt_keyspaces = ortho_keyspaces if auto_squeeze else subject.keyspaces

        # NOTE: Apply pre_cross_fill BEFORE pre_fill
        if pre_cross_fill:
            subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)

        # TO CONSIDER: Apply pre_fill=True as default arg
        # OR (more sophisticated) explicitly evaluate/sample
        # the Quble at the requisite number of dates over the window
        if pre_fill:
            subject = subject._apply_pre_fill(allow_shallow_copy=True)

        # Apply view to subject
        # -----------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)

        # Access & validate freq
        freq = subject.get_freq(keyspace, allow_infer=True, assign_inferred=True)

        # Validate recent_key
        # --------------------
        # First, trap to special case: recent_key.lower() == 'recent'
        # Intentionally not an elif here
        if (recent_key is None) or (
            isinstance(recent_key, str) and (recent_key.lower() == "recent")
        ):
            recent_key = subject.recent_datetime1d(keyspace)

        # Now, process the recent_key
        if recent_key is None:
            # In case .recent_datetime1d() yielded None
            recent_key = "now()"
        elif isinstance(recent_key, (datetime, date)):
            recent_key = f"'{str(recent_key)}'"  # <-- We add extra single-quotes for proper template rendering below
        elif hasattr(recent_key, "dtype") and np.issubdtype(recent_key, np.datetime64):
            recent_key = f"'{str(recent_key)}'"  # <-- We add extra single-quotes for proper template rendering below
        elif not isinstance(recent_key, str):
            raise Exception(
                f"Invalid recent_key:{recent_key}...datetime, date, np.datetime64 or str ('now', 'recently_completed', 'in_progress') or None"
            )
        elif recent_key.lower() in ("now", "now()"):
            recent_key = "now()"  # <-- No extra single-quotes here
        else:
            # Assume/hope we have been given a valid datetime formatted string
            # [Example: recent_key = "'2022-12-31'"]
            # NOTE: We add extra inner single-quotes for proper template rendering below
            recent_key = f"'{recent_key}'"

        # Validate tfill_max
        # Evaluate tfill_end_mode_scalar until it is assigned a non-trivial value
        tfill_max = subject._space_info_indirection(
            info_type="tfill_max",
            space=keyspace,
            info_assignment=tfill_max,
            grace=True,
        )

        # Validate tfill_max...
        # [This validation step will capture
        # format: '<n> <units>' (e.g., '2 years')]
        tfill_max = self.validate_periods1d(
            periods=tfill_max,
            keyspace=keyspace,
            freq=freq,
            coerce_none_to_zero=True,
            grace=True,
        )

        # Confirm tfill_max
        if not isinstance(tfill_max, int):
            raise Exception(f"Invalid tfill_max:{tfill_max}...int (or None) required")

        # Generate target table_name
        table_name = generate_random_table_name()

        # Access the proper SQL template
        if ignore_missing:
            # ignore_missing...here we need to invoke a univariate wrapper approach
            sql_template = JINJA_ENV.get_template("recent1d.j2")
        else:
            # Not ignore_missing...here we do NOT need univariate wrapper approach (can use sright multi-variate logic)
            sql_template = JINJA_ENV.get_template("recent1d_no_ignore.j2")

        # Render the SQL template
        sql_command = sql_template.render(
            src_table_name=subject.table_name,
            tgt_table_name=table_name,  # <-- Used by query_base.j2
            calendar_table_name=RootLib().get_control("calendar_table_name"),
            keyspace=keyspace,
            keyspaces=subject.keyspaces,
            tgt_keyspaces=tgt_keyspaces,
            valuespaces=subject.valuespaces,  # <-- Used by univariate_query_wrapper.j2 when using 'recent1d.j2'
            recent_key=recent_key,
            tfill_max=0 if tfill_max is None else tfill_max,
            freq=freq,
            auto_squeeze=auto_squeeze,
            ignore_missing=ignore_missing,  # <-- Not applicable when using 'recent1d_no_ignore.j2'
            key_ordering=key_ordering,  # <-- Used by univariate_query_wrapper.j2 when using'recent1d.j2'
        )

        execute(sql_command, format_flag=False)

        return Quble.from_table(
            table_name,
            col_info=self.get_space_info(
                info_type=CUSTOM_INFO_TYPES,
                space=tgt_keyspaces + subject.valuespaces,
                omit_unassigned=True,
            ),
        )

    def validate_periods1d(
        self,
        periods,
        keyspace: str = "<first_time_keyspace>",
        freq: str = None,
        coerce_none_to_zero: bool = True,
        grace: bool = True,
    ):
        """
        Validates a proposed number of periods to be applied
        to the designated time-keyspace (for filling/moving aves, etc.)

        periods arg be validated/translated to an integer (or None)
        representing number of periods at the associated time-frequency.

        Supports the following forms for proposed periods:

           int: acceptable as is
           relativedelta: convert to # periods at related frequency
           timedelta: convert to # periods at related frequency
           str: first coerce to a relativedelta object then convert to # periods
           None: will be returned as such

           Example str usage:
           'infinite', 'indefinite', '10 days', '6 months', '5 weeks', '4 years', etc.

        :param periods: proposed number of periods
        :type: int, str, relativedelta, timedelta, None

            ==> '<first_time_keyspace> will identify the first time-keyspace (if present)
            ==> This method will throw an Exception if the specified keyspace does not exist or does not correspond to a time-keyspace of subject Quble

        :param keyspace: time-keyspace to apply periodic time-op
        :type: str
            ==> '<first_time_keyspace> will identify the first time-keyspace (if present)
            ==> This method will throw an Exception if the specified keyspace does not exist or does not correspond to a time-keyspace of subject Quble

        :param freq: underlying time-frequency of associated keyspace
        :type: str or None

            ==> If freq arg is not None, provided arg will be trusted/used
            ==> If freq arg is None, freq will be accessed or inferred

        :param coerce_none_to_zero: flag to coerce None to zero int
        :type: bool (False*/True)

        :param grace: graceful handing of contingencies (e.g., freq is None)
        :type: bool (True*/False)

        :returns: Validated periods at the underlying freq
        :rtype: int
        """
        from datetime import timedelta
        from dateutil.relativedelta import relativedelta

        # Handle trvial cases first
        if self.is_undefined:
            # Should consider returning 0 (zero int) here
            return 0 if coerce_none_to_zero else periods
        elif periods is None:
            # Should consider returning 0 (zero int) here
            return 0 if coerce_none_to_zero else periods
        elif isinstance(periods, int):
            # Retain as an integer
            return periods
        elif not isinstance(periods, (str, relativedelta, timedelta)):
            raise Exception(
                f"Invalid periods:{periods}...required type: int,str,relativedelta,timedelta,None"
            )

        # (Re)Validate the time-keyspace (?)
        # [Alternatively, we could merely trust the keyspace provided]
        keyspace = self.validate_keyspace(
            keyspace, grace=False, solo_required=True, time_space_required=True
        )

        # ------------------------------
        # Here periods is either:
        #    1) str
        #    2) relativedelta
        # or 3) timedelta
        # ------------------------------
        if isinstance(periods, str):
            # Coerce string to a relativedelta form
            # Assume/require string format such as:
            # "10 days", "6 months", etc.
            periods = periods.strip().lower()  # <-- Strip and convert to lower case
            if periods in ("infinite", "indefinite"):
                return -1

            parts = periods.split(" ", 1)
            if len(parts) != 2:
                raise Exception(
                    f"Invalid periods str format: {periods}...expected two words w/format: '10 days', '6 months' etc. "
                )
            try:
                val = int(parts[0])
            except:
                raise Exception(
                    f"Invalid periods str format: {periods} First word must coerce to int...expected format: '10 days', '6 months' etc. "
                )

            units = parts[1].lower()
            valid_units = ("days", "weeks", "months", "years")
            if units not in valid_units:
                raise Exception(
                    f"Invalid time-units:{units}...valid units: {valid_units}"
                )
            periods = relativedelta(**{units: int(val)})

        # Get the underlying time-frequency
        # and associated ppy (periods-per-year)
        if freq is None:
            # Access/infer/validate freq if needed
            # Access & validate freq
            freq = self.get_freq(keyspace, allow_infer=True, assign_inferred=True)
        # else:
        ## otherwise trust the non-trivial freq provided
        # pass

        # Convert freq to ppy
        if freq is None:
            # freq is None can legitimately happen if/when there
            # are no non-null records to allow inference of time freq
            if self.has_non_nulls(keyspace):
                # This should not happen and seems to risky to pass through
                # [we may need to think about formally supporting
                # a non-structured 'n/a' or 'tick' frequency and ppy thereof ]
                raise Exception(
                    f"Unable to establish existing freq for keyspace:{keyspace} w/# non-nulls:{self.num_non_nulls_space(keyspace)}"
                )
            elif not grace:
                raise Exception(
                    f"Unable to establish existing freq for keyspace:{keyspace} w/# non-nulls:{self.num_non_nulls_space(keyspace)}"
                )
            elif coerce_none_to_zero:
                return 0
            else:
                return None

        elif freq not in PPY:
            # This should ideally not happen if freq is not None
            raise Exception(f"Unsupported freq:{freq} for keyspace:{keyspace}")

        # --------------------------------------
        # At this point, periods is either a
        # relativedelta or a timedelta object
        # --------------------------------------
        ppy = PPY[freq]
        if ppy is None:
            # This should ideally not happen
            # if PPY dict has good integrity
            raise Exception(
                f"ppy = PPY[freq:{freq}] yielded None for keyspace:{keyspace}"
            )

        if isinstance(periods, timedelta):
            # CASE: timedelta...
            # NOTE: Using timedelta.days alone ignores
            # the seconds & microseconds components
            # of the timedelta object
            span_in_days = periods.days
        else:  # elif isinstance(periods,relativedelta)
            # CASE: relativedelta...
            # A bit ackward here, but we need to
            # create a temporary relativedelta (rd_tmp)
            # so that we can access the total elasped days
            # for the entire span of the relativedelta  :(
            now = datetime.now()
            # Next line now yields total span in days
            # [Unfortunately, simpler periods.days may yield the wrong result!]
            rd_tmp = now - (now - periods)
            span_in_days = rd_tmp.days

        # --------------------------------------------
        # Compute periods as the total span specified
        # in number of periods at underlying freq
        # --------------------------------------------
        span_in_years = span_in_days / 365.25
        periods = round(span_in_years * ppy)
        return periods

    @RootLib.lazy_kwargs()
    def kurtosis1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes the kurtosis across a specified valuespace
        [The fourth moment about the mean]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="kurtosis",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    def wtd_kurtosis1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes a weighted kurtosis across a specified valuespace
        [The fourth moment about the mean]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="wtd_kurtosis",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def skew1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes the skew across a specified valuespace
        [The third moment about the mean]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="skew",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_skew1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="wtd_skew",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def pos_std1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes an upper semi-deviation across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="pos_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_pos_std1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="wtd_pos_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def neg_std1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes a lower semi-deviation across a specified valuespace
        [target semi-deviation (TSV)]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="neg_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_neg_std1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="wtd_neg_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def pos_var1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes an upper semi-variance across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="pos_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_pos_var1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="wtd_pos_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def neg_var1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Computes a lower semi-variance across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="neg_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_neg_var1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="wtd_neg_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def max_drawdown1d(
        self,
        keyspace="<first_time_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        geo_cume_src_flag=True,
        geo100_flag=False,
    ) -> Quble:
        """
        Computes the 'maximum drawdown' (presented as a negative percentage value)
        for investment strategy returns across the specified time-keyspace
        for the specified valuespace(s) (numeric valuespaces required).

        ---------------------------------------------------
        The source Quble return data can be presented in one these two formats:

            geo_cume_src_flag==True: geometric cumulative source return profile
                        (e.g., growth of a dollar profile, return index AUM profile, etc.)

            geo_cume_src_flag==False: periodic source returns profile
                        (period return stream w/convention according to geo100_flag)

        NOTE: The resultant Quble will no longer exhibit the specified time-keyspace

        ---------------------------------------------------
        The definition of the drawdown is as follows:

            The greatest loss (expressed as a negative percentage loss)
            experienced by an investment return series
            as measured from a recent investment peak
            to a subsequent worst-case loss level
            (prior to any new latter investment peak).

            geo100_flag==True:  -100 <= max_draw_down <= 0
            geo100_flag==False: -1 <= max_draw_down <= 0

        NOTE: This method should not return positive drawdown values.

        ---------------------------------------------------

        :type keyspace: str
        :param keyspace: time-keyspace to perform temporal draw-down operation

        :type valuespace: str or list of strings
        :param valuespace: valuespace(s) for draw-down operation

        :param view: Quble indicating conditional elements
                     for which aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :type geo_cume_src_flag: bool
        :param geo_cume_src_flag: flag indicating if source data is either:

            ==> geo_cume_src_flag==True:  pre-cumulated investment strategy data
            ==> geo_cume_src_flag==false: periodic return data (according to geo100_flag)

        :type geo100_flag: bool
        :param geo100_flag: flag indicating scaling convention of:
                    1) source return data (if geo_cume_src_flag==False)
                AND 2) resultant drawdown values

            ==> geo100_flag==True: drawdown of -25% will be represented as -25.0
            ==> geo100_flag==False: -25% will be represented as -0.25

        :returns: The resultant Quble
        :rtype: qubles.core.quble.Quble
        """
        # Handle trivial cases
        if self.is_undefined:
            return self.copy()

        # Validate keyspace
        keyspace = self.validate_keyspace(
            keyspace, solo_required=True, time_space_required=True, grace=False
        )

        # Validate valuespace
        if self.is_nonvariate:
            raise Exception("valued Quble required")

        valuespace = self.validate_valuespace(
            valuespace, coerce_to_list=True, numeric_required=True, grace=False
        )

        # Isolate the valuespace(s) of interest
        subject = self.sub_variate(valuespace, allow_shallow_copy=True)

        # Apply view to subject (if provided)
        if view is not None:
            subject = subject.apply_view(view, allow_shallow_copy=True)

        # Handle empty Quble case
        # by merely excluding the designated keyspace column
        # from the selection command
        if subject.is_empty:
            return subject.select(
                column_names=[col for col in self.spaces if col != keyspace]
            )

        # Establish any orthogonal keyspaces
        ortho_keyspaces = subject.ortho_keyspaces(keyspace)

        # Call drawdown template
        tgt_table_name = generate_random_table_name()
        sql_template = JINJA_ENV.get_template("max_drawdown.j2")
        sql_command = sql_template.render(
            keyspace=keyspace,
            valuespaces=valuespace,
            ortho_keyspaces=ortho_keyspaces,
            geo_cume_src_flag=geo_cume_src_flag,
            geo100_flag=geo100_flag,
            src_table_name=subject.table_name,
            tgt_table_name=tgt_table_name,
        )
        execute(sql_command)

        # Build modified new_col_info from subject._col_info:
        #   1) remove keyspace references from new_col_info
        #   2) remove time-related space_info for valuespaces in new_col_info
        if subject._column_info is None:
            new_col_info = None
        else:
            new_col_info = deepcopy(subject._column_info)
            info_types = [it1 for it1 in new_col_info.keys()]
            for info_type in info_types:
                # We do not want to assign 'built-in' info types
                if info_type in BUILTIN_INFO_TYPES:
                    new_col_info.pop(info_type)
                    continue

                info_assignments = new_col_info[info_type]
                if info_assignments is None:
                    continue

                for space1 in list(info_assignments.keys()):
                    if space1 is None:
                        continue
                    elif space1 == keyspace:
                        new_col_info[info_type].pop(space1)
                    elif space1 in valuespace and info_type in (
                        "tfill_max",
                        "tfill_honor_nulls",
                        "tfill_end_mode",
                        "tfill_method",
                    ):
                        new_col_info[info_type].pop(space1)

                    # pop any info_types where no assignments remain
                    if len(new_col_info[info_type]) == 0:
                        new_col_info.pop(info_type)
        # Build new Quble from the target table and new_col_info
        return Quble.from_table(table_name=tgt_table_name, col_info=new_col_info)

    # ========================================= CROSS/ORTHO-DIMENSION AGGREGATION ===========================================

    @RootLib.lazy_kwargs()
    def aggregatex1d(
        self,
        keyspace: str = "<first_keyspace>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        percentile: float = 50.0,
        epsilon: float = None,
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Aggregates across all keyspaces EXCEPT for the specified keyspace
        When auto_squeeze=True, the result will be a single-dimensional Quble
        See: :meth:`~qubles.core.quble.Quble.aggregate`
        """
        return self.aggregate(
            aggr_keyspaces=self.ortho_keyspaces(keyspace),
            aggr_method=aggr_method,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            percentile=percentile,
            epsilon=epsilon,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def countx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        unfolded: bool = False,
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        # Quble.count() method contains special logic for unfolded case,
        # As such, we call Quble.count() here instead of calling aggregatex1d(aggr_method='count',...)
        return self.count(
            aggr_keyspaces=self.ortho_keyspaces(keyspace),
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            unfolded=unfolded,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def sumx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="sum",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_sumx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="wtd_sum",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def prodx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="prod",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    def wtd_prodx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="wtd_prod",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def meanx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="avg",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_meanx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="wtd_mean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def avgx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="avg",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_avgx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="wtd_mean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def averagex1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="avg",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_averagex1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="wtd_mean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def avex1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="avg",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_avex1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="wtd_mean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def medianx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="median",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_medianx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="wtd_median",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            interpolate_flag=True,
        )

    @RootLib.lazy_kwargs()
    def minx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="min",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def maxx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="max",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def stddev_sampx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="stddev_samp",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def stddev_popx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="stddev_pop",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def var_sampx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="var_samp",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def var_popx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="var_pop",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def stdx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="stddev_pop",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_stdx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="wtd_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def stddevx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="stddev_pop",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_stddevx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="wtd_stddev",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def varx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="var_pop",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_varx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="wtd_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def firstx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.first(
            aggr_keyspaces=self.ortho_keyspaces(keyspace),
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def lastx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.last(
            aggr_keyspaces=self.ortho_keyspaces(keyspace),
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def kurtosisx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="kurtosis",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_kurtosisx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="wtd_kurtosis",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def skewx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="skew",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_skewx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="wtd_skew",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def pos_stdx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="pos_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_pos_stdx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="wtd_pos_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def neg_stdx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="neg_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_neg_stdx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="wtd_neg_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def pos_varx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="pos_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_pos_varx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="wtd_pos_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def neg_varx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="neg_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def wtd_neg_varx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="wtd_neg_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    # ========================================= ALL-DIMENSION AGGREGATION ===========================================

    @RootLib.lazy_kwargs()
    def unfolded_count(
        self,
        aggr_keyspaces="<keyspaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.count(
            aggr_keyspaces=aggr_keyspaces,
            ignore_missing=False,
            view=view,
            key_ordering=key_ordering,
            unfolded=True,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    def _apply_pre_cross_fill(
        self,
        crosser_keyspace="<time_keyspaces>",
        allow_shallow_copy: bool = True,
        fill_keyspace: str = "Vantage",
        remove_dupes: bool = True,
    ) -> Quble:
        """
        Cross-fills the (fill) keyspace (e.g, 'Vantage') (if present)
        against specified crosser_keyspace(s) for ALL valuespaces of the Quble
        """
        # Initialize result
        subject = self if allow_shallow_copy else self.copy()

        # Handle trivial cases
        if fill_keyspace not in subject.keyspaces:
            # Exit early if fill_keyspace absent from subject.keyspaces
            return subject
        elif subject.is_nonvariate:
            # Exit early if no valuespaces present
            return subject

        # Validate crosser_keyspace -> crossers
        # Chose not to use: subject.validate_keyspace(..., time_space_required=True)
        # [Will check time-space below and want to relieve caller from such pre-checks/requirements]
        crossers = subject.validate_keyspace(
            keyspace=crosser_keyspace, grace=False, coerce_to_list=True
        )

        # Exit early if no crossers exist
        if crossers is None or len(crossers) == 0:
            return subject

        # Crossing requires that
        # fill_keyspace ('Vantage')
        # be present in subject
        # ---------------------------------
        if fill_keyspace in subject.keyspaces:
            for crosser1 in crossers:
                # Vantage cannot be a crosser (only a fill_keyspace)
                # Also, crosser1 must be a time-keyspace
                if crosser1 != fill_keyspace and subject.is_time_space(
                    space=crosser1, grace=True
                ):
                    subject = subject.cross_fill1d(
                        keyspace=fill_keyspace,
                        crosser_keyspace=crosser1,
                        key_ordering=None,
                        remove_dupes=remove_dupes,
                    )

        return subject

    def _apply_pre_fill(
        self,
        keyspace: str = "<resampling_keyspaces>",
        valuespace="<valuespaces>",
        allow_shallow_copy: bool = True,
    ) -> Quble:
        """
        Fills the specified valuespace(s) (str or list of str) of a Quble
        across the specified (non-vantage) filling time-keyspace(s)

        Here, valuespace arg indicates the valuespace(s) to fill
        However, resultant Quble will retain ALL original valuespaces of self
        """
        # Initialize result
        subject = self if allow_shallow_copy else self.copy()

        # Validate keyspace -> filling_keyspaces
        # Chose not to use: subject.validate_keyspace(..., time_space_required=True)
        # [Will check time/resampling space below and want to relieve caller from such pre-checks/requirements]
        filling_keyspaces = subject.validate_keyspace(
            keyspace=keyspace, grace=False, coerce_to_list=True
        )

        # Exit early if no keyspace(s) earmarked for filling
        if filling_keyspaces is None or len(filling_keyspaces) == 0:
            return subject

        # Validate valuespace
        valuespace = subject.validate_valuespace(
            valuespace=valuespace, grace=False, coerce_to_list=True
        )

        # Exit early if no valuespace(s) to be filled
        # were earmarked for filling
        if valuespace is None or len(valuespace) == 0:
            return subject

        # fill across specified filling time-keyspaces
        # EXCEPT 'Vantage' keyspace
        for ks in filling_keyspaces:
            if (ks != "Vantage") and subject.is_resampling_space(space=ks, grace=True):
                subject = subject.fill1d(
                    keyspace=ks,
                    valuespace=valuespace,
                    key_ordering=None,
                    pre_cross_fill=False,
                    deep_copy=not allow_shallow_copy,
                )

        return subject

    @RootLib.lazy_kwargs()
    def hier_aggregate_inplace(
        self,
        keygroup,
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        view=RootLib.lazy_eval("view"),
        percentile: float = 50.0,
        epsilon: float = None,
        clob_export_mode=RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode=RootLib.lazy_eval("blob_export_mode"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        allow_new_aggregate_keys: bool = True,
        keep_basic_keys: bool = True,
    ):
        """
        In-place version of method: Quble.hier_aggregate()
        See: :meth:`~qubles.core.quble.Quble.hier_aggregate`
        """
        return self.hier_aggregate(
            keygroup=keygroup,
            aggr_method=aggr_method,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            view=view,
            percentile=percentile,
            epsilon=epsilon,
            inplace=True,
            clob_export_mode=clob_export_mode,
            blob_export_mode=blob_export_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            allow_new_aggregate_keys=allow_new_aggregate_keys,
            keep_basic_keys=keep_basic_keys,
        )

    def hier_concurrent_depth_loop(
        self,
        i,
        hier_depth,
        hierspaces,
        aggr_method,
        ignore_missing,
        pct_required,
        num_required,
        valuespace,
        view,
        epsilon,
        clob_export_mode,
        blob_export_mode,
        pre_cross_fill,
        pre_fill,
    ):
        aggr_keyspaces = hierspaces[i : len(hierspaces)]
        aggr1 = self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method=aggr_method,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            pct_required=pct_required,
            num_required=num_required,
            view=view,
            epsilon=epsilon,
            auto_squeeze=False,
            clob_export_mode=clob_export_mode,
            blob_export_mode=blob_export_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

        return aggr1

    @RootLib.lazy_kwargs()
    def hier_aggregate(
        self,
        keygroup,
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        percentile: float = 50.0,
        epsilon: float = None,
        inplace: bool = False,
        clob_export_mode: str = RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode: str = RootLib.lazy_eval("blob_export_mode"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        allow_new_aggregate_keys: bool = True,
        keep_basic_keys: bool = True,
    ):
        """
        Adds hierarchical 'aggregation keys' (at all applicable levels)
        using the specified aggr_method & ignore_missing & pct_required settings

        :type keygroup: str (keygroup) or list of str (keyspaces)
        :param keygroup: Heirarchical keyspaces

        :param inplace: Flag for changing self directly inplace
        :type inplace: boolean (True/False*)
            inplace=True: modifies self Quble directly and returns self
            inplace=False: returns a (possibly) modified Quble (leaves self unchanged)

        :param keep_basic_keys: Flag to keep the original non-aggregated keys
        :type keep_basic_keys: boolean (True/False*)
            keep_basic_keys=True: retains original keys/rows
            keep_basic_keys=False: removes original keys/rows

        See: :meth:`~qubles.core.quble.Quble.aggregate`
        """
        # Handle trivial cases
        # ------------------------
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_empty:
            return self.copy()
        elif self.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...no valuespace(s) present")

        valuespace = self.validate_valuespace(
            valuespace,
            grace=False,
            coerce_to_list=True,
        )
        if valuespace is None or len(valuespace) == 0:
            raise Exception("No valuespace(s) to aggregate")

        # Break keygroup into keyspaces components
        # ------------------------------------------
        if isinstance(keygroup, str):
            hierspaces = self.keygroups[keygroup]
        elif isinstance(keygroup, (list, tuple)):
            hierspaces = keygroup
        else:
            raise Exception(f"Invalid keygroup:{keygroup}")

        # Build keymap
        # ----------------
        """
        aggr_records = Quble.undefined_instance()
        hier_depth = len(hierspaces)
        func = partial(
            self.hier_concurrent_depth_loop,
            hier_depth=hier_depth,
            hierspaces=hierspaces,
            aggr_method=aggr_method,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            epsilon=epsilon,
            clob_export_mode=clob_export_mode,
            blob_export_mode=blob_export_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )
        index_list = []
        for index in range(0, len(hierspaces)):
            index_list.append(index)

        result_list = []
        for i in range(0, 3):
            result_list = []
            try:
                with Pool() as pool:
                    result_list = pool.map(func, [i for i in index_list])
                    pool.close()
                    pool.join()
            except:
                _logger.debug("hier aggregate threw an exception, retrying")
                continue
            break

        for result in result_list:
            aggr_records = aggr_records.merge(
                result,
                self_precedence=True,
                variate_mode="multi",
                auto_link=RootLib.lazy_eval("auto_link"),
                link_check=RootLib.lazy_eval("link_check"),
                link_dupe_grace=True,
            )
        """
        aggr_records = None
        hier_depth = len(hierspaces)
        for i in range(0, hier_depth):
            aggr_keyspaces = hierspaces[i:hier_depth]
            aggr1 = self.aggregate(
                aggr_keyspaces=aggr_keyspaces,
                aggr_method=aggr_method,
                ignore_missing=ignore_missing,
                pct_required=pct_required,
                num_required=num_required,
                view=view,
                epsilon=epsilon,
                auto_squeeze=False,
                clob_export_mode=clob_export_mode,
                blob_export_mode=blob_export_mode,
                pre_cross_fill=pre_cross_fill,
                pre_fill=pre_fill,
                valuespace=valuespace,
            )
            if aggr_records is None:
                aggr_records = aggr1
            else:
                aggr_records.merge_inplace(
                    aggr1,
                    self_precedence=True,
                    auto_link=RootLib.lazy_eval("auto_link"),
                    link_check=RootLib.lazy_eval("link_check"),
                    link_dupe_grace=True,
                )

        # Merge aggregated records with the original subject
        # NOTE: we do this last to minimize re-writing/re-copying of the (larger) original Quble's table
        # ---------------------------------------------------
        if not keep_basic_keys:
            if inplace:
                if aggr_records is None:
                    return self.clear(deep_copy=False)
                else:
                    self._swap_table(aggr_records)
            else:
                return aggr_records
        elif aggr_records is not None:
            if inplace:
                return self.merge_inplace(
                    aggr_records,
                    self_precedence=True,
                    variate_mode="multi",
                    auto_link=RootLib.lazy_eval("auto_link"),
                    link_check=RootLib.lazy_eval("link_check"),
                    link_dupe_grace=True,
                )
            else:
                return self.merge(
                    aggr_records,
                    self_precedence=True,
                    variate_mode="multi",
                    inplace=False,
                    auto_link=RootLib.lazy_eval("auto_link"),
                    link_check=RootLib.lazy_eval("link_check"),
                    link_dupe_grace=True,
                )
        elif inplace:
            return self
        else:
            return self.copy()

    def hier_value_sort(
        self,
        keygroup,
        value_ordering: str = "asc",
        key_ordering="asc",
        valuespace: str = "<valuespace>",
    ) -> Quble:
        """
        Adds hierarchical 'aggregation keys' (at all applicable levels)
        using the specified aggr_method & ignore_missing & pct_required settings

        :type keygroup: str (keygroup) or list/tuple of str (keyspaces)
        :param keygroup: Heirarchical keyspaces

        ==> If keygroup is a str: Treat and validate as keygroup
        ==> If keygroup is a list/tuple: Treat as (new) keygroup definition  from the specified keyspaces in list

        :param value_ordering: Sorting order for sorting valuespace
        :type value_ordering: 'asc' or 'desc'

        :param valuespace: valuespace to rank across
        :type valuespace: str (a specific valuespace) OR '<valuespace>' (primary valuespace)
        """
        # Handle trivial cases
        # ------------------------
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_empty:
            return self.copy()
        elif self.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...no valuespace(s) present")

        # Validate valuespace
        # ---------------------
        valuespace = self.validate_valuespace(
            valuespace, grace=False, solo_required=True
        )

        # Break keygroup into keyspaces components
        # ------------------------------------------
        if isinstance(keygroup, str):
            # Validate keygroup arg
            if self.keygroups is None:
                raise Exception("No keygroups present")
            elif keygroup not in self.keygroups:
                raise Exception(f"Unsupported keygroup:{keygroup}")

            hierspaces = self.keygroups[keygroup]

        elif isinstance(keygroup, (list, tuple)):
            # Validate the each element is a valid keyspace
            keygroup = self.validate_keyspace(keygroup)
            hierspaces = keygroup

        else:
            raise Exception(f"Invalid keygroup:{keygroup}")

        controls = {
            "ignore_add": False,
            "ignore_mult": False,
        }  # <-- We will be adding ranks to initially nullified
        with ControlContextManager(controls=controls) as ccm:
            ortho_keyspaces = self.ortho_keyspaces(hierspaces)
            multiplier = 1
            hier_ranks = None

            # ---------------------------------------------------
            # Handle valuespace sort order...
            # ---------------------------------------------------
            # NOTE: nulls are treated as lowest values
            #       during sorting w/include_nulls_in_rank=True
            # This behavior is fine when requesting sorted descending (highest values first)
            # For when requesting sorted ascending
            # ---------------------------------------------------
            # Try to handle sort order via value negation if possible
            # and use ascending = True to place nulls
            # as lowest partitioned records in post-sort result
            # ---------------------------------------------------
            # NOTE that the final re-sort will hard-code descending sort order
            # As such, initial partitoned sorts should be counter to specified value_ordering
            ascending = True
            placeheld_self = self.placehold(space=hierspaces)

            if not isinstance(value_ordering, str):
                # Invalid value_ordering
                raise Exception("Invalid value_ordering:{0}...str expected")
            elif value_ordering[0:3].lower() != "asc":
                # descending sort not troubled by nulls treated as smallest values
                negate_flag = False
                ascending = False
            elif placeheld_self.is_numeric():
                # Here, we negate values if possible to affect ascending sort
                # [In actuality, we will sort negated values
                # in descending (non-ascending) order]
                negate_flag = True
                ascending = False
            else:
                # Here, we cannot actually negate a non-numeric Quble
                # As such, we sort ascending with caveat that
                # sort placement of nulls may not be handled correctly
                negate_flag = False
                ascending = True
                _logger.warning(
                    "Cannot negate non-numeric Quble...null handling/sort placement may be incorrect"
                )

            hier_null_placeholders = self.null_placeholder_as_str(
                space=hierspaces
            )  # <-- list w/len = len(hierspaces)
            for hierspace_no in reversed(
                list(range(len(hierspaces) + 1))
            ):  # <-- NOTE: reverse order!!!
                # NOTE: hierspace_no starts at len(hierspaces) and ends at 0
                lower_hierspaces = hierspaces[0:hierspace_no]
                upper_hierspaces = hierspaces[hierspace_no : len(hierspaces)]

                where_clause = ""
                where_or_and = "WHERE "
                # Loop through lower_hierspaces (by index number)
                # for ks in lower_hierspaces:
                for i in range(0, hierspace_no):
                    where_clause += (
                        where_or_and
                        + '("'
                        + hierspaces[i]
                        + '" <> '
                        + hier_null_placeholders[i]
                        + ")"
                    )
                    where_or_and = " AND "

                # Loop through upper_hierspaces (by index number)
                # for ks in upper_hierspaces:
                for i in range(hierspace_no, len(hierspaces)):
                    where_clause += (
                        where_or_and
                        + '("'
                        + hierspaces[i]
                        + '" = '
                        + hier_null_placeholders[i]
                        + ")"
                    )
                    where_or_and = " AND "

                # Only select lower_hierspaces columns
                # This will allow for lower_hierspaces ranks
                # to also be assigned to upper_hierspaces in plus operation below
                # columns_to_select = lower_hierspaces + [valuespace]
                where_clause = where_clause if (len(where_clause) > 0) else None
                partition = placeheld_self.select(
                    column_names=placeheld_self.spaces, where_clause=where_clause
                )
                # column_expressions=placehold_expressions)
                # Negate if required
                if negate_flag:
                    partition *= -1

                if partition.num_records > 0:
                    # -----------------------------------------
                    # Apply partition rank
                    # NOTE: we include nulls in rank...
                    # ==> null values will treated as
                    # ==> smallest values during ranking
                    # -----------------------------------------
                    sub_ranks = partition.rank(
                        ranking_keyspaces=lower_hierspaces,
                        ascending=ascending,
                        key_ordering=key_ordering,
                        valuespace=valuespace,
                        include_nulls_in_rank=True,
                    )
                    # Here, sub_ranks hsould be a univariate Quble
                    if sub_ranks.is_empty:
                        continue

                    max_sub_rank = sub_ranks.max(quble_flag=False).item()
                    if max_sub_rank is None or max_sub_rank < 0:
                        continue
                    else:
                        max_sub_rank = int(max_sub_rank)

                    if multiplier != 1:
                        sub_ranks *= multiplier

                    if hier_ranks is None:
                        # Should be sub_ranks for lower_hierspaces only
                        hier_ranks = sub_ranks
                    else:
                        # Add rankings for upper_hierspaces to lower_hierspaces
                        if len(upper_hierspaces) > 0:
                            upper_ranks = sub_ranks.select(
                                column_names=lower_hierspaces
                                + ortho_keyspaces
                                + [valuespace]
                            )
                            hier_ranks += upper_ranks
                        hier_ranks.merge_inplace(sub_ranks, self_precedence=True)

                    multiplier *= max_sub_rank + 1

            # Re-Sort based on scaled/cascaded ranks accordingly
            # NOTE: Always use ascending True here
            #       as ordering has already been established above!!!
            # -------------------------------------------------------------
            sorted_values = hier_ranks.value_sort(
                sorting_keyspaces=hierspaces,
                value_ordering="asc",
                key_ordering=key_ordering,
                valuespace=valuespace,
            )
            # NOTE: reindexing operation will not work properly if NULLs present
            result = placeheld_self.reindex(sorted_values, key_ordering=None)
            result = result.unplacehold(space=hierspaces)
            return result

    @RootLib.lazy_kwargs()
    def aggregate(
        self,
        aggr_keyspaces="<keyspaces>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        percentile: float = 50.0,
        epsilon: float = None,
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        clob_export_mode: str = RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode: str = RootLib.lazy_eval("blob_export_mode"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag=True,
        non_abs_weights=False,
        **kwargs,
    ) -> Quble:
        """
        Aggregates the specified valuespace(s) across the specified keyspace(s)
        When auto_squeeze=True, aggr_keyspaces will be absent from resultant Quble tbale

        :param quble_flag: Control if a quble should be returned or a scalar value
        :type aggr_keyspaces: str or list of str
        :param keyspace: Keyspaces to be aggregated across

        :type aggr_method: str
        :param aggr_method:
            Aggregation method

        :type ignore_missing: bool
        :param ignore_missing:
            Control for whether to ignore the presence of null values in the count

        :type pct_required: None or float
        :param pct_required:
            Control for necessary support across distinct keys of the specified
            keyspace. Value must be: 0.0 <= pct_required <= 1.0

        :type num_required: None or int
        :param num_required:
            Control for necessary support across distinct keys of specified keyspace(s)
            Value must  either None or an int >= 0

        :param valuespace: the valuespace(s) to be aggregated
                           (only these valuespaces will remain in result)
        :type valuespace: str or list of strings
                      (keywords may be used such as '<valuespaces>', '<valuespace>', etc.
                      [See: :meth:`~qubles.core.quble.Quble.validate_valuespace`]

        :param view: Quble indicating conditional elements
                     for which aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float) or str (valuespace) or None

        :param key_ordering: controls row ordering by key
        :type key_ordering: None, str or dictionary
           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace

        :type percentile: float
        :param percentile:
            Percentile level. Only applies if the ``aggr_method`` is 'PERCENTILE' or
            'QUANTILE'. Value must be: 0.0 <= percentile <= 100.0

        :type epsilon: float or None
        :param epsilon:
            epsilon criterion to be used for certain custom aggregation functions
            (e.g., aggr_method = 'num_zero' or 'num_non_zero')

        :param auto_squeeze: Flag to auto_squeeze the columns keyspace
                             if there is only one value column
                             and the column space is not explicitly named
        :type auto_squeeze: boolean

        :param clob_export_mode: treament for column type: 'clob'/'CLOB'
                                 in Python-based aggregation functions
        :type clob_export_mode: 'unicode','object','string','str',None

        :param blob_export_mode: treament for column type: 'blob'/'BLOB'
                                 in Python-based aggregation functions
        :type blob_export_mode: 'object','string','str','unicode',None

        :param pre_cross_fill: flag to control whether to pre-cross-fill
                           when some keyspaces being aggregated are a time keyspaces
                           and ortho_resampling_keyspaces also exist
        :type pre_cross_fill: boolean (True*/False)

        :param pre_fill: flag to control whether to pre-fill
                         when some being aggregated are resampling keyspaces
        :type pre_fill: boolean (True/False*)
        :param non_abs_weights: Flag to signify the usage of negative values in the weight space
                                If set to True, we won't use ABS() when computing the weights.
        """
        # Handle trivial cases
        if aggr_method in ("first", "last"):
            # ===========================================================
            # SPECIAL LOGIC FOR aggr_method in ("first","last")...
            # HERE, We call self.first_last() SINCE THE STANDARD SQL
            # "GROUPING" SUB-SET APPROACH MAY NOT HONOR KEY SORT ORDERING
            # NOTE: pct_required and num_required are NOT applicable here
            # ===========================================================
            return self._first_last(
                aggr_keyspaces=aggr_keyspaces,
                ignore_missing=ignore_missing,
                valuespace=valuespace,
                view=view,
                key_ordering=key_ordering,
                auto_squeeze=auto_squeeze,
                rank_direction="asc" if aggr_method == "first" else "desc",
                pre_cross_fill=pre_cross_fill,
                pre_fill=pre_fill,
            )
        elif self.is_undefined:
            return self.copy()
        # Scalars are already fully aggregated
        elif self.is_scalar:
            pass
        elif self.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")
        elif aggr_method == "count":
            aggr_method = "count" if ignore_missing else "count_all"

        orig_primary_vs = self.valuespace

        # Validate valuespace arg
        numeric_required = aggr_method in NUMERIC_ONLY_AGGR_METHODS
        valuespace = self.validate_valuespace(
            valuespace,
            grace=False,
            coerce_to_list=True,
            numeric_required=numeric_required,
        )
        if valuespace is None or len(valuespace) == 0:
            raise Exception("No valuespace(s) to aggregate")

        # Add view (str) to valuespace (list) when applicable
        if (
            isinstance(view, str)
            and view in self.valuespaces
            and view not in valuespace
        ):
            valuespace.append(view)

        # Restrict Quble to only the valuespace(s) of interest
        # [valuespace arg is validated within sub_variate method]
        # (allow for shallow copy when valuespaces are unchanged)
        # ==> Only refer to subject (not self) hereafter
        # ------------------------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)

        # May perform auto-linking
        aggr_keyspaces = subject.validate_keyspace(
            aggr_keyspaces,
            grace=False,
            coerce_to_list=True,
        )

        # NOTE: Apply pre_cross_fill BEFORE pre_fill
        if pre_cross_fill:
            subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)

        if pre_fill:
            subject = subject._apply_pre_fill(allow_shallow_copy=True)

        # Apply view to subject
        # using view's primary valuespace
        # --------------------------------
        weightspace = None
        if view is None:
            pass
        elif isinstance(view, str):
            # Here, view (str) identifies a weightspace column of the Quble
            if view not in subject.valuespaces:
                raise Exception(
                    f"view:{view} absent from subject.valuespaces:{subject.valuespaces}"
                )
            weightspace = view
            weightspace_type = self.get_column_type(weightspace)
            weightspace_is_numeric = coltype_is_numeric(weightspace_type)
            weightspace_is_bool = coltype_is_bool(weightspace_type)
            if aggr_method not in WTD_TO_UNWTD_AGGR_DICT or weightspace_is_bool:
                # Non-weighted aggregation OR boolean weightspace
                # Implementation: Restrict to records where weightspace = True
                if weightspace_is_bool:
                    where_clause = (
                        'WHERE "'
                        + weightspace
                        + '" IS NOT NULL AND "'
                        + weightspace
                        + '" <> False'
                    )
                elif weightspace_is_numeric:
                    where_clause = (
                        'WHERE "'
                        + weightspace
                        + '" IS NOT NULL AND "'
                        + weightspace
                        + '" <> 0'
                    )
                else:
                    raise Exception(
                        f"Invalid coltype:{weightspace_type} for weightspace:{weightspace} with aggr_method:{aggr_method}"
                    )

                spacesxweightspace = [
                    space1 for space1 in subject.spaces if space1 != weightspace
                ]
                subject = subject.select(
                    column_names=spacesxweightspace, where_clause=where_clause
                )
                # No need to continue to recognize weightspace now
                weightspace = None
            elif not weightspace_is_numeric:
                raise Exception(
                    f"weightspace:{weightspace} has invalid column type:{weightspace_type}...numeric or bool type required"
                )

        elif not isinstance(view, Quble):
            raise Exception("Invalid view...Quble, str or None expected")
        elif view.is_undefined:
            pass
        elif (
            aggr_method not in WTD_TO_UNWTD_AGGR_DICT
            or view.is_scalar
            or view.is_multiscalar
            or view.is_index
            or view.is_bool()
        ):
            # Determine if this is a weighted aggregation method by looking at:
            # aggr_method not in WTD_TO_UNWTD_AGGR_DICT
            subject = subject.apply_view(view, allow_shallow_copy=True)
        elif not view.is_numeric():
            raise Exception(
                "For weight aggregation:{0}, view must be index, bool or numeric Quble"
            )
        elif subject.are_coindexed(view):
            if view.valuespace is None:
                # Highly unlikely case, but check to be sure
                raise Exception(
                    "self & view are coindexed, yet view.valuespace is None"
                )
            weightspace = view.valuespace
        else:
            # Here, we are performing a weighted aggregation with a numeric non-scalar view (weighting Quble)
            if subject.valuespace is None or subject.valuespace != "weighting":
                weightspace = "weighting"
            else:
                weightspace = "wgt"
            # NOTE: weightspace will be imposed column,
            # but must be distinct from subject.valuespace
            subject = subject.apply_view(
                view, view_valuespace_as=weightspace, allow_shallow_copy=True
            )

            # Perform some checks
            if weightspace not in subject.valuespaces:
                raise Exception(
                    "weightspace:{0} was not created during the join operation"
                )
            elif subject.valuespace is not None and weightspace == subject.valuespace:
                raise Exception(
                    f"weightspace:{weightspace} expectedly equals subject.valuespace:{subject.valuespace}"
                )
        # =========================== START: VALUESPACES LOOP ===========================
        sql_aggr_fn_per_vs = {}
        extra_fn_args_per_vs = {}
        include_null_values_per_vs = {}
        aggr_keyspaces_presort_needed_per_vs = {}

        for vs in subject.valuespaces:
            # Validate/convert aggr_method
            # (will convert to SQL compatible lower-case FUNCTION NAME)
            (
                sql_aggr_fn,
                extra_fn_args,
                is_custom,
                is_weighted,
                aggr_keyspaces_presort_needed,
            ) = subject._validate_and_convert_aggr_method(
                aggr_method,
                column_name=vs,
                ignore_missing=ignore_missing,
                num_required=num_required,
                percentile=percentile,
                epsilon=epsilon,
                weightspace=weightspace,
                clob_export_mode=clob_export_mode,
                blob_export_mode=blob_export_mode,
            )
            sql_aggr_fn_per_vs[vs] = sql_aggr_fn
            extra_fn_args_per_vs[vs] = extra_fn_args
            aggr_keyspaces_presort_needed_per_vs[vs] = aggr_keyspaces_presort_needed
            # In most cases, we DO NOT INCLUDE null value records from the aggregation query
            # Implemented default case as: include_null_values=False
            # (as opposed to compress=True) so that bad/no arg (interface w/template) is treated as excluding nulls
            include_null_values = False

            # NOTE: we need to include_null_values for 'num_not_null' case to get proper zero count result behavior for certain key combinations
            if (aggr_method in ("num_null", "num_not_null", "count_all")) or (
                aggr_method == "count" and ignore_missing == True
            ):
                include_null_values = True
            # Needed following logic for custom Python UDFs when all records are null
            # --------------------------------------------
            # Otherwise, with no non-null records,
            # the underlying Python UDF never gets called!!??
            elif is_custom and not subject.has_non_nulls(vs):
                include_null_values = True

            include_null_values_per_vs[vs] = include_null_values
        # =========================== END: VALUESPACES LOOP ===========================

        # List of all the extra keyspaces
        # (excluding the keyspace provided as an argument)
        ortho_keyspaces = subject.ortho_keyspaces(aggr_keyspaces)

        # Build col_types_dict (if needed)
        if not auto_squeeze:
            col_types_dict = subject.get_column_type(subject.keyspaces)
        else:
            col_types_dict = None

        # Build build_key_ordering_dict when applicable
        if key_ordering is not None and not isinstance(key_ordering, str):
            key_ordering = build_key_ordering_dict(
                key_ordering, keyspaces=subject.keyspaces
            )

        if weightspace is None:
            valuespaces_xweightspace = subject.valuespaces
        elif weightspace not in subject.valuespaces:
            raise Exception(
                "weightspace:{0} absent from post-join valuespaces:{0}".format(
                    weightspace, subject.valuespaces
                )
            )
        else:
            valuespaces_xweightspace = subject.ortho_valuespaces(weightspace)

        tgt_keyspaces = ortho_keyspaces if auto_squeeze else subject.keyspaces
        table_name = generate_random_table_name() if quble_flag else None

        # These templates hold the sql queries to run
        sql_template = JINJA_ENV.get_template("aggregate.j2")
        wtd_template = JINJA_ENV.get_template("wtd_aggregate.j2")

        # Do we need a group_sizes_cte construct in the query?
        group_sizes_cte = None
        if aggr_method == "count":
            pass
        elif aggr_method == "count_all":
            group_sizes_cte = None
        elif not ignore_missing or pct_required:
            group_sizes_cte = "group_sizes_cte"

        if percentile > 1:
            percentile *= 0.01

        # Generate the aggregation query
        if "wtd" in aggr_method:
            # wtd_aggregate.j2 expects the percentile in the form of a list
            # whether we are doing a singular or multiple percentile_level calculation
            # different methods pass the parameter as either percentile or percentiles, so I am
            # capturing both variables in addition to ensuring we always have a default.
            if percentile:
                percentiles = [0.5]
            else:
                percentiles = kwargs.get("percentile", [0.50])
            com = wtd_template.render(
                function=aggr_method,
                aggr_keyspaces=aggr_keyspaces,
                keyspaces=subject.keyspaces,
                ortho_keyspaces=[
                    ks for ks in subject.keyspaces if ks not in aggr_keyspaces
                ],
                src_table_name=subject.table_name,
                tgt_table_name=table_name,
                valuespaces=valuespaces_xweightspace,
                weightspace=weightspace,
                auto_squeeze=auto_squeeze,
                num_required=num_required,
                pct_required=pct_required,
                ignore_missing=ignore_missing,
                non_abs_weights=non_abs_weights,
                percentile_keyspace=kwargs.get("percentile_keyspace", "Percentiles"),
                percentiles=percentiles,
                interpolate_flag=kwargs.get("interpolate", True),
            )
        else:
            com = sql_template.render(
                aggr_keyspaces=aggr_keyspaces,
                sql_aggr_fn_per_vs=sql_aggr_fn_per_vs,
                key_ordering=key_ordering,
                keyspaces=subject.keyspaces,
                src_table_name=subject.table_name,
                tgt_keyspaces=tgt_keyspaces,
                tgt_table_name=table_name,
                valuespaces=valuespaces_xweightspace,
                weightspace=weightspace,
                auto_squeeze=auto_squeeze,
                col_types_dict=col_types_dict,
                percentile=percentile,  # <-- For calling Python non-native function: percentile_level(percentile=[0,100])
                extra_fn_args_per_vs=extra_fn_args_per_vs,
                include_null_values_per_vs=include_null_values_per_vs,
                aggr_keyspaces_presort_needed_per_vs=aggr_keyspaces_presort_needed_per_vs,
                group_sizes_cte=group_sizes_cte,
                num_required=num_required,
                pct_required=pct_required,
                ignore_missing=ignore_missing,
            )

        # When not quble_flag, exit early with results of SQL query
        if not quble_flag:
            return execute_snowalchemy(com, method_name="read_numpy")
        elif table_name is None:
            # Should not happen here
            raise Exception(
                f"table_name should not be None when quble_flag:{quble_flag}"
            )
        else:
            execute(com)

        # Establish col_info for copy
        if table_name == subject.table_name:
            col_info = None
        else:
            if aggr_method in (
                "count",
                "count_all",
                "num_null",
                "num_not_null",
                "num_zero",
                "num_non_zero",
                "num_positive",
                "num_nonpositive",
                "num_negative",
                "num_nonnegative",
            ):
                info_types_to_copy = [
                    it1 for it1 in CUSTOM_INFO_TYPES if it1 not in ["fx", "time_basis"]
                ]
            else:
                info_types_to_copy = CUSTOM_INFO_TYPES

            col_info = subject.get_space_info(
                info_type=info_types_to_copy,
                space=tgt_keyspaces + valuespaces_xweightspace,
                omit_unassigned=True,
            )

        # Instantiate Quble from the new table
        result = Quble.from_table(
            table_name, col_info=col_info, duplicate_key_grace=False
        )

        # Try to reinstate original primary valuespace (if possible)
        # NOTE: This may not be possible when original primary valuespace
        # did not participate in the aggregation operation
        if (
            quble_flag
            and result.is_variate
            and result.valuespace is not None
            and orig_primary_vs is not None
            and result.valuespace != orig_primary_vs
            and orig_primary_vs in result.valuespaces
        ):
            result.promote_valuespace_inplace(valuespace=orig_primary_vs)

        return result

    @RootLib.lazy_kwargs()
    def first(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag=True,
    ) -> Quble:
        """
        See: :meth:`~qubles.core.quble.Quble.last`
        """
        return self._first_last(
            aggr_keyspaces=aggr_keyspaces,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            rank_direction="asc",
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def last(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Yields the last record across each combined key
        across the aggregation keyspaces

        :type aggr_keyspaces: str or list of str
        :param aggr_keyspaces: Keyspaces to be aggregated across

        :type ignore_missing: bool
        :param ignore_missing:
            Control for whether to ignore the presence of null values in the count

        :param valuespace: the valuespace(s) to be aggregated
                           (only these valuespaces will remain in result)
        :type valuespace: str or list of strings
                      (keywords may be used such as '<valuespaces>', '<valuespace>', etc.
                      [See: :meth:`~qubles.core.quble.Quble.validate_valuespace`]

        :param view: Quble indicating conditional elements
                     for which aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :param key_ordering: controls row ordering by key
        :type key_ordering: None, str or dictionary
           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace
           dictionary: dict keys (str): keyspaces, dict values (str): 'asc' or 'desc'
           ==> allows for assigning key ordering (ascending/descending)
           ==> (and relative priority) for each keyspace individually

        :param auto_squeeze: Flag to auto_squeeze the columns keyspace
                             if there is only one value column
                             and the column space is not explicitly names
        :type auto_squeeze: boolean

        :param pre_cross_fill: flag to control whether to pre-cross-fill
                           when some keyspaces being aggregated are a time keyspaces
                           and ortho_resampling_keyspaces also exist
        :type pre_cross_fill: boolean (True*/False)

        :param pre_fill: flag to control whether to pre-fill
                         when some being aggregated are resampling keyspaces
        :type pre_fill: boolean (True/False*)

        NOTE: first/last aggregation does not require a valuespace
        """
        return self._first_last(
            aggr_keyspaces=aggr_keyspaces,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            rank_direction="desc",
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def _first_last(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        rank_direction: str = "desc",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Joint hidden method for implementing first or last aggregation
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        # Restrict Quble to only the valuespace(s) of interest
        # [valuespace arg is validated within sub_variate method]
        # (allow for shallow copy when valuespaces are unchanged)
        # ==> Only refer to subject (not self) hereafter
        # ------------------------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # Preclude ill-defined multivariate case where:
        #   ignore_missing==True & auto_squeeze==False
        if subject.is_multivariate and ignore_missing and not auto_squeeze:
            raise Exception(
                "Invalid/ill defined case: multi-variate Quble (# valuespaces:{0}) and ignore_missing:{1} and auto_squeeze:{2}".format(
                    len(self.valuespaces), ignore_missing, auto_squeeze
                )
            )

        keyspaces = subject.keyspaces

        # May perform auto-linking
        aggr_keyspaces = subject.validate_keyspace(
            aggr_keyspaces,
            grace=False,
            coerce_to_list=True,
        )

        # List of all the extra keyspaces
        # (excluding the keyspace provided as an argument)
        ortho_keyspaces = subject.ortho_keyspaces(aggr_keyspaces)

        # NOTE: Apply pre_cross_fill BEFORE pre_fill
        if pre_cross_fill:
            subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)

        if pre_fill:
            subject = subject._apply_pre_fill(allow_shallow_copy=True)

        # Apply view to subject
        # -----------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)

        tgt_keyspaces = ortho_keyspaces if auto_squeeze else keyspaces
        table_name = generate_random_table_name()
        sql_template = JINJA_ENV.get_template("first_last.j2")

        sql_command = sql_template.render(
            aggr_keyspaces=aggr_keyspaces,
            rank_direction=rank_direction,
            key_ordering=key_ordering,
            keyspaces=keyspaces,
            src_table_name=subject.table_name,
            tgt_keyspaces=tgt_keyspaces,
            tgt_table_name=table_name,
            valuespaces=subject.valuespaces,
            ignore_missing=ignore_missing,
            auto_squeeze=auto_squeeze,
        )
        # NOTE tgt_keyspaces may be needed for ordering of keys (if requested)
        execute(sql_command)
        # Copy over custom column info for any persisted columns
        if self.is_variate:
            relevant_spaces = tgt_keyspaces + subject.valuespaces
        else:
            relevant_spaces = tgt_keyspaces

        if quble_flag:
            result = Quble.from_table(
                table_name,
                col_info=self.get_space_info(
                    info_type=CUSTOM_INFO_TYPES,
                    space=relevant_spaces,
                    omit_unassigned=True,
                ),
            )
        else:
            result = execute_snowalchemy(
                f"SELECT * FROM {table_name.lower()}", method_name="read_numpy"
            )

        return result

    @RootLib.lazy_kwargs()
    def count(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        unfolded: bool = False,
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes the number of data points across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        # Handle trivial case
        if self.is_undefined:
            return Quble.undefined_instance()

        # Restrict Quble to only the valuespace(s) of interest
        # [valuespace arg is validated within sub_variate method]
        # (allow for shallow copy when valuespaces are unchanged)
        # ==> Only refer to subject (not self) hereafter
        # ------------------------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # TYPICAL CASE: not unfolded or ignore_missing
        if not unfolded or ignore_missing:
            return subject.aggregate(
                aggr_keyspaces=aggr_keyspaces,
                aggr_method="count",
                ignore_missing=ignore_missing,
                pct_required=pct_required,
                num_required=num_required,
                valuespace=valuespace,
                view=view,
                key_ordering=key_ordering,
                auto_squeeze=auto_squeeze,
                pre_cross_fill=pre_cross_fill,
                pre_fill=pre_fill,
                quble_flag=quble_flag,
            )
        # SPECIAL CASE: unfolded and not ignore_missing
        else:
            if subject.is_scalar or subject.is_multiscalar or subject.is_empty:
                return Quble(subject.num_records, valuespace=subject.valuespaces)

            # May perform auto-linking
            aggr_keyspaces = subject.validate_keyspace(
                aggr_keyspaces,
                grace=False,
                coerce_to_list=True,
            )
            # Validate aggr_keyspace
            if aggr_keyspaces is None or len(aggr_keyspaces) == 0:
                raise Exception("No keyspaces to aggregate")

            # NOTE: Apply pre_cross_fill BEFORE pre_fill
            if pre_cross_fill:
                subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)

            if pre_fill:
                subject = subject._apply_pre_fill(allow_shallow_copy=True)

            # Apply view to subject
            # -----------------------
            subject = subject.apply_view(view, allow_shallow_copy=True)
            if subject.is_empty:
                return Quble(subject.num_records, valuespace=subject.valuespaces)
            elif subject.is_scalar or subject.is_multiscalar:
                return Quble(subject.num_records, valuespace=subject.valuespaces)

            key_counts = self.distinct_key_counts

            # if hyper_index is None or len(hyper_index) == 0:
            if key_counts is None or len(key_counts) == 0:
                return Quble(subject.num_records)

            ortho_keyspaces = []
            num_footprint = 1
            for ks in self.keyspaces:
                if ks not in key_counts:
                    raise Exception("Absent keyspace:{0}".fornmat(ks))
                if ks in aggr_keyspaces:
                    num_footprint *= key_counts[ks]
                else:
                    ortho_keyspaces.append(ks)

            if len(ortho_keyspaces) == 0:
                num_footprint_dict = {}
                for vs in subject.valuespaces:
                    num_footprint_dict[vs] = [num_footprint]
                return Quble(data=num_footprint_dict, valuespace=subject.valuespaces)
            else:
                # Build a structured array (across valuespaces)
                # using the literal scalar num_footprint value
                _, hyper_index = subject.hyper_data(
                    hyper_values_format=None, hyper_index_format="dict"
                )
                for ks in aggr_keyspaces:
                    if ks not in hyper_index:
                        raise Exception("Absent keyspace:{0}".fornmat(ks))
                    hyper_index.pop(ks)

                array_dict = {}
                for vs in subject.valuespaces:
                    array_dict[vs] = [num_footprint]
                num_footprint_sa = array_dict_to_struct_array(array_dict)

                return Quble(
                    valuespace=subject.valuespaces,
                    data=num_footprint_sa,
                    hyper_index=hyper_index,
                )

    @RootLib.lazy_kwargs()
    def sum(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a summation across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="sum",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_sum(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a weighted summation across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="wtd_sum",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def prod(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a product of a sequence of factors across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="prod",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_prod(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a weighted product of a sequence of factors across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """

        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="wtd_prod",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def mean(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes the mean across a specified valuespace
        [First moment about the origin]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="avg",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_mean(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag=True,
    ) -> Quble:
        """
        Computes a weighted mean across a specified valuespace
        [First moment about the origin]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="wtd_mean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def avg(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag=True,
    ) -> Quble:
        """
        Computes a weighted mean across a specified valuespace
        [First moment about the origin]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="avg",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_avg(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a weighted mean across a specified valuespace
        [First moment about the origin]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="wtd_mean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def average(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a weighted mean across a specified valuespace
        [First moment about the origin]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="avg",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_average(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a weighted mean across a specified valuespace
        [First moment about the origin]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="wtd_mean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def ave(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="avg",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_ave(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="wtd_mean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def median(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes the median across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="median",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_median(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a weighted median across a specified valuespace
        [The 50% weighted percentile]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="wtd_median",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
            interpolate_flag=True,
        )

    @RootLib.lazy_kwargs()
    def min(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes the minimum value across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="min",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def max(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes the maximum value across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="max",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def stddev_samp(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="stddev_samp",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def stddev_pop(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="stddev_pop",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def var_samp(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="var_samp",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def var_pop(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="var_pop",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def std(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes the standard deviation across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="stddev_pop",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_std(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a weighted standard deviation across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="wtd_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def stddev(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes the standard deviation across a specified valuespace.
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="stddev_pop",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_stddev(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a weighted standard deviation across a specified valuespace.
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="wtd_stddev",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_std_samp(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a weighted standard deviation across a specified valuespace with an added factor of (n/n-1)
        to account for the delta degrees of freedom, similar to Bessel's correction. Useful when each
        data point's weight is inversely proportional to the square of its uncertainty.
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="wtd_std_samp",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def var(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes the variance across a specified valuespace
        [The second moment about the mean]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="var_pop",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_var(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a weighted variance across a specified valuespace
        [The second moment about the mean]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="wtd_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def kurtosis(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes the kurtosis across a specified valuespace
        [The fourth moment about the mean]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="kurtosis",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_kurtosis(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a weighted kurtosis across a specified valuespace
        [The fourth moment about the mean]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="wtd_kurtosis",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def skew(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes the skew across a specified valuespace
        [The third moment about the mean]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="skew",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_skew(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag=True,
    ) -> Quble:
        """
        Computes a weighted skew across a specified valuespace
        [The third moment about the mean]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="wtd_skew",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def pos_std(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes an upper semi-deviation across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="pos_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_pos_std(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a weighted upper semi-deviation across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="wtd_pos_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def neg_std(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a lower semi-deviation across a specified valuespace
        [target semi-deviation (TSV)]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="neg_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_neg_std(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a weighted lower semi-deviation across a specified valuespace
        [target semi-deviation (TSV)]
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="wtd_neg_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def pos_var(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes an upper semi-variance across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="pos_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_pos_var(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a weighted upper semi-variance across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="wtd_pos_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def neg_var(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a lower semi-variance across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="neg_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_neg_var(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Computes a weighted lower semi-variance across a specified valuespace
        See: :meth:`~qubles.core.quble.Quble.aggregate
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="wtd_neg_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def percentile_level(
        self,
        aggr_keyspaces="<keyspaces>",
        percentile: float = 50.0,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        interpolate_flag: bool = True,
        percentile_keyspace: str = "Percentiles",
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag=True,
    ) -> Quble:
        """
        Returns a Quble providing the percentile value(s) across all keyspaces
        For percentile=50. this method returns the median value through the specified keyspace at each orthogonal key data

        If a single (scalar) percentile level arg is provided, will return a (n-1) Dimensional Quble containing the orthogonal keyspaces and associated keys

        If multiple percentiles are requested (e.g., percentile arg is a tuple or list of numeric scalars),
        yields a n-Dimensional Quble containing the (n-1) orthogonal keyspaces as well as a (newly introduced) percentile_keyspace)
        """
        if isinstance(percentile, (list, tuple)):
            return self.multi_percentile_level(
                aggr_keyspaces=aggr_keyspaces,
                percentile_keyspace=percentile_keyspace,
                ignore_missing=ignore_missing,
                pct_required=pct_required,
                num_required=num_required,
                valuespace=valuespace,
                view=view,
                key_ordering=key_ordering,
                percentiles=percentile,
                auto_squeeze=auto_squeeze,
                pre_cross_fill=pre_cross_fill,
                pre_fill=pre_fill,
                interpolate_flag=interpolate_flag,
                quble_flag=quble_flag,
            )
        else:
            return self.aggregate(
                aggr_keyspaces=aggr_keyspaces,
                aggr_method="percentile_level",
                ignore_missing=ignore_missing,
                pct_required=pct_required,
                num_required=num_required,
                valuespace=valuespace,
                view=view,
                key_ordering=key_ordering,
                percentile=percentile,
                auto_squeeze=auto_squeeze,
                pre_cross_fill=pre_cross_fill,
                pre_fill=pre_fill,
                interpolate_flag=interpolate_flag,
                quble_flag=quble_flag,
            )

    @RootLib.lazy_kwargs()
    def wtd_percentile_level(
        self,
        aggr_keyspaces="<keyspaces>",
        percentile: float = 50.0,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        interpolate_flag: bool = True,
        percentile_keyspace: str = "Percentiles",
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Returns a Quble providing the percentile value(s) across all keyspaces
        For percentile=50. this method returns the median value through the specified keyspace at each orthogonal key data

        If a single (scalar) percentile level arg is provided, will return a (n-1) Dimensional Quble containing the orthogonal keyspaces and associated keys

        If multiple percentiles are requested (e.g., percentile arg is a tuple or list of numeric scalars),
        yields a n-Dimensional Quble containing the (n-1) orthogonal keyspaces as well as a (newly introduced) percentile_keyspace)
        """
        if isinstance(percentile, (list, tuple)):
            return self.wtd_multi_percentile_level(
                aggr_keyspaces=aggr_keyspaces,
                # aggr_method="percentile_level",
                percentile_keyspace=percentile_keyspace,
                ignore_missing=ignore_missing,
                pct_required=pct_required,
                num_required=num_required,
                valuespace=valuespace,
                view=view,
                key_ordering=key_ordering,
                percentiles=percentile,
                auto_squeeze=auto_squeeze,
                pre_cross_fill=pre_cross_fill,
                pre_fill=pre_fill,
            )
        else:
            return self.aggregate(
                aggr_keyspaces=aggr_keyspaces,
                aggr_method="wtd_percentile_level",
                ignore_missing=ignore_missing,
                pct_required=pct_required,
                num_required=num_required,
                valuespace=valuespace,
                view=view,
                key_ordering=key_ordering,
                percentile=percentile,
                auto_squeeze=auto_squeeze,
                pre_cross_fill=pre_cross_fill,
                pre_fill=pre_fill,
            )

    # =============================================== SUB-AGGREGATION =================================================

    @RootLib.lazy_kwargs()
    def sub_aggregate1d(
        self,
        keymap: Quble,
        keyspace: str = "<first_keyspace>",
        tgt_keyspace: str = None,
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        # freq:str=RootLib.lazy_eval('freq'),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        percentile: float = 50.0,
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis=aggr_method,
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_first1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="first",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_last1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="last",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_count1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="count",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_sum1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="sum",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_prod1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="prod",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_mean1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="avg",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_avg1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="avg",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_average1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="avg",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_ave1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="avg",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_median1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="median",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_min1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys: bool = None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="min",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_max1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="max",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_stddev_samp1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="stddev_samp",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_stddev_pop1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="stddev_pop",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_stddev1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="stddev_pop",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_std1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="stddev_pop",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_var_samp1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="var_samp",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_var_pop1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="var_pop",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_var1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="var_pop",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_kurtosis1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="kurtosis",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            view=view,
            valuespace=valuespace,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_skew1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="skew",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_pos_std1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="pos_std",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_neg_std1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="neg_std",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_pos_var1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="pos_var",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def sub_neg_var1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        unmap_flag: bool = False,
    ) -> Quble:
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            map_type="aggregate",
            unmap_flag=unmap_flag,
            map_basis="neg_var",
            # aggr_method=aggr_method, # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    # ========================================================================================
    #                                       SUB-RANKING
    # ========================================================================================

    @RootLib.lazy_kwargs()
    def sub_rank1d(
        self,
        keymap: Quble,
        keyspace: str,
        ascending: bool = True,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
    ) -> Quble:
        """
        Applies "ranking" within each group
        as defined by the groupings from the primary valuespace
        of the keymap Quble provided
        Ranking is applied across the contents of specified valuespaces
        See: :meth:`~qubles.core.quble.Quble.remap1d`
        """
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            map_type="aggregate",
            map_basis="rank",
            aggr_method=aggr_method,  # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_methof for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
            rank_direction="asc" if ascending else "desc",
        )

    @RootLib.lazy_kwargs()
    def sub_uniform_rank1d(
        self,
        keymap: Quble,
        keyspace: str,
        ascending: bool = True,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        include_endpoints: bool = True,
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
    ) -> Quble:
        """
        Applies "uniform ranking" (0 to 1) within each group
        as defined by the groupings from the primary valuespace
        of the keymap Quble provided
        Ranking is applied across the contents of specified valuespaces
        See: :meth:`~qubles.core.quble.Quble.remap1d`
        """
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            map_type="aggregate",
            map_basis="uniform_rank",
            aggr_method=aggr_method,  # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_method for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
            rank_direction="asc" if ascending else "desc",
            include_endpoints=include_endpoints,
        )

    @RootLib.lazy_kwargs()
    def sub_biuniform_rank1d(
        self,
        keymap: Quble,
        keyspace: str,
        ascending: bool = True,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        include_endpoints: bool = True,
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
    ) -> Quble:
        """
        Applies "biuniform ranking" (-1 to +1) within each group
        as defined by the groupings from the primary valuespace
        of the keymap Quble provided
        Ranking is applied across the contents of specified valuespaces
        See: :meth:`~qubles.core.quble.Quble.remap1d`
        """
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            map_type="aggregate",
            map_basis="biuniform_rank",
            aggr_method=aggr_method,  # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_method for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
            rank_direction="asc" if ascending else "desc",
            include_endpoints=include_endpoints,
        )

    @RootLib.lazy_kwargs()
    def sub_pct_rank1d(
        self,
        keymap: Quble,
        keyspace: str,
        ascending: bool = True,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        include_endpoints: bool = True,
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
    ) -> Quble:
        """
        Applies "percentile ranking" (0 to 100) within each group
        as defined by the groupings from the primary valuespace
        of the keymap Quble provided
        Ranking is applied across the contents of specified valuespaces
        See: :meth:`~qubles.core.quble.Quble.remap1d`
        """
        return self.remap1d(
            keymap=keymap,
            keyspace=keyspace,
            map_type="aggregate",
            map_basis="pct_rank",
            aggr_method=aggr_method,  # <-- This would relate to other dimensions that will be aggregated away...by not providing arg, remap1d() will invoke the default aggr_method for ortho dimensions
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            ignore_missing=ignore_missing,
            valuespace=valuespace,
            view=view,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            force_tgt_keys=force_tgt_keys,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
            rank_direction="asc" if ascending else "desc",
            include_endpoints=include_endpoints,
        )

    # ========================================================================================
    #                       MOVING (ROLLING) TEMPORAL AGGREGATIONS
    # ========================================================================================

    @RootLib.lazy_kwargs()
    def maggregate1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_honor_nulls="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
        **kwargs,
    ) -> Quble:
        """
        Performs a moving aggregation over the trailing number of periods across the specified keyspace(s)
        The schema of the resultant table will match the original (self) table

        :param periods: number of trailing periods for aggregation (>0)
        :type periods: int (> 0) or CUME_WINDOW (for cumulative)

        :param keyspace: keyspace (dimension) to aggregate across
        :type keyspace: string

        :param aggr_method: moving aggregation method
        :type aggr_method: string

        :param ignore_missing: flag to control whether to ignore missing/null records for a window computation
        :type ignore_missing: boolean (True/False)

        :param pct_required: parameter to control minimal fraction of window for non-missing/non-null records
        :type pct_required: float (default: 0.0)

        :type valuespace: str or list/tuple of strings
        :param valuespace:
            The valuespace(s) for rolling aggregation
            [Any 'orthogonal' (extra) valuespaces will be retained, but not rolled
            but possibly filled forward at any newly introduced date records
            depending each ortho valuespace's tfill_max settings etc.]

            Following templated values supported via Quble.valuidate_valuespace() method...
            ``<valuespace>``: fill only the primary valuespace
            ``<all>``: fill all valuespaces
            ``<first>``: fill only the first valuespace
            ``<last>``: fill only the last valuespace
            ``<auxvalspaces>``: fill only the auxillary valuespaces

        :param view: Quble indicating conditional elements for which aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :param key_ordering: controls row ordering by key
        :type key_ordering: None, str or dictionary
           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace
           dictionary: dict keys (str): keyspaces, dict values (str): 'asc' or 'desc'
           ==> allows for assigning key ordering (ascending/descending)
           ==> (and relative priority) for each keyspace individually

        :param compress: flag for compressing resultant Quble
                        (so long as not original_dates_only and not contiguous_flag)
        :type compress: bool (True/False)

        :param original_dates_only:
            Controls whether restrict the result
            to only those dates originally present
        :type original_dates_only: bool (True/False*)

        :param contiguous_flag: controls whether contiguous dates (at prevailing freq) are required
        :type contiguous_flag: bool (True/False*)

        :param tfill_end_mode: Controls extension/limits beyond original dates (derived against rolled valuespaces)
        :type tfill_end_mode: string (None or 'unconstrained', 'no_future', 'in_progress', 'no_extension', 'full_extension')

        :type tfill_method: str
        :param tfill_method:
            For non-rolled (ortho) yet filled valuespaces...
            ==> Fill method against the new keyspace index.
            Can be None, 'pad' or 'backfill'.

        :type tfill_max: int
        :param tfill_max:
            For non-rolled (ortho) yet filled valuespaces...
            ==> Maximum number of consecutive value fill-ins
            Treat tfill_max > 0: finite filling
            Treat tfill_max < 0: Infinite tfill_max
            Treat tfill_max = None: NO filling
            Treat tfill_max = 0: NO filling

        :type tfill_honor_nulls: bool
        :param tfill_honor_nulls:
            For non-rolled (ortho) yet filled valuespaces...
            ==> Flag to honor any existing null values

        :param pre_cross_fill: flag to control whether to pre-cross-fill
                           when the keyspace for moving aggregation is a time keyspace
                           AND ortho_resampling_keyspaces also exist
        :type pre_cross_fill: boolean (True*/False)

        :param pre_fill: flag to control whether to pre-fill when the
                         keyspace for moving aggregation is a resampling keyspace
        :type pre_fill: boolean (True/False*)

        :param ks_is_freq_idx: flag to indicate that the specified keyspace column
                is a 'frequency index' (integer) at a specific time-frequency
        :type ks_is_freq_idx: boolean (True/False*)

        NOTE: ks_is_freq_idx feature is ONLY ALLOWED with original_dates_only analysis
        """
        if self.is_undefined:
            return Quble()
        elif self.is_empty:
            return self.copy()

        # Validate periods arg
        # ----------------------
        periods = self._validate_periods(periods)
        keyspaces = self.keyspaces

        # Validate keyspace
        # [May perform auto-linking]
        keyspace = self.validate_keyspace(
            keyspace,
            grace=False,
            solo_required=True,
            time_space_required=not ks_is_freq_idx,
        )

        # Make a shallow copy of self as subject
        # Only refer to subject (not self) afterwards
        # ---------------------------------------------
        subject = self

        # Validate valuespace
        if not subject.is_index:
            valuespaces_to_roll = subject.validate_valuespace(
                valuespace=valuespace, grace=False, coerce_to_list=True
            )
        elif valuespace not in (
            "<valuespace>",
            "<valuespaces>",
            "<numeric_valuespaces>",
        ):
            raise Exception(
                "Absent non-trivial valuespace:{0}...subject is an index-only (non-variate) Quble".format(
                    valuespace
                )
            )
        else:
            # Proceed to convert to bool
            subject = subject.index_to_bool()
            valuespaces_to_roll = [subject.valuespace]

        # Remove any null valuespaces
        if valuespaces_to_roll is not None:
            for i in range(len(valuespaces_to_roll)):
                if valuespaces_to_roll[i] is None:
                    valuespaces_to_roll.pop(i)

        # If no valuespaces to roll, simply return a copy
        if len(valuespaces_to_roll) == 0:
            return subject.copy()

        # NOTE: Apply pre_cross_fill BEFORE pre_fill
        if pre_cross_fill:
            subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)

        if pre_fill:
            subject = subject._apply_pre_fill(allow_shallow_copy=True)

        # Apply view to subject
        # -----------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)

        # If necessary, establish freq & ppy (periods per year)
        # for the specified temporal frequency
        # ------------------------------------------------------
        if aggr_method == "mave":
            aggr_method = "mmean"  # <-- Substitute mmean for mave

        if aggr_method in (
            "mgeo_mean_ann",
            "mgeo100_mean_ann",
            "mgeo_std_ann",
            "mgeo100_std_ann",
            "mgeo_ir",
            "mgeo100_ir",
        ):
            freq = subject.get_freq(keyspace, allow_infer=True, assign_inferred=True)

            if freq is None:
                raise Exception("Unable to establish existing freq")
            elif freq not in PPY:
                raise Exception(f"Invalid freq:{freq}")
            else:
                ppy = PPY[freq]
        else:
            ppy = None

        # If necessary, scale the percentile argument accordingly
        # ------------------------------------------------------
        # Here we have to assume that if we are supplied percentile = 1
        # We want the 100th percentile. There would be no way to determine unless an additional
        # Parameter was supplied giving the scale of our percentiles
        if kwargs.get("percentile") and kwargs.get("percentile") > 1:
            kwargs.update({"percentile": kwargs.get("percentile") / 100})

        # Map from aggr_method -> (extra_fn_args_type, extra_fn_args_default)
        # -------------------------------------------------------------------
        # extra_fn_args_type: dictionary w/keys: arg_name
        # extra_fn_args_default: dictionary w/keys: arg_name
        # NOTE: Can leave arg_name key out/absent from extra_fn_args_default
        #        ==> indicates that this arg_name is REQUIRED within kwargs
        # -------------------------------------------------------------------

        if aggr_method in (
            "mz",
            "mpos_var",
            "mneg_var",
            "mpos_std",
            "mneg_std",
        ):
            extra_args_config = (dict([("ddof", "integer")]), {"ddof": 0})
        # NOTE: excluding 'percentile' from defaults for aggr_method='mpercentile_level' indicating that 'percentile'
        # is required to be present in kwargs
        # Snowflake's RANK, PCT_RANK does not accept any additional arguments
        if aggr_method == "miqr":
            extra_args_config = (
                dict(
                    [
                        ("lower_percentile", "double"),
                        ("upper_percentile", "double"),
                        ("scale", "varchar(16)"),
                        ("interpolation", "varchar(16)"),
                    ]
                ),
                {
                    "lower_percentile": 25.0,
                    "upper_percentile": 75.0,
                    "scale": "raw",
                    "interpolation": "linear",
                },
            )
        elif aggr_method in ("mgeo_mean_ann", "mgeo100_mean_ann"):
            extra_args_config = (dict([("ppy", "double")]), {"ppy": ppy})
        elif aggr_method in ("mgeo_std_ann", "mgeo_ir", "mgeo100_ir"):
            extra_args_config = (
                dict([("ppy", "double"), ("ddof", "integer")]),
                {"ppy": ppy, "ddof": 0},
            )
        else:
            extra_args_config = None

        # Create the extra_fn_args list of assigned values (if applicable)
        extra_fn_args = []
        if extra_args_config is not None:
            (extra_fn_args_type, extra_fn_args_default) = extra_args_config
            for arg_name in extra_fn_args_type:
                if arg_name in kwargs:
                    argument = kwargs[arg_name]
                elif arg_name in extra_fn_args_default:
                    argument = extra_fn_args_default[arg_name]
                else:
                    raise Exception(
                        f"aggr_method:{aggr_method}...Absent required arg: {arg_name}"
                    )

                # Need to wrap string args in quotes to be handle property during JINJA2 rendering below
                if isinstance(argument, str):
                    extra_fn_args.append(f"'{argument}'")
                else:
                    extra_fn_args.append(argument)
        else:
            extra_fn_args_type = {}
            extra_fn_args_default = {}

        # --------------------------------
        # Establish tfill_end_mode_scalar
        # --------------------------------
        tfill_end_mode_scalar = None  # <-- Implemented as a scalar (not valuespace-specific for practical reasons)

        # =============== START: valuespaces_to_roll LOOP ===============
        for roll_vs in valuespaces_to_roll:
            if tfill_end_mode_scalar is None:
                # Evaluate tfill_end_mode_scalar until it is assigned a non-trivial value
                tfill_end_mode_scalar = subject._space_info_indirection(
                    info_type="tfill_end_mode",
                    space=roll_vs,
                    info_assignment=tfill_end_mode,
                    grace=True,
                )
        # ================ END: valuespaces_to_roll LOOP ================

        # ----------------------------------------------
        # Prep "ortho" (non-rolled) valuespaces
        # Ortho-valuespaces my incur time-filling at
        # new date records introduced by maggregate op
        # ----------------------------------------------
        # NOTE: filling info (e.g., tfill_method, etc.)
        # is sourced / associated with each non-rolled valuespace
        # (NOT the valuespaces being rolled)
        # ----------------------------------------------
        tfill_method_dict = {}
        tfill_max_dict = {}
        tfill_honor_nulls_dict = {}
        null_placeholder_dict = {}
        valuespace_col_types = {}

        # ================= START: ortho_valuespaces LOOP =================
        for ortho_vs in subject.ortho_valuespaces(valuespaces_to_roll):
            if ortho_vs is None:
                continue
            valuespace_col_types[ortho_vs] = subject.get_space_info(
                info_type="type", space=ortho_vs
            )

            # Update tfill_end_mode_scalar (if needed)
            if tfill_end_mode_scalar is None:
                # Evaluate tfill_end_mode_scalar until it is assigned a non-trivial value
                tfill_end_mode_scalar = subject._space_info_indirection(
                    info_type="tfill_end_mode",
                    space=ortho_vs,
                    info_assignment=tfill_end_mode,
                    grace=True,
                )

            # Update tfill_method_dict
            if not isinstance(tfill_method, dict):
                tfill_method_dict[ortho_vs] = subject._space_info_indirection(
                    info_type="tfill_method",
                    space=ortho_vs,
                    info_assignment=tfill_method,
                    grace=True,
                )
            elif ortho_vs in tfill_method:
                tfill_method_dict[ortho_vs] = tfill_method[ortho_vs]
            else:
                tfill_method_dict[ortho_vs] = subject._space_info_indirection(
                    info_type="tfill_method",
                    space=ortho_vs,
                    info_assignment="<space_root>",
                    grace=True,
                )

            # Update tfill_max_dict
            if not isinstance(tfill_max, dict):
                tfill_max_dict[ortho_vs] = subject._space_info_indirection(
                    info_type="tfill_max",
                    space=ortho_vs,
                    info_assignment=tfill_max,
                    grace=True,
                )
            elif ortho_vs in tfill_max:
                tfill_max_dict[ortho_vs] = tfill_max[ortho_vs]
            else:
                tfill_max_dict[ortho_vs] = subject._space_info_indirection(
                    info_type="tfill_max",
                    space=ortho_vs,
                    info_assignment="<space_root>",
                    grace=True,
                )

            # Update tfill_honor_nulls_dict
            if not isinstance(tfill_honor_nulls, dict):
                tfill_honor_nulls_dict[ortho_vs] = subject._space_info_indirection(
                    info_type="tfill_honor_nulls",
                    space=ortho_vs,
                    info_assignment=tfill_honor_nulls,
                    grace=True,
                )
            elif ortho_vs in tfill_honor_nulls:
                tfill_honor_nulls_dict[ortho_vs] = tfill_honor_nulls[ortho_vs]
            else:
                tfill_honor_nulls_dict[ortho_vs] = subject._space_info_indirection(
                    info_type="tfill_honor_nulls",
                    space=ortho_vs,
                    info_assignment="<space_root>",
                    grace=True,
                )

            if tfill_honor_nulls_dict[ortho_vs]:
                null_placeholder_dict[ortho_vs] = null_placeholder_as_str(
                    valuespace_col_types[ortho_vs]
                )
        # ================== END: ortho_valuespaces LOOP ==================

        # Validate tfill_end_mode_scalar
        # ---------------------------------
        if tfill_end_mode_scalar is None:
            tfill_end_mode_scalar = "no_future"
        elif tfill_end_mode_scalar not in (
            "no_future",
            "in_progress",
            "no_extension",
            "full_extension",
            "unconstrained",
        ):
            raise ValueError(f"Invalid tfill_end_mode: {tfill_end_mode_scalar}")

        # =============================================
        # Craft & Execute Moving Aggregation Query
        # =============================================

        table_name = generate_random_table_name()

        # Establish & validate existing freq
        if ks_is_freq_idx:
            # Not required / not applicable here
            freq = None
        else:
            freq = subject.get_freq(keyspace, allow_infer=True, assign_inferred=True)

        # Build key_ordering dictionary when applicable
        if key_ordering is not None and not isinstance(key_ordering, str):
            key_ordering = build_key_ordering_dict(
                key_ordering, keyspaces=subject.keyspaces
            )

        # Establish extension_periods based on periods & pct_required
        if periods == CUME_WINDOW:
            extension_periods = None
        elif pct_required is None or periods is None or periods < 0:
            extension_periods = periods
        else:
            # 0 <= extension_periods <= (periods-1)
            extension_periods = min(
                max(periods - int(np.ceil(pct_required * periods)), 0), (periods - 1)
            )

        # dictionary from moving aggregate to SQL aggregate
        window_func_dict = {
            "msum": "SUM",
            "mmean": "AVG",
            "mcount": "COUNT",  # <-- needs to honor ignore_missing=True/False?
            "mvar": "VAR_POP" if kwargs.get("ddof") == 0 else "VAR_SAMP",
            "mstd": "STDDEV_POP" if kwargs.get("ddof") == 0 else "STDDEV_SAMP",
            "mpos_std": None,
            "mneg_std": None,
            "mvar_pop": "VAR_POP",
            "mstd_pop": "STDDEV_POP",
            "mvar_samp": "VAR_SAMP",
            "mstd_samp": "STDDEV_SAMP",
            "mfirst": "FIRST_VALUE",
            "mlast": "LAST_VALUE",
            "mmin": "MIN",
            "mmax": "MAX",
            "mprod": "_PROD_",  # <-- REPLACE PROD(x) WITH EXP(SUM(LN((x)))
            "mmedian": "MEDIAN",
            "mskew": "SKEW",  # <-- SAMPLE SKEW
            "mkurtosis": "KURTOSIS",
            "mmode": "MODE",
            "mpos_var": None,
            "mneg_var": None,
            "mz": (
                "_ZSCORE_POP_" if kwargs.get("ddof") == 0 else "_ZSCORE_SAMP_"
            ),  # <-- REPLACE WITH ((x - AVG(x))/ STDDEV_POP(x))
            "mrank": "DENSE_RANK",  # <-- ranking_algo] = [DENSE_RANK(x) (default), RANK(x), ROW_NUMBER(x)
            "mpct_rank": "_PCT_RANK_",  # <-- REPLACE WITH] = [100.0*PERCENT_RANK(x)]
            "mptp": None,
            "mpercentile_level": "_PERCENTILE_LEVEL_",  # <-- REPLACE WITH: PERCENTILE_CONT(x, percentile_level/100.0)
            "miqr": "_IQR_",  # <-- REPLACE WITH: PERCENTILE_CONT(x, 0.75) - PERCENTILE_CONT(x, 0.25)
            "muniform_rank": "PERCENT_RANK",
            "mbiuniform_rank": "_BIUNIFORM_RANK_",  # <-- REPLACE WITH] = [(2.0*PERCENT_RANK(x) - 1.0)
            "mgeo_prod": "_GEO_PROD_",
            "mgeo100_prod": "_GEO100_PROD_",
            "mgeo_cume": "_GEO_CUME_",
            "mgeo100_cume": "_GEO100_CUME_",
            "mgeo_mean": "_GEO_MEAN_",
            "mgeo100_mean": "_GEO100_MEAN_",
            "mgeo_mean_ann": "_GEO_MEAN_ANN_",
            "mgeo100_mean_ann": "_GEO100_MEAN_ANN_",
            "mgeo_std_ann": (
                "_GEO_STD_POP_ANN_" if kwargs.get("ddof") == 0 else "_GEO_STD_SAMP_ANN_"
            ),
            "mgeo100_std_ann": (
                "_GEO100_STD_POP_ANN_"
                if kwargs.get("ddof") == 0
                else "_GEO100_STD_SAMP_ANN_"
            ),
            "mgeo_ir": "_GEO_IR_POP_" if kwargs.get("ddof") == 0 else "_GEO_IR_SAMP_",
            "mgeo100_ir": (
                "_GEO100_IR_POP_" if kwargs.get("ddof") == 0 else "_GEO100_IR_SAMP_"
            ),
            "wtd_mean": None,
            "wtd_median": None,
            "wtd_iqr": None,
            "wtd_average": None,
            "wtd_ave": None,
            "wtd_sum": None,
            "wtd_std": None,
            "wtd_stddev": None,
            "wtd_var": None,
            "wtd_skew": None,
            "wtd_kurtosis": None,
            "wtd_pos_std": None,
            "wtd_neg_std": None,
            "wtd_pos_var": None,
            "wtd_neg_var": None,
            "wtd_percentile_level": None,
        }
        sql_aggr_fn_name = window_func_dict.get(aggr_method, aggr_method)

        # Establish num_required
        # ----------------------
        if ignore_missing:
            # set num_required2 = pct_required * periods (and round up)
            if isinstance(periods, str):
                if periods.upper() != "UNBOUNDED":
                    raise Exception(f"Invalid periods:{periods}")
                num_required2 = None
            else:
                num_required2 = (
                    np.ceil((pct_required * periods) - 0.000001)
                    if pct_required is not None
                    else None
                )

            # Combine num_required2 into num_required
            if num_required is None:
                num_required = 0 if num_required2 is None else num_required2
            elif num_required2 is None:
                # Honor existing num_required
                pass
            else:
                # Here, num_required is not None and num_required2 is not None
                # so we take the larger if these two values
                num_required = max(num_required, num_required2)

        elif isinstance(periods, str):
            if periods.upper() != "UNBOUNDED":
                raise Exception(f"Invalid periods:{periods}")
        elif periods is None:
            raise Exception(f"Invalid periods:{periods}")
        else:
            # When ignore_missing==False, set num_required to periods
            num_required = periods

        # Two approaches for cume_aggregate
        if (
            periods == CUME_WINDOW or periods < 0
        ) and aggr_method in UNSUPPORTED_SNOWFLAKE_FUNCS_CUME:
            if aggr_method in ("mpct_rank", "muniform_rank", "mbiuniform_rank"):
                raise Exception(
                    f"{aggr_method} currently unsupported by Snowflake for cumulative calculations."
                )
            sql_template = JINJA_ENV.get_template("cume_aggregate_non_window.j2")
            sql_command = sql_template.render(
                keyspace=keyspace,
                sql_aggr_fn_name=sql_aggr_fn_name,
                ignore_missing=ignore_missing,
                num_required=num_required,
                ppy=ppy,
                keyspaces=keyspaces,
                src_table_name=subject.table_name,
                tgt_table_name=table_name,
                calendar_table_name=RootLib().get_control("calendar_table_name"),
                valuespaces=subject.valuespaces,
                valuespaces_to_roll=valuespaces_to_roll,
                key_ordering=key_ordering,
                extra_fn_args=extra_fn_args,
                percentile=kwargs.get("percentile"),
                freq=freq,
                ks_is_freq_idx=ks_is_freq_idx,
            )
        elif (
            periods == CUME_WINDOW or periods < 0
        ) and aggr_method not in UNSUPPORTED_SNOWFLAKE_FUNCS_CUME:
            sql_template = JINJA_ENV.get_template("cume_aggregate_window.j2")
            sql_command = sql_template.render(
                keyspace=keyspace,
                sql_aggr_fn_name=sql_aggr_fn_name,
                ignore_missing=ignore_missing,
                num_required=num_required,
                ppy=ppy,
                keyspaces=keyspaces,
                src_table_name=subject.table_name,
                tgt_table_name=table_name,
                # calendar_table_name=RootLib().get_control("calendar_table_name"),
                valuespaces=subject.valuespaces,
                valuespaces_to_roll=valuespaces_to_roll,
                key_ordering=key_ordering,
                extra_fn_args=extra_fn_args,
                percentile=kwargs.get("percentile"),
                freq=freq,
                # ks_is_freq_idx=ks_is_freq_idx,
            )
        else:
            # ks_is_freq_idx feature is ONLY ALLOWED with original_dates_only analysis
            if ks_is_freq_idx and not original_dates_only:
                raise Exception(
                    f"ks_is_freq_idx==True flag can only be use when original_dates_only==True"
                )

            sql_template = JINJA_ENV.get_template("maggregate.j2")
            sql_command = sql_template.render(
                keyspace=keyspace,
                freq=freq,
                sql_aggr_fn_name=sql_aggr_fn_name,
                window=periods,
                extension_periods=extension_periods,
                ignore_missing=ignore_missing,
                num_required=num_required,
                ppy=ppy,
                keyspaces=keyspaces,
                src_table_name=subject.table_name,
                tgt_table_name=table_name,
                valuespaces=subject.valuespaces,
                valuespaces_to_roll=valuespaces_to_roll,
                tfill_method_dict=tfill_method_dict,  # <-- For non-rolled, yet filled ortho_valuespaces
                tfill_max_dict=tfill_max_dict,  # <-- For non-rolled, yet filled ortho_valuespaces
                null_placeholder_dict=null_placeholder_dict,  # <-- For non-rolled, yet filled ortho_valuespaces
                calendar_table_name=RootLib().get_control("calendar_table_name"),
                key_ordering=key_ordering,
                extra_fn_args=extra_fn_args,
                original_dates_only=original_dates_only,
                contiguous_flag=contiguous_flag,
                fill_end_mode=tfill_end_mode_scalar,
                compress=compress,
                percentile=kwargs.get("percentile"),
                ks_is_freq_idx=ks_is_freq_idx,
            )

        # NOTE tgt_keyspaces may be need for ordering of keys (if requested)
        # NOTE: Need to divide percentile by 100.0 when rendering SQL command
        #       due to convention differences between Quble implementation
        execute(sql_command)

        # Establish col_info & table_info for copy
        if table_name == subject.table_name:
            col_info = None
        else:
            if aggr_method in ("count",):
                info_types_to_copy = [
                    it1 for it1 in CUSTOM_INFO_TYPES if it1 not in ["fx", "time_basis"]
                ]
            elif periods == CUME_WINDOW:
                info_types_to_copy = [
                    it1 for it1 in CUSTOM_INFO_TYPES if it1 not in ["time_basis"]
                ]
            else:
                info_types_to_copy = CUSTOM_INFO_TYPES

            col_info = subject.get_space_info(
                info_type=info_types_to_copy,
                space="<all>",
                omit_unassigned=True,
            )
            # Assign col_info['tfill_max'][vs]=0
            if (
                col_info is not None
                and "tfill_max" in col_info
                and col_info["tfill_max"] is not None
            ):
                # For Non-Infinite Filled Valuespaces, set tfill_max to zero
                # [To prevent multiple extensions that violate the original filling criterion]
                #
                # ==> Open question: Should we maintain the original
                #     tfill_max != 0 for rolled valuespaces?..Currently we do
                for vs in subject.valuespaces:
                    # Is this a non-rolled, but (finitely) filled valuespace?
                    if (
                        vs in col_info["tfill_max"]
                        and col_info["tfill_max"][vs] is not None
                        and col_info["tfill_max"][vs] > 0
                    ):
                        # Here, we set 'tfill_max'=0 for finite filling vs in (target) table to prevent additional filling later
                        col_info["tfill_max"][vs] = 0

        # Finally, build new Quble using new table_name
        result = Quble.from_table(
            table_name=table_name,
            col_info=col_info,
        )

        # TODO: Add code here to promote result's primary valuespace in accordance with the original primary valuespace (when possible)

        # TODO: Ensure implementation result RETAINS ALL ORIGINAL VALUESPACES, yet only applies the maggregate operation
        # those valuespace(s) indicated within the valuespace arg of this method

        return result

    @RootLib.lazy_kwargs()
    def mcount1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) non-missing sample count across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mcount",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def msum1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) sum across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="msum",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mprod1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) product across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mprod",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mmean1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) average across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mmean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mave1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) average across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mmean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mmedian1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) median across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mmedian",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mmax1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) maximum across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mmax",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mmin1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) median across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mmin",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mvar1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) variance across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]

        :param ddof: delta degrees of freedom (default:0)
                     ddof=0: 'population' variance
                     ddof=1: 'sample' variance
        :type ddof: int

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mvar",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mstd1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) standard deviation across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]

        :param ddof: delta degrees of freedom (default:0)
                     ddof=0: 'population' standard deviation
                     ddof=1: 'sample' standard deviation
        :type ddof: int

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mstd",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mz1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) z-score [(value - mean)/std] of the current value
        in reference to the samples across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]

        :param ddof: delta degrees of freedom (default:0)
                     ddof=0: 'population' standard deviation
                     ddof=1: 'sample' standard deviation
        :type ddof: int

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mz",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mfirst1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Yields the first value within a trailing temporal window along the specified time keyspace
        If ignore_missing=True, will yield the first non-missing (non-null) value within the trailing window.
        [window is specified in number of periods at associated temporal frequency]

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mfirst",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mlast1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Yields the last value within a trailing temporal window along the specified time keyspace
        If ignore_missing=True, will yield the last non-missing (non-null) value within the trailing window.
        [window is specified in number of periods at associated temporal frequency]

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mlast",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mpos_var1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) positive semi-variance across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]

        :param ddof: delta degrees of freedom (default:0)
                     ddof=0: 'population' variance
                     ddof=1: 'sample' variance
        :type ddof: int

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mpos_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mneg_var1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) negative semi-variance across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]

        :param ddof: delta degrees of freedom (default:0)
                     ddof=0: 'population' variance
                     ddof=1: 'sample' variance
        :type ddof: int

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mneg_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mpos_std1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) positive semi-standard deviation across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]

        :param ddof: delta degrees of freedom (default:0)
                     ddof=0: 'population' standard deviation
                     ddof=1: 'sample' standard deviation
        :type ddof: int

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mpos_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mneg_std1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) negative semi-standard deviation
        across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]

        :param ddof: delta degrees of freedom (default:0)
                     ddof=0: 'population' standard deviation
                     ddof=1: 'sample' standard deviation
        :type ddof: int

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mneg_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mskew1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        bias: bool = True,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) skewness across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]
        For normally distributed data, the skewness should be about 0.
        A skewness value > 0 means that there is more weight in the left tail of the distribution.

        :param bias: bias control
                     bias=True (default): no bias correction applied
                     bias=False: calculations are corrected for statistical bias
        :type bias: bool

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mskew",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            bias=bias,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mkurtosis1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        fisher: bool = True,
        bias: bool = True,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) kurtosis across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]
        Kurtosis is the fourth central moment divided by the square of the variance.

        :param fisher: control for use of fisher's definition of kurtosis
                       fisher=True (default): uses Fisher's definition (3.0 is subtracted from the result to give 0.0 for a normal distribution)
                       fisher=False: do not use Fisher's definition of skewness
        :type fisher: bool

        :param bias: bias control
                     bias=True (default): no bias corection applied
                     bias=False: calculations are corrected for statistical bias
        :type bias: bool

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mkurtosis",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            fisher=fisher,
            bias=bias,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mpercentile_level1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        percentile: float = 50.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) percentile level [0,100] for the samples within a temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]

        :param percentile: The desired percentile level
        :type percentile: float

        See :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mpercentile_level",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            percentile=percentile,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mrank1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        method: str = "average",
        ascending: bool = True,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) rank [1,n] of the current value in relation to the samples
        within a temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]

        :param method: The method used to assign ranks to tied elements.
        method='average' (default): The average of the ranks that would have been assigned to all the tied values is assigned to each value.
        method='min': The minimum of the ranks that would have been assigned to all the tied values is assigned to each value.(also referred to as "competition" ranking.)
        method='max': The maximum of the ranks that would have been assigned to all the tied values is assigned to each value.
        method='dense': Like 'min', but the rank of the next highest element is assigned the rank immediately after those assigned to the tied elements.
        method='ordinal': All values are given a distinct rank, corresponding to the order that the values occur in a.
        :type method: (string) The options are 'average', 'min', 'max', 'dense' and 'ordinal'

        :param ascending: Controls direction of sorting / ranking
        :type ascending: (boolean) True (default) / False

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mrank",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            method=method,
            ascending=ascending,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def muniform_rank1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        method: str = "average",
        ascending: bool = True,
        include_endpoints: bool = True,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) "uniform rank" [0,1] of the current value in relation to the samples
        within a temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]

        :param method: The method used to assign ranks to tied elements.
        method='average' (default): The average of the ranks that would have been assigned to all the tied values is assigned to each value.
        method='min': The minimum of the ranks that would have been assigned to all the tied values is assigned to each value.(also referred to as "competition" ranking.)
        method='max': The maximum of the ranks that would have been assigned to all the tied values is assigned to each value.
        method='dense': Like 'min', but the rank of the next highest element is assigned the rank immediately after thos assigned to the tied elements.
        method='ordinal': All values are given a distinct rank, corresponding to the order that the values occur in a.
        :type method: (string) The options are 'average', 'min', 'max', 'dense' and 'ordinal'

        :param ascending: Controls direction of sorting / ranking
        :type ascending: (boolean) True (default) / False

        :param include_endpoints: Controls whether to include 0 and 100 percentile ranks in result
                                 (otherwise, min percent rank=100/(n+1), max percent rank=(100 - (100/n+1))
        :type include_endpoints: (boolean) True (default) / False

        See: :meth:`~qubles.core.quble.Quble.maggregate1d` and `~scipy.stats.rankdata' for more information
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="muniform_rank",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            method=method,
            ascending=ascending,
            include_endpoints=include_endpoints,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mbiuniform_rank1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        method: str = "average",
        ascending: bool = True,
        include_endpoints: bool = True,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) "bi-uniform rank" [-1,+1] of the current value in relation to the samples
        within a temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]

        :param method: The method used to assign ranks to tied elements.
        method='average' (default): The average of the ranks that would have been assigned to all the tied values is assigned to each value.
        method='min': The minimum of the ranks that would have been assigned to all the tied values is assigned to each value. (also referred to as "competition" ranking.)
        method='max': The maximum of the ranks that would have been assigned to all the tied values is assigned to each value.
        method='dense': Like 'min', but the rank of the next highest element is assigned the rank immediately after thos assigned to the tied elements.
        method='ordinal': All values are given a distinct rank, corresponding to the order that the values occur in a.
        :type method: (string) The options are 'average', 'min', 'max', 'dense' and 'ordinal'

        :param ascending: Controls direction of sorting / ranking
        :type ascending: (boolean) True (default) / False

        :param include_endpoints: Controls whether to include 0 and 100 percentile ranks in result
                                 (otherwise, min percent rank=100/(n+1), max percent rank=(100 - (100/n+1))
        :type include_endpoints: (boolean) True (default) / False

        See: :meth:`~qubles.core.quble.Quble.maggregate1d` and `~scipy.stats.rankdata' for more information
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mbiuniform_rank",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            method=method,
            ascending=ascending,
            include_endpoints=include_endpoints,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mpct_rank1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        method: str = "average",
        ascending: bool = True,
        include_endpoints: bool = True,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) "percent rank" [0,100] of the current value in relation to the samples
        within a temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]

        :param method: The method used to assign ranks to tied elements.
        method='average' (default): The average of the ranks that would have been assigned to all the tied values is assigned to each value.
        method='min': The minimum of the ranks that would have been assigned to all the tied values is assigned to each value.(also referred to as "competition" ranking.)
        method='max': The maximum of the ranks that would have been assigned to all the tied values is assigned to each value.
        method='dense': Like 'min', but the rank of the next highest element is assigned the rank immediately after thos assigned to the tied elements.
        method='ordinal': All values are given a distinct rank, corresponding to the order that the values occur in a.
        :type method: (string) The options are 'average', 'min', 'max', 'dense' and 'ordinal'

        :param ascending: Controls direction of sorting / ranking
        :type ascending: (boolean) True (default) / False

        :param include_endpoints: Controls whether to include 0 and 100 percentile ranks in result
                                 (otherwise, min percent rank=100/(n+1), max percent rank=(100 - (100/n+1))
        :type include_endpoints: (boolean) True (default) / False

        See: :meth:`~qubles.core.quble.Quble.maggregate1d` and `~scipy.stats.rankdata' for more information
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mpct_rank",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            method=method,
            ascending=ascending,
            include_endpoints=include_endpoints,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mptp1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) peak-to-peak (ptp) [max-min] across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]

        See: :meth:`~qubles.core.quble.Quble.maggregate1d` and `~numpy.ptp` for more information
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mptp",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mrange1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) peak-to-peak (ptp) [max-min] across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]

        See: :meth:`~qubles.core.quble.Quble.maggregate1d` and `~numpy.ptp` for more information
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mptp",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def miqr1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        lower_percentile: float = 25.0,
        upper_percentile: float = 75.0,
        scale: float = 1.0,
        interpolation="linear",
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) inter-quartile range (iqr) across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]

        :param lower_percentile: lower end of range specified as a percentile (default=25.0)
        :type lower_percentile: float

        :param upper_percentile: upper end of range specified as a percentile (default=75.0)
        :type upper_percentile: float

        :param scale: scaling factor...the numerical value of scale will be divided out of the final result
                      The following strings values are recognized:

                    scale='1' (default): No scaling, just return the raw IQR
                    scale='normal': Scale by 22-sqrt(erf)-1(12) approximately 1.349

        :param interpolation: interpolation method to use when the percentile boundaries lie between two data points i and j
        interpolation='linear' (default): i + (j - i) * fraction, where fraction is the fractional part of the index surrounded by i and j.
        interpolation='lower': i
        interpolation='higher':j
        interpolation='nearest': i or j whichever is nearest
        interpolation='midpoint': (i+j)/2
        type interpolation: string ('linear', 'lower', 'higher', 'midpoint', 'nearest')

        See: :meth:`~qubles.core.quble.Quble.maggregate1d` and `~scipy.stats.iqr` for more information
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="miqr",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            lower_percentile=lower_percentile,
            upper_percentile=upper_percentile,
            scale=scale,
            interpolation=interpolation,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mgeo_prod1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        geo100_flag: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) 'geometric product'
           ==> geo100_flag == False: prod(x + 1)
           ==> geo100_flag == True: 100.0*prod((0.01*x) + 1)
        across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mgeo_prod" if not geo100_flag else "mgeo100_prod",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mgeo100_prod1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) 'geometric100 product' = 100.0 * prod((0.01*x) + 1)
        across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mgeo100_prod",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mgeo_cume1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        geo100_flag: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) 'geometric cume'
           ==> geo100_flag==False: [prod(x + 1) - 1]
           ==> geo100_flag==True: [100.0*(prod((0.01*x) + 1) - 1)]
        across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mgeo_cume" if not geo100_flag else "mgeo100_cume",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mgeo100_cume1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) 'geometric100 cume'=[100*(prod((0.01*x) + 1) - 1)]
        across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mgeo100_cume",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mgeo_mean1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        geo100_flag: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) 'geometric mean'
           ==>geo100_flag==False: [prod(x + 1)**(1/n) - 1]
           ==>geo100_flag==True: [100.0 * (prod((0.01*x) + 1)**(1/n) - 1)]
        across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mgeo_mean" if not geo100_flag else "mgeo100_mean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mgeo100_mean1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) 'geometric100 mean' [100.0 * (prod((0.01*x) + 1)**(1/n) - 1)]
        across a trailing temporal window along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mgeo100_mean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mgeo_mean_ann1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        geo100_flag: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) 'geometric annualized mean'
           ==> geo100_flag==False: [prod(x + 1)**(ppy/n) - 1]
           ==> geo100_flag==True: [100*(prod((0.01*x) + 1)**(ppy/n) - 1)]
        across a trailing temporal window along the specified time keyspace at the associated frequency
        [window is specified in number of periods at associated temporal frequency]
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mgeo_mean_ann" if not geo100_flag else "mgeo100_mean_ann",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mgeo100_mean_ann1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) 'geometric100 annualized mean'=[100*(prod((0.01*x) + 1)**(ppy/n) - 1)]
        across a trailing temporal window along the specified time keyspace at the associated frequency
        [window is specified in number of periods at associated temporal frequency]
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mgeo_mean_ann",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mgeo_std_ann1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        ppy: float = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) 'geometric annualized standard deviation'=[std(x) * sqrt(ppy)]
        across a trailing temporal window along the specified time keyspace at the associated frequency
        [window is specified in number of periods at associated temporal frequency]
        NOTE: This calculation is independent of geo100_flag
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mgeo_std_ann",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ppy=ppy,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mgeo_ir1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ppy: float = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        geo100_flag: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) 'geometric information ratio' (IR)
           ==> geo100_flag==False: [geo_mean_ann / geo_std_ann] = [prod(x + 1)**(ppy/n) - 1] / [std(x) * sqrt(ppy)]
           ==> geo100_flag==True: [geo100_mean_ann / geo_std_ann] = [100*(prod((0.01*x) + 1)**(ppy/n) - 1)] / [std(x) * sqrt(ppy)]
        across a trailing temporal window along the specified time keyspace at the associated frequency
        [window is specified in number of periods at associated temporal frequency]
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mgeo_ir" if not geo100_flag else "mgeo100_ir",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ppy=ppy,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mgeo100_ir1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ppy: float = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) 'geometric100 information ratio' (IR)
        = [geo_mean_ann / geo_std_ann] = [100.0*(prod((0.01*x) + 1)**(ppy/n) - 1)] / [std(x) * sqrt(ppy)]
        across a trailing temporal window along the specified time keyspace at the associated frequency
        [window is specified in number of periods at associated temporal frequency]
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            aggr_method="mgeo100_ir",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ppy=ppy,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def mdiff1d(
        self,
        periods: int,
        keyspace="<first_time_keyspace>",
        valuespace="<numeric_valuespaces>",
        ignore_add=False,
        view=RootLib.lazy_eval("view"),
        original_dates_only: bool = True,
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Performs a moving difference over the trailing number of periods across the specified keyspace(s)

        :param periods: number of trailing periods for differencing (>0)
        :type periods: int (> 0)

        :param keyspace: keyspace (dimension) to perform difference across
        :type keyspace: string

        :param ignore_add: control for treatment of missing/null values in difference operation
        :type ignore_add: boolean

        :param view: Quble indicating conditional elements for which
                     aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :param original_dates_only: flag to inmpose original dates
        :type original_dates_only: boolean (True*/False)
        """
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_empty:
            return self.copy()

        # Validate periods arg
        # ----------------------
        periods = self._validate_periods(periods)

        keyspace = self.validate_keyspace(
            keyspace, grace=False, solo_required=True
        )  # <-- May perform auto-linking

        if not self.is_time_space(space=keyspace):
            raise Exception(f"Non time-index keyspace:{keyspace}")

        # Validate valuespace arg
        valuespace = self.validate_valuespace(
            valuespace, grace=False, coerce_to_list=True, numeric_required=True
        )

        # Restrict Quble to only the valuespace(s) of interest
        # [valuespace arg is validated within sub_variate method]
        # (allow for shallow copy when valuespaces are unchanged)
        # ==> Only refer to subject (not self) hereafter
        # ------------------------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # NOTE: Apply pre_cross_fill BEFORE pre_fill
        if pre_cross_fill:
            subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)

        if pre_fill:
            subject = subject._apply_pre_fill(allow_shallow_copy=True)

        # Apply view to subject
        # -----------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)

        # Perform moving difference
        # inside a ControlContextManager
        # w/specified ignore_add & variate_mode settings
        controls = {"ignore_add": ignore_add}
        if subject.is_multivariate:
            controls["variate_mode"] = "multi"

        with ControlContextManager(controls=controls) as ccm:
            # Here, we impose tfill_end_mode='no_extension' when original_dates_only
            shifted = subject.shift1d(
                periods=periods,
                keyspace=keyspace,
                original_dates_only=original_dates_only,
                tfill_end_mode="no_extension" if original_dates_only else "no_future",
            )
            result = subject - shifted

        return result

    @RootLib.lazy_kwargs()
    def mratio1d(
        self,
        periods: int,
        keyspace="<first_time_keyspace>",
        valuespace="<numeric_valuespaces>",
        ignore_mult=False,
        view=RootLib.lazy_eval("view"),
        original_dates_only: bool = True,
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Performs a moving ratio
        over the trailing number of periods
        across the specified keyspace(s)

        :param periods: number of trailing periods for ratio (>0)
        :type periods: int (> 0)

        :param keyspace: keyspace (dimension) to perform ratio across
        :type keyspace: string

        :param ignore_mult: control for treatment of missing/null values in ratio operation
        :type ignore_mult: boolean

        :param view: Quble indicating conditional elements for which
                     aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :param original_dates_only: flag to inmpose original dates
        :type original_dates_only: boolean (True*/False)
        """
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_empty:
            return self.copy()

        # Validate periods arg
        # ----------------------
        periods = self._validate_periods(periods)

        keyspace = self.validate_keyspace(
            keyspace, grace=False, solo_required=True
        )  # <-- May perform auto-linking

        if not self.is_time_space(space=keyspace):
            raise Exception(f"Non time-index keyspace:{keyspace}")

        # Validate valuespace arg
        valuespace = self.validate_valuespace(
            valuespace, grace=False, coerce_to_list=True, numeric_required=True
        )

        # Restrict Quble to only the valuespace(s) of interest
        # [valuespace arg is validated within sub_variate method]
        # (allow for shallow copy when valuespaces are unchanged)
        # ==> Only refer to subject (not self) hereafter
        # ------------------------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # NOTE: Apply pre_cross_fill BEFORE pre_fill
        if pre_cross_fill:
            subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)

        if pre_fill:
            subject = subject._apply_pre_fill(allow_shallow_copy=True)

        # Apply view to subject
        # -----------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)

        # Perform moving ratio
        # inside a ControlContextManager
        # w/specified ignore_mult & variate_mode settings
        controls = {"ignore_mult": ignore_mult}
        if subject.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            result = subject / subject.shift1d(
                periods=periods,
                keyspace=keyspace,
                original_dates_only=original_dates_only,
            )

        return result

    @RootLib.lazy_kwargs()
    def mpctchg1d(
        self,
        periods: int,
        keyspace="<first_time_keyspace>",
        valuespace="<numeric_valuespaces>",
        ignore_mult=False,
        ignore_add=False,
        view=RootLib.lazy_eval("view"),
        original_dates_only: bool = True,
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Performs a moving percent change
        over the trailing number of periods
        across the specified keyspace(s)

        :param periods: number of trailing periods for ratio (>0)
        :type periods: int (> 0)

        :param keyspace: keyspace (dimension) to perform ratio across
        :type keyspace: string

        :param ignore_mult: control for treatment of missing/null values in pctchg operation
        :type ignore_mult: boolean

        :param ignore_add: control for treatment of missing/null values in pctchg operation
        :type ignore_add: boolean

        :param view: Quble indicating conditional elements for which
                     aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :param original_dates_only: flag to inmpose original dates
        :type original_dates_only: boolean (True*/False)
        """
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_empty:
            return self.copy()

        # Validate periods arg
        # ----------------------
        periods = self._validate_periods(periods)

        keyspace = self.validate_keyspace(
            keyspace, grace=False, solo_required=True
        )  # <-- May perform auto-linking

        if not self.is_time_space(space=keyspace):
            raise Exception(f"Non time-index keyspace:{keyspace}")

        # Validate valuespace arg
        valuespace = self.validate_valuespace(
            valuespace, grace=False, coerce_to_list=True, numeric_required=True
        )

        # Restrict Quble to only the valuespace(s) of interest
        # [valuespace arg is validated within sub_variate method]
        # (allow for shallow copy when valuespaces are unchanged)
        # ==> Only refer to subject (not self) hereafter
        # ------------------------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # NOTE: Apply pre_cross_fill BEFORE pre_fill
        if pre_cross_fill:
            subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)

        if pre_fill:
            subject = subject._apply_pre_fill(allow_shallow_copy=True)

        # Apply view to subject
        # -----------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)

        # Perform moving ratio
        # inside a ControlContextManager
        # w/specified ignore_mult & variate_mode settings
        controls = {"ignore_mult": ignore_mult, "ignore_add": ignore_add}
        if subject.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            result = (
                subject
                / subject.shift1d(
                    periods=periods,
                    keyspace=keyspace,
                    original_dates_only=original_dates_only,
                )
            ) - 1.0

        return result

    # ========================================================================================
    #                          CUMULATIVE TEMPORAL AGGREGATIONS
    # ========================================================================================

    @RootLib.lazy_kwargs()
    def cume_aggregate1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        valuespace="<valuespace>",
        pct_required: float = 0.0,
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
        **kwargs,
    ) -> Quble:
        """
        Performs a cumulative aggregation across the specified keyspace(s)
        The schema of the resultant table will match the original (self) table

        :param keyspace: keyspace (dimension) to cumulatively aggregate across
        :type keyspace: string

        :param key_ordering: (optional) Indicates whether/how to order result records within the keyspaces (index columns)
        :type key_ordering: None (no ordering of results records), 'asc' or 'desc'

        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method=f"m{aggr_method}",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
            **kwargs,
        )

    @RootLib.lazy_kwargs()
    def cume_count1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Cumulative non-missing sample count along the specified time keyspace
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mcount",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_sum1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Cumulative sum along the specified time keyspace
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="msum",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_prod1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Cumulative product along the specified time keyspace
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mprod",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_mean1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Cumulative average across a trailing temporal window along the specified time keyspace
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mmean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_ave1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ):
        """
        Cumulative average across a trailing temporal window along the specified time keyspace
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mmean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_median1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Cumulative median across a trailing temporal window along the specified time keyspace
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mmedian",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_max1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Cumulative minimum across a trailing temporal window along the specified time keyspace
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mmax",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_min1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Cumulative minimum across a trailing temporal window along the specified time keyspace
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mmin",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_var1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Cumulative variance along the specified time keyspace

        :param ddof: delta degrees of freedom (default:0)
                     ddof=0: 'population' variance
                     ddof=1: 'sample' variance
        :type ddof: int

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mvar",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_std1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Cumulative standard deviation along the specified time keyspace

        :param ddof: delta degrees of freedom (default:0)
                     ddof=0: 'population' standard deviation
                     ddof=1: 'sample' standard deviation
        :type ddof: int

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mstd",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_z1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Cumulative z-score [(value - mean)/std] in reference to the samples
        within a cumulative / growing window along the specified time keyspace

        :param ddof: delta degrees of freedom (default:0)
                     ddof=0: 'population' standard deviation
                     ddof=1: 'sample' standard deviation
        :type ddof: int

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mz",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_first1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Yields the first value within a growing/cumulative window along the specified time keyspace
        If ignore_missing=True, will yield the first non-missing (non-null) value within the trailing window.

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mfirst",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_last1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Yields the first value within a growing/cumulative window along the specified time keyspace
        If ignore_missing=True, will yield the first non-missing (non-null) value within the trailing window.

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mlast",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_pos_var1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) positive semi-variance across a trailing temporal window along the specified time keyspace

        :param ddof: delta degrees of freedom (default:0)
                     ddof=0: 'population' variance
                     ddof=1: 'sample' variance
        :type ddof: int

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mpos_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_neg_var1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) negative semi-variance across a trailing temporal window along the specified time keyspace

        :param ddof: delta degrees of freedom (default:0)
                     ddof=0: 'population' variance
                     ddof=1: 'sample' variance
        :type ddof: int

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mneg_var",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_pos_std1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) positive semi-standard deviation across a trailing temporal window along the specified time keyspace

        :param ddof: delta degrees of freedom (default:0)
                     ddof=0: 'population' standard deviation
                     ddof=1: 'sample' standard deviation
        :type ddof: int

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mpos_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_neg_std1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Moving (rolling) negative semi-standard deviation across a trailing temporal window along the specified time keyspace

        :param ddof: delta degrees of freedom (default:0)
                     ddof=0: 'population' standard deviation
                     ddof=1: 'sample' standard deviation
        :type ddof: int

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mneg_std",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    def cume_skew1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        bias: bool = True,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Cumulative skewness across a trailing temporal window along the specified time keyspace
        For normally distributed data, the skewness should be about 0.
        A skewness value > 0 means that there is more weight in the left tail of the distribution.

        :param bias: bias control
                     bias=True (default): no bias corection applied
                     bias=False: calculations are corrected for statistical bias
        :type bias: bool

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mskew",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            bias=bias,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    def cume_kurtosis1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        fisher: bool = True,
        bias: bool = True,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Cumulative kurtosis across a trailing temporal window along the specified time keyspace
        Kurtosis is the fourth central moment divided by the square of the variance.

        :param fisher: control for use of fisher's definition of kurtosis
                       fisher=True (default): uses Fisher's definition (3.0 is subtracted from the result to give 0.0 for a normal distribution)
                       fisher=False: do not use Fisher's definition of skewness
        :type fisher: bool

        :param bias: bias control
                     bias=True (default): no bias corection applied
                     bias=False: calculations are corrected for statistical bias
        :type bias: bool

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mkurtosis",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            fisher=fisher,
            bias=bias,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    def cume_percentile_level1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        percentile=50.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Percentile level [0,100] for the samples along a growing / cumulative temporal window along the specified time keyspace

        :param percentile: The desired percentile level
        :type percentile: percentile

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mpercentile_level",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            percentile=percentile,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_rank1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        method: str = "average",
        ascending: bool = True,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Rank [1,n] of the current value in relation to the samples
        within a growing / cumulative window along the specified time keyspace

        :param method: The method used to assign ranks to tied elements.
        method='average' (default): The average of the ranks that would have been assigned to all the tied values is assigned to each value.
        method='min': The minimum of the ranks that would have been assigned to all the tied values is assigned to each value.(also referred to as "competition" ranking.)
        method='max': The maximum of the ranks that would have been assigned to all the tied values is assigned to each value.
        method='dense': Like 'min', but the rank of the next highest element is assigned the rank immediately after thos assigned to the tied elements.
        method='ordinal': All values are given a distinct rank, corresponding to the order that the values occur in a.
        :type method: (string) The options are 'average', 'min', 'max', 'dense' and 'ordinal'

        :param ascending: Controls direction of sorting / ranking
        :type ascending: (boolean) True (default) / False

        See: :meth:`~qubles.core.quble.Quble.maggregate1d` and `scipy.stats.rankdata` for more information
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mrank",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            method=method,
            ascending=ascending,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_uniform_rank1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        method: str = "average",
        ascending: bool = True,
        include_endpoints: bool = True,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Uniform rank [0,1] of the current value in relation to the samples
        within a growing / cumulative window along the specified time keyspace

        :param method: The method used to assign ranks to tied elements.
        method='average' (default): The average of the ranks that would have been assigned to all the tied values is assigned to each value.
        method='min': The minimum of the ranks that would have been assigned to all the tied values is assigned to each value.(also referred to as "competition" ranking.)
        method='max': The maximum of the ranks that would have been assigned to all the tied values is assigned to each value.
        method='dense': Like 'min', but the rank of the next highest element is assigned the rank immediately after thos assigned to the tied elements.
        method='ordinal': All values are given a distinct rank, corresponding to the order that the values occur in a.
        :type method: (string) The options are 'average', 'min', 'max', 'dense' and 'ordinal'

        :param ascending: Controls direction of sorting / ranking
        :type ascending: (boolean) True (default) / False

        :param include_endpoints: Controls whether to include 0 and 100 percentile ranks in result
                                 (otherwise, min percent rank=100/(n+1), max percent rank=(100 - (100/n+1))
        :type include_endpoints: (boolean) True (default) / False

        See: :meth:`~qubles.core.quble.Quble.maggregate1d` and `scipy.stats.rankdata` for more information
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="muniform_rank",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            method=method,
            ascending=ascending,
            include_endpoints=include_endpoints,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_biuniform_rank1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        method: str = "average",
        ascending: bool = True,
        include_endpoints: bool = True,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Bi-uniform rank [-1,+1] of the current value in relation to the samples
        within a growing / cumulative window along the specified time keyspace

        :param method: The method used to assign ranks to tied elements.
        method='average' (default): The average of the ranks that would have been assigned to all the tied values is assigned to each value.
        method='min': The minimum of the ranks that would have been assigned to all the tied values is assigned to each value. (also referred to as "competition" ranking.)
        method='max': The maximum of the ranks that would have been assigned to all the tied values is assigned to each value.
        method='dense': Like 'min', but the rank of the next highest element is assigned the rank immediately after thos assigned to the tied elements.
        method='ordinal': All values are given a distinct rank, corresponding to the order that the values occur in a.
        :type method: (string) The options are 'average', 'min', 'max', 'dense' and 'ordinal'

        :param ascending: Controls direction of sorting / ranking
        :type ascending: (boolean) True (default) / False

        :param include_endpoints: Controls whether to include 0 and 100 percentile ranks in result
                                 (otherwise, min percent rank=100/(n+1), max percent rank=(100 - (100/n+1))
        :type include_endpoints: (boolean) True (default) / False

        See: :meth:`~qubles.core.quble.Quble.maggregate1d` and `scipy.stats.rankdata` for more information
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mbiuniform_rank",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            method=method,
            ascending=ascending,
            include_endpoints=include_endpoints,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_pct_rank1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        method: str = "average",
        ascending: bool = True,
        include_endpoints: bool = True,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Percent rank [0,100] of the current value in relation to the samples
        within a growing / cumulative window along the specified time keyspace

        :param method: The method used to assign ranks to tied elements.
        method='average' (default): The average of the ranks that would have been assigned to all the tied values is assigned to each value.
        method='min': The minimum of the ranks that would have been assigned to all the tied values is assigned to each value.(also referred to as "competition" ranking.)
        method='max': The maximum of the ranks that would have been assigned to all the tied values is assigned to each value.
        method='dense': Like 'min', but the rank of the next highest element is assigned the rank immediately after thos assigned to the tied elements.
        method='ordinal': All values are given a distinct rank, corresponding to the order that the values occur in a.
        :type method: (string) The options are 'average', 'min', 'max', 'dense' and 'ordinal'

        :param ascending: Controls direction of sorting / ranking
        :type ascending: (boolean) True (default) / False

        :param include_endpoints: Controls whether to include 0 and 100 percentile ranks in result
                                 (otherwise, min percent rank=100/(n+1), max percent rank=(100 - (100/n+1))
        :type include_endpoints: (boolean) True (default) / False

        See: :meth:`~qubles.core.quble.Quble.maggregate1d` and `scipy.stats.rankdata` for more information
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mpct_rank",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            method=method,
            ascending=ascending,
            include_endpoints=include_endpoints,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_ptp1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Peak-to-peak (ptp) [max-min] across a cumulative / growing trailing temporal window along the specified time keyspace

        See: :meth:`~qubles.core.quble.Quble.maggregate1d` and `numpy.ptp` for more information
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mptp",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_range1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ddof: int = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Peak-to-peak (ptp) [max-min] across a cumulative / growing trailing temporal window along the specified time keyspace

        See: :meth:`~qubles.core.quble.Quble.maggregate1d` and `numpy.ptp` for more information
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mptp",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            ddof=ddof,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    def cume_iqr1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        lower_percentile: float = 25.0,
        upper_percentile: float = 75.0,
        scale="raw",
        interpolation="linear",
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Inter-quartile range (iqr) across a cumulative / growing temporal window along the specified time keyspace

        :param lower_percentile: lower end of range specified as a percentile (default=25.0)
        :type lower_percentile: float

        :param upper_percentile: upper end of range specified as a percentile (default=75.0)
        :type upper_percentile: float

        :param scale: scaling factor...the numerical value of scale will be divided out of the final result
        The following strings values are recognized:

        scale='raw' (default): No scaling, just return the raw IQR
        scale='normal': Scale by 22-sqrt(erf)-1(12) approximately 1.349

        :param interpolation: interpolation method to use when the percentile boundaries lie between two data points i and j
        interpolation='linear' (default): i + (j - i) * fraction,
                        where fraction is the fractional part of the index surrounded by i and j.
        interpolation='lower': i
        interpolation='higher': j
        interpolation='nearest': i or j whichever is nearest
        interpolation='midpoint': (i+j)/2
        type interpolation: string ('linear', 'lower', 'higher', 'midpoint', 'nearest')

        See: :meth:`~qubles.core.quble.Quble.maggregate1d` and `scipy.stats.iqr` for more information
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="miqr",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            lower_percentile=lower_percentile,
            upper_percentile=upper_percentile,
            scale=scale,
            interpolation=interpolation,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_geo_prod1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        geo100_flag: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Cumulative / growing 'geometric product' along the specified time keyspace

            geo100_flag==False: prod(x + 1)
            geo100_flag==True: 100*prod((0.01*x) + 1)

                    See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mgeo_prod",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_geo_cume1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        geo100_flag: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Cumulative / growing 'geometric product' along the specified time keyspace

            geo100_flag==False: [prod(x + 1) - 1]
            geo100_flag==True: 100*[prod((0.01*x) + 1) - 1]

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mgeo100_cume" if geo100_flag else "mgeo_cume",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_geo_mean1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        geo100_flag: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Cumulative / growing 'geometric mean' along the specified time keyspace
        [window is specified in number of periods at associated temporal frequency]

            geo100_flag==False: [prod(x + 1)**(1/n) - 1]
            geo100_flag==True:  100*[prod((0.01*x) + 1)**(1/n) - 1]

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mgeo100_mean" if geo100_flag else "mgeo_mean",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_geo_mean_ann1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        geo100_flag: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Cumulative / growing 'geometric annualized mean'
        along the specified time keyspace at the associated frequency

            geo100_flag==False: [prod(x + 1)**(ppy/n) - 1]
            geo100_flag==True:  100*[prod((0.01*x) + 1)**(ppy/n) - 1]

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mgeo100_mean_ann" if geo100_flag else "mgeo_mean_ann",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_geo_std_ann1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ppy: float = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Cumulative / growing 'geometric annualized standard deviation'=[std(x) * sqrt(ppy)]
        along the specified time keyspace at the associated frequency

        NOTE: This operation is computed indepedently of
        the underlying return scaling convention of geo100_flag

        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mgeo_std_ann",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ppy=ppy,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    @RootLib.lazy_kwargs()
    def cume_geo_ir1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        ppy: float = 0,
        valuespace="<valuespace>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        ks_is_freq_idx: bool = False,
    ) -> Quble:
        """
        Cumulative / growing 'geometric information ratio' (IR)
        = [geo_mean_ann / geo_std_ann] = [prod(x + 1)**(ppy/n) - 1] / [std(x) * sqrt(ppy)]
        along the specified time keyspace at the associated frequency
        See: :meth:`~qubles.core.quble.Quble.maggregate1d`
        """
        return self.maggregate1d(
            periods=CUME_WINDOW,
            keyspace=keyspace,
            aggr_method="mgeo_ir",
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            ppy=ppy,
            ks_is_freq_idx=ks_is_freq_idx,
        )

    # ========================================================================================
    #                          ONE-DIMENSION RANKS & PERCENTILE LEVELS
    # ========================================================================================

    @RootLib.lazy_kwargs()
    def multi_percentile_level1d(
        self,
        keyspace: str = "<first_keyspace>",
        percentiles: list = [50.0],
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        interpolate_flag: bool = True,
        percentile_keyspace: str = "Percentiles",
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.multi_percentile_level(
            aggr_keyspaces=keyspace,
            percentiles=percentiles,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            interpolate_flag=interpolate_flag,
            percentile_keyspace=percentile_keyspace,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            is_weighted=False,
            pre_cross_fill=True,
            pre_fill=False,
        )

    @RootLib.lazy_kwargs()
    def wtd_multi_percentile_level1d(
        self,
        keyspace: str = "<first_keyspace>",
        percentiles: list = [50.0],
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        interpolate_flag: bool = True,
        percentile_keyspace: str = "Percentiles",
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        return self.multi_percentile_level(
            aggr_keyspaces=keyspace,
            percentiles=percentiles,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            interpolate_flag=interpolate_flag,
            percentile_keyspace=percentile_keyspace,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            is_weighted=True,
            pre_cross_fill=True,
            pre_fill=False,
        )

    @RootLib.lazy_kwargs()
    def multi_percentile_levelx1d(
        self,
        keyspace: str = "<first_keyspace>",
        percentiles: list = [50.0],
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        interpolate_flag: bool = True,
        percentile_keyspace: str = "Percentiles",
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Returns a Quble providing the multiple percentile value(s) for each 1-D analysis
        through the unspecified 'orthogonal' keyspaces
        """
        ortho_keyspaces = self.ortho_keyspaces(keyspace, grace=True)
        return self.multi_percentile_level(
            aggr_keyspaces=ortho_keyspaces,
            percentile_keyspace=percentile_keyspace,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            percentiles=percentiles,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            interpolate_flag=interpolate_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_multi_percentile_levelx1d(
        self,
        keyspace: str = "<first_keyspace>",
        percentiles: list = [50.0],
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        interpolate_flag: bool = True,
        percentile_keyspace: str = "Percentiles",
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Returns a Quble providing the multiple percentile value(s) for each 1-D analysis
        through the unspecified 'orthogonal' keyspaces
        """
        ortho_keyspaces = self.ortho_keyspaces(keyspace, grace=True)
        return self.wtd_multi_percentile_level(
            aggr_keyspaces=ortho_keyspaces,
            percentile_keyspace=percentile_keyspace,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            percentiles=percentiles,
            auto_squeeze=auto_squeeze,
            is_weighted=True,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            interpolate_flag=interpolate_flag,
        )

    @RootLib.lazy_kwargs()
    def wtd_multi_zscore_level(
        self,
        z_levels: list | dict = [-1, 0, 1],
        aggr_keyspaces: str | list = "<keyspaces>",
        zscore_keyspace: str = "z",
        valuespace: str | list | tuple = "<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        is_weighted=True,
    ) -> Quble:
        """
        ~see qubles.core.quble.Quble.multi_zscore_level
        """
        return self.multi_zscore_level(
            z_levels=z_levels,
            aggr_keyspaces=aggr_keyspaces,
            zscore_keyspace=zscore_keyspace,
            valuespace=valuespace,
            view=view,
            is_weighted=is_weighted,
        )

    @RootLib.lazy_kwargs()
    def multi_zscore_level(
        self,
        z_levels: list | dict = [-1, 0, 1],
        aggr_keyspaces: str | list = "<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        zscore_keyspace: str = "z",
        valuespace: str | list | tuple = "<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        is_weighted=False,
    ) -> Quble:
        """
        Calculates multiple z-score value(s) for each 1-D analysis
        (through the specified keyspace) for each orthogonal (n-1) hyperkey.
        This method calculates the offset from the mean
        by multiplying the Z-Score by the Standard Deviation and
        then adds that value to the mean to get the final value.
        i.e., AVERAGE + OFFSET=(Z-SCORE * STANDARD DEVIATION)


        :param z_levels: A list or dictionary of Z-Scores to calculate.
                If a dictionary is provided, the keys will be introduced
                into the zscore_keyspace column.
                The values are used internally for the calculation
                and not visible in the output Quble.
        :type z_levels: list|dict

        :param aggr_keyspaces: A list of keyspaces to be aggregated across
        :type aggr_keyspaces: str|list

        :param ignore_missing: Flag to ignore missing (null) values in calculations
        :type ignore_missing: bool

        :param pct_required: Percentage of non-null values required for a given z-score calculation
        :type pct_required: float or None

        :param num_required: Number of non-null values required for a given z-score calculation
        :type num_required: int or None

        :param zscore_keyspace: Name of the Z-Score keyspace
                    which associates a calculation with its given Z-Score
        :type zscore_keyspace: str

        :param valuespace: valuespace(s) to perform the calculation
        :type valuespace: str|list|tuple

        :param view: 'view' (weights) to use for weighted calculation (if desired)
        :type view: str|Quble|None

        :param is_weighted: flag for weighted calculation (if desired)
        :type is_weighted: bool

        :returns: Quble with applied calculation
        :rtype: qubles.core.quble.Quble
        :raises Exception: An exception is raised if incorrect or incompatible arguments are supplied

        """
        # Validate z_levels arg
        # and build z (Quble) accordingly
        if isinstance(z_levels, dict):
            z = Quble(
                {zscore_keyspace: z_levels.keys(), "Z_LEVELS": z_levels.values()},
                valuespace=["Z_LEVELS"],
            )
        elif isinstance(z_levels, list):
            z = Quble(
                {zscore_keyspace: z_levels, "Z_LEVELS": z_levels},
                valuespace=["Z_LEVELS"],
            )
        else:
            raise Exception(
                f"Invalid argument provided for z_levels. Needs list or dict - Got: {type(z_levels)}"
            )

        # Validate zscore_keyspace
        if not isinstance(zscore_keyspace, str):
            raise Exception(
                f"Invalid argument provided for zscore_keyspace. Needs str - Got: {type(zscore_keyspace)}"
            )

        # Validate aggr_keyspaces arg
        # [NOTE: May perform auto-linking]
        aggr_keyspaces = self.validate_keyspace(
            aggr_keyspaces,
            grace=False,
            coerce_to_list=True,
        )

        # Validate valuespace arg
        valuespace = self.validate_valuespace(
            valuespace, grace=False, coerce_to_list=True, numeric_required=True
        )

        # Perform avg and std calculations accordingly
        if is_weighted:
            avg = self.wtd_mean(
                aggr_keyspaces=aggr_keyspaces,
                valuespace=valuespace,
                view=view,
                ignore_missing=ignore_missing,
                pct_required=pct_required,
                num_required=num_required,
            )
            std = self.wtd_std_samp(
                aggr_keyspaces=aggr_keyspaces,
                valuespace=valuespace,
                view=view,
                ignore_missing=ignore_missing,
                pct_required=pct_required,
                num_required=num_required,
            )
        else:
            avg = self.mean(
                aggr_keyspaces=aggr_keyspaces,
                valuespace=valuespace,
                ignore_missing=ignore_missing,
                pct_required=pct_required,
                num_required=num_required,
            )
            std = self.stddev_samp(
                aggr_keyspaces=aggr_keyspaces,
                valuespace=valuespace,
                ignore_missing=ignore_missing,
                pct_required=pct_required,
                num_required=num_required,
            )

        # Compute z-levels using avg, std and z Qubles
        with ControlContextManager({"variate_mode": "mixed"}) as ccm:
            # NOTE: Due to the behavior of mixed mode and the multiply operator,
            # the STD Quble must be the first component of the operation.
            z_lvl = avg + (std * z)

        # Return the resultant z-level Quble
        return z_lvl

    @RootLib.lazy_kwargs()
    def multi_percentile_level(
        self,
        aggr_keyspaces="<keyspaces>",
        percentiles: list | dict = [50.0],
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        interpolate_flag: bool = True,
        percentile_keyspace: str = "Percentiles",
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        is_weighted: bool = False,
        epsilon: float = None,
        quble_flag: bool = True,
        non_abs_weights=False,
    ) -> Quble:
        """
        Returns a Quble providing the multiple percentile value(s) for each 1-D analysis (through the specified keyspace) for each orthogonal (n-1) hyperkey.
        For percentile=50. this method returns the median value through the specified keyspace at each orthogonal key data

        If a single (scalar) percentile level arg is provided, will return a (n-1) Dimensional Quble containing the orthogonal keyspaces and associated keys

        If multiple percentiles are requested (e.g., percentile arg is a tuple or list of numeric scalars),
        yields a n-Dimensional Quble containing the (n-1) orthogonal keyspaces as well as a (newly introduced) percentile_keyspace)
        """
        # Validate pct_required arg
        if percentiles is None:
            raise Exception("No percentile provided")
        # Numpy array case
        elif isinstance(percentiles, np.ndarray):
            # Snowflake stored procedure needs this arg to be a Python list
            percentiles = {pct: pct for pct in percentiles.tolist()}
        # Scalar case
        elif isinstance(percentiles, (float, int)):
            percentiles = {percentiles: percentiles}
        # List case
        elif isinstance(percentiles, list):
            percentiles = {pct: pct for pct in percentiles}
        elif not isinstance(percentiles, dict):
            raise Exception(f"Invalid type(percentiles):{type(percentiles)}")

        # Validate percentiles list
        if len(percentiles) == 0:
            pass
        elif (min(percentiles.values()) < 0) or (max(percentiles.values()) > 100):
            raise Exception(
                f"Invalid percentile.values():{list(percentiles.values())}...each value must be between 0 and 100 inclusive"
            )
        # Here we have to assume that if we are supplied percentiles = [1, 1, 1, 1, etc]
        # We want the 100th percentile. There would be no way to determine unless an additional
        # Parameter was supplied giving the scale of our percentiles
        # Unfortunately we have to loop through the list twice rather than have the conditional
        # in the list comp. e.g. percentiles=[1, 2, 3, 4] with the conditional in the list comp would
        # give us [1, 0.02, 0.03, 0.04] whereas the below logic will give us [0.01, 0.02, 0.03, 0.04]
        if any(pct > 1 for pct in percentiles.values()):
            percentiles = {colname: pct / 100 for colname, pct in percentiles.items()}

        # Validate percentile_keyspace arg
        if percentile_keyspace is None:
            raise Exception("No percentile_keyspace provided")
        elif not isinstance(percentile_keyspace, str):
            raise Exception(
                f"Invalid percentile_keyspace:{percentile_keyspace}...string required"
            )

        # ================== MULTI-PERCENTILE LEVEL LOGIC ======================
        if self.is_undefined:
            return Quble.undefined_instance()
        # Scalars are already fully aggregated
        elif self.is_scalar:
            pass
        elif self.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # Validate valuespace arg
        valuespace = self.validate_valuespace(
            valuespace, grace=False, coerce_to_list=True, numeric_required=True
        )

        # Add view (str) to valuespace (list) when applicable
        if (
            isinstance(view, str)
            and view in self.valuespaces
            and view not in valuespace
        ):
            valuespace.append(view)

        # Restrict Quble to only the valuespace(s) of interest
        # [valuespace arg is validated within sub_variate method]
        # (allow for shallow copy when valuespaces are unchanged)
        # ==> Only refer to subject (not self) hereafter
        # ------------------------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)

        # May perform auto-linking
        aggr_keyspaces = subject.validate_keyspace(
            aggr_keyspaces,
            grace=False,
            coerce_to_list=True,
        )

        # NOTE: Apply pre_cross_fill BEFORE pre_fill
        if pre_cross_fill:
            subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)

        if pre_fill:
            subject = subject._apply_pre_fill(allow_shallow_copy=True)

        aggr_method = "wtd_percentile_level" if is_weighted else "percentile_level"

        # Apply view to subject
        # using view's primary valuespace
        # --------------------------------
        weightspace = None
        if view is None:
            pass
        elif isinstance(view, str):
            # Here, view (str) identifies a weightspace column of the Quble
            if view not in subject.valuespaces:
                raise Exception(
                    f"view:{view} absent from subject.valuespaces:{subject.valuespaces}"
                )
            weightspace = view
            weightspace_type = self.get_column_type(weightspace)
            weightspace_is_numeric = coltype_is_numeric(weightspace_type)
            weightspace_is_bool = coltype_is_bool(weightspace_type)
            if aggr_method not in WTD_TO_UNWTD_AGGR_DICT or weightspace_is_bool:
                # Non-weighted aggregation OR boolean weightspace
                # Implementation: Restrict to records where weightspace = True
                if weightspace_is_bool:
                    where_clause = (
                        'WHERE "'
                        + weightspace
                        + '" IS NOT NULL AND "'
                        + weightspace
                        + '" <> False'
                    )
                elif weightspace_is_numeric:
                    where_clause = (
                        'WHERE "'
                        + weightspace
                        + '" IS NOT NULL AND "'
                        + weightspace
                        + '" <> 0'
                    )
                else:
                    raise Exception(
                        f"Invalid coltype:{weightspace_type} for weightspace:{weightspace} with aggr_method:{aggr_method}"
                    )

                spacesxweightspace = [
                    space1 for space1 in subject.spaces if space1 != weightspace
                ]
                subject = subject.select(
                    column_names=spacesxweightspace, where_clause=where_clause
                )
                # No need to continue to recognize weightspace now
                weightspace = None
            elif not weightspace_is_numeric:
                raise Exception(
                    f"weightspace:{weightspace} has invalid column type:{weightspace_type}...numeric or bool type required"
                )
        elif not isinstance(view, Quble):
            raise Exception("Invalid view...Quble or None expected")
        elif view.is_undefined:
            pass
        elif (
            aggr_method not in WTD_TO_UNWTD_AGGR_DICT
            or view.is_scalar
            or view.is_multiscalar
            or view.is_index
            or view.is_bool()
        ):
            # Determine if this is a weighted aggregation method by looking at:
            # aggr_method not in WTD_TO_UNWTD_AGGR_DICT
            subject = subject.apply_view(view, allow_shallow_copy=True)
        elif not view.is_numeric():
            raise Exception(
                "For weight percentile level:{0}, view must be index, bool or numeric Quble"
            )
        elif subject.are_coindexed(view):
            if view.valuespace is None:
                # Highly unlikely case, but check to be sure
                raise Exception(
                    "self & view are coindexed, yet view.valuespace is None"
                )
            weightspace = view.valuespace
        else:
            # Here, we are performing a weighted aggregation with a numeric non-scalar view (weighting Quble)
            if subject.valuespace is None or subject.valuespace != "weighting":
                weightspace = "weighting"
            else:
                weightspace = "wgt"
            # NOTE: weightspace will be imposed column,
            # but must be distinct from subject.valuespace
            subject = subject.apply_view(
                view, view_valuespace_as=weightspace, allow_shallow_copy=True
            )

            # Perform some checks
            if weightspace not in subject.valuespaces:
                raise Exception(
                    "weightspace:{0} was not crated during the join operation"
                )
            elif subject.valuespace is not None and weightspace == subject.valuespace:
                raise Exception(
                    "weightspace:{0} expectedly equals subject.valuespace:{1}".format(
                        weightspace, subject.valuespace
                    )
                )

        # =========================== START: VALUESPACES LOOP ===========================
        sql_aggr_fn_per_vs = {}

        for vs in subject.valuespaces:
            # Validate/convert aggr_method
            # (will convert to SQL compatible upper-case FUNCTION NAME)

            if aggr_method is None or not isinstance(aggr_method, str):
                raise Exception(f"Invalid aggr_method:{aggr_method}")

            aggr_method = aggr_method.lower().strip()

            # Assign is_weighted
            if aggr_method not in WTD_TO_UNWTD_AGGR_DICT:
                is_weighted = False
            elif weightspace is None:
                # Convert to non-weighted aggr_method
                aggr_method = WTD_TO_UNWTD_AGGR_DICT[aggr_method]
                is_weighted = False
            else:
                is_weighted = True

            if aggr_method in CUSTOM_AGGR_CONFIGS:
                is_custom = True
                sql_aggr_fn = aggr_method

            elif aggr_method not in NATIVE_AGGR_DICT:
                raise Exception(f"Invalid aggr_method():{aggr_method}")
            # BY NUMPY CONVENTION, std YIELDS POPULATION STANDARD DEVIATION
            else:
                sql_aggr_fn = NATIVE_AGGR_DICT[aggr_method]

            sql_aggr_fn_per_vs[vs] = sql_aggr_fn

        # =========================== END: VALUESPACES LOOP ===========================

        # List of all the extra keyspaces
        # (excluding the keyspace provided as an argument)
        ortho_keyspaces = subject.ortho_keyspaces(aggr_keyspaces)

        # Build col_types_dict (if needed)
        if not auto_squeeze:
            col_types_dict = subject.get_column_type(subject.keyspaces)
        else:
            col_types_dict = None

        # Build build_key_ordering_dict when applicable
        if key_ordering is not None and not isinstance(key_ordering, str):
            key_ordering = build_key_ordering_dict(
                key_ordering, keyspaces=subject.keyspaces
            )

        if weightspace is None:
            valuespaces_xweightspace = subject.valuespaces
        elif weightspace not in subject.valuespaces:
            raise Exception(
                "weightspace:{0} absent from post-join valuespaces:{0}".format(
                    weightspace, subject.valuespaces
                )
            )
        else:
            valuespaces_xweightspace = subject.ortho_valuespaces(weightspace)

        if auto_squeeze:
            tgt_keyspaces = ortho_keyspaces + [percentile_keyspace]
            tgt_keyspaces_xpercentile_ks = ortho_keyspaces
        else:
            tgt_keyspaces = subject.keyspaces + [percentile_keyspace]
            tgt_keyspaces_xpercentile_ks = subject.keyspaces

        table_name = generate_random_table_name()

        # Do we need a group_sizes_cte construct in the query?
        group_sizes_cte = None
        if aggr_method == "count":
            pass
        elif not ignore_missing or pct_required:
            group_sizes_cte = "group_sizes_cte"

        if is_weighted:
            wtd_template = JINJA_ENV.get_template("wtd_aggregate.j2")
            com = wtd_template.render(
                function=aggr_method,
                aggr_keyspaces=aggr_keyspaces,
                keyspaces=subject.keyspaces,
                ortho_keyspaces=[
                    ks for ks in subject.keyspaces if ks not in aggr_keyspaces
                ],
                src_table_name=subject.table_name,
                tgt_table_name=table_name,
                valuespaces=valuespaces_xweightspace,
                weightspace=weightspace,
                auto_squeeze=auto_squeeze,
                num_required=num_required,
                pct_required=pct_required,
                ignore_missing=ignore_missing,
                non_abs_weights=non_abs_weights,
                interpolate_flag=interpolate_flag,
                percentiles=percentiles,
                percentile_keyspace=percentile_keyspace,
            )
            execute(com)
        else:
            sql_template = JINJA_ENV.get_template("multi_percentile_level.j2")
            com = sql_template.render(
                aggr_keyspaces=aggr_keyspaces,
                keyspaces=subject.keyspaces,
                ortho_keyspaces=[
                    ks for ks in subject.keyspaces if ks not in aggr_keyspaces
                ],
                src_table_name=subject.table_name,
                tgt_table_name=table_name,
                valuespaces=valuespaces_xweightspace,
                auto_squeeze=auto_squeeze,
                num_required=num_required,
                pct_required=pct_required,
                ignore_missing=ignore_missing,
                interpolate_flag=interpolate_flag,
                percentiles=percentiles,
                percentile_keyspace=percentile_keyspace,
            )
            execute(com)

        # Establish col_info for copy
        if table_name == subject.table_name:
            col_info = None
        else:
            if aggr_method in (
                "count",
                "num_null",
                "num_not_null",
                "num_zero",
                "num_non_zero",
                "num_positive",
                "num_nonpositive",
                "num_negative",
                "num_nonnegative",
            ):
                info_types_to_copy = [
                    it1 for it1 in CUSTOM_INFO_TYPES if it1 not in ["fx", "time_basis"]
                ]
            else:
                info_types_to_copy = CUSTOM_INFO_TYPES

            col_info = subject.get_space_info(
                info_type=info_types_to_copy,
                space=tgt_keyspaces_xpercentile_ks + valuespaces_xweightspace,
                omit_unassigned=True,
            )
            if "role" not in col_info:
                col_info["role"] = {}
            col_info["role"][percentile_keyspace] = "keyspace"

        if quble_flag:
            # Instantiate Quble from the new table
            return Quble.from_table(
                table_name=table_name,
                col_info=col_info,
            )
        else:
            # This usage is only approriate when there
            # are no residual orthogonal ("group by")
            # keyspaces in the result
            valuespace_selections = ",".join(dquote_dot(valuespaces_xweightspace))
            sql_command = f'SELECT {valuespace_selections} FROM "{table_name}" ORDER BY "{percentile_keyspace}"'
            return execute_snowalchemy(sql_command, method_name="read_numpy")

    @RootLib.lazy_kwargs()
    def wtd_multi_percentile_level(
        self,
        aggr_keyspaces="<keyspaces>",
        percentiles: list | dict = [50.0],
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        interpolate_flag: bool = True,
        percentile_keyspace: str = "Percentiles",
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        non_abs_weights=False,
    ) -> Quble:
        return self.multi_percentile_level(
            aggr_keyspaces=aggr_keyspaces,
            percentiles=percentiles,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            interpolate_flag=interpolate_flag,
            percentile_keyspace=percentile_keyspace,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            is_weighted=True,
            pre_cross_fill=True,
            pre_fill=False,
        )

    @RootLib.lazy_kwargs()
    def percentile_level1d(
        self,
        keyspace: str = "<first_keyspace>",
        percentile: float = 50.0,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        interpolate_flag: bool = True,
        percentile_keyspace: str = "Percentiles",
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Returns a Quble providing the percentile value(s) for each 1-D analysis
        (through the specified keyspace) for each orthogonal (n-1) hyperkey.

        For percentile=50, this method returns the median value
        through the specified keyspace at each orthogonal key data.

        If a single (scalar) percentile level arg is provided, will return a
        (n-1)Dimension Quble containing orthogonal keyspaces and associated keys

        If multiple percentiles are requested
        (e.g., percentile arg is a tuple or list of numeric scalars),
        yields a n-Dimensional Quble containing the (n-1) orthogonal keyspaces
        as well as a (newly introduced) percentile_keyspace)
        """
        if isinstance(percentile, (list, tuple)):
            return self.multi_percentile_level(
                aggr_keyspaces=keyspace,
                percentile_keyspace=percentile_keyspace,
                ignore_missing=ignore_missing,
                pct_required=pct_required,
                num_required=num_required,
                valuespace=valuespace,
                view=view,
                key_ordering=key_ordering,
                percentiles=percentile,
                auto_squeeze=auto_squeeze,
                pre_cross_fill=pre_cross_fill,
                pre_fill=pre_fill,
                interpolate_flag=interpolate_flag,
            )
        else:
            return self.aggregate(
                aggr_keyspaces=keyspace,
                aggr_method="percentile_level",
                ignore_missing=ignore_missing,
                pct_required=pct_required,
                num_required=num_required,
                valuespace=valuespace,
                view=view,
                key_ordering=key_ordering,
                percentile=percentile,
                auto_squeeze=auto_squeeze,
                pre_cross_fill=pre_cross_fill,
                pre_fill=pre_fill,
                interpolate_flag=interpolate_flag,
            )

    @RootLib.lazy_kwargs()
    def percentile_levelx1d(
        self,
        keyspace: str = "<first_keyspace>",
        percentile: float = 50.0,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        interpolate_flag: bool = True,
        percentile_keyspace: str = "Percentiles",
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Returns a Quble providing the percentile value(s) for each 1-D analysis
        through the unspecified 'orthogonal' keyspaces

        For percentile=50. this method returns the median value through the specified keyspace at each orthogonal key data

        If a single (scalar) percentile level arg is provided, will return a (n-1) Dimensional Quble containing the orthogonal keyspaces and associated keys

        If multiple percentiles are requested (e.g., percentile arg is a tuple or list of numeric scalars),
        yields a n-Dimensional Quble containing the (n-1) orthogonal keyspaces as well as a (newly introduced) percentile_keyspace)
        """
        ortho_keyspaces = self.ortho_keyspaces(keyspace, grace=True)
        if isinstance(percentile, (list, tuple)):
            return self.multi_percentile_level(
                aggr_keyspaces=ortho_keyspaces,
                percentile_keyspace=percentile_keyspace,
                ignore_missing=ignore_missing,
                pct_required=pct_required,
                num_required=num_required,
                valuespace=valuespace,
                view=view,
                key_ordering=key_ordering,
                percentiles=percentile,
                auto_squeeze=auto_squeeze,
                pre_cross_fill=pre_cross_fill,
                pre_fill=pre_fill,
                interpolate_flag=interpolate_flag,
            )
        else:
            return self.aggregate(
                aggr_keyspaces=ortho_keyspaces,
                aggr_method="percentile_level",
                ignore_missing=ignore_missing,
                pct_required=pct_required,
                num_required=num_required,
                valuespace=valuespace,
                view=view,
                key_ordering=key_ordering,
                percentile=percentile,
                auto_squeeze=auto_squeeze,
                pre_cross_fill=pre_cross_fill,
                pre_fill=pre_fill,
                interpolate_flag=interpolate_flag,
            )

    @RootLib.lazy_kwargs()
    def uniform_rankx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ascending: bool = True,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        include_endpoints: bool = True,
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        include_nulls_in_rank: bool = False,
        ranking_algo: str = None,
    ) -> Quble:
        """
        Generates a uniform distribution translation
        of the data across the non-specified keyspace(s)
        Values will range from [0,1] in a uniform manner
        ~see qubles.core.quble.Quble.pct_rankx1d
        """
        return self.pct_rankx1d(
            keyspace=keyspace,
            ascending=ascending,
            ignore_missing=ignore_missing,
            include_endpoints=include_endpoints,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            include_nulls_in_rank=include_nulls_in_rank,
            ranking_algo=ranking_algo,
            min_value=0.0,
            max_value=1.0,
        )

    @RootLib.lazy_kwargs()
    def biuniform_rankx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ascending: bool = True,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        include_endpoints: bool = True,
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        include_nulls_in_rank: bool = False,
        ranking_algo: str = None,
    ) -> Quble:
        """
        Generates a bi-directional uniform distribution
        translation of the data across the non-specified keyspace(s)
        Values will range from [-1,+1] in a uniform manner
        ~see qubles.core.quble.Quble.pct_rankx1d
        """
        return self.pct_rankx1d(
            keyspace=keyspace,
            ascending=ascending,
            ignore_missing=ignore_missing,
            include_endpoints=include_endpoints,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            include_nulls_in_rank=include_nulls_in_rank,
            ranking_algo=ranking_algo,
            min_value=-1.0,
            max_value=1.0,
        )

    @RootLib.lazy_kwargs()
    def pct_rankx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ascending: bool = True,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        include_endpoints: bool = True,
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        include_nulls_in_rank: bool = False,
        ranking_algo: str = None,
        min_value: float = 0.0,
        max_value: float = 100.0,
    ) -> Quble:
        """
        Percentile ranking of the valuespace(s) column(s) across the non-specified keyspace(s)
        Output values will range from min_value to max_value [nominally: 0 to 100]
        The schema of the resultant table will match the original (self) table

        :param keyspace: keyspace (dimension) to EXCLUDE IN THE ranking process
        :type keyspace: string

        :param ascending: (optional) Direction of the sorting operation
        :type ascending: boolean (True/False)

        :param include_endpoints: (optional) Flag to include/exclude 0.0 & 100.0 in pct rank results
        :type include_endpoints: boolean (True:pct_ranks=[0,100] / False:pct_ranks=(0,100))

        :param key_ordering: (optional) Indicates whether/how to order result records within the keyspaces (index columns)
        :type key_ordering: None (no ordering of results records), 'asc' or 'desc'

        :param include_nulls_in_rank: (optional) flag to include nulls in rank
                                    (treated as smallest value)
                                    otherwise rank for null values will be null
        :type include_nulls_in_rank: boolean (True/False*)

        :param ranking_algo: (optional) ranking algorithm
                               (otherwise dense ranking algorithm will be used)
        :type ranking_algo: str ("dense_rank", "rank", "row_number", None)

        :param min_value: minimum output value (default:0.0)
        :type min_value: float

        :param max_value: maximum output value (default:100.0)
        :type max_value: float
        """
        ortho_keyspaces = self.ortho_keyspaces(keyspace, grace=True)
        return self.pct_rank(
            ranking_keyspaces=ortho_keyspaces,
            ascending=ascending,
            ignore_missing=ignore_missing,
            include_endpoints=include_endpoints,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            include_nulls_in_rank=include_nulls_in_rank,
            ranking_algo=ranking_algo,
            min_value=min_value,
            max_value=max_value,
        )

    @RootLib.lazy_kwargs()
    def rankx1d(
        self,
        keyspace: str = "<first_keyspace>",
        ascending: bool = True,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        include_nulls_in_rank: bool = False,
        ranking_algo: str = None,
    ) -> Quble:
        """
        Rank of the valuespace(s) column(s) across the non-specified keyspace(s)
        The schema of the resultant table will match the original (self) table

        :param keyspace: keyspace (dimension) to EXCLUDE IN THE ranking process
        :type keyspace: string

        :param ascending: (optional) Direction of the sorting operation
        :type ascending: boolean (True/False)

        :param key_ordering: (optional) Indicates whether/how to order result records within the keyspaces (index columns)
        :type key_ordering: None (no ordering of results records), 'asc' or 'desc'

        :param include_nulls_in_rank: (optional) flag to include nulls in rank
                                    (treated as smallest value)
                                    otherwise rank for null values will be null
        :type include_nulls_in_rank: boolean (True/False*)

        :param ranking_algo: (optional) ranking algorithm
                               (otherwise dense ranking algorithm will be used)
        :type ranking_algo: str ("dense_rank", "rank", "row_number", None)
        """
        ortho_keyspaces = self.ortho_keyspaces(keyspace, grace=True)
        return self.rank(
            ranking_keyspaces=ortho_keyspaces,
            ascending=ascending,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            view=view,
            valuespace=valuespace,
            key_ordering=key_ordering,
            include_nulls_in_rank=include_nulls_in_rank,
            ranking_algo=ranking_algo,
        )

    @RootLib.lazy_kwargs()
    def uniform_rank1d(
        self,
        keyspace: str = "<first_keyspace>",
        ascending: bool = True,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        include_endpoints: bool = True,
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        include_nulls_in_rank: bool = False,
        ranking_algo: str = None,
    ) -> Quble:
        """
        Generates a uniform distribution translation
        of the data across the specified keyspace
        Values will range from [0,1] in a uniform manner
        ~see qubles.core.quble.Quble.pct_rank1d
        """
        return self.pct_rank1d(
            keyspace=keyspace,
            ascending=ascending,
            ignore_missing=ignore_missing,
            include_endpoints=include_endpoints,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            include_nulls_in_rank=include_nulls_in_rank,
            ranking_algo=ranking_algo,
            min_value=0.0,
            max_value=1.0,
        )

    @RootLib.lazy_kwargs()
    def biuniform_rank1d(
        self,
        keyspace: str = "<first_keyspace>",
        ascending: bool = True,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        include_endpoints: bool = True,
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        include_nulls_in_rank: bool = False,
        ranking_algo: str = None,
    ) -> Quble:
        """
        Generates a bi-directional uniform distribution
        translation of the data across the specified keyspace
        Values will range from [-1,+1] in a uniform manner
        ~see qubles.core.quble.Quble.pct_rank1d
        """
        return self.pct_rank1d(
            keyspace=keyspace,
            ascending=ascending,
            ignore_missing=ignore_missing,
            include_endpoints=include_endpoints,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            include_nulls_in_rank=include_nulls_in_rank,
            ranking_algo=ranking_algo,
            min_value=-1.0,
            max_value=1.0,
        )

    @RootLib.lazy_kwargs()
    def pct_rank1d(
        self,
        keyspace: str = "<first_keyspace>",
        ascending: bool = True,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        include_endpoints: bool = True,
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        include_nulls_in_rank: bool = False,
        ranking_algo: str = None,
        min_value: float = 0.0,
        max_value: float = 100.0,
    ) -> Quble:
        """
        Percentile ranking of the valuespace column across the specified keyspace
        Output values will range from min_value to max_value [nominally: 0 to 100]
        The schema of the resultant table will match the original (self) table

        :param keyspace: keyspace (dimension) to EXCLUDE IN THE ranking process
        :type keyspace: string

        :param ascending: (optional) Direction of the sorting operation
        :type ascending: boolean (True/False)

        :param include_endpoints: (optional) Flag to include/exclude 0.0 & 100.0 in pct rank results
        :type include_endpoints: boolean (True:pct_ranks=[0,100] / False:pct_ranks=(0,100))

        :param key_ordering: controls row ordering by key
        :type key_ordering: None, str or dictionary
           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace
           dictionary: dict keys (str): keyspaces, dict values (str): 'asc' or 'desc'
           ==> allows for assigning key ordering (ascending/descending)
           ==> (and relative priority) for each keyspace individually

        :param include_nulls_in_rank: (optional) flag to include nulls in rank
                                    (treated as smallest value)
                                    otherwise rank for null values will be null
        :type include_nulls_in_rank: boolean (True/False*)

        :param valuespace: valuespace(s) to compress across
        :type valuespace: str (a specific valuespace)
                        OR list of string (specific valuespaces)
                        OR '<valuespaces>' or <all>' (all valuespaces)
                        OR '<valuespace>' (primary valuespace)

        :param ranking_algo: (optional) ranking algorithm
                               (otherwise dense ranking algorithm will be used)
        :type ranking_algo: str ("dense_rank", "rank", "row_number", None)

        :param min_value: minimum output value (default:0.0)
        :type min_value: float

        :param max_value: maximum output value (default:100.0)
        :type max_value: float
        """
        return self.pct_rank(
            ranking_keyspaces=keyspace,
            ascending=ascending,
            ignore_missing=ignore_missing,
            include_endpoints=include_endpoints,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            include_nulls_in_rank=include_nulls_in_rank,
            ranking_algo=ranking_algo,
            min_value=min_value,
            max_value=max_value,
        )

    @RootLib.lazy_kwargs()
    def rank1d(
        self,
        keyspace: str = "<first_keyspace>",
        ascending: bool = True,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        include_nulls_in_rank: bool = False,
        ranking_algo: str = None,
    ) -> Quble:
        """
        Ranks the valuespace(s) column(s) across the specified keyspace
        The schema of the resultant table will match the original (self) table

        :param keyspace: keyspace (dimension) to rank across
        :type keyspace: string

        :param ascending: (optional) Direction of the sorting operation
        :type ascending: boolean (True/False)

        :param key_ordering: controls row ordering by key
        :type key_ordering: None, str or dictionary
           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace
           dictionary: dict keys (str): keyspaces, dict values (str): 'asc' or 'desc'
           ==> allows for assigning key ordering (ascending/descending)
           ==> (and relative priority) for each keyspace individually

        :param include_nulls_in_rank: (optional) flag to include nulls in rank
                                    (treated as smallest value)
                                    otherwise rank for null values will be null
        :type include_nulls_in_rank: boolean (True/False*)

        :param valuespace: valuespace(s) to rank
        :type valuespace: str (a specific valuespace)
                        OR list of string (specific valuespaces)
                        OR '<valuespaces>' or '<all>' (all valuespaces)
                        OR '<valuespace>' (primary valuespace)

        :param ranking_algo: (optional) ranking algorithm
                               (otherwise dense ranking algorithm will be used)
        :type ranking_algo: str ("dense_rank", "rank", "row_number", None)

        """
        return self.rank(
            ranking_keyspaces=keyspace,
            ascending=ascending,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            include_nulls_in_rank=include_nulls_in_rank,
            ranking_algo=ranking_algo,
        )

    @RootLib.lazy_kwargs()
    def uniform_rank(
        self,
        ranking_keyspaces="<keyspaces>",
        ascending: bool = True,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        include_endpoints: bool = True,
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        include_nulls_in_rank: bool = False,
        ranking_algo: str = None,
    ) -> Quble:
        """
        Generates a uniform distribution translation
        of the data across the specified keyspace
        Values will range from [0,1] in a uniform manner
        ~see qubles.core.quble.Quble.pct_rank
        """
        return self.pct_rank(
            ranking_keyspaces=ranking_keyspaces,
            ascending=ascending,
            ignore_missing=ignore_missing,
            include_endpoints=include_endpoints,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            include_nulls_in_rank=include_nulls_in_rank,
            ranking_algo=ranking_algo,
            min_value=0.0,
            max_value=1.0,
        )

    @RootLib.lazy_kwargs()
    def biuniform_rank(
        self,
        ranking_keyspaces="<keyspaces>",
        ascending: bool = True,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        include_endpoints: bool = True,
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        include_nulls_in_rank: bool = False,
        ranking_algo: str = None,
    ) -> Quble:
        """
        Generates a bi-directional uniform distribution
        translation of the data across the specified keyspace
        Values will range from [-1,+1] in a uniform manner
        ~see qubles.core.quble.Quble.pct_rank
        """
        return self.pct_rank(
            ranking_keyspaces=ranking_keyspaces,
            ascending=ascending,
            ignore_missing=ignore_missing,
            include_endpoints=include_endpoints,
            pct_required=pct_required,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            include_nulls_in_rank=include_nulls_in_rank,
            ranking_algo=ranking_algo,
            min_value=-1.0,
            max_value=1.0,
        )

    @RootLib.lazy_kwargs()
    def pct_rank(
        self,
        ranking_keyspaces="<keyspaces>",
        ascending: bool = True,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        include_endpoints: bool = True,
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        include_nulls_in_rank: bool = False,
        ranking_algo: str = None,
        min_value: float = 0.0,
        max_value: float = 100.0,
    ) -> Quble:
        """
        Percentile ranking of the valuespace column across the specified keyspace(s)
        Output values will range from min_value to max_value [nominally: 0 to 100]
        The schema of the resultant table will match the original (self) table

        :param ranking_keyspaces: keyspaces (dimensions) to rank across [1,n]
        :type ranking_keyspaces: list of strings

        :param ascending: (optional) Direction of the sorting operation
        :type ascending: boolean (True/False)

        :param include_endpoints: (optional) Flag to include/exclude 0.0 & 100.0 in pct rank results
        :type include_endpoints: boolean (True:pct_ranks=[0,100] / False:pct_ranks=(0,100))

        :param valuespace: valuespace(s) to compress across
        :type valuespace: str (a specific valuespace)
                        OR list of string (specific valuespaces)
                        OR '<valuespaces>' or <all>' (all valuespaces)
                        OR '<valuespace>' (primary valuespace)

        :param key_ordering: (optional) Indicates whether/how to order result
                                    records within the keyspaces (index columns)
        :type key_ordering: None (no ordering of results), 'asc' or 'desc'

        :param include_nulls_in_rank: (optional) flag to include nulls in rank
                                    (treated as smallest value)
                                    otherwise rank for null values will be null
        :type include_nulls_in_rank: boolean (True/False*)

        :param ranking_algo: (optional) ranking algorithm
                               (otherwise dense ranking algorithm will be used)
        :type ranking_algo: str ("dense_rank", "rank", "row_number", None)

        :param min_value: minimum output value (default:0.0)
        :type min_value: float

        :param max_value: maximum output value (default:100.0)
        :type max_value: float
        """
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_empty:
            return self.copy()
        elif self.is_index:
            raise Exception("Valued Quble required, yet index Quble provided")

        # Validate min_value and max_value args
        if min_value is None:
            min_value = 0.0

        if max_value is None:
            max_value = 100.0

        if min_value >= max_value:
            raise Exception(
                f"Invalid args: min_value:{min_value} >= max_value:{max_value}"
            )

        # Apply view to self
        # [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.apply_view(view, allow_shallow_copy=True)
        if subject.is_empty:
            return subject.copy()

        # Get keyspaces & valuespaces
        keyspaces = subject.keyspaces
        valuespaces = subject.validate_valuespace(
            valuespace, grace=False, coerce_to_list=True
        )
        if len(valuespaces) == 0:
            return self.copy()
        ranking_keyspaces = subject.validate_keyspace(
            ranking_keyspaces, grace=False, coerce_to_list=True
        )  # <-- May perform auto-linking

        table_name = generate_random_table_name()

        # -----------------------------------------------------------------------------
        # NOTE: IN SQL, RANKS START WITH ONE (NOT ZERO)
        # NOTE: NULLS ARE INCLUDED IN RANK (WITH LOWEST VALUE)
        #       AS SUCH WE WILL NEED TO:
        #         1) FIRST REMOVE NULLS FROM TABLE
        #         2) PERFORM RANK SUB-TABLE
        #         3) REINSERT THE NULL RECORDS WITH A NULL RANK
        # NOTE: For pct ranks, we need to normalize by max(rank) (not count) as
        #       records with the same value get the same rank value. However, when
        #       duplicate ranks exist (due to ties), upper ranks can be skipped
        # -----------------------------------------------------------------------------
        # EXAMPLE: SELECT Ticker, Value, RANK(ORDER BY Value_ asc) AS Rank, (RANK-1)/MAX(RANK) PctRank FROM Table1
        #   Ticker  Value_   Rank   PctRank=(RANK-1)/MAX(RANK) <-- NOT USING TOTAL RECORD COUNT=13!!
        #   ------  ------   ----   --------------------------
        #     'D'    NULL      1       100*0/11 =    0.00
        #     'K'    NULL      1       100*0/11 =    0.00
        #     'W'    NULL      1       100*0/11 =    0.00
        #     'X'      7       4       100*4/11 =   36.36
        #     'M'     11       5       100*5/11 =   45.45
        #     'C'     11       5       100*5/11 =   45.45
        #     'E'     11       5       100*5/11 =   45.45
        #     'G'     16       8       100*8/11 =   72.72
        #     'B'     16       8       100*8/11 =   72.72
        #     'Q'     21      10       100*10/11 =  90.91
        #     'N'     26      11       100*11/11 = 100.00
        #     'L'     26      11       100*11/11 = 100.00
        #     'A'     26      11       100*11/11 = 100.00
        # -----------------------------------------------------------------------------
        # NOTE: APPARENTLY THE SUPPORT FOR WINDOWS FUNCTIONS IN MONETLB IS LIMITED
        #    WINDOW FUNCTIONS: ROW_NUMBER, MIN_RANK, RANK, DENSE_RANK, PERCENT_RANK, CUME_DIST, MEDIAN
        #    AGGREGATE FUNCTIONS: N, SD, VAR, MEDIAN, COR
        # -----------------------------------------------------------------------------

        # Build key_ordering dictionary when applicable
        if key_ordering is not None and not isinstance(key_ordering, str):
            key_ordering = build_key_ordering_dict(
                key_ordering, keyspaces=subject.keyspaces
            )

        sql_template = JINJA_ENV.get_template("pct_rank.j2")

        sql_command = sql_template.render(
            src_table_name=subject.table_name,
            tgt_table_name=table_name,
            ranking_keyspaces=ranking_keyspaces,
            rank_direction="asc" if ascending else "desc",
            keyspaces=keyspaces,
            valuespaces=valuespaces,
            include_endpoints=include_endpoints,
            key_ordering=key_ordering,
            include_nulls_in_rank=include_nulls_in_rank,
            ranking_algo=ranking_algo.lower() if ranking_algo is not None else None,
            min_value=0.0 if min_value is None else min_value,
            max_value=100.0 if max_value is None else max_value,
        )

        execute(sql_command)

        # Establish col_info for copy
        if table_name == subject.table_name:
            col_info = None
        else:
            col_info = subject.get_space_info(
                info_type=[it1 for it1 in CUSTOM_INFO_TYPES if it1 != "fx"],
                space=keyspaces + valuespaces,
                omit_unassigned=True,
            )

        return Quble.from_table(
            table_name,
            col_info=col_info,
        )

    @RootLib.lazy_kwargs()
    def rank(
        self,
        ranking_keyspaces="<keyspaces>",
        ascending: bool = True,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        include_nulls_in_rank: bool = False,
        ranking_algo: str = None,
    ) -> Quble:
        """
        Ranks the valuespace column across the specified keyspace(s)
        The schema of the resultant table will match the original (self) table

        :param ranking_keyspaces: keyspaces (dimensions) to rank across [1,n]
        :type ranking_keyspaces: list of strings

        :param ascending: (optional) Direction of the sorting operation
        :type ascending: boolean (True/False)

        :param valuespace: valuespace(s) to rank across
        :type valuespace: str (a specific valuespace)
                        OR list of strings (specific valuespaces)
                        OR '<valuespaces>' OR '<all>' (all valuespaces)
                        OR '<valuespace>' (primary valuespace)

        :param key_ordering: (optional) Indicates whether/how to order result
                                    records within the keyspaces (index columns)
        :type key_ordering: None (no ordering of results), 'asc' or 'desc'

        :param include_nulls_in_rank: (optional) flag to include nulls in rank
                                    (treated as smallest value)
                                    otherwise rank for null values will be null
        :type include_nulls_in_rank: boolean (True/False*)

        :param ranking_algo: (optional) ranking algorithm
                               (otherwise dense ranking algorithm will be used)
        :type ranking_algo: str ("dense_rank", "rank", "row_number", None)
        """
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_empty:
            return self.copy()
        elif self.is_index:
            raise Exception("Valued Quble required, yet index Quble provided")

        # Apply view to self
        # [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.apply_view(view, allow_shallow_copy=True)
        if subject.is_empty:
            return subject.copy()

        # Get keyspaces & valuespace
        keyspaces = subject.keyspaces
        valuespaces = subject.validate_valuespace(
            valuespace, grace=False, coerce_to_list=True
        )
        if len(valuespaces) == 0:
            return self.copy()
        ranking_keyspaces = subject.validate_keyspace(
            ranking_keyspaces, grace=False, coerce_to_list=True
        )  # <-- May perform auto-linking

        table_name = generate_random_table_name()

        # -----------------------------------------------------------------------------
        # NOTE: IN SQL, RANKS START WITH ONE (NOT ZERO)
        # NOTE: NULLS ARE INCLUDED IN RANK (WITH LOWEST VALUE)
        #       AS SUCH WE WILL NEED TO:
        #         1) FIRST REMOVE NULLS FROM TABLE
        #         2) PERFORM RANK SUB-TABLE
        #         3) REINSERT THE NULL RECORDS WITH A NULL RANK
        # -----------------------------------------------------------------------------
        # NOTE: APPARENTLY THE SUPPORT FOR WINDOWS FUNCTIONS IN MONETDB IS LIMITED
        #    WINDOW FUNCTIONS: ROW_NUMBER, MIN_RANK, RANK, DENSE_RANK, PERCENT_RANK, CUME_DIST, MEDIAN
        #    AGGREGATE FUNCTIONS: N, SD, VAR, MEDIAN, COR
        # -----------------------------------------------------------------------------
        # Build key_ordering dictionary when applicable
        if key_ordering is not None and not isinstance(key_ordering, str):
            key_ordering = build_key_ordering_dict(
                key_ordering, keyspaces=subject.keyspaces
            )

        sql_template = JINJA_ENV.get_template("rank.j2")

        sql_command = sql_template.render(
            src_table_name=subject.table_name,
            tgt_table_name=table_name,
            ranking_keyspaces=ranking_keyspaces,
            rank_direction="asc" if ascending else "desc",
            keyspaces=keyspaces,
            valuespaces=valuespaces,
            key_ordering=key_ordering,
            include_nulls_in_rank=include_nulls_in_rank,
            ranking_algo=ranking_algo.lower() if ranking_algo is not None else None,
        )

        execute(sql_command)

        # Establish col_info for copy
        if table_name == subject.table_name:
            col_info = None
        else:
            col_info = subject.get_space_info(
                info_type=[it1 for it1 in CUSTOM_INFO_TYPES if it1 != "fx"],
                space=keyspaces + valuespaces,
                omit_unassigned=True,
            )

        # Instantiate Quble from the new table
        return Quble.from_table(
            table_name,
            col_info=col_info,
        )

    @RootLib.lazy_kwargs()
    def zscore_invnorm1d(
        self,
        keyspace: str = "<first_keyspace>",
        keymap: Quble = None,
        ascending: bool = True,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
    ) -> Quble:
        """
        Computes a zscore by first computing a percentile rank with
        non-inclusive endpoints, then applying an inverse Normal CDF.

        See :meth:`~qubles.core.quble.Quble.uniform_rank1d`
        """
        # Handle trivial cases
        if self.is_undefined or self.is_empty or self.is_nonvariate:
            return self.copy()

        keyspace = self.validate_keyspace(keyspace, grace=False, solo_required=True)
        if self.is_index:
            raise Exception("Valued Quble required, yet index Quble provided")

        # Validate valuespace
        valuespace = self.validate_valuespace(
            valuespace, grace=False, numeric_required=True
        )

        # Isolate valuespaces as subject
        # [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # Apply view to subject
        # ------------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)
        if subject.is_empty:
            remaining_keyspaces = subject.ortho_keyspaces(keyspace)
            return subject.select(
                column_names=remaining_keyspaces + subject.valuespaces
            )

        # Perform percentile ranking
        # across the specified keyspace
        # use view=None here as view has already been applied to subject
        if keymap is None:
            x = subject.uniform_rank1d(
                keyspace=keyspace,
                ascending=ascending,
                ignore_missing=ignore_missing,
                include_endpoints=False,
                pct_required=pct_required,
                valuespace=valuespace,
                view=None,
                key_ordering=key_ordering,
            )
        else:
            x = subject.sub_uniform_rank1d(
                keymap=keymap,
                keyspace=keyspace,
                ascending=ascending,
                ignore_missing=ignore_missing,
                include_endpoints=False,
                pct_required=pct_required,
                valuespace=valuespace,
                view=None,
                key_ordering=key_ordering,
            )

        # Since we are now using uniform_rank1d,
        # x is now a float in (0.0, 1.0), not inclusive of endpoints.
        # Before calling the inverse normal cdf,
        # transform x to a unit scale (0,1).
        # Set controls...
        controls = {"ignore_mult": False}
        if subject.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            # x = 0.01 * x
            z = x.inv_normal_cdf()
            return z

    @RootLib.lazy_kwargs()
    def zscore1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        view=RootLib.lazy_eval("view"),
        winsorize_level: float = None,
        outliers_to_missing: bool = False,
        compress: bool = RootLib.lazy_eval("auto_compress"),
    ) -> Quble:
        """
        Generates z-score for the specified valuespace(s) across the specified keyspace

        :param keyspace: keyspace to compute z-score across
        :type keyspace: string

        :param valuespace: valuespace(s) for z-score computation
        :type valuespace: string or list of strings
                      (keywords may be used such as '<valuespaces>', '<valuespace>', etc.
                      [See: :meth:`~qubles.core.quble.Quble.validate_valuespace`]

        :param ignore_missing: flag to ignore missing/null values
        :type ignore_missing: bool

        :param pct_required:
            Control for necessary support across distinct keys of the specified
            keyspace. Value must be: 0.0 <= pct_required <= 1.0
        :type pct_required: None or float

        :param view: Quble indicating conditional elements
                     for which aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :param winsorize_level: Post-zscore winsorization (truncation) level (e.g., 3.0)
        :type winsorize_level: None or float (symmetric) or two-element tuple/list: (min,max)

        :param outliers_to_missing (bool): (False*/True) Outlier treatment...
               False (default): set outliers to min/max parameters
               True: set outliers to null / missing value

        :param compress: flag for compressing resultant Quble
                               (only applicable if outliers_to_missing=True)
               False (default): DO NOT remove records where the specified space / column is null/missing_value
               True: Remove records where the specified space / column is null/missing_value
        """
        # Handle trivial cases
        if self.is_undefined or self.is_empty or self.is_nonvariate:
            return self.copy()

        # Validate keyspace
        keyspace = self.validate_keyspace(keyspace, grace=False, solo_required=True)

        # Validate valuespace
        valuespace = self.validate_valuespace(
            valuespace, grace=False, coerce_to_list=True, numeric_required=True
        )

        # Isolate valuespaces as subject
        # [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # Apply view to subject
        # ------------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)
        if subject.is_empty:
            remaining_keyspaces = subject.ortho_keyspaces(keyspace)
            return subject.select(
                column_names=remaining_keyspaces + subject.valuespaces
            )

        # use view=None here as view has already been applied to subject
        mu = subject.mean1d(
            keyspace=keyspace,
            valuespace=subject.valuespaces,
            ignore_missing=ignore_missing,
            auto_squeeze=True,
            pct_required=pct_required,
            num_required=num_required,
            view=None,
        )
        sigma = subject.std1d(
            keyspace=keyspace,
            valuespace=subject.valuespaces,
            ignore_missing=ignore_missing,
            auto_squeeze=True,
            pct_required=pct_required,
            num_required=num_required,
            view=None,
        )

        controls = {"ignore_mult": False, "ignore_add": False}
        if subject.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            z = (subject - mu) / sigma

        if winsorize_level is not None:
            if type(winsorize_level) in (tuple, list):
                z = z.truncate(
                    min_value=winsorize_level[0],
                    max_value=winsorize_level[1],
                    space=z.valuespaces,
                    outliers_to_missing=outliers_to_missing,
                    compress=compress,
                )
            else:
                z = z.truncate(
                    min_value=(-1.0 * winsorize_level),
                    max_value=winsorize_level,
                    space=z.valuespaces,
                    outliers_to_missing=outliers_to_missing,
                    compress=compress,
                )
        return z

    @RootLib.lazy_kwargs()
    def zscorex1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        view=RootLib.lazy_eval("view"),
        winsorize_level: float = None,
        outliers_to_missing: bool = False,
        compress: bool = RootLib.lazy_eval("auto_compress"),
    ) -> Quble:
        """
        Generates z-score for the specified valuespace(s)
        across the orthogonals to the specified keyspace

        :meth:`~qubles.core.quble.Quble.zscore1d`
        """
        # Handle trivial cases
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate keyspace
        keyspace = self.validate_keyspace(keyspace, grace=False, solo_required=True)

        # Validate valuespace
        valuespace = self.validate_valuespace(
            valuespace, grace=False, coerce_to_list=True, numeric_required=True
        )

        # Isolate valuespaces as subject
        # [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # Apply view to subject
        # ------------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)
        if subject.is_empty:
            remaining_keyspaces = subject.ortho_keyspaces(keyspace)
            return subject.select(
                column_names=remaining_keyspaces + subject.valuespaces
            )

        # use view=None here as view has already been applied to subject
        xmu = subject.meanx1d(
            keyspace=keyspace,
            valuespace=subject.valuespaces,
            ignore_missing=ignore_missing,
            auto_squeeze=False,
            pct_required=pct_required,
            num_required=num_required,
            view=None,
        )
        xsigma = subject.stdx1d(
            keyspace=keyspace,
            valuespace=subject.valuespaces,
            ignore_missing=ignore_missing,
            auto_squeeze=False,
            pct_required=pct_required,
            num_required=num_required,
            view=None,
        )

        # Set controls...
        controls = {"ignore_mult": False, "ignore_add": False}
        if subject.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            z = (subject - xmu) / xsigma

        # Winsorize (as directed)
        if winsorize_level is None:
            pass
        elif type(winsorize_level) in (tuple, list):
            z = z.truncate(
                min_value=winsorize_level[0],
                max_value=winsorize_level[1],
                space=z.valuespaces,
                outliers_to_missing=outliers_to_missing,
                compress=compress,
            )
        else:
            z = z.truncate(
                min_value=(-1.0 * winsorize_level),
                max_value=winsorize_level,
                space=z.valuespaces,
                outliers_to_missing=outliers_to_missing,
                compress=compress,
            )
        return z

    @RootLib.lazy_kwargs()
    def mzscore1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        valuespace="<numeric_valuespaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        view=RootLib.lazy_eval("view"),
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
        winsorize_level: float = None,
        outliers_to_missing: bool = False,
    ) -> Quble:
        """
        Generates moving z-score for the specified valuespace(s)
        across the orthogonals to the specified keyspace

        :meth:`~qubles.core.quble.Quble.zscore1d`
        """
        # Handle trivial cases
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate keyspace
        keyspace = self.validate_keyspace(keyspace, grace=False, solo_required=True)

        # Validate valuespace
        valuespace = self.validate_valuespace(
            valuespace, grace=False, numeric_required=True
        )

        # Isolate valuespaces as subject
        # [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # Apply view to subject
        # ------------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)
        if subject.is_empty:
            return subject.copy() if subject.shares_table_with(self) else subject

        mu = subject.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            valuespace=subject.valuespaces,
            pct_required=pct_required,
            aggr_method="mean",
            ignore_missing=ignore_missing,
            # use view=None here as view has already been applied to subject
            view=None,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
        )

        sigma = subject.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            valuespace=subject.valuespaces,
            pct_required=pct_required,
            aggr_method="std",
            ignore_missing=ignore_missing,
            # use view=None here as view has already been applied to subject
            view=None,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
        )

        # Set controls...
        controls = {"ignore_mult": False, "ignore_add": False}
        if subject.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            z = (subject - mu) / sigma  # <-- DO NOT IMPOSE CASE ON RESULT

        if winsorize_level is None:
            pass
        elif type(winsorize_level) in (tuple, list):
            z = z.truncate(
                min_value=winsorize_level[0],
                max_value=winsorize_level[1],
                space=z.valuespaces,
                outliers_to_missing=outliers_to_missing,
                compress=compress,
            )
        else:
            z = z.truncate(
                min_value=(-1.0 * winsorize_level),
                max_value=winsorize_level,
                space=z.valuespaces,
                outliers_to_missing=outliers_to_missing,
                compress=compress,
            )
        return z

    @RootLib.lazy_kwargs()
    def demean1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        view=RootLib.lazy_eval("view"),
    ) -> Quble:
        # Handle trivial cases
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate keyspace
        keyspace = self.validate_keyspace(keyspace, grace=False, solo_required=True)

        # Validate valuespace
        valuespace = self.validate_valuespace(
            valuespace, grace=False, numeric_required=True
        )

        # Isolate valuespaces as subject
        # [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # Apply view to subject
        # ------------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)
        if subject.is_empty:
            remaining_keyspaces = subject.ortho_keyspaces(keyspace)
            return subject.select(
                column_names=remaining_keyspaces + subject.valuespaces
            )

        mu = subject.mean1d(
            keyspace=keyspace,
            valuespace=valuespace,
            ignore_missing=ignore_missing,
            auto_squeeze=True,
            pct_required=pct_required,
            num_required=num_required,
            # use view=None here as view has already been applied to subject
            view=None,
        )

        # Set controls...
        controls = {"ignore_mult": False, "ignore_add": False}
        if subject.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            dm = subject - mu
        return dm

    @RootLib.lazy_kwargs()
    def demeanx1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        view=RootLib.lazy_eval("view"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
    ) -> Quble:
        # Handle trivial cases
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate keyspace
        keyspace = self.validate_keyspace(keyspace, grace=False, solo_required=True)

        # Validate valuespace
        valuespace = self.validate_valuespace(
            valuespace, grace=False, numeric_required=True
        )

        # Isolate valuespaces as subject
        # [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # Apply view to subject
        # ------------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)
        if subject.is_empty:
            return subject.select(column_names=[keyspace] + subject.valuespaces)

        xmu = subject.meanx1d(
            keyspace=keyspace,
            valuespace=subject.valuespaces,
            ignore_missing=ignore_missing,
            auto_squeeze=False,
            pct_required=pct_required,
            num_required=num_required,
            # use view=None here as view has already been applied to subject
            view=None,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
        )

        # Set controls...
        controls = {"ignore_mult": False, "ignore_add": False}
        if subject.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            dm = subject - xmu
        return dm

    @RootLib.lazy_kwargs()
    def mdemean1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        valuespace="<numeric_valuespaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        view=RootLib.lazy_eval("view"),
        compress: bool = RootLib.lazy_eval("auto_compress"),
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        tfill_end_mode="<space_root>",
    ) -> Quble:
        # Handle trivial cases
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate keyspace
        keyspace = self.validate_keyspace(keyspace, grace=False, solo_required=True)

        # Validate valuespace
        valuespace = self.validate_valuespace(
            valuespace, grace=False, numeric_required=True
        )

        # Isolate valuespaces as subject
        # [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # Apply view to subject
        # ------------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)
        if subject.is_empty:
            return subject.copy() if subject.shares_table_with(self) else subject

        mu = subject.maggregate1d(
            periods=periods,
            keyspace=keyspace,
            valuespace=subject.valuespaces,
            pct_required=pct_required,
            aggr_method="mean",
            ignore_missing=ignore_missing,
            # use view=None here as view has already been applied to subject
            view=None,
            compress=compress,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
            tfill_end_mode=tfill_end_mode,
        )

        # Set controls...
        controls = {"ignore_mult": False, "ignore_add": False}
        if subject.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            mdm = subject - mu
        return mdm

    @RootLib.lazy_kwargs()
    def sub_zscore1d(
        self,
        keymap: Quble,
        keyspace: str,
        valuespace="<numeric_valuespaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        view=RootLib.lazy_eval("view"),
        winsorize_level: float = None,
        outliers_to_missing: bool = False,
        compress: bool = RootLib.lazy_eval("auto_compress"),
    ) -> Quble:
        # Handle trivial cases
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate keyspace
        keyspace = self.validate_keyspace(keyspace, grace=False, solo_required=True)

        # Validate valuespace
        valuespace = self.validate_valuespace(
            valuespace, grace=False, numeric_required=True
        )

        # Isolate valuespaces as subject
        # [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # Apply view to subject
        # ------------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)
        if subject.is_empty:
            remaining_keyspaces = subject.ortho_keyspaces(keyspace)
            return subject.select(
                column_names=remaining_keyspaces + subject.valuespaces
            )

        if keymap.valuespace is not None:
            tgt_keyspace = keymap.valuespace
        else:
            tgt_keyspace = "__groups__"  # <-- arbitraily chosen, but will not show up in result since unmap_flag=True

        # NOTE: DO NOT SEND/PROPAGATE ORIGINAL view ARG ON TO sub_aggregate1d() METHODS BELOW
        #       ...want to honor RootLib().set_control('view', view) as assigned above
        mu = subject.sub_aggregate1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            valuespace=subject.valuespaces,
            aggr_method="mean",
            ignore_missing=ignore_missing,
            # use view=None here as view has already been applied to subject
            view=None,
            link_check=link_check,
            unmap_flag=True,
        )

        sigma = subject.sub_aggregate1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            valuespace=subject.valuespaces,
            aggr_method="std",
            ignore_missing=ignore_missing,
            # use view=None here as view has already been applied to subject
            view=None,
            link_check=link_check,
            unmap_flag=True,
        )

        # Set controls...
        controls = {"ignore_mult": False, "ignore_add": False}
        if subject.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            z = (subject - mu) / sigma

        if winsorize_level is None:
            pass
        elif type(winsorize_level) in (tuple, list):
            z = z.truncate(
                min_value=winsorize_level[0],
                max_value=winsorize_level[1],
                space=z.valuespaces,
                outliers_to_missing=outliers_to_missing,
                compress=compress,
            )
        else:
            z = z.truncate(
                min_value=(-1.0 * winsorize_level),
                max_value=winsorize_level,
                space=z.valuespaces,
                outliers_to_missing=outliers_to_missing,
                compress=compress,
            )
        return z

    @RootLib.lazy_kwargs()
    def sub_demean1d(
        self,
        keymap,
        keyspace,
        valuespace="<numeric_valuespaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        view=RootLib.lazy_eval("view"),
    ) -> Quble:
        # Handle trivial cases
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate keyspace
        keyspace = self.validate_keyspace(keyspace, grace=False, solo_required=True)

        # Validate valuespace
        valuespace = self.validate_valuespace(
            valuespace, grace=False, numeric_required=True
        )

        # Isolate valuespaces as subject
        # [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # Apply view to subject
        # ------------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)
        if subject.is_empty:
            remaining_keyspaces = subject.ortho_keyspaces(keyspace)
            return subject.select(
                column_names=remaining_keyspaces + subject.valuespaces
            )

        if keymap.valuespace is not None:
            tgt_keyspace = keymap.valuespace
        else:
            tgt_keyspace = "__groups__"  # <-- arbitraily chosen, but will not show up in result since unmap_flag=True

        # NOTE: DO NOT SEND/PROPAGATE ORIGINAL view ARG ON TO sub_aggregate1d() METHODS BELOW
        #       ...want to honor RootLib().set_control('view', view) as assigned above
        mu = subject.sub_aggregate1d(
            keymap=keymap,
            keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            valuespace=subject.valuespaces,
            aggr_method="mean",
            ignore_missing=ignore_missing,
            # use view=None here as view has already been applied to subject
            view=None,
            link_check=link_check,
            unmap_flag=True,
        )
        # Set controls...
        controls = {"ignore_mult": False, "ignore_add": False}
        if subject.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            dm = subject - mu
        return dm

    @RootLib.lazy_kwargs()
    def value_range(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<numeric_valuespaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        view=RootLib.lazy_eval("view"),
        as_literal_scalar: bool = False,
    ) -> Quble:
        """
        Returns the value range of a (numeric-valued) Quble
        as a univariate Quble
        """
        # Handle trivial cases
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate aggr_keyspaces
        # May perform auto-linking
        aggr_keyspaces = self.validate_keyspace(
            aggr_keyspaces, grace=False, coerce_to_list=True
        )

        # Validate valuespace (numeric valuespace(s) only)
        valuespace = self.validate_valuespace(
            valuespace, grace=False, coerce_to_list=True, numeric_required=True
        )

        # Isolate valuespaces as subject
        # [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # Apply view to subject
        # ------------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)

        if subject.is_empty:
            remaining_keyspaces = subject.ortho_keyspaces(aggr_keyspaces)
            result = subject.select(
                column_names=remaining_keyspaces + subject.valuespaces
            )
        else:
            # Procure min_value
            min_value = subject.min(
                aggr_keyspaces=aggr_keyspaces,
                valuespace=subject.valuespaces,
                view=view,
                ignore_missing=ignore_missing,
                pct_required=pct_required,
                num_required=num_required,
            )
            # Procure max_value
            max_value = subject.max(
                aggr_keyspaces=aggr_keyspaces,
                valuespace=subject.valuespaces,
                view=view,
                ignore_missing=ignore_missing,
                pct_required=pct_required,
                num_required=num_required,
            )
            # Set controls...
            controls = {
                "ignore_mult": False,
                "ignore_add": False,
                "ignore_compare": False,
            }
            if subject.is_multivariate:
                controls["variate_mode"] = "multi"

            with ControlContextManager(controls=controls) as ccm:
                result = max_value - min_value

                # Apply coverage conditions
                if not ignore_missing:
                    has_missing_samples = subject.has_missing(
                        aggr_keyspaces=aggr_keyspaces,
                        valuespace=result.valuespaces,
                        view=None,
                    )
                    result.conditional_nullify_inplace(
                        has_missing_samples, valuespace=result.valuespaces
                    )

                elif pct_required is not None and pct_required > 0.0:
                    pct_non_missing = subject.pct_non_missing(
                        aggr_keyspaces=aggr_keyspaces,
                        valuespace=subject.valuespaces,
                        view=None,
                        unfolded=False,
                        key_ordering=None,
                        auto_squeeze=True,
                        pre_cross_fill=True,
                        pre_fill=False,
                    )
                    insufficient_samples = pct_non_missing <= pct_required
                    result.conditional_nullify_inplace(
                        insufficient_samples, valuespace=result.valuespaces
                    )

        # Apply literal scalar when applicable
        if not as_literal_scalar:
            pass
        elif result.is_scalar:
            result = result.scalar_value
        elif result.is_multiscalar:
            result = result.scalar_values

        return result

    def shifts_iterator(
        self, shift1, result, subject, keyspace, tfill_end_mode, shift_keyspace
    ):
        if not isinstance(shift1, int):
            shift1 = int(shift1)
        if not isinstance(shift1, int):
            raise Exception(
                f"Bad shifts arg...shift1:{shift1} not-coercable to integer...type(shift1):{type(shift1)}"
            )
        if shift1 == 0:
            shifted_quble = subject
        else:
            shifted_quble = subject.shift1d(
                periods=shift1, keyspace=keyspace, tfill_end_mode=tfill_end_mode
            )
        local_result = shifted_quble.insert_keyspace(
            keyspace=shift_keyspace, key=shift1, col_type="int"
        )
        # Merge local records with result
        if local_result is None or local_result.is_undefined:
            pass
        elif result is None or result.is_undefined:  # or result.is_empty:
            result = local_result
        elif local_result.is_empty:
            pass
        elif result.is_empty:
            result = local_result
        else:
            result = local_result
        return result

    def multi_shift1d(
        self,
        shifts,
        keyspace: str = "<first_time_keyspace>",
        valuespace="<valuespaces>",
        shift_keyspace: str = "shift",
        tfill_end_mode="<space_root>",
    ) -> Quble:
        """
        Implements multiple shifts over the specified time-keyspace
        for the specified valuespaces by introducing a new shift keyspace

        :param shifts: shifting counts
        :type shifts: scalar int, list/tuple/np.ndarray of ints, comma-delimited string,
                      Quble scalar or single-dimension Quble (non-valued) index

        :param keyspace: time-keyspace to be shifted
        :type keyspace: string

        :param valuespace: Specific valuespace(s) column(s) to be shifted
                           (only the specified valuespaces will be retained)
        :type valuespace: {q_keyspace_type}

        :param shift_keyspace: new keyspace to delineate shifted results
        :type shift_keyspace: string

        :returns: The (temporally-shifted) resultant Quble
        :rtype: qubles.core.quble.Quble
        """
        # Handle trivial cases
        if self.is_undefined:
            raise UndefinedQubleError("Quble is undefined")
        elif self.is_nonvariate:
            # is_nonvariate:True ==> self.valuespace=None
            raise Exception(
                "valued Quble required, yet index (non-valued) Quble provided"
            )

        # Validate (time) keyspace arg...
        # ---------------------------------
        keyspace = self.validate_keyspace(
            keyspace, grace=False, solo_required=True, time_space_required=True
        )

        if not self.is_time_space(space=keyspace, grace=False):
            raise Exception(f"non-time-keyspace:{keyspace}")

        # Validate shift_keyspace if present in self...
        # ---------------------------------------------
        if shift_keyspace is None:
            raise Exception("shift_keyspace arg required")
        elif shift_keyspace in self.keyspaces:
            raise Exception(f"Pre-existing shift_keyspace: {shift_keyspace}")

        # Validate valuespace
        # ---------------------
        valuespace = self.validate_valuespace(
            valuespace, grace=False, coerce_to_list=True
        )

        # Isolate valuespaces as subject
        # [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # --------------------------------------
        # Convert shifts to nparray of ints
        # --------------------------------------

        # CASE #1: shifts is None
        if shifts is None:
            return subject.copy()
            # return Exception('shifts arg is None')
        # CASE #2: shifts is str arg
        # of comma-delimited integer-freindlyu strings
        elif isinstance(shifts, str):
            shifts = np.array(
                [int(shift1) for shift1 in shifts.split(",")], dtype=np.int32
            )
        # CASE #3: shifts is (integer-friendly) literal scalar
        elif np.isscalar(shifts):
            shifts = np.array([shifts], np.int32)
        # CASE #4: shifts is scalar Quble or (single-dimension) index Quble
        elif isinstance(shifts, Quble):
            if shifts.is_scalar:
                shifts = np.array([shifts.scalar_value], np.int32)
            elif shifts.is_empty:
                return Exception("shifts arg is empty Quble")
            elif shifts.is_index:
                if len(shifts.keyspaces) != 1:
                    raise Exception(
                        "shifts arg in Quble form requires scalar or single-dimension index"
                    )

                old_keyspace = shifts.keyspaces[0]
                if shifts.is_int(space=old_keyspace, grace=False):
                    # Change the keyspace name
                    shifts = shifts.get_column(column_name=old_keyspace)
                elif shifts.is_float(space=old_keyspace, grace=False):
                    # Change the type and keyspace name
                    shifts = shifts.change_type(
                        new_type="int", space=old_keyspace
                    ).get_column(column_name=old_keyspace)
                else:
                    raise Exception(
                        "shifts arg as single-dimension Quble index must be type int (or float)"
                    )
            else:
                raise Exception(
                    "shifts arg in Quble form requires scalar or single-dimension index"
                )
        # CASE #5: shifts is a list or tuple
        elif isinstance(shifts, (list, tuple)):
            shifts = np.array(shifts, np.int32)
        # CASE #6: Other/invalid shifts
        elif not isinstance(shifts, np.ndarray):
            raise Exception(
                "Invalid shifts arg:{0}...list/tuple/nparray of integers OR scalar Quble OR 1-D index Quble expected".format(
                    shifts
                )
            )
        # CASE #7: shifts is a structured np.ndarray
        elif is_structured_dtype(shifts.dtype):
            shifts = Quble.from_struct_array()
        # CASE #8: shifts is a non-structured np.ndarray
        else:
            shifts = np.array(shifts, np.int32)

        # --------------------------------
        # Apply shifts iteratively
        # --------------------------------
        # When shifts is an empty list,
        # we return an trivial Quble()
        # --------------------------------
        result = Quble.undefined_instance()
        """
        final_result = Quble.undefined_instance()
        result_list = []

        func = partial(
            self.shifts_iterator,
            result=result,
            subject=subject,
            keyspace=keyspace,
            tfill_end_mode=tfill_end_mode,
            shift_keyspace=shift_keyspace,
        )
        for i in range(0, 3):
            try:
                with Pool() as pool:
                    result_list = pool.map(func, [shift1 for shift1 in shifts])
            except:
                _logger.debug("shifts iterator  excepted, retrying..")
                continue
            break

        for resultant_quble in result_list:
            final_result = final_result.merge(
                resultant_quble, self_precedence=True, variate_mode="multi"
            )
        return final_result
        """
        for shift1 in shifts:
            if not isinstance(shift1, int):
                shift1 = int(shift1)
            if not isinstance(shift1, int):
                raise Exception(
                    f"Bad shifts arg...shift1:{shift1} not-coercable to integer...type(shift1):{type(shift1)}"
                )
            if shift1 == 0:
                shifted_quble = subject
            else:
                shifted_quble = subject.shift1d(
                    periods=shift1, keyspace=keyspace, tfill_end_mode=tfill_end_mode
                )

            local_result = shifted_quble.insert_keyspace(
                keyspace=shift_keyspace, key=shift1, col_type="int"
            )

            # Merge local records with result
            if local_result is None or local_result.is_undefined:
                pass
            elif result is None or result.is_undefined:  # or result.is_empty:
                result = local_result
            elif local_result.is_empty:
                pass
            elif result.is_empty:
                result = local_result
            else:
                # Use variate_mode='multi' here for merging
                # as we know that valuespaces will match across iterations
                # and we would like to retain the original multi-variate state
                result.merge_inplace(
                    local_result, self_precedence=True, variate_mode="multi"
                )

        return result

    def run_window_loop(
        self,
        window1,
        missing_int,
        stagger_keys,
        subject_with_freq_idx,
        apply_delay_per_window,
        num_stagger,
        stagger_pcts,
        start_offset,
        keyspace,
        tfill_method,
        tfill_end_mode,
        tfill_honor_nulls,
        window_keyspace,
        num_stagger_was_none,
        windows,
        stagger_keyspace,
        result,
    ):
        column_expressions = {}
        if not isinstance(window1, int):
            window1 = int(window1)
        # Double check window1
        if (window1 == missing_int) or (window1 <= 0):
            raise Exception(f"Invalid window: {window1}...integer > 0 expected")
        if apply_delay_per_window:
            # To implement delay, we affiliate current data with a future date/freq_idx
            column_expressions["freq_idx"] = f'("freq_idx" + {str(window1)})'
        # ------------------------- START: STAGGER LOOP ---------------------------
        for stagger_no, stagger_key1 in enumerate(stagger_keys):
            if np.abs(num_stagger) > 1:
                stagger_offset = int(
                    np.round(stagger_pcts[stagger_no] * float(window1))
                )
                # Double check stagger_offset
                if (stagger_offset == missing_int) or (stagger_offset < 0):
                    raise Exception(
                        "Internal inconsistency...Invalid stagger_offset:{0}".format(
                            stagger_offset
                        )
                    )
            else:
                stagger_offset = 0
            # Select then fill appropriate cyclical records,
            # based on current start_offet, stagger_offset & window1
            # --------------------------------------------------------
            where_clause = 'WHERE ((("freq_idx" - {0} + {1}) % {2}) = 0)'.format(
                start_offset, stagger_offset, window1
            )
            temp_result1 = subject_with_freq_idx.select(
                where_clause=where_clause, column_expressions=column_expressions
            )
            local_result = temp_result1.freq_idx_to_datetime1d(
                space="freq_idx", timespace=keyspace
            )
            # When applicable, we need to fill (window1-1)
            # (as we aleady have one record for this window1 cycle)
            if tfill_method is not None:
                local_result = local_result.fill1d(
                    keyspace=keyspace,
                    valuespace=local_result.valuespaces,
                    tfill_method=tfill_method,
                    tfill_max=(window1 - 1),
                    # Could consider hardcoding: tfill_end_mode='no_extension'
                    tfill_end_mode=tfill_end_mode,
                    tfill_honor_nulls=tfill_honor_nulls,
                )
            # Augment local_result with ortho_index
            # for this window1 & stagger_key1
            hyper_key = {}
            hyper_col_types = {}
            if window_keyspace is not None:
                hyper_key[window_keyspace] = window1
                hyper_col_types[window_keyspace] = "int"
            elif len(windows) > 1:
                raise Exception(
                    f"window_keyspace arg required for for #windows:{len(windows)}"
                )
            if not num_stagger_was_none:
                hyper_key[stagger_keyspace] = stagger_key1
                hyper_col_types[stagger_keyspace] = (
                    "varchar(8)"  # <-- Should be big enough to hold keys
                )
            if len(hyper_key) > 0:
                local_result = local_result.insert_keyspaces(
                    hyper_key=hyper_key, hyper_col_types=hyper_col_types
                )
            # Merge local records with result
            if local_result is None or local_result.is_undefined:
                pass
            elif result is None or result.is_undefined:  # or result.is_empty:
                result = local_result
            elif local_result.is_empty:
                pass
            elif result.is_empty:
                result = local_result
            else:
                # Use variate_mode='multi' here for merging
                # as we know that valuespaces will match across iterations
                # and we would like to retain the original multi-variate state
                result.merge_inplace(
                    local_result, self_precedence=True, variate_mode="multi"
                )
        return result

    def multi_hold1d(
        self,
        windows,
        keyspace: str = "<first_time_keyspace>",
        valuespace="<valuespaces>",
        window_keyspace: str = "Windows",
        num_stagger: int = None,
        stagger_keyspace: str = "Stagger",
        force_first_key: bool = True,
        apply_delay_per_window=False,
        tfill_method="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Implements a (possibly staggered) 'hold' over the specified time-keyspace
        (for the values in the specified valuespaces)
        using multiple windows and possible multiple stagger/offset points
        Introduces new window_keyspace (and possibly stagger_keyspace)

        :param windows: the window size(s) for holding (specified in # periods of underlying frequency)
        :type windows: scalar int, list/tuple/np.ndarray of ints or comma-delimited string (multi-windows)
                       or Quble scalar or single-dimension, non-variate (index) Quble

        windows may be an integer (single window), a list of integers (multi-windows) or a comma-delimited string (multi-windows)
        For window=1 or [1] (e.g., single, unitary window), the window_keyspace will not be present in the result

        :param keyspace: time-keyspace to be held
        :type keyspace: string

        :param valuespace: Specific valuespace(s) column(s) to be shifted
                           (only the specified valuespaces will be retained)
        :type valuespace: {q_keyspace_type}

        :param window_keyspace: new keyspace to delineate respective window held results
        :type window_keyspace: string
            ==> For single window (#windows=1), can set window_keyspace=None
            ==> In this case, the resultant Quble will NOT exhibit a window_keyspace

        :param num_stagger: number of staggered starting points for each holding cycle
        :type num_stagger: int (or None)

        :param stagger_keyspace: new keyspace to delineate staggering
        :type stagger_keyspace: string

        :param force_first_key: flag to force first date as the start of each window'w cycle
        :type force_first_key: bool (True*/False)

        :param apply_delay_per_window: flag to delay each window cycle by the window size
        :type apply_delay_per_window: bool (False*/True)

        :param tfill_method: time filling method for each cycle's window
        :type tfill_method: string or None (No filling)

        :param tfill_end_mode: time filling end-mode for each cycle's window
        :type tfill_end_mode: string

        :param pre_cross_fill: flag to control whether to pre-cross-fill
                           when some keyspaces being aggregated are a time keyspaces
                           and ortho_resampling_keyspaces also exist
        :type pre_cross_fill: boolean (True*/False)

        :param pre_fill: flag to control whether to pre-fill
                         when some being aggregated are resampling keyspaces
        :type pre_fill: boolean (True/False*)

        :returns: The (temporally-held) resultant Quble
        :rtype: qubles.core.quble.Quble

        """
        # Handle trivial cases
        if self.is_undefined:
            raise UndefinedQubleError("Quble is undefined")
        elif self.is_nonvariate:
            # is_nonvariate:True ==> self.valuespace=None
            raise Exception(
                "valued Quble required, yet index (non-valued) Quble provided"
            )
        elif self.is_empty:
            return self.copy()

        # Validate keyspace arg...
        # ---------------------------
        keyspace = self.validate_keyspace(keyspace, grace=False, solo_required=True)
        if not self.is_time_space(space=keyspace, grace=False):
            raise Exception(f"non-time-keyspace:{keyspace}")

        # Validate valuespace (numeric valuespace(s) only)
        valuespace = self.validate_valuespace(
            valuespace, grace=False, coerce_to_list=True, numeric_or_bool_required=True
        )

        # Isolate valuespaces as subject
        # [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # NOTE: Apply pre_cross_fill BEFORE pre_fill
        if pre_cross_fill:
            subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)

        if pre_fill:
            subject = subject._apply_pre_fill(allow_shallow_copy=True)

        # Double-check for trivial subject
        if subject is None or subject.is_empty:
            raise Exception("Internal inconsistency...subject is None or empty")

        # --------------------------------------
        # Convert windows to np.array of ints
        # --------------------------------------

        # CASE #1: windows is None
        if windows is None:
            # return Exception('windows arg is None')
            windows = np.array([1], dtype=np.int32)
        # CASE #2: windows is str arg
        # of comma-delimited integer-friendly strings
        elif isinstance(windows, str):
            windows = np.array(
                [int(window1) for window1 in windows.split(",")], dtype=np.int32
            )
        # CASE #3: windows is (integer-friendly) literal scalar
        elif np.isscalar(windows):
            windows = np.array([windows], np.int32)
        # CASE #4: windows is scalar Quble or (single-dimension) index Quble
        elif isinstance(windows, Quble):
            if windows.is_scalar:
                windows = np.array([windows.scalar_value], np.int32)
            elif windows.is_empty:
                return Exception("windows arg is empty Quble")
            elif windows.is_index:
                if len(windows.keyspaces) != 1:  # or windows.ndim != 1
                    raise Exception(
                        "windows arg in Quble form requires scalar or single-dimension index"
                    )

                old_keyspace = windows.keyspaces[0]
                if windows.is_int(space=old_keyspace, grace=False):
                    # Change the keyspace name
                    windows = windows.get_column(column_name=old_keyspace)
                elif windows.is_float(space=old_keyspace, grace=False):
                    # Change the type and keyspace name
                    windows = windows.change_type(
                        new_type="int", space=old_keyspace
                    ).get_column(column_name=old_keyspace)
                else:
                    raise Exception(
                        "shifts arg as single-dimension Quble index must be type int (or float)"
                    )
            else:
                raise Exception(
                    "shifts arg in Quble form requires scalar or single-dimension index"
                )
        # CASE #5: windows is a list, tuple or np.ndarray
        elif isinstance(windows, (np.ndarray, list, tuple)):
            windows = np.array(windows, np.int32)
        # CASE #6: Other/invalid windows
        else:
            raise Exception(
                "Invalid windows arg:{0}...list/tuple/nparray of integers OR scalar Quble OR 1-D index Quble expected".format(
                    windows
                )
            )

        # Validate window_keyspace if present in self...
        # ---------------------------------------------
        if window_keyspace is None:
            if len(windows) > 1:
                raise Exception(
                    f"window_keyspace arg required for for #windows:{len(windows)}"
                )
            else:
                pass
        elif window_keyspace in self.keyspaces:
            raise Exception(f"Pre-existing window_keyspace: {window_keyspace}")

        # Validate num_stagger arg...
        # -------------------------------
        num_stagger_was_none = False
        if num_stagger is None:
            num_stagger = 1
            num_stagger_was_none = True
        elif not np.isscalar(num_stagger):
            raise Exception("Invalid num_stagger: non-zero integer expected")
        else:
            # In case a float (or other) is provided
            num_stagger = int(np.round(num_stagger))

        if num_stagger <= 0:
            raise Exception("Invalid num_stagger: positive integer expected")

        # Validate stagger_keyspace if present in subject...
        # ---------------------------------------------------
        if num_stagger is None or np.abs(num_stagger) == 1:
            # Here, stagger_keyspace is not relevant
            # when num_stagger is trivial
            pass
        elif stagger_keyspace is None:
            raise Exception(
                "stagger_keyspace arg required for non-trivial num_stagger:{0}".format(
                    num_stagger
                )
            )
        elif stagger_keyspace in subject.keyspaces:
            raise Exception(f"Pre-existing stagger_keyspace: {stagger_keyspace}")
        elif stagger_keyspace == window_keyspace:
            raise Exception(
                "stagger_keyspace: {0} must be distinct from window_keyspace".format(
                    stagger_keyspace
                )
            )

        # Build stagger_pcts (list) from num_stagger arg
        # ---------------------------------------------------------
        stagger_pcts_interval = np.min(
            np.array([np.max(np.array([(1.0 / float(np.abs(num_stagger))), 0.0])), 1.0])
        )
        stagger_pcts = np.repeat(0.0, np.abs(num_stagger))  # <-- Initialization
        stagger_keys = []
        for stagger_no in range(0, np.abs(num_stagger)):
            stagger_pcts[stagger_no] = np.min(
                np.array(
                    [
                        np.max(
                            np.array([(float(stagger_no) * stagger_pcts_interval), 0.0])
                        ),
                        1.0,
                    ]
                )
            )
            # Following code will yield: 0->'A', 1->'B', 2->'C', ..., 25->'Z', 26->'AA', 27->'AB', 51->'AZ', 52->'BA',...
            stagger_key1 = ""
            if stagger_no >= 26:
                stagger_key1 += chr(64 + int(stagger_no / 26))
            stagger_key1 += chr(65 + (stagger_no % 26))
            if not isinstance(stagger_key1, str):
                raise Exception(
                    f"Internal inconsistency...non-string stagger_key:{stagger_key1}"
                )
            stagger_keys.append(stagger_key1)

        # Convert the dates in subject's
        # (time)keyspace to freq_idx (ints)
        # ----------------------------------
        subject_with_freq_idx = subject.datetime_to_freq_idx1d(
            space=keyspace, freq_idx_space="freq_idx"
        )
        if (
            subject_with_freq_idx is None
            or not isinstance(subject_with_freq_idx, Quble)
            or subject_with_freq_idx.is_empty
        ):
            raise Exception(
                "Internal inconsistency...subject_with_freq_idx is None or empty"
            )
        elif "freq_idx" not in subject_with_freq_idx.keyspaces:
            raise Exception(
                "Internal inconsistency...'freq_idx' absent from subject_with_freq_idx.keyspaces"
            )

        missing_int = missing_val_by_dtype(int)
        if force_first_key:
            # start_offset will be the freq_idx of the first date record
            distinct_freq_idxs = subject_with_freq_idx.index_array1d(
                keyspace="freq_idx", distinct=True
            )
            if distinct_freq_idxs is None or len(distinct_freq_idxs) == 0:
                raise Exception(
                    "Internal inconsistency...distinct_freq_idxs (np of ints) is None or empty"
                )
            # start_offset is the minimum distinct_freq_idxs
            start_offset = np.min(distinct_freq_idxs)
            if (
                start_offset is None
                or (start_offset == missing_int)
                or (start_offset < 0)
            ):
                raise Exception(
                    f"Internal inconsistency...Invalid start_offset:{start_offset}"
                )
        else:
            start_offset = 0

        result = Quble.undefined_instance()
        """
        # ------------------------- START: WINDOW LOOP ---------------------------
        final_result = Quble.undefined_instance()
        # ------------------------- START: WINDOW LOOP ---------------------------
        column_expressions = {}
        func = partial(
            self.run_window_loop,
            missing_int=missing_int,
            stagger_keys=stagger_keys,
            subject_with_freq_idx=subject_with_freq_idx,
            apply_delay_per_window=apply_delay_per_window,
            num_stagger=num_stagger,
            stagger_pcts=stagger_pcts,
            start_offset=start_offset,
            keyspace=keyspace,
            tfill_method=tfill_method,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            window_keyspace=window_keyspace,
            num_stagger_was_none=num_stagger_was_none,
            windows=windows,
            stagger_keyspace=stagger_keyspace,
            result=result,
        )

        result_list = []
        for i in range(0, 3):
            result_list = []
            try:
                with Pool() as pool:
                    result_list = pool.map(func, [window1 for window1 in windows])
            except:
                _logger.debug("multi hold window loop excepted, retrying..")
                continue
            break

        for resultant_quble in result_list:
            final_result = final_result.merge(
                resultant_quble, self_precedence=True, variate_mode="multi"
            )
        return final_result
        """
        column_expressions = {}
        for window1 in windows:
            if not isinstance(window1, int):
                window1 = int(window1)
            # Double check window1
            if (window1 == missing_int) or (window1 <= 0):
                raise Exception(f"Invalid window: {window1}...integer > 0 expected")
            if apply_delay_per_window:
                # To implement delay, we affiliate current data with a future date/freq_idx
                column_expressions["freq_idx"] = f'("freq_idx" + {str(window1)})'

            # ------------------------- START: STAGGER LOOP ---------------------------
            for stagger_no, stagger_key1 in enumerate(stagger_keys):
                if np.abs(num_stagger) > 1:
                    stagger_offset = int(
                        np.round(stagger_pcts[stagger_no] * float(window1))
                    )
                    # Double check stagger_offset
                    if (stagger_offset == missing_int) or (stagger_offset < 0):
                        raise Exception(
                            "Internal inconsistency...Invalid stagger_offset:{0}".format(
                                stagger_offset
                            )
                        )
                else:
                    stagger_offset = 0

                # Select then fill appropriate cyclical records,
                # based on current start_offet, stagger_offset & window1
                # --------------------------------------------------------
                where_clause = 'WHERE ((("freq_idx" - {0} + {1}) % {2}) = 0)'.format(
                    start_offset, stagger_offset, window1
                )

                temp_result1 = subject_with_freq_idx.select(
                    where_clause=where_clause, column_expressions=column_expressions
                )
                local_result = temp_result1.freq_idx_to_datetime1d(
                    space="freq_idx", timespace=keyspace
                )

                # When applicable, we need to fill (window1-1)
                # (as we aleady have one record for this window1 cycle)
                if tfill_method is not None:
                    local_result = local_result.fill1d(
                        keyspace=keyspace,
                        valuespace=local_result.valuespaces,
                        tfill_method=tfill_method,
                        tfill_max=(window1 - 1),
                        # Could consider hardcoding: tfill_end_mode='no_extension'
                        tfill_end_mode=tfill_end_mode,
                        tfill_honor_nulls=tfill_honor_nulls,
                    )

                # Augment local_result with ortho_index
                # for this window1 & stagger_key1
                hyper_key = {}
                hyper_col_types = {}
                if window_keyspace is not None:
                    hyper_key[window_keyspace] = window1
                    hyper_col_types[window_keyspace] = "int"
                elif len(windows) > 1:
                    raise Exception(
                        f"window_keyspace arg required for for #windows:{len(windows)}"
                    )

                if not num_stagger_was_none:
                    hyper_key[stagger_keyspace] = stagger_key1
                    hyper_col_types[stagger_keyspace] = (
                        "varchar(8)"  # <-- Should be big enough to hold keys
                    )

                if len(hyper_key) > 0:
                    local_result = local_result.insert_keyspaces(
                        hyper_key=hyper_key, hyper_col_types=hyper_col_types
                    )

                # Merge local records with result
                if local_result is None or local_result.is_undefined:
                    pass
                elif result is None or result.is_undefined:  # or result.is_empty:
                    result = local_result
                elif local_result.is_empty:
                    pass
                elif result.is_empty:
                    result = local_result
                else:
                    # Use variate_mode='multi' here for merging
                    # as we know that valuespaces will match across iterations
                    # and we would like to retain the original multi-variate state
                    result.merge_inplace(
                        local_result, self_precedence=True, variate_mode="multi"
                    )

            # -------------------------- END: STAGGER LOOP ----------------------------
        # -------------------------- END: WINDOW LOOP ----------------------------

        return result

    def cleanse(
        self,
        cleanse_ops=None,
        allow_shallow_copy=False,
        grace=False,
        context_lib=None,
        context_field=None,
    ):
        """
        Performs a sequence of 'cleasing' operations / tranformations

        :type cleanse_ops: dict or None
        :param cleanse_ops: cleansing sequence
        dict keys: str representing supported Quble cleansing operations
        dict values: associated cleansing parameters for each operator dict, scalar (str, int, ...) or None

        ==> in the case of inner dict:
            inner dict keys: parameter name
            inner dict values: parameter value

        Valid cleansing operator names:
            'valuespace': (required) specific valuespace(s) to be isolated/limited
                ~see qubles.core.quble.Quble.valuespace

            'unpivot': (required) new_keyspace arg for unpivoting
                from multi-variate to uni-variate Quble
                ~see qubles.core.quble.Quble.unpivot

            'pivot': (required) pivot_keyspace arg for pivoting
                from uni-variate (or primary) to multi-variate Quble
                ~see qubles.core.quble.Quble.pivot

            'compress': (optional) 'summarize' parameter or dict
                ~see qubles.core.quble.Quble.compress

            'variate_to_index': (optional) 'valuespace', 'allow_shallow_copy', 'new_keyspace', 'force_new_keyspace' parameters
                ~see qubles.core.quble.Quble.variate_to_index

            'tfill' or 'time_fill' or 'fill': (required) max tfill number of periods
                (as int or a str that will be treated as a property name)
                ~see qubles.core.quble.Quble.fill1d

            'shift' or 'time_shift': number of time-periods to shift
                (>0:past info/causal, <0:future info/look-ahead bias)
                ~see qubles.core.quble.Quble.shift1d

            'reindex' or 'project' or 'cross_project'
                or 'inner_project' or 'left_inner_project' or 'inner_tup_project'
                or 'outer_project' or 'left_outer_project': projection methods
                ~see qubles.core.quble.Quble.reindex
                ~see qubles.core.quble.Quble.project

            'apply_view': applies prevailing view
                ~see qubles.core.quble.Quble.apply_view

            'absolute' or 'abs': no parameters expected
            'floor': floor to lower whole number
            'ceil': floor to upper whole number
            'round': round to closest resolution (optional num_decimals parameter)
            'sqrt': square root (numeric valuespaces)
            'exp': exponential function (numeric valuespaces)
            'log': natural log function (numeric valuespaces)
            'log10': square root (numeric valuespaces)
            'sin': sine function (numeric valuespaces)
            'cos': cosine function (numeric valuespaces)
            'tan': tangent function (numeric valuespaces)
            'upper': upper-case function (string-type valuespaces)
            'lower': lower-case function (string-type valuespaces)
            'trim': removes leading and trailing spaces (string-type valuespaces)
            'ltrim': removes leading spaces (string-type valuespaces)
            'rtrim': removes trailing spaces (string-type valuespaces)
            'num_chars': number of characters (string-type valuespaces)

            'fx' or 'convert_fx': (required) currency translation
                (to be used with numeric valuespaces)
                ~see qubles.core.quble.Quble.convert_fx

            'freq' or 'asfreq': frequency conversion
                ~see qubles.core.quble.Quble.asfreq

            'truncate': removes outliers, expects params dict: {'min_value':<x>, 'max_value':<y>, 'outliers_to_missing':<z>, 'compress':<c>, 'valuespace':<v>} )
                ~see qubles.core.quble.Quble.truncate

            'pct_rank' or 'pct_rank_securities' or 'pct_rank_secs':
                optional parameters: 'valuespace', 'ranking_keyspaces', 'ascending', 'ranking_algo'
                ~see qubles.core.quble.Quble.pct_rank

            'uniform_rank' or 'uniform_rank_securities' or 'uniform_rank_secs':
                optional parameters: 'valuespace', 'ranking_keyspaces', 'ascending', 'ranking_algo'
                ~see qubles.core.quble.Quble.uniform_rank

            'biuniform_rank' or 'biuniform_rank_securities' or 'biuniform_rank_secs':
                optional parameters: 'valuespace', 'ranking_keyspaces', 'ascending', 'ranking_algo'
                ~see qubles.core.quble.Quble.biuniform_rank

            'transform1d' or 'transform1d_secs' or 'transform1d_securities': (required) transform arg (str) or None
                ~see qubles.core.quble.Quble.transform1d

            'date_limits': applies date limits...expects params dict:'start_date', 'end_date', 'allow_shallow_copy'
                ~see qubles.core.quble.Quble.apply_date_limits

            'filter_records': filters records (required) 'filter_cmd' arg
                ~see qubles.core.quble.Quble.apply_date_limits

            'multi_shift': applies multi-shift
                ~see qubles.core.quble.Quble.multi_shift1d

            'multi_hold': applies hold/freezing
                ~see qubles.core.quble.Quble.multi_hold1d

            'aggr_fill' or 'sub_aggr_fill': fills null values with (sub) aggregate values
                ~see qubles.core.quble.Quble.aggr_fill/sub_aggr_fill

            'unfill' or 'sub_unfill': unfills non-null values subject to unfill criteria
                ~see qubles.core.quble.Quble.unfill/sub_unfill

            'get': isolate a sub-set of the key structure
                ~see qubles.core.quble.Quble.get

        :param allow_shallow_copy: permission flag to return a shallow copy
                                   of original self Quble for trivial cases
        :type allow_shallow_copy: bool (True/False*)

        :param grace: grace flag for non-variate case
        :type grace: boolean (True/False*)

        :type context_lib: DataLib or None
        :param context_lib: DataLib providing a context for cleansing

        :type context_field: str or None (for lib default property)
        :param context_field: field within context_lib for cleansing context
        """
        from qubles.io.base.screen import Screen

        # Validate self
        if self.is_undefined:
            return self if allow_shallow_copy else self.copy()
        elif self.is_empty:
            # We may need to (re)think whether we may want to apply
            # any of the possible 'cleansing' operations in this (empty) case
            return self if allow_shallow_copy else self.copy()

        # Validate cleanse_ops
        if cleanse_ops is None:
            # Do nothing is no cleansing operations were provided
            return self if allow_shallow_copy else self.copy()
        elif not isinstance(cleanse_ops, dict):
            raise Exception(
                f"Invalid cleanse_ops: None or dict expected but type(cleanse_ops):{type(cleanse_ops)}"
            )

        # Preliminaries...
        orig_table = self.table_name
        src_data = self  # <-- Perform initial shallow copy for now
        dates_keyspace = src_data.first_non_vantage_time_keyspace(grace=True)

        # ================================= START: operator loop ================================

        # Loop through the operators (src_ops)
        for op_name, op_params in cleanse_ops.items():
            # --------------------------------------
            # op_name: 'valuespace'
            # [Isolates (reduces columns) the specified valuespace(s) of the Quble]
            # Calls method: Quble.sub_variate/index_to_bool
            # Assume scalar param: valuespace (str or None)
            # ==> If None, merely isolate the primary valuespace
            # --------------------------------------
            if op_name == "valuespace":
                # These cases should likely have been applied above
                if not isinstance(op_params, dict):
                    # Nominally, str or None
                    valuespace1 = op_params
                elif "valuespace" in op_params:
                    valuespace1 = op_params["valuespace"]
                else:
                    valuespace1 = None

                if valuespace1 is None:
                    if src_data.is_nonvariate:
                        # Convert nonvariate Quble to boolean univariate Quble
                        src_data = src_data.index_to_bool()
                    else:
                        # Isolate the primary valuespace
                        src_data = src_data.sub_variate(allow_shallow_copy=True)
                elif not isinstance(valuespace1, str):
                    raise Exception(
                        f"op_name:{op_name}, op_params:{op_params} yielded valuespace1:{valuespace1} but expected str"
                    )
                elif src_data.is_nonvariate:
                    src_data = src_data.index_to_bool(valuespace=valuespace1)
                else:
                    src_data = src_data.sub_variate(
                        valuepace=valuespace1, allow_shallow_copy=True
                    )

            # -----------------------------------------------------
            # op_name: 'unpivot'
            # [Unpivots the (multiple) valuespaces of the Quble]
            # Calls method: Quble.unpivot
            # Assume scalar param: new_keyspace (str)
            #  or multi-key dict...
            # dict key                   dict value
            # --------                   ----------
            # 'new_keyspace'             str [default=None...yields Exception]
            # 'new_valuespace'           str [default=<DEFAULT_VALUESPACE>]
            # -----------------------------------------------------
            elif op_name == "unpivot":
                # These cases should likely have been applied above
                if not src_data.is_multivariate:
                    if grace:
                        pass
                    else:
                        raise Exception(
                            "Cannot apply unpivot operator to non-multivariate Quble"
                        )
                else:
                    new_keyspace1 = None
                    new_valuespace1 = DEFAULT_VALUESPACE

                    # Parse op_params
                    if op_params is None:
                        pass
                    elif isinstance(op_params, str):
                        # Assume scalar op is new_keyspace arg
                        new_keyspace1 = op_params
                    elif not isinstance(op_params, dict):
                        raise Exception(
                            f"Invalid op_params:{op_params}...str,dict or None expected"
                        )
                    else:
                        # Process op_params directives
                        for k, v in op_params.items():
                            if k == "new_keyspace":
                                new_keyspace1 = v
                            elif k == "new_valuespace":
                                new_valuespace1 = v
                            else:
                                raise Exception(
                                    f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'new_keyspace', 'new_valuespace'"
                                )

                    if not isinstance(new_keyspace1, str):
                        raise Exception(
                            f"op_name:{op_name}, op_params:{op_params} yielded new_keyspace1:{new_keyspace1} but expected str"
                        )
                    else:
                        src_data = src_data.unpivot(
                            new_keyspace=new_keyspace1, new_valuespace=new_valuespace1
                        )

            # -----------------------------------------------------
            # op_name: 'pivot'
            # Pivots the specified pivot_keyspace of the Quble
            # using the primary valuespace.
            # The new Quble will yield new valuespaces based
            # on the discrete keys across the pivot_keyspace.
            # Calls method: Quble.pivot
            # -------------------------------------------------------------------
            # Assume scalar param: pivot_keyspace (str)
            #  or single-key dict w/key: "pivot_keyspace" and value: str
            # -----------------------------------------------------
            elif op_name == "pivot":
                # These cases should likely have been applied above
                if src_data.is_nonvariate:
                    src_data = src_data.index_to_bool()

                # NOTE: Allowing multivariate...
                #   ==> In this case, we will pivot using primary valuespace
                # if src_data.is_multivariate:
                #     if grace:
                #         pass
                #     else:
                #         raise Exception("Cannot apply pivot operator to multivariate Quble")
                # else:
                if not isinstance(op_params, dict):
                    # Nominally, str or None
                    pivot_keyspace1 = op_params
                elif "pivot_keyspace" in op_params:
                    pivot_keyspace1 = op_params["pivot_keyspace"]
                else:
                    pivot_keyspace1 = None

                if not isinstance(pivot_keyspace1, str):
                    raise Exception(
                        f"op_name:{op_name}, op_params:{op_params} yielded pivot_keyspace1:{pivot_keyspace1} but expected str"
                    )
                else:
                    src_data = src_data.pivot(pivot_keyspace=pivot_keyspace1)

            # -------------------------------------------------------------------
            # op_name: 'compress'
            # [Applies compression of src_data Quble]
            # Calls method: Quble.compress
            # -------------------------------------------------------------------
            # Assume scalar param: summarize arg (bool or str)
            #  or multi-key dict...
            # dict key                   dict value
            # --------                   ----------
            # 'summarize'                str or bool [default='any']
            # 'treat_false_as_null'      bool [default=True]
            # 'drop'                     bool or str [default=False]
            # 'auto_squeeze'             bool [default=False]
            # 'valuespace'               str [default="<valuespaces>"]
            # -------------------------------------------------------------------
            elif op_name == "compress":
                if src_data.is_nonvariate:
                    # Compression does not apply to non-variate Qubles
                    pass
                else:
                    # Assign default params
                    summarize1 = "any"
                    treat_false_as_null1 = True
                    drop1 = False
                    auto_squeeze1 = False
                    # FORMERLY, default compression focused on primary valuespace only
                    # NOW we default to including all valuespaces in compression
                    valuespace1 = "<valuespaces>"

                    # Parse op_params
                    if op_params is None:
                        pass
                    elif isinstance(op_params, (str, bool)):
                        # Assume scalar op is summarize arg
                        summarize1 = op_params
                    elif not isinstance(op_params, dict):
                        raise Exception(
                            f"Invalid op_params:{op_params}...str,bool,dict or None expected"
                        )
                    else:
                        # Process op_params directives
                        for k, v in op_params.items():
                            if k == "summarize":
                                summarize1 = v
                            elif k == "treat_false_as_null":
                                treat_false_as_null1 = v
                            elif k == "drop":
                                drop1 = v
                            elif k == "auto_squeeze":
                                auto_squeeze1 = v
                            elif k == "valuespace":
                                valuespace1 = v
                            else:
                                raise Exception(
                                    f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'summarize', 'treat_false_as_null', 'drop', 'auto_squeeze', 'valuespace'"
                                )

                    # Apply the compression operation
                    src_data = src_data.compress(
                        valuespace=valuespace1,
                        treat_false_as_null=treat_false_as_null1,
                        drop=drop1,
                        auto_squeeze=auto_squeeze1,
                        summarize=summarize1,
                    )

            # -------------------------------------------------------------------
            # op_name: 'variate_to_index'
            # [Applies variate to index conversion of src_data Quble]
            # Calls method: Quble.variate_to_index
            # -------------------------------------------------------------------
            # scalar op_params: valuespace arg (str)
            # -------------------------------------------------------------------
            # dictionary op_params:
            # dict key                   dict value
            # --------                   ----------
            # 'valuespace'               str [default='<valuespace>']
            # 'allow_shallow_copy'       bool [default=False]
            # 'new_keyspace'             str [default="levels"]
            # 'force_new_keyspace'       bool [default=False]
            # -------------------------------------------------------------------
            elif op_name == "variate_to_index":
                if src_data.is_nonvariate:
                    # Already an index (non-variate) here
                    pass
                else:
                    # Default focus to primary valuespace only
                    valuespace1 = "<valuespace>"
                    # For performance...shallow copy should be OK here (if needed)
                    allow_shallow_copy1 = True
                    new_keyspace1 = "levels"
                    force_new_keyspace1 = False

                    if op_params is None:
                        pass
                    elif isinstance(op_params, str):
                        # Assume scalar op is valuespace arg
                        valuespace1 = op_params
                    elif not isinstance(op_params, dict):
                        raise Exception(
                            f"Invalid op_params:{op_params}...int,dict or None expected"
                        )
                    else:
                        # Process op_params directives
                        for k, v in op_params.items():
                            if k == "valuespace":
                                valuespace1 = v
                            elif k == "allow_shallow_copy":
                                allow_shallow_copy1 = v
                            elif k == "new_keyspace":
                                new_keyspace1 = v
                            elif k == "force_new_keyspace":
                                force_new_keyspace1 = v
                            else:
                                raise Exception(
                                    f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'valuespace', 'allow_shallow_copy'"
                                )

                    # valuespace promotion not necessary here
                    src_data = src_data.variate_to_index(
                        valuespace=valuespace1,
                        allow_shallow_copy=allow_shallow_copy1,
                        new_keyspace=new_keyspace1,
                        force_new_keyspace=force_new_keyspace1,
                    )

            # -------------------------------------------------------------------
            # op_name: 'index_to_bool'
            # [Converts index src_data Quble to a boolean format]
            # Calls method: Quble.variate_to_index
            # -------------------------------------------------------------------
            # scalar op_params: valuespace arg (str)
            # -------------------------------------------------------------------
            # dictionary op_params:
            # dict key                   dict value
            # --------                   ----------
            # 'valuespace'               str [default=DEFAULT_VALUESPACE]
            # -------------------------------------------------------------------
            elif op_name == "index_to_bool":
                if src_data.is_variate:
                    # Already a variate here...should we throw an Exception or pass?
                    pass
                else:
                    # Default focus to primary valuespace only
                    valuespace1 = DEFAULT_VALUESPACE

                    if op_params is None:
                        pass
                    elif isinstance(op_params, str):
                        # Assume scalar op is valuespace arg
                        valuespace1 = op_params
                    elif not isinstance(op_params, dict):
                        raise Exception(
                            f"Invalid op_params:{op_params}...int,dict or None expected"
                        )
                    else:
                        # Process op_params directives
                        for k, v in op_params.items():
                            if k == "valuespace":
                                valuespace1 = v
                            else:
                                raise Exception(
                                    f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'valuespace', 'allow_shallow_copy'"
                                )

                    src_data = src_data.index_to_bool(valuespace=valuespace1)

            # -------------------------------------------------------------------
            # op_name: 'fill' or 'tfill' or 'time_fill'
            # [Applies time-filling by specified number of periods]
            # Retains all original valuespaces.
            # Defaults to filling across all valuespaces or the Quble,
            # but can limit the filling to a subset of valuespace(s)
            # through the use of the 'valuespace' key in the op_params dict
            # Example: For primary vs fill only, use op_params:{"valuespace":"<valuespace>"}
            # Calls method: Quble.fill1d
            # -------------------------------------------------------------------
            # scalar op_params: number of time-fill periods (int)
            # -------------------------------------------------------------------
            # dictionary op_params:
            # dict key                        dict value
            # --------                        ----------
            # 'fill_max' or 'tfill_max'       int or or str or None [default=None]
            #     ==> If str, will consult: context_lib.get_property(<str>, src_name, grace=True)
            # 'fill_method' or 'tfill_method' str or None [default='pad']
            # 'valuespace'                    str [default='<valuespace>']
            # -------------------------------------------------------------------
            elif op_name in ("fill", "tfill", "time_fill"):
                if src_data.is_nonvariate:
                    # Filling does not apply to non-variate Qubles
                    pass
                else:
                    # Assign default params
                    tfill_max1 = None
                    tfill_method1 = "pad"
                    # FORMERLY, default filling focused on primary valuespace only
                    # valuespace1 = "<valuespace>"
                    # NOW we default to applying filling to all valuespaces
                    valuespace1 = "<valuespaces>"

                    # Parse op_params
                    if op_params is None:
                        pass
                    elif isinstance(op_params, int):
                        # Assume scalar op is number of time-fill periods
                        tfill_max1 = op_params
                    elif not isinstance(op_params, dict):
                        raise Exception(
                            f"Invalid op_params:{op_params}...int,dict or None expected"
                        )
                    else:
                        # Process op_params directives
                        for k, v in op_params.items():
                            if k in ("fill_max", "tfill_max"):
                                tfill_max1 = v
                            elif k in ("fill_method", "tfill_method"):
                                tfill_method1 = v
                            elif k in ("valuespace"):
                                valuespace1 = v
                            else:
                                raise Exception(
                                    f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'fill_max', 'tfill_max', 'fill_method', 'tfill_method', 'valuespace'"
                                )

                    # Coerce tfill_max1 to int
                    if not tfill_max1:
                        # tfill_max1 is likely None or zero here
                        tfill_max1 = 0
                    elif not isinstance(tfill_max1, str):
                        tfill_max1 = int(tfill_max1)
                    elif len(tfill_max1) == 0:
                        # Empty str provided
                        tfill_max1 = 0
                    elif tfill_max1.isalpha():
                        if context_lib is None:
                            raise Exception(
                                f"context_lib required for tfill_max1:{tfill_max1}"
                            )
                        # Alpha characters present in tfill_max1 string?
                        # So look for the designated field-specific property of the context_lib
                        # Hopefully, context_field is valid/appropriate field...field-specific property
                        tfill_max1 = context_lib.get_property(
                            tfill_max1, context_field, grace=True
                        )
                    else:
                        # If a single (non-alpha) string param was given,
                        # assume it is the tfill_max1 arg and coerce to an int
                        tfill_max1 = int(tfill_max1)

                    # Apply time-filling (if required)
                    if (tfill_max1 is None) or (tfill_max1 == 0):
                        # No filling requested
                        pass
                    elif dates_keyspace is not None:
                        # Promote valuespace (if needed)
                        if valuespace1 not in (
                            None,
                            "<valuespace>",
                            src_data.valuespace,
                        ):
                            src_data = src_data.promote_valuespace(
                                valuespace=valuespace1
                            )
                        # Apply filling
                        src_data = src_data.fill1d(
                            keyspace=dates_keyspace,
                            valuespace=valuespace1,
                            tfill_method=tfill_method1,
                            tfill_max=tfill_max1,
                        )
                    elif grace:
                        pass
                    else:
                        raise Exception(
                            f"Unable to apply fill1d...no time-series keyspaces present"
                        )

            # -------------------------------------------------------------------
            # op_name: 'shift' or 'time_shift'
            # [Applies time-shift by specified number of periods]
            # For scalar param: number (int) of shift periods (>0: lag, <0: lead)
            # This operation is valuespace independent, all current valuespaces retained.
            # Calls method: Quble.shift1d
            # -------------------------------------------------------------------
            # For int param: periods
            # -------------------------------------------------------------------
            # For dict param:
            # dict key              dict value
            # --------              ----------
            # 'periods'             int
            # -------------------------------------------------------------------
            elif op_name in ("shift", "time_shift"):
                # NOTE: Currently, variate Quble is required here
                periods1 = None
                # Assume op_params (if provided) represents num_periods to shift1d arg
                if op_params is None:
                    pass
                elif isinstance(op_params, int):
                    periods1 = op_params
                elif not isinstance(op_params, dict):
                    raise Exception(
                        f"Invalid op_params:{op_params}...int,dict or None expected"
                    )
                else:
                    # Process op_params directives
                    for k, v in op_params.items():
                        if k == "periods":
                            periods1 = v
                        else:
                            raise Exception(
                                f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'periods'"
                            )
                # Validate periods1
                if periods1 is None or periods1 == 0:
                    pass
                elif dates_keyspace is not None:
                    # valuespace promotion not needed here
                    src_data = src_data.shift1d(
                        periods=periods1,
                        keyspace=dates_keyspace,
                    )
                elif grace:
                    pass
                else:
                    raise Exception(
                        f"Cannot apply time-shifting...no time_keyspaces present for vs:{vs}"
                    )

            # -------------------------------------------------------------------
            # op_name: 'reindex', 'project', 'cross_project',
            #     'inner_project', 'left_inner_project', 'inner_tup_project'
            #     'outer_project', 'left_outer_project'
            # [Applies project of src_data Quble]
            # Calls method: Quble.reindex/project/...
            # -------------------------------------------------------------------
            # Assume scalar param: screen arg (Quble or str)
            #  or multi-key dict...
            # dict key                   dict value
            # --------                   ----------
            # 'index'                    Quble or str
            # 'auto_fill1'               bool [default=RootLib().get_control("auto_fill")]
            # 'tfill_method'             str [default="<space_root>"]
            # 'tfill_max'                int [default="<space_root>"]
            # 'tfill_end_mode'           str [default="<space_root>"]
            # 'tfill_honor_nulls'        bool [default="<space_root>"]
            # 'tdistribute_mode'         str [default="<space_root>"]
            # -------------------------------------------------------------------
            elif op_name in (
                "reindex",
                "project",
                "cross_project",
                "inner_project",
                "left_inner_project",
                "inner_tup_project",
                "outer_project",
                "left_outer_project",
            ):
                index1 = None
                auto_fill1 = RootLib().get_control("auto_fill")
                tfill_method1 = "<space_root>"
                tfill_max1 = "<space_root>"
                tfill_end_mode1 = "<space_root>"
                tfill_honor_nulls1 = "<space_root>"
                tdistribute_mode1 = "<space_root>"

                # Assume op_params (if provided) represents index to be projected
                if op_params is None:
                    pass
                elif isinstance(op_params, Quble):
                    index1 = op_params
                elif isinstance(op_params, Screen):
                    index1 = op_params.apply_screen()
                elif isinstance(op_params, DataLib):  # <-- includes Screen objects
                    # TODO: How to properly handle DataLib with multiple fields
                    # In which case, screen.to_quble() may yield a multi-variate Quble
                    index1 = op_params.to_quble()
                elif not isinstance(op_params, dict):
                    raise Exception(
                        f"Invalid op_params:{op_params}...Quble,Screen,DataLib,dict or None expected"
                    )
                else:
                    # Process op_params directives
                    for k, v in op_params.items():
                        if k == "index":
                            index1 = v
                        elif k == "auto_fill":
                            auto_fill1 = v
                        elif k == "tfill_method":
                            tfill_method1 = v
                        elif k == "tfill_max":
                            tfill_max1 = v
                        elif k == "tfill_end_mode":
                            tfill_end_mode1 = v
                        elif k == "tfill_honor_nulls":
                            tfill_honor_nulls1 = v
                        elif k == "tdistribute_mode":
                            tdistribute_mode1 = v
                        else:
                            raise Exception(
                                f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'index','tfill_method','tfill_max','tfill_end_mode','tfill_honor_nulls','tdistribute_mode1'"
                            )
                # Validate index1
                if index1 is not None:
                    pass
                elif op_name == "reindex":
                    # Apply the reindex operation
                    src_data = src_data.reindex(
                        index=index1,
                        auto_fill=auto_fill1,
                        tfill_method=tfill_method1,
                        tfill_max=tfill_max1,
                        tfill_end_mode=tfill_end_mode1,
                        tdistribute_mode=tdistribute_mode1,
                    )
                elif op_name == "project":
                    # Apply the project operation
                    src_data = src_data.project(
                        index=index1,
                        auto_fill=auto_fill1,
                        tfill_method=tfill_method1,
                        tfill_max=tfill_max1,
                        tfill_end_mode=tfill_end_mode1,
                        tdistribute_mode=tdistribute_mode1,
                    )
                elif op_name == "cross_project":
                    # Apply the cross_project operation
                    src_data = src_data.cross_project(
                        index=index1,
                        auto_fill=auto_fill1,
                        tfill_method=tfill_method1,
                        tfill_max=tfill_max1,
                        tfill_end_mode=tfill_end_mode1,
                        tdistribute_mode=tdistribute_mode1,
                    )
                elif op_name == "inner_project":
                    # Apply the inner_project operation
                    src_data = src_data.inner_project(
                        index=index1,
                        auto_fill=auto_fill1,
                        tfill_method=tfill_method1,
                        tfill_max=tfill_max1,
                        tfill_end_mode=tfill_end_mode1,
                        tdistribute_mode=tdistribute_mode1,
                    )
                elif op_name == "left_inner_project":
                    # Apply the left_inner_project operation
                    src_data = src_data.left_inner_project(
                        index=index1,
                        auto_fill=auto_fill1,
                        tfill_method=tfill_method1,
                        tfill_max=tfill_max1,
                        tfill_end_mode=tfill_end_mode1,
                        tdistribute_mode=tdistribute_mode1,
                    )
                elif op_name == "inner_tup_project":
                    # Apply the inner_tup_project operation
                    src_data = src_data.inner_tup_project(
                        index=index1,
                        auto_fill=auto_fill1,
                        tfill_method=tfill_method1,
                        tfill_max=tfill_max1,
                        tfill_end_mode=tfill_end_mode1,
                        tdistribute_mode=tdistribute_mode1,
                    )
                elif op_name == "outer_project":
                    # Apply the outer_project operation
                    src_data = src_data.outer_project(
                        index=index1,
                        auto_fill=auto_fill1,
                        tfill_method=tfill_method1,
                        tfill_max=tfill_max1,
                        tfill_end_mode=tfill_end_mode1,
                        tdistribute_mode=tdistribute_mode1,
                    )
                elif op_name == "left_outer_project":
                    # Apply the left_outer_project operation
                    src_data = src_data.left_outer_project(
                        index=index1,
                        auto_fill=auto_fill1,
                        tfill_method=tfill_method1,
                        tfill_max=tfill_max1,
                        tfill_end_mode=tfill_end_mode1,
                        tdistribute_mode=tdistribute_mode1,
                    )
                else:
                    raise Exception(f"Invalid projection method...op_name:{op_name}")

            # -------------------------------------------------------------------
            # op_name: 'apply_view'
            # [Applies view onto src_data Quble]
            # Calls method: Quble.apply_view
            # -------------------------------------------------------------------
            # Assume scalar param: screen arg (Quble)
            #  or multi-key dict...
            # dict key                   dict value
            # --------                   ----------
            # 'view'                     Quble
            # 'allow_shallow_copy'       bool
            # -------------------------------------------------------------------
            elif op_name == "apply_view":
                view1 = RootLib().get_control("view")
                allow_shallow_copy1 = True

                # Assume op_params (if provided) represents index to be projected
                if op_params is None:
                    pass
                elif isinstance(op_params, Quble):
                    view1 = op_params
                elif not isinstance(op_params, dict):
                    raise Exception(
                        f"Invalid op_params:{op_params}...Quble,Screen,DataLib,dict or None expected"
                    )
                else:
                    # Process op_params directives
                    for k, v in op_params.items():
                        if k == "view":
                            view1 = v
                        elif k == "allow_shallow_copy":
                            allow_shallow_copy1 = v
                        else:
                            raise Exception(
                                f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'view','allow_shallow_copy'"
                            )
                # Validate view1
                if view1 is not None:
                    src_data = src_data.apply_view(
                        view=view1, allow_shallow_copy=allow_shallow_copy1
                    )

            # ----------------------------------------------------
            #                   unistat operators
            # op_name: 'absolute', 'abs', 'floor', 'ceil', 'round',
            #          'sqrt', 'exp', log', 'log10', 'sin', 'cos', 'tan'
            #          'upper', 'lower', 'trim', 'ltrim', 'rtrim', 'num_chars'
            # [Applies unistat to numeric/string Quble valuespace]
            # Recall that these unistat methods will retain all current valuespaces
            # but will only apply specified operator to the specified valuespace(s)
            # For str param: valuespace
            # For int param: num_decimals (if op_name == "round")
            # Calls method: Quble.absolute/floor/ceil/round/...
            # ----------------------------------------------------
            # For dict param:
            # dict key              dict value
            # --------              ----------
            # 'valuespace'          str [default: "<numeric_valuespace>" or "<string_valuespaces>"]
            # 'num_decimals'        int [default: 0] (if op_name == "round")
            # ----------------------------------------------------
            elif op_name in (
                "absolute",
                "abs",
                "floor",
                "ceil",
                "round",
                "sqrt",
                "exp",
                "log",
                "log10",
                "sin",
                "cos",
                "tan",
                "upper",
                "lower",
                "trim",
                "ltrim",
                "rtrim",
                "num_chars",
            ):
                # Ignore op_params here
                if src_data.is_nonvariate:
                    # No valuespaces to operate on
                    # (and choosing to leave as non-variate)
                    pass
                else:
                    # FORMERLY, default these unistat operations
                    # focused on primary valuespace only
                    # valuespace1 = "<valuespace>"
                    # NOW we default to these unistat ops
                    # to the numeric/string valuespaces accordingly
                    if op_name in (
                        "upper",
                        "lower",
                        "trim",
                        "ltrim",
                        "rtrim",
                        "num_chars",
                    ):
                        valuespace1 = "<string_valuespaces>"
                        string_required = True
                        numeric_required = False
                    else:
                        valuespace1 = "<numeric_valuespaces>"
                        string_required = False
                        numeric_required = True

                    num_decimals1 = 0
                    if op_params is None:
                        pass
                    elif isinstance(op_params, str):
                        valuespace1 = op_params
                    elif isinstance(op_params, int) and op_name == "round":
                        num_decimals1 = op_params
                    elif not isinstance(op_params, dict):
                        raise Exception(
                            f"Invalid op_params:{op_params}...str,dict or None expected"
                        )
                    else:
                        # Process op_params directives
                        for k, v in op_params.items():
                            if k == "valuespace":
                                valuespace1 = v
                            elif k == "num_decimals":
                                num_decimals1 = v
                            else:
                                raise Exception(
                                    f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'valuespace', 'num_decimals'"
                                )

                    # NO LONGER PROMOTING THE SPECIFIED VALUESPACE
                    ## Promote valuespace (if needed)
                    # if valuespace1 not in (None,"<valuespace>",src_data.valuespace):
                    #    src_data = src_data.promote_valuespace(valuespace=valuespace1)

                    # Apply unistat operator
                    if numeric_required and not src_data.is_numeric(space=valuespace1):
                        if grace:
                            pass
                        else:
                            raise Exception(
                                f"Cannot apply op_name:{op_name} to non-numeric Quble.valuespace:{src_data.valuespace} w/coltype:{src_data.get_space_info(info_type='type', space=src_data.valuespace)}"
                            )
                    elif string_required and not src_data.is_string(space=valuespace1):
                        if grace:
                            pass
                        else:
                            raise Exception(
                                f"Cannot apply op_name:{op_name} to non-string Quble.valuespace:{src_data.valuespace} w/coltype:{src_data.get_space_info(info_type='type', space=src_data.valuespace)}"
                            )
                    elif op_name in ("absolute", "abs"):
                        # Apply absolute (if possible)
                        src_data = src_data.absolute(space=valuespace1)
                    elif op_name == "floor":
                        # Apply floor (if possible)
                        src_data = src_data.floor(space=valuespace1)
                    elif op_name == "ceil":
                        # Apply ceil (if possible)
                        src_data = src_data.ceil(space=valuespace1)
                    elif op_name == "round":
                        # Apply "round" (if possible)
                        src_data = src_data.round(
                            num_decimals=num_decimals1, space=valuespace1
                        )
                    elif op_name == "sqrt":
                        # Apply sqrt (if possible)
                        src_data = src_data.sqrt(space=valuespace1)
                    elif op_name == "exp":
                        # Apply exp (if possible)
                        src_data = src_data.exp(space=valuespace1)
                    elif op_name == "log":
                        # Apply log (if possible)
                        src_data = src_data.log(space=valuespace1)
                    elif op_name == "log10":
                        # Apply log10 (if possible)
                        src_data = src_data.log10(space=valuespace1)
                    elif op_name == "sin":
                        # Apply sin (if possible)
                        src_data = src_data.sin(space=valuespace1)
                    elif op_name == "cos":
                        # Apply cos (if possible)
                        src_data = src_data.cos(space=valuespace1)
                    elif op_name == "tan":
                        # Apply tan (if possible)
                        src_data = src_data.tan(space=valuespace1)
                    elif op_name == "upper":
                        # Apply upper (if possible)
                        src_data = src_data.upper(space=valuespace1)
                    elif op_name == "lower":
                        # Apply lower (if possible)
                        src_data = src_data.lower(space=valuespace1)
                    elif op_name == "trim":
                        # Apply trim (if possible)
                        src_data = src_data.trim(space=valuespace1)
                    elif op_name == "ltrim":
                        # Apply ltrim (if possible)
                        src_data = src_data.ltrim(space=valuespace1)
                    elif op_name == "rtrim":
                        # Apply rtrim (if possible)
                        src_data = src_data.rtrim(space=valuespace1)
                    elif op_name == "num_chars":
                        # Apply num_chars (if possible)
                        src_data = src_data.num_chars(space=valuespace1)
                    else:
                        raise Exception(f"Invalid op_name:{op_name}")

            # ----------------------------------------------------------
            # op_name: 'truncate'
            # [Truncates the specified values of a (numeric) Quble]
            # Retains all current valuespaces, but only truncates specified valuespace(s)
            # Calls method: Quble.src_data
            # ----------------------------------------------------------
            # scalar arg: throw Exception...dict required
            # ----------------------------------------------------------
            # dict key               dict value
            # --------               ----------
            # 'min_value'            float (or int or None) [default=None]
            # 'max_value'            float (or int or None) [default=None]
            # 'outliers_to_missing'  bool [default=False]
            # 'compress'             bool or str [default=False]
            # 'valuespace'           str [default="<numeric_valuespaces>"]
            # ----------------------------------------------------------
            elif op_name == "truncate":
                if src_data.is_nonvariate:
                    # No valuespaces to truncate
                    # (and choosing to leave as non-variate)
                    pass
                else:
                    min_value1 = None
                    max_value1 = None
                    outliers_to_missing1 = False
                    compress1 = False
                    # FORMERLY, by default truncated primary valuespace only
                    # valuespace1 = "<valuespace>"
                    # NOW we default truncation to all numeric valuespaces
                    valuespace1 = "<numeric_valuespaces>"
                    # op_params must be a dictionary here
                    if op_params is None:
                        pass
                    elif not isinstance(op_params, dict):
                        raise Exception(
                            f"Processing op_name:{op_name}..invalid op_params:{op_params}...dict expected"
                        )
                    else:
                        # Process op_params directives
                        for k, v in op_params.items():
                            if k == "min_value":
                                min_value1 = v
                            elif k == "max_value":
                                max_value1 = v
                            elif k == "outliers_to_missing":
                                outliers_to_missing1 = v
                            elif k == "compress":
                                compress1 = v
                            elif k == "valuespace":
                                valuespace1 = v
                            else:
                                raise Exception(
                                    f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'min_value', 'max_value', 'outliers_to_missing', 'compress', 'valuespace'"
                                )

                        # NO LONGER PROMOTING THE SPECIFIED VALUESPACE
                        ## Promote valuespace (if needed)
                        # if valuespace1 not in (None,"<valuespace>",src_data.valuespace):
                        #    src_data = src_data.promote_valuespace(valuespace=valuespace1)

                        # Now, apply the truncate operator
                        if (min_value1 is None) and (max_value1 is None):
                            pass
                        elif src_data.is_numeric(space=valuespace1):
                            # We only truncate when min and/or max values are provided and not None
                            src_data = src_data.truncate(
                                min_value=min_value1,
                                max_value=max_value1,
                                space=valuespace1,
                                outliers_to_missing=outliers_to_missing1,
                                compress=compress1,
                            )

            # ---------------------------------------------------------
            # op_name: 'fx' or 'convert_fx'
            # [Converts currency of numeric Quble to desired setting]
            # Calls method: Quble.convert_fx
            # ----------------------------------------------------------
            # Assume scalar param is the (scalar) fx arg (str)
            # ----------------------------------------------------------
            # dict key               dict value
            # --------               ----------
            # 'fx'                   target fx (str)
            # 'valuespace'           str [default="<numeric_valuespaces>" so long as fx relevant]
            # ----------------------------------------------------------
            elif op_name in ("fx", "convert_fx"):
                if src_data.is_nonvariate:
                    # No valuespaces to operate on
                    # (and choosing to leave as non-variate)
                    pass
                else:
                    fx1 = None
                    # FORMERLY, by default applied fx conversion to primary valuespace only
                    # valuespace1 = "<valuespace>"
                    # NOW we default fx conversion to all numeric valuespaces
                    # We could consider limiting to a sub-set of the
                    # numeric valuspaces where fx attribute currently applies
                    valuespace1 = "<numeric_valuespaces>"

                    # Assume op_params (if provided) represents num_periods to shift1d arg
                    if op_params is None:
                        pass
                    elif isinstance(op_params, str):
                        fx1 = op_params
                    elif not isinstance(op_params, dict):
                        raise Exception(
                            f"Invalid op_params:{op_params}...str,dict or None expected"
                        )
                    else:
                        # Process op_params directives
                        for k, v in op_params.items():
                            if k == "fx":
                                fx1 = v
                            elif k == "valuespace":
                                valuespace1 = v
                            else:
                                raise Exception(
                                    f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'fx','valuespace'"
                                )

                    # Assume scalar param is the (scalar) fx arg
                    if valuespace1 is None:
                        pass
                    elif src_data.is_numeric(space=valuespace1):
                        src_data = src_data.convert_fx(fx=fx1, valuespace=valuespace1)
                    elif grace:
                        pass
                    else:
                        raise Exception(
                            f"Cannot apply fx conversion to non-numeric valuespace:{valuespace1}"
                        )

            # ---------------------------------------------------------
            # op_name: 'freq' or 'asfreq'
            # [Converts frequency of temporal Quble]
            # This operation is valuespace independent, all current valuespaces retained.
            # Calls method: Quble.convert_fx
            # ----------------------------------------------------------
            # Assume scalar param is the target freq (str)
            # ----------------------------------------------------------
            # dict key               dict value
            # --------               ----------
            # 'freq'                 target fx (str)
            # 'keyspace'             str [default=first_non_vantage_time_keyspace]
            # 'time_basis_override'  str [default="<no override>"]
            # 'tdistribute_mode'  str [default="<space_root>"]
            # ----------------------------------------------------------
            elif op_name in ("freq", "asfreq"):
                # Default focus to primary valuespace only
                freq1 = RootLib().get_control("freq")
                keyspace1 = dates_keyspace
                time_basis_override1 = ("<no override>",)
                tdistribute_mode1 = ("<space_root>",)

                # Assume op_params (if provided) represents num_periods to shift1d arg
                if op_params is None:
                    pass
                elif isinstance(op_params, str):
                    freq1 = op_params
                elif not isinstance(op_params, dict):
                    raise Exception(
                        f"Invalid op_params:{op_params}...str,dict or None expected"
                    )
                else:
                    # Process op_params directives
                    for k, v in op_params.items():
                        if k == "freq":
                            freq1 = v
                        elif k == "keyspace":
                            keyspace1 = v
                            # Validate the time-keyspace provided we use grace=True/False below as we choose to pass/fail
                            keyspace1 = src_data.validate_keyspace(
                                keyspace=keyspace1,
                                grace=(
                                    True
                                    if (
                                        isinstance(keyspace1, str)
                                        and keyspace1[0] == "<"
                                    )
                                    else False
                                ),
                                solo_required=True,
                                time_space_required=True,
                            )

                        elif k == "time_basis_override":
                            time_basis_override1 = v
                        elif k == "tdistribute_mode":
                            tdistribute_mode1 = v
                        else:
                            raise Exception(
                                f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'freq','keyspace','time_basis_override','tdistribute_mode'"
                            )

                # Assume scalar param is the (scalar) freq arg
                if freq1 is None:
                    pass
                elif keyspace1 is not None:
                    src_data = src_data.asfreq(
                        freq=freq1,
                        keyspace=keyspace1,
                        time_basis_override=time_basis_override1,
                        tdistribute_mode=tdistribute_mode1,
                    )

            # -------------------------------------------------
            # op_name: 'pct_rank'
            # op_name: 'pct_rank_securities'
            # op_name: 'pct_rank_secs'
            # op_name: 'uniform_rank'
            # op_name: 'uniform_rank_securities'
            # op_name: 'uniform_rank_secs'
            # op_name: 'biuniform_rank'
            # op_name: 'biuniform_rank_securities'
            # op_name: 'biuniform_rank_secs'
            # [Applies associated ranking scross security dimension (if present)]
            # Calls method: Quble.pct_rank/uniform_rank/biuniform_rank
            # -------------------------------------------------
            # Assume scalar param is the (scalar) valuespace
            # -------------------------------------------------
            # dict key           dict value
            # --------           ----------
            # 'valuespace'        str [default="<valuespaces>"]
            # 'ranking_keyspaces' str or list of strs
            #                     [default=None or "<security_keyspace>"]
            # 'ascending'         bool [default=True]
            # 'ranking_algo'      str or None [default=None]
            # -------------------------------------------------
            elif op_name in (
                "pct_rank",
                "pct_rank_securities",
                "pct_rank_secs",
                "uniform_rank",
                "uniform_rank_securities",
                "uniform_rank_secs",
                "biuniform_rank",
                "biuniform_rank_securities",
                "biuniform_rank_secs",
            ):
                if src_data.is_nonvariate:
                    # No valuespaces to operate/rank on (and choosing to leave as non-variate)
                    pass
                else:
                    valuespace1 = "<valuespaces>"
                    ranking_keyspaces1 = None
                    ascending1 = True
                    ranking_algo1 = None

                    # Assume op_params (if provided) represents num_periods to shift1d arg
                    if op_params is None:
                        pass
                    elif isinstance(op_params, str):
                        valuespace1 = op_params
                    elif not isinstance(op_params, dict):
                        raise Exception(
                            f"Invalid op_params:{op_params}...str,dict or None expected"
                        )
                    else:
                        # Process op_params directives
                        for k, v in op_params.items():
                            if k == "valuespace":
                                valuespace1 = v
                            elif k == "ranking_keyspaces":
                                ranking_keyspaces1 = v
                            elif k == "ascending":
                                ascending1 = v
                            elif k == "ranking_algo":
                                ranking_algo1 = v
                            else:
                                raise Exception(
                                    f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'valuespace','keyspace'"
                                )

                    # Validate ranking_keyspaces1
                    if ranking_keyspaces1 is not None:
                        pass
                    elif op_name in (
                        "pct_rank_securities",
                        "pct_rank_secs",
                        "uniform_rank_securities",
                        "uniform_rank_secs",
                        "biuniform_rank_securities",
                        "biuniform_rank_secs",
                    ):
                        # Successful inference of security_keyspace is required here
                        ranking_keyspaces1 = src_data.security_keyspace(grace=False)

                    # Is ranking_keyspaces1 still None?
                    if ranking_keyspaces1 is None:
                        # Could consult grace is True to not throw an error when keyspace not provided
                        raise Exception(
                            f"Processing op_name:{op_name}..invalid op_params:{op_params}...'keyspace' required"
                        )

                    if op_name in (
                        "uniform_rank",
                        "uniform_rank_securities",
                        "uniform_rank_secs",
                    ):
                        src_data = src_data.uniform_rank(
                            ranking_keyspaces=ranking_keyspaces1,
                            ascending=ascending1,
                            ignore_missing=True,
                            pct_required=0.0,
                            valuespace=valuespace1,
                            view=None,
                            ranking_algo=ranking_algo1,
                        )
                    elif op_name in (
                        "biuniform_rank",
                        "biuniform_rank_securities",
                        "biuniform_rank_secs",
                    ):
                        src_data = src_data.biuniform_rank(
                            ranking_keyspaces=ranking_keyspaces1,
                            ascending=ascending1,
                            ignore_missing=True,
                            pct_required=0.0,
                            valuespace=valuespace1,
                            view=None,
                            ranking_algo=ranking_algo1,
                        )
                    else:
                        src_data = src_data.pct_rank(
                            ranking_keyspaces=ranking_keyspaces1,
                            ascending=ascending1,
                            ignore_missing=True,
                            pct_required=0.0,
                            valuespace=valuespace1,
                            view=None,
                            ranking_algo=ranking_algo1,
                        )

            # -------------------------------------------------
            # op_name: 'transform1d'
            # op_name: 'transform1d_secs'
            # op_name: 'transform1d_securities'
            # Assume scalar arg is transform param (str)
            # Calls method: Quble.transform1d
            # -------------------------------------------------
            # Assume scalar param is the (scalar) transform operator
            # -------------------------------------------------
            # dict key           dict value
            # --------           ----------
            # 'transform1d'        str [default=None]
            # 'valuespace'       str [default="<numeric_valuespaces>"]
            # 'keyspace'         str [default="<security_keyspace>"]
            # -------------------------------------------------
            elif op_name in (
                "transform1d",
                "transform1d_secs",
                "transform1d_securities",
            ):
                if src_data.is_nonvariate:
                    # No valuespaces to operate on (and choosing to leave as non-variate)
                    pass
                else:
                    # Default focus to primary valuespace only
                    transform1 = None
                    keyspace1 = None
                    valuespace1 = "<numeric_valuespaces>"

                    # Assume op_params (if provided) represents num_periods to shift1d arg
                    if op_params is None:
                        pass
                    elif isinstance(op_params, str):
                        transform1 = op_params
                    elif not isinstance(op_params, dict):
                        raise Exception(
                            f"Invalid op_params:{op_params}...str,dict or None expected"
                        )
                    else:
                        # Process op_params directives
                        for k, v in op_params.items():
                            if k == "transform1d":
                                transform1 = v
                            elif k == "valuespace":
                                valuespace1 = v
                            elif k == "keyspace":
                                keyspace1 = v
                            else:
                                raise Exception(
                                    f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'transform','valuespace'"
                                )

                    # Validate keyspace1
                    if keyspace1 is not None:
                        pass
                    elif op_name in ("transform1d_secs", "transform1d_securities"):
                        # Successful inference of security_keyspace is required here
                        keyspace1 = src_data.security_keyspace(grace=False)

                    # Is keyspace1 still None?
                    if keyspace1 is None:
                        # Could consult grace is True to not throw an error when keyspace not provided
                        raise Exception(
                            f"Processing op_name:{op_name}..invalid op_params:{op_params}...'keyspace' required"
                        )

                    # Assume op_params is the transform1d arg
                    if transform1 is None:
                        pass
                    elif valuespace1 is None:
                        pass
                    elif src_data.is_numeric(space=valuespace1):
                        src_data = src_data.transform1d(
                            transform1,
                            keyspace=keyspace1,
                            valuespace=valuespace1,
                        )
                    elif grace:
                        pass
                    else:
                        raise Exception(
                            f"Cannot apply transform op:{transform1} to non-numeric valuespace:{valuespace1}"
                        )

            # -----------------------------------------------------
            # op_name: 'date_limits'
            # [Applies start/end date limits]
            # This operation is valuespace independent, all current valuespaces retained.
            # Calls method: Quble.apply_date_limits
            # -----------------------------------------------------
            # scalar arg: throw Exception...dict required
            # dict key             dict value
            # --------             ----------
            # 'start_date'         datetime.date, datetime.datetime or np.datetime64 scalar (or str or None) [default_value=None]
            # 'end_date'           datetime.date, datetime.datetime or np.datetime64 scalar (or str or None) [default_value=None]
            # 'allow_shallow_copy' bool [default=True]
            # -----------------------------------------------------
            elif op_name == "date_limits":
                if not dates_keyspace:
                    # Non-historical src_data
                    if grace:
                        pass
                    else:
                        raise Exception(
                            f"Processing op_name:{op_name}...no time_keyspaces present"
                        )
                elif dates_keyspace not in src_data.keyspaces:
                    # Should probably not happen...could consider throwing an Exception here
                    if grace:
                        pass
                    else:
                        raise Exception(
                            f"Processing op_name:{op_name}...dates_keyspace:{dates_keyspace} absent from keyspaces:{src_data.keyspaces}"
                        )
                else:
                    start_date1 = None
                    end_date1 = None
                    allow_shallow_copy1 = True

                    if op_params is None:
                        pass
                    elif not isinstance(op_params, dict):
                        raise Exception(
                            f"Processing op_name:{op_name}..invalid op_params:{op_params}...dict expected"
                        )
                    else:
                        # Process op_params directives
                        for k, v in op_params.items():
                            if k == "start_date":
                                start_date1 = v
                            elif k == "end_date":
                                end_date1 = v
                            elif k == "allow_shallow_copy":
                                allow_shallow_copy1 = v
                            else:
                                raise Exception(
                                    f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'start_date', 'end_date', 'keyspace', 'allow_shallow_copy'"
                                )

                    if (start_date1 is not None) or (end_date1 is not None):
                        src_data = src_data.apply_date_limits(
                            start_date=start_date1,
                            end_date=end_date1,
                            space=dates_keyspace,
                            allow_shallow_copy=allow_shallow_copy1,
                        )

            # -----------------------------------------------------
            # op_name: 'filter_records'
            # [Filters record according to where clause provided]
            # This operation is valuespace independent, all current valuespaces retained.
            # Calls method: Quble.filter_records
            # -----------------------------------------------------
            # scalar arg: filter_cmd (str)
            # dict key             dict value
            # --------             ----------
            # 'filter_cmd'         str
            # -----------------------------------------------------
            elif op_name == "filter_records":
                filter_cmd1 = None
                # Parse op_params
                if op_params is None:
                    pass
                elif isinstance(op_params, str):
                    # Assume scalar op is filter_cmd arg
                    filter_cmd1 = op_params
                elif not isinstance(op_params, dict):
                    raise Exception(
                        f"Processing op_name:{op_name}..invalid op_params:{op_params}...str,dict expected"
                    )
                else:
                    # Process op_params directives
                    for k, v in op_params.items():
                        if k == "filter_cmd":
                            filter_cmd1 = v
                        else:
                            raise Exception(
                                f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'filter_cmd'"
                            )
                if filter_cmd1:
                    src_data = src_data.filter_records(filter_cmd=filter_cmd1)

            # -----------------------------------------------------
            # op_name: 'multi_shift'
            # Incorporates delay(s)
            # This operation is valuespace independent, all current valuespaces retained.
            # Calls method: Quble.multi_shift1d
            # -----------------------------------------------------
            # scalar arg: throw Exception...dict required
            # -----------------------------------------------------
            # dict key                             dict value
            # --------                             ----------
            # 'delay' or 'shift' or 'shifts'       int/list of ints/comma-delimited str or None [default=None]
            # 'delay_keyspace' or 'shift_keyspace' str or None [default=None]
            #     ==> If None, will consult: context_lib.get_property('delay_keyspace', grace=True, default_property_value='Delay')
            # 'tfill_end_mode'                     str or None [default='no_extension']
            # 'valuespace'                         str [default="<valuespaces>"]
            # -----------------------------------------------------
            elif op_name == "multi_shift":
                # NOTE: Currently, variate Quble is required here
                if not dates_keyspace:
                    # Non-historical src_data
                    if grace:
                        pass
                    else:
                        raise Exception(
                            f"Processing op_name:{op_name}...no time_keyspaces present"
                        )
                elif dates_keyspace not in src_data.keyspaces:
                    # Should probably not happen...could consider throwing an Exception here
                    if grace:
                        pass
                    else:
                        raise Exception(
                            f"Processing op_name:{op_name}...dates_keyspace:{dates_keyspace} absent from keyspaces:{src_data.keyspaces}"
                        )
                else:
                    shifts1 = None
                    keyspace1 = None
                    delay_keyspace1 = None
                    tfill_end_mode1 = "no_extension"
                    valuespace1 = "<valuespaces>"

                    # op_params must be a dictionary here
                    if op_params is None:
                        pass
                    elif not isinstance(op_params, dict):
                        raise Exception(
                            f"Processing op_name:{op_name}..invalid op_params:{op_params}...dict expected"
                        )
                    # Process op_params directives
                    for k, v in op_params.items():
                        if k in ("delay", "shift", "shifts"):
                            shifts1 = v
                        elif k in ("delay_keyspace", "shift_keyspace"):
                            delay_keyspace1 = v
                        elif k == "tfill_end_mode":
                            tfill_end_mode1 = v
                        elif k == "valuespace":
                            valuespace1 = v
                        else:
                            raise Exception(
                                f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'shifts', 'shift_keyspace', 'tfill_end_mode', 'valuespace"
                            )

                    # Validate shifts1
                    if shifts1 is None:
                        pass
                    else:
                        if delay_keyspace1 is None and context_lib is not None:
                            delay_keyspace1 = context_lib.get_property(
                                "delay_keyspace",
                                grace=True,
                                default_property_value="Delay",
                            )
                        if delay_keyspace1 is None:
                            delay_keyspace1 = "Delay"

                        src_data = src_data.multi_shift1d(
                            shifts=shifts1,
                            keyspace=dates_keyspace,
                            valuespace=valuespace1,
                            shift_keyspace=delay_keyspace1,
                            tfill_end_mode=tfill_end_mode1,
                        )

            # ---------------------------------------------------------
            # op_name: 'multi_hold'
            # [Incorporates hold(s) (rebalancing)
            # Calls method: Quble.multi_hold1d
            # ---------------------------------------------------------
            # scalar arg: throw Exception...dict required
            # ---------------------------------------------------------
            # dict key                    dict value
            # --------                    ----------
            # 'rebal_freq' or 'windows'   int/list of ints/comma-delimited str or None [default=None]
            # 'rebal_freq_keyspace'       str or None [default=None]
            #     ==> If None, will consult: context_lib.get_property('rebal_freq_keyspace', grace=True, default_property_value='Rebal_Freq')
            # 'num_stagger'               int or None [default=None]
            # 'stagger_keyspace'          str or None [default=None]
            #     ==> If None, will consult: context_lib.get_property('stagger_keyspace', grace=True, default_property_value='Stagger')
            # 'tfill_method'              str or None [default='pad']
            # 'force_first_key'           bool [default=True]
            # 'tfill_end_mode'            str [default='no_future']
            # 'valuespace'                str [default="<valuespaces>"]
            # ---------------------------------------------------------
            elif op_name == "multi_hold":
                # NOTE: Currently, variate Quble is required here
                if not dates_keyspace:
                    # Non-historical src_data
                    if grace:
                        pass
                    else:
                        raise Exception(
                            f"Processing op_name:{op_name}...no time_keyspaces present"
                        )
                elif dates_keyspace not in src_data.keyspaces:
                    # Should probably not happen...could consider throwing an Exception here
                    if grace:
                        pass
                    else:
                        raise Exception(
                            f"Processing op_name:{op_name}...dates_keyspace:{dates_keyspace} absent from keyspaces:{src_data.keyspaces}"
                        )
                else:
                    windows1 = None
                    rebal_freq_keyspace1 = None
                    num_stagger1 = None
                    stagger_keyspace1 = None
                    tfill_method1 = "pad"
                    force_first_key1 = True
                    tfill_end_mode1 = "no_future"
                    valuespace1 = "<valuespaces>"

                    # op_params must be a dictionary here
                    if op_params is None:
                        pass
                    elif not isinstance(op_params, dict):
                        raise Exception(
                            f"Processing op_name:{op_name}..invalid op_params:{op_params}...dict expected"
                        )
                    else:
                        # Process op_params directives
                        for k, v in op_params.items():
                            if k in ("rebal_freq", "windows"):
                                windows1 = v
                            elif k == "rebal_freq_keyspace":
                                rebal_freq_keyspace1 = v
                            elif k == "num_stagger":
                                num_stagger1 = v
                            elif k == "stagger_keyspace":
                                stagger_keyspace1 = v
                            elif k == "tfill_method":
                                tfill_method1 = v
                            elif k == "force_first_key":
                                force_first_key1 = v
                            elif k == "tfill_end_mode":
                                tfill_end_mode1 = v
                            elif k == "valuespace":
                                valuespace1 = v
                            else:
                                raise Exception(
                                    f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'windows', 'rebal_freq_keyspace', 'num_stagger', 'stagger_keyspace', 'tfill_method', 'force_first_key', 'tfill_end_mode', 'valuespace'"
                                )

                    # ------------------------------------------------------
                    # Incorporate rebal_freq (if applicable)...
                    # ------------------------------------------------------
                    # NOTE: Staggering only applies if rebalancing applies
                    # ------------------------------------------------------
                    if windows1 is None:
                        pass
                    elif windows1 == 1:
                        pass
                    else:
                        if rebal_freq_keyspace1 is None and context_lib is not None:
                            rebal_freq_keyspace1 = context_lib.get_property(
                                "rebal_freq_keyspace",
                                grace=True,
                                default_property_value="Rebal_Freq",
                            )
                        if rebal_freq_keyspace1 is None:
                            rebal_freq_keyspace1 = "Rebal_Freq"

                        if num_stagger1 is None and context_lib is not None:
                            num_stagger1 = context_lib.get_property(
                                "num_stagger", grace=True
                            )

                        if stagger_keyspace1 is None and context_lib is not None:
                            stagger_keyspace1 = context_lib.get_property(
                                "stagger_keyspace",
                                grace=True,
                                default_property_value="Stagger",
                            )
                        if stagger_keyspace1 is None:
                            stagger_keyspace1 = "Stagger"

                        src_data = src_data.multi_hold1d(
                            windows=windows1,
                            keyspace=dates_keyspace,
                            valuespace=valuespace1,
                            window_keyspace=rebal_freq_keyspace1,
                            num_stagger=num_stagger1,
                            stagger_keyspace=stagger_keyspace1,
                            tfill_method=tfill_method1,
                            force_first_key=force_first_key1,
                            tfill_end_mode=tfill_end_mode1,
                        )

            # ---------------------------------------------------------
            # op_name: 'aggr_fill' or 'sub_aggr_fill'
            # [Fills null values using aggregated values
            # Calls method: Quble.aggr_fill/sub_aggr_fill
            # ---------------------------------------------------------
            # scalar arg: throw Exception...dict required
            # ---------------------------------------------------------
            # dict key                    dict value
            # --------                    ----------
            # 'keymap'(for sub_aggr_fill) str (LibAddress or valuespace) or Quble or None [default=None]
            # 'aggr_keyspaces'            str or list of strs or None [default="<keyspaces>"]
            # 'aggr_method'               str or None [default=None] may contain keymap as prefix...Example: "mean:TRBC2"
            # 'valuespace'                str or list of strs [default="<numeric_valuespaces>"]
            # 'pct_required'              float or None [default=0.0]
            # 'num_required'              int or None [default=0]
            # 'fill_max'                  int or None [default=None]
            # 'pct_required_glb'          float or None [default=0.0]
            # 'num_required_glb'          int or None [default=0]
            # 'fill_max_glb'              int or None [default=None]
            # ---------------------------------------------------------
            elif op_name in ("aggr_fill", "sub_aggr_fill"):
                if src_data.is_nonvariate:
                    # No valuespaces to operate on (and choosing to leave as non-variate)
                    pass
                else:
                    keymap1 = None
                    aggr_keyspaces1 = "<keyspaces>"
                    aggr_method1 = None
                    # We can consider possible inclusion of non-numeric valuespaces
                    # if/when we use/support aggr methods such as "first"/"last"/etc...
                    valuespace1 = "<numeric_valuespaces>"
                    pct_required1 = 0.0
                    num_required1 = 0
                    fill_max1 = None
                    pct_required_glb1 = 0.0
                    num_required_glb1 = 0
                    fill_max_glb1 = None

                    # op_params must be a dictionary here
                    if op_params is None:
                        pass
                    elif not isinstance(op_params, dict):
                        raise Exception(
                            f"Processing op_name:{op_name}..invalid op_params:{op_params}...dict expected"
                        )
                    else:
                        # Process op_params directives
                        for k, v in op_params.items():
                            if k == "keymap":
                                # Establish keymap
                                if not isinstance(v, str):
                                    # Nominally, v will be a Quble or None here
                                    keymap1 = v
                                elif v in src_data.valuespaces:
                                    # Here, we assume the specified valuespace of src_data provides the keymap
                                    pass
                                else:
                                    # Here, we assume that a value address was given (which we ideally hope to resolve to a Quble)
                                    keymap1 = RootLib()[v]

                            elif k == "aggr_keyspaces":
                                aggr_keyspaces1 = v
                            elif k == "aggr_method":
                                aggr_method1 = v
                                if aggr_method1 is None:
                                    pass
                                elif not isinstance(aggr_method1, str):
                                    raise Exception(
                                        f"Processing op_name:{op_name}..invalid op_params:{op_params}...'aggr_method' must be a str or None"
                                    )
                                else:
                                    # See if a keymap reference was used...Example: mean:TRBC2
                                    aggr_method1_parts = aggr_method1.split(":")
                                    if len(aggr_method1_parts) > 1:
                                        sub_keyspace1 = aggr_method1_parts[1].strip()
                                        if len(sub_keyspace1) == 0:
                                            sub_keyspace1 = None
                                    else:
                                        sub_keyspace1 = None

                                    aggr_method1 = aggr_method1_parts[0].strip()

                                    if sub_keyspace1 is not None:
                                        keymap1 = RootLib().ks_map(
                                            src_data.security_keyspace(grace=False),
                                            sub_keyspace1,
                                        )

                            elif k == "valuespace":
                                valuespace1 = v
                            elif k == "pct_required":
                                pct_required1 = v
                            elif k == "num_required":
                                num_required1 = v
                            elif k == "fill_max":
                                fill_max1 = v
                            elif k == "pct_required_glb":
                                pct_required_glb1 = v
                            elif k == "num_required_glb":
                                num_required_glb1 = v
                            elif k == "fill_max_glb":
                                fill_max_glb1 = v
                            else:
                                raise Exception(
                                    f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'aggr_keyspaces', 'aggr_method', 'valuespace', 'pct_required', 'num_required', 'fill_max', 'pct_required_glb', 'num_required_glb', 'fill_max_glb'"
                                )

                    # --------------------
                    # Apply aggr_fill...
                    # --------------------
                    if aggr_method1 is None:
                        # Absence of a specified aggr_method not acceptable
                        # It is too dangerous to pass through silently here
                        raise Exception(
                            f"Processing op_name:{op_name}..invalid op_params:{op_params}...no aggr_method specified"
                        )
                    elif keymap1 is None:
                        src_data = src_data.aggr_fill(
                            aggr_keyspaces=aggr_keyspaces1,
                            aggr_method=aggr_method1,
                            valuespace=valuespace1,
                            pct_required=pct_required1,
                            num_required=num_required1,
                            fill_max=fill_max1,
                            pct_required_glb=pct_required_glb1,
                            num_required_glb=num_required_glb1,
                            fill_max_glb=fill_max_glb1,
                        )
                    else:
                        src_data = src_data.sub_aggr_fill(
                            keymap=keymap1,
                            aggr_keyspaces=aggr_keyspaces1,
                            aggr_method=aggr_method1,
                            valuespace=valuespace1,
                            pct_required=pct_required1,
                            num_required=num_required1,
                            fill_max=fill_max1,
                            pct_required_glb=pct_required_glb1,
                            num_required_glb=num_required_glb1,
                            fill_max_glb=fill_max_glb1,
                        )

            # ---------------------------------------------------------
            # op_name: 'unfill' or 'sub_unfill'
            # [Un-fills non-null values subject to unfilling criteria
            # Calls method: Quble.unfill/sub_unfill
            # ---------------------------------------------------------
            # scalar arg: throw Exception...dict required
            # ---------------------------------------------------------
            # dict key                    dict value
            # --------                    ----------
            # 'keymap'(for sub_aggr_fill) str (LibAddress or valuespace) or Quble or None [default=None]
            # 'aggr_keyspaces'            str or list of strs or None [default="<keyspaces>"]
            # 'valuespace'                str or list of strs [default="<valuespaces>"]
            # 'unfill_pct_max'            float or None [default=None]
            # 'unfill_max'                int or None [default=None]
            # ---------------------------------------------------------
            elif op_name in ("unfill", "sub_unfill"):
                if src_data.is_nonvariate:
                    # No valuespaces to operate on (and choosing to leave as non-variate)
                    pass
                else:
                    keymap1 = None
                    aggr_keyspaces1 = "<keyspaces>"
                    valuespace1 = "<valuespaces>"
                    unfill_pct_max1 = None
                    unfill_max1 = None

                    # op_params must be a dictionary here
                    if op_params is None:
                        pass
                    elif not isinstance(op_params, dict):
                        raise Exception(
                            f"Processing op_name:{op_name}..invalid op_params:{op_params}...dict expected"
                        )
                    else:
                        # Process op_params directives
                        for k, v in op_params.items():
                            if k == "keymap":
                                # Establish keymap
                                if not isinstance(v, str):
                                    # Nominally, v will be a Quble or None here
                                    keymap1 = v
                                elif v in src_data.valuespaces:
                                    # Here, we assume the specified valuespace
                                    # of src_data provides the keymap
                                    pass
                                else:
                                    # Here, we assume that a value address was given
                                    # (which we ideally hope to resolve to a Quble)
                                    keymap1 = RootLib()[v]

                            elif k == "aggr_keyspaces":
                                aggr_keyspaces1 = v
                            elif k == "aggr_method":
                                aggr_method1 = v
                                if aggr_method1 is None:
                                    pass
                                elif not isinstance(aggr_method1, str):
                                    raise Exception(
                                        f"Processing op_name:{op_name}..invalid op_params:{op_params}...'aggr_method' must be a str or None"
                                    )
                                else:
                                    # See if a keymap reference was used...Example: mean:TRBC2
                                    aggr_method1_parts = aggr_method1.split(":")
                                    if len(aggr_method1_parts) > 1:
                                        sub_keyspace1 = aggr_method1_parts[1].strip()
                                        if len(sub_keyspace1) == 0:
                                            sub_keyspace1 = None
                                    else:
                                        sub_keyspace1 = None

                                    aggr_method1 = aggr_method1_parts[0].strip()

                                    if sub_keyspace1 is not None:
                                        keymap1 = RootLib().ks_map(
                                            src_data.security_keyspace(grace=False),
                                            sub_keyspace1,
                                        )

                            elif k == "valuespace":
                                valuespace1 = v
                            elif k == "pct_required":
                                pct_required1 = v
                            elif k == "num_required":
                                num_required1 = v
                            elif k == "fill_max":
                                fill_max1 = v
                            elif k == "pct_required_glb":
                                pct_required_glb1 = v
                            elif k == "num_required_glb":
                                num_required_glb1 = v
                            elif k == "fill_max_glb":
                                fill_max_glb1 = v
                            else:
                                raise Exception(
                                    f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'aggr_keyspaces', 'aggr_method', 'valuespace', 'pct_required', 'num_required', 'fill_max', 'pct_required_glb', 'num_required_glb', 'fill_max_glb'"
                                )

                    # --------------------
                    # Apply aggr_fill...
                    # --------------------
                    if aggr_method1 is None:
                        # Absence of a specified aggr_method not acceptable
                        # It is too dangerous to pass through silently here
                        raise Exception(
                            f"Processing op_name:{op_name}..invalid op_params:{op_params}...no aggr_method specified"
                        )
                    elif keymap1 is None:
                        src_data = src_data.unfill(
                            aggr_keyspaces=aggr_keyspaces1,
                            valuespace=valuespace1,
                            unfill_pct_max=unfill_pct_max1,
                            unfill_max=unfill_max1,
                        )
                    else:
                        src_data = src_data.sub_unfill(
                            keymap=keymap1,
                            aggr_keyspaces=aggr_keyspaces1,
                            valuespace=valuespace1,
                            unfill_pct_max=unfill_pct_max1,
                            unfill_max=unfill_max1,
                        )

            # -------------------------------------------------------------------
            # op_name: 'get'
            # [Isolates a sub-set of the Quble]
            # Calls method: Quble.get
            # -------------------------------------------------------------------
            # Assume scalar param: hyper_key arg (scalar of various forms)
            # or a multiple-key dictionary:
            # dict key                   dict value
            # --------                   ----------
            # 'hyper_key'
            # '<a valid keyspace>'       scalar or list
            # -------------------------------------------------------------------
            elif op_name == "get":
                if op_params is None:
                    # Nothing to get in this case
                    pass
                elif not isinstance(op_params, dict):
                    raise Exception(
                        f"Processing op_name:{op_name}..invalid op_params:{op_params}...dict expected"
                    )
                else:
                    # Initialize defaults
                    hyper_key1 = None  # <-- Will eventually be required below
                    auto_squeeze1 = RootLib().get_control("auto_squeeze")
                    auto_fill1 = RootLib().get_control("auto_fill")
                    tfill_method1 = RootLib().get_control("tfill_method")
                    tfill_max1 = RootLib().get_control("tfill_max")
                    tfill_end_mode1 = RootLib().get_control("tfill_end_mode")
                    tfill_honor_nulls1 = RootLib().get_control("tfill_honor_nulls")

                    # What is the format of the op_perams provided?
                    if "hyper_key" in op_params:
                        # Here, the user provided specific Quble.get() method args
                        # As such, process each op_params directive...
                        for k, v in op_params.items():
                            if k == "hyper_key":
                                hyper_key1 = op_params["hyper_key"]
                            elif k == "auto_squeeze":
                                auto_squeeze1 = op_params["auto_squeeze"]
                            elif k == "auto_fill":
                                auto_fill1 = op_params["auto_fill"]
                            elif k == "tfill_method":
                                tfill_method1 = op_params["tfill_method"]
                            elif k == "tfill_max":
                                tfill_max1 = op_params["tfill_max"]
                            elif k == "tfill_end_mode":
                                tfill_end_mode1 = op_params["tfill_end_mode"]
                            elif k == "tfill_honor_nulls":
                                tfill_honor_nulls1 = op_params["tfill_honor_nulls"]
                            else:
                                raise Exception(
                                    f"Processing op_name:{op_name}..invalid op_params:{op_params}...valid dict keys: 'hyper_key', 'auto_squeeze', 'auto_fill', 'tfill_method', 'tfill_max', 'tfill_end_mode', 'tfill_honor_nulls'"
                                )
                    else:
                        # Here, the user implicitly provided only the hyper_key for Quble.get()
                        # Assume the direct hyper_key was given as a dict
                        hyper_key1 = op_params

                    # Apply the Quble.get operation with the provided op_params
                    if hyper_key1 is not None:
                        src_data = src_data.get(
                            hyper_key=hyper_key1,
                            auto_squeeze=auto_squeeze1,
                            auto_fill=auto_fill1,
                            tfill_method=tfill_method1,
                            tfill_max=tfill_max1,
                            tfill_end_mode=tfill_end_mode1,
                            tfill_honor_nulls=tfill_honor_nulls1,
                        )

            else:
                raise Exception(
                    f"Cannot perform Quble cleanse operation. Invalid op_name:{op_name}"
                )

        # ================================== END: operator loop =================================

        # Handle case when no material operations were performed
        # but the user requested to not allow_shallow_copy
        if (
            src_data.table_name is not None
            and src_data.table_name == orig_table
            and not allow_shallow_copy
        ):
            # Here, the original Quble has not been modified
            src_data = src_data.copy()

        return src_data

    def locate_keymap(
        self, keymap_proxy: str, keymap_lib="SECINFO", grace: bool = False
    ):
        """
        Given a keymap_proxy (str or Quble or None),
        locates the associated (security-based) keymap (Quble)
        by searching through fields of the designated keymap_lib
        (or the RootLib when keymap_lib is not provided)
        """
        if keymap_proxy is None:
            return keymap_proxy
        elif isinstance(keymap_proxy, Quble):
            return keymap_proxy
        elif not isinstance(keymap_proxy, str):
            raise Exception(
                f"Invalid keymap_proxy:{keymap_proxy}...str or Quble expected yet type(keymap_proxy):{type(keymap_proxy)}"
            )
        else:
            keymap_proxy = keymap_proxy.strip()
            # Find keymap_lib
            keymap_lib_orig = keymap_lib  # <-- For latter diagnostics below
            if keymap_lib is None:
                keymap_lib = RootLib()
            elif isinstance(keymap_lib, DataLib):
                pass
            elif not isinstance(keymap_lib, str):
                raise Exception(
                    f"Invalid keymap_lib:{keymap_lib}...str, DataLib or None expected"
                )
            elif keymap_lib in RootLib().fields():
                # Assume keymap_lib represents a global address
                keymap_lib = RootLib()[keymap_lib]
            else:
                keymap_lib = None

            # First, look for keymap_proxy (str) field
            # within the keymap_lib (DataLib)
            # Then, (re)assign keymap using this field
            # Initialize keymap
            keymap = None
            if keymap_lib is not None and isinstance(keymap_lib, DataLib):
                # The below if condition takes care of case-sensitive comparison
                if keymap_proxy in keymap_lib.fields():
                    keymap = keymap_lib[keymap_proxy]
                # The below elif condition takes care of case-insensitive comparison
                # For Ex - In some cases, The field : REGION2 is being passed as Region2
                # The SECINFO library has REGION2 init, we make sure to perform case-insensitive comparison
                elif keymap_proxy.upper() in keymap_lib.fields():
                    keymap = keymap_lib[keymap_proxy.upper()]

            # Did we find a valid Quble keymap?
            # Confirm that keymap is a valid, defined Quble
            if keymap is None:
                if grace:
                    return keymap
                else:
                    raise Exception(
                        f"Unable to locate keymap for keymap_proxy:{keymap_proxy} w/keymap_lib:{keymap_lib_orig}"
                    )
            elif not isinstance(keymap, Quble):
                raise Exception(
                    f"Non-Quble keymap for keymap_proxy:{keymap_proxy} w/keymap_lib:{keymap_lib_orig}"
                )
            elif keymap.is_undefined:
                raise Exception(
                    f"Undefined Quble keymap for keymap_proxy:{keymap_proxy} w/keymap_lib:{keymap_lib_orig}"
                )

            return keymap

    def _parse_func_name(self, func_name, keymap_lib="SECINFO"):
        """
        Given a function name (string with an optional ':' delimiter)
        as well as an optional keymap_lib

          1) Identifies prefix as sub_func_name
          2) Tries to locate a (security-based)
             keymap (Quble) from the suffix string

        Returns tuple: (sub_func_name, keymap)
        """
        func_name_parts = func_name.split(":")
        sub_fn_name = func_name_parts[0].strip()
        keymap = None  # <-- Initialization

        # Are we being asked to perform a sub-function?
        # If so, we need to resolve the keymap
        if len(func_name_parts) > 1:
            keymap = self.locate_keymap(
                keymap_proxy=func_name_parts[1],
                keymap_lib=keymap_lib,
                grace=False,
            )

        return (sub_fn_name, keymap)

    @RootLib.lazy_kwargs()
    def transform1d(
        self,
        transform_method: str,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        winsorize_level: float = 3.0,
        keymap_lib="SECINFO",
    ) -> Quble:
        """
        (Generalized) transformation of the specified valuespaces
        across the specified one-dimension of a Quble...
        Valid transform_method: None, 'Z', 'ZW', 'ZI', 'PR', 'DM',
        'Z:GICS<2/4/6/8>', 'PR:GICS<2/4/6/8>', 'DM:GICS<2/4/6/8>'

        :param transform_method: tranformation operation
        :type transform_method: str
            ==> 'Z': Z-Score
            ==> 'ZW': Z-Score with Winsorization
            ==> 'ZI': Inverse CDF Z-Score
            ==> 'PR': Percentile Rank [0,100]
            ==> 'UR': Uniform Rank [0,1]
            ==> 'BR': Bi-uniform Rank [-1,+1]
            ==> 'DM': De-Mean

        :param keyspace: keyspace(s) over which to apply transformation
        :type keyspace: str or list/tuple of strings

        :param valuespace: valuespace(s) to transform
        :type valuespace: str or list

        :param view: Quble indicating conditional elements
                     for which transformation will be applied
                     (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :param ignore_missing: Flag that controls the ignore_missing
                               for statistical calcs (for implicit aggregation)
        :type ignore_missing: bool

        :param winsorize_level: Post-zscore winsorization (truncation) level (e.g., 3.0)
        :type winsorize_level: None or float (symmetric) or two-element tuple/list: (min,max)

        :param keymap_lib: Lib for locating keymap (when applicable)
        :type keymap_lib: str (LibAddress) or DataLib or None

        NOTE: Will inspect RootLib to find keymap (e.g., keyspace->subkeyspace) when applicable.
        """
        # Validate self
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_empty:
            return self.copy()

        # Validate transform_method
        if transform_method is None:
            return self.copy()
        elif not isinstance(transform_method, str):
            raise Exception("Invalid transform_method arg: str expected")
        elif keyspace is None:
            raise Exception("keyspace required")

        # Parse transform_method arg...
        # Format of transform_method: <transform_fn_name>:<sub_keyspace>
        # Here, the usage of colon and suffix is optional
        # --------------------------------------------------
        (transform_fn_name, keymap) = self._parse_func_name(
            func_name=transform_method, keymap_lib=keymap_lib
        )
        # When the keymap is not None,
        # then a security keyspace is required
        security_keyspace_required = keymap is not None

        # Validate keyspace
        # ----------------
        keyspace = self.validate_keyspace(
            keyspace,
            grace=True,
            solo_required=True,
            security_space_required=security_keyspace_required,
        )
        if keyspace not in self.keyspaces:
            return self.clear()  # Return an empty image of self

        # Validate valuespace (numeric valuespace(s) only)
        valuespace = self.validate_valuespace(
            valuespace, grace=False, coerce_to_list=True, numeric_required=True
        )

        # Isolate valuespaces as subject
        # [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # CASE 1: Z-Score (or subset there of)
        # --------------------------------------
        if transform_fn_name == "Z":
            if keymap is None:
                return subject.zscore1d(
                    keyspace=keyspace,
                    valuespace=valuespace,
                    ignore_missing=ignore_missing,
                    pct_required=0.0,
                    view=view,
                )
            else:
                return subject.sub_zscore1d(
                    keymap=keymap,
                    keyspace=keyspace,
                    valuespace=valuespace,
                    ignore_missing=ignore_missing,
                    view=view,
                )
        # CASE 2: Z-Score with Winsorization (or subset there of)
        # ---------------------------------------------------------
        elif transform_fn_name == "ZW":
            if keymap is None:
                return subject.zscore1d(
                    keyspace=keyspace,
                    valuespace=valuespace,
                    ignore_missing=ignore_missing,
                    pct_required=0.0,
                    view=view,
                    winsorize_level=winsorize_level,
                )
            else:
                return subject.sub_zscore1d(
                    keymap=keymap,
                    keyspace=keyspace,
                    valuespace=valuespace,
                    ignore_missing=ignore_missing,
                    view=view,
                    winsorize_level=winsorize_level,
                )
        # CASE 3: Z-Score Inverse Normal CDF (or subset there of)
        # ----------------------------------------------------------
        elif transform_fn_name == "ZI":
            if keymap is None:
                return subject.zscore_invnorm1d(
                    keyspace=keyspace,
                    valuespace=valuespace,
                    ascending=True,
                    ignore_missing=ignore_missing,
                    view=view,
                )
            else:
                return subject.zscore_invnorm1d(
                    keyspace=keyspace,
                    keymap=keymap,
                    valuespace=valuespace,
                    ascending=True,
                    ignore_missing=ignore_missing,
                    view=view,
                )
        # CASE 4: Percentile/Uniform/Bi-uniform Rank Case (or subset)
        # -----------------------------------------------------------
        elif transform_fn_name in ("PR", "UR", "BR"):
            if keymap is None:
                if transform_fn_name == "UR":
                    min_value = 0.0
                    max_value = 1.0
                elif transform_fn_name == "BR":
                    min_value = -1.0
                    max_value = 1.0
                else:  # elif transform_fn_name == "PR":
                    min_value = 0.0
                    max_value = 100.0

                return subject.pct_rank1d(
                    keyspace=keyspace,
                    valuespace=valuespace,
                    ascending=True,
                    ignore_missing=ignore_missing,
                    view=view,
                    min_value=min_value,
                    max_value=max_value,
                )
            elif transform_fn_name == "UR":
                return subject.sub_uniform_rank1d(
                    keymap=keymap,
                    keyspace=keyspace,
                    valuespace=valuespace,
                    ascending=True,
                    ignore_missing=ignore_missing,
                    view=view,
                )
            elif transform_fn_name == "BR":
                return subject.sub_biuniform_rank1d(
                    keymap=keymap,
                    keyspace=keyspace,
                    valuespace=valuespace,
                    ascending=True,
                    ignore_missing=ignore_missing,
                    view=view,
                )
            else:
                return subject.sub_pct_rank1d(
                    keymap=keymap,
                    keyspace=keyspace,
                    valuespace=valuespace,
                    ascending=True,
                    ignore_missing=ignore_missing,
                    view=view,
                )

        # CASE 5: "De-Meaned" (or subset there of)
        # --------------------------------------------
        elif transform_fn_name == "DM":
            if keymap is None:
                return subject.demean1d(
                    keyspace=keyspace,
                    valuespace=valuespace,
                    ignore_missing=ignore_missing,
                    pct_required=0.0,
                    view=view,
                )
            else:
                return subject.sub_demean1d(
                    keymap=keymap,
                    keyspace=keyspace,
                    valuespace=valuespace,
                    ignore_missing=ignore_missing,
                    view=view,
                )
        else:
            raise Exception(f"Bad transform_fn_name arg: {transform_fn_name}")

    def run_stats_loop(
        self, stats_key, local_stats_dict, stats_keyspace, num_chars_longest_stats_key
    ):
        if stats_key not in local_stats_dict:
            raise Exception(
                "Internal inconsistency...stats_key:{0} not present in local_stats_dict"
            )
        local_stats = local_stats_dict[stats_key]

        if local_stats is None or local_stats.is_empty:
            return Quble.undefined_instance()

        local_stats = local_stats.insert_keyspace(
            keyspace=stats_keyspace,
            key=stats_key,
            col_type=f"varchar({str(num_chars_longest_stats_key)})",
        )

        return local_stats

    @RootLib.lazy_kwargs()
    @RootLib.temp_frame()
    def multi_stats1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        stats_keyspace: str = "Stats",
        valuespace="<numeric_valuespaces>",
        stats_mode="ARITH",
        sub_ranges=None,
        subrange_keyspace: str = None,
        ignore_missing: bool = True,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        vs_prefix_delimiter=":",
    ) -> Quble:
        """
        Multi-Stats summary across specified time-keyspace
        for each orthogonal (non-time) keyspace of self

        ==> Result will be a multi-dimensional numeric Quble with following keyspaces:

             + othogonal (non-time) keyspaces of self
             + stats_keyspace
             + subrange_keyspace (if sub_ranges provided)

        ==> Result may be multi-variate (depending on valuespace arg)
        ==> Result will contain a new keyspace (stats_keyspace) to reference each respective summary statistic
        ==> Result may also contain the new subrange_keyspace if a non-trivial sub_ranges Quble is provided
        ==> Result will no longer contain the specified (time) keyspace (a.k.a., auto_squeeze=True)

        :param keyspace: time-keyspace of self over which to compute stats
        :type keyspace: str

        :param stats_keyspace: (optional) new output keyspace that qualifies stats by stats keys
            ==> when stats_keyspace=None, each resultant statistic will be stored
            ==> as a "pivoted" Quble with (possibly multiple) valuespaces
        :type stats_keyspace: str

        :param valuespace: participating (numeric) valuespace(s) over which to compute stats
                           [By default, all numeric valuespaces will participate]
        :type valuespace: str

        :param stats_mode: stats to be computed
        :type stats_mode: string (comma-delimited) or list/tuple of strings

            ==> Parses the comma-delimited stats_mode (property)
            ==> Supported stats keys:

           'NUM':  non-missing sample count
           'SUM'
           'MEAN'
           'STD'
           'S2N'

           'GEO_MEAN'
           'GEO_CUME'
           'GEO_MEAN_ANN'
           'GEO_STD_ANN'
           'MAX_DRAWDOWN'
           'GEO_IR'

           'TSTAT'

          OR Special short-cut args...

           'ARITH' ==> 'NUM','SUM','MEAN','STD','S2N'
           'GEO' ==> 'NUM','GEO_MEAN','GEO_CUME','GEO_MEAN_ANN','GEO_STD_ANN','GEO_IR'

        NOTE: If stats_mode ends with an asterisk (i.e., stats_mode[-1] == '*'),
        then a squeeze of the stats_keyspace will be attempted

        :param sub_ranges: (optional) Quble that identified the sub-ranges for computation
        :type sub_ranges: (index or boolean-valued) Quble or None

        :param subrange_keyspace: (optional) keyspace of the sub_ranges Quble
                                  that denotes each sub-range.
                                  Will only be used to unpivot multi-variate sub_ranges
        :type subrange_keyspace: Quble

          ==> NOTE: if sub_ranges is None, then unqualified statistics will be computed
          ==> sub_ranges Quble should exhibit both the specified keyspace

        :param vs_prefix_delimiter: (optional) delimiter between valuespace prefix and stats suffix
        :type vs_prefix_delimiter: string (or None)
            ==> ONLY applies when stats_keyspace=None
                Here, we create multi-variate Quble result w/target valuespaces: <original valuespace><delimiter><stat>
                For example: if Quble has original valuespaces: ["X","Y","Z"] and stats_mode="NUM,MEAN"
                in this case, w/vs_prefix_delimiter=":" yields 6V Quble
                w/valuespaces: ["X:NUM","X:MEAN","Y:NUM","Y:MEAN","Z:NUM","Z:MEAN"]
            ==> vs_prefix_delimiter is IGNORED when stats_keyspace is not None
            ==> When stats_keyspace=None and vs_prefix_delimiter=None, no valuespace prefix is used
                In this case, user MUST provide/isolate a univariate Quble sub-set
                For example: if Quble has original valuespaces: ["X"] and stats_mode="NUM,MEAN"
                in this case, w/vs_prefix_delimiter=None yields 2V Quble w/valuespaces: ["NUM","MEAN"]
                NOTE: In this case, the valuespace IS ABSENT from the target valuespaces
        """
        # Validate self
        # ----------------
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_empty:
            return Quble()
        elif self.is_index:
            raise Exception("non-Index (valued) Quble required")

        keyspace = self.validate_keyspace(
            keyspace, grace=False, solo_required=True, time_space_required=True
        )

        # Establish & validate existing freq
        freq = self.get_space_info(
            info_type="freq", space=keyspace, allow_infer=True, assign_inferred=True
        )

        if freq is None:
            raise Exception("Unable to establish existing freq")
        elif freq not in PPY:
            raise Exception(f"Invalid freq:{freq}")
        else:
            periods_per_yr = PPY[freq]

        # -------------------------------------------------------------
        # Validate valuespace (numeric valuespace(s) only)
        # -------------------------------------------------------------
        # When stats_keyspace is None and vs_prefix_delimiter is None:
        # target valuespaces: ["<stat1>"", "<stat2>", ...]
        # Here, we will yield each stat as a separate valuespace.
        # In this case, we must specify/isolate a SINGLE valuespace
        # on which to perform these statistics
        # -------------------------------------------------------------
        valuespace = self.validate_valuespace(
            valuespace,
            grace=False,
            coerce_to_list=True,
            numeric_required=True,
            solo_required=stats_keyspace is None and vs_prefix_delimiter is None,
        )

        # Isolate valuespaces as subject
        # [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # Build stats_index
        # ------------------
        has_geo_stats = False

        # Evaluate whether to squeeze the stats_keyspace from the resultant summary Quble
        stats_keyspace_squeeze = False

        # Create stats_mode_strlist
        # --------------------------
        if isinstance(stats_mode, (list, tuple)):
            stats_mode_strlist = []
            for stats_mode1 in stats_mode:
                if stats_mode1 is None:
                    continue
                elif not isinstance(stats_mode1, str):
                    raise Exception(f"Non-string stats_mode:{stats_mode1}")
                elif len(stats_mode1) > 0:
                    stats_mode_strlist.append(stats_mode1)
        elif not isinstance(stats_mode, str):
            raise Exception(
                "Invalid stats_mode....string or list/tuple of strings expected"
            )
        else:
            stats_mode_strlist = stats_mode.split(",")

        # Process stats_mode_strlist to create stats_keylist
        # ---------------------------------------------------
        stats_keylist = []
        for stats_mode_str_tmp in stats_mode_strlist:
            if stats_mode_str_tmp is None or len(stats_mode_str_tmp) == 0:
                continue
            # Remove trailing asterisk from stats_mode
            elif stats_mode_str_tmp[-1] == "*":
                stats_mode_str_tmp = stats_mode_str_tmp[:-1]
                if len(stats_mode_str_tmp) == 0:
                    continue
                elif len(stats_mode_strlist) == 1:
                    stats_keyspace_squeeze = True

            stats_mode_str_upper = stats_mode_str_tmp.upper()

            if len(stats_mode_str_upper) == 0:
                pass
            # Handle 'ARITH' short-cut
            # -------------------------
            elif stats_mode_str_upper == "ARITH":
                # NOTE: 'ARITH' is not a stats key itself,
                # but serves as a qualifier/representative for other stats keys
                for stats_key1 in ("NUM", "SUM", "MEAN", "MEDIAN", "STD", "S2N"):
                    if stats_key1 not in stats_keylist:
                        # Make sure we do not add something twice
                        # (could happen with improper short-cut usage such as: stats_mode='ARITH,MEAN')
                        stats_keylist.append(stats_key1)
            # Handle 'GEO' short-cut
            # -----------------------
            elif stats_mode_str_upper == "GEO":
                # NOTE: 'GEO' is not a stats key itself,
                # but serves as a qualifier/representative for other stats keys
                has_geo_stats = True
                for stats_key1 in ("NUM", "GEO_MEAN", "GEO_CUME"):

                    if stats_key1 not in stats_keylist:
                        # Make sure we do not add something twice
                        # (could happen with improper short-cut usage such as: stats_mode='ARITH,MEAN')
                        stats_keylist.append(stats_key1)

                if periods_per_yr is not None:
                    for stats_key1 in (
                        "GEO_MEAN_ANN",
                        "GEO_STD_ANN",
                        "GEO_IR",
                    ):
                        if stats_key1 not in stats_keylist:
                            # Make sure we do not add something twice
                            # (could happen with improper short-cut usage such as: stats_mode='ARITH,MEAN')
                            stats_keylist.append(stats_key1)
            elif stats_mode_str_upper in ("NUM"):
                if stats_mode_str_upper not in stats_keylist:
                    # Make sure we do not add something twice
                    stats_keylist.append(stats_mode_str_upper)
            elif stats_mode_str_upper in ("SUM", "MEAN", "MEDIAN", "STD", "S2N"):
                if stats_mode_str_upper not in stats_keylist:
                    # Make sure we do not add something twice
                    stats_keylist.append(stats_mode_str_upper)
            elif stats_mode_str_upper in (
                "GEO_MEAN",
                "GEO_CUME",
                "GEO_MEAN_ANN",
                "GEO_STD_ANN",
                "GEO_IR",
            ):
                has_geo_stats = True
                if stats_mode_str_upper not in stats_keylist:
                    # Make sure we do not add something twice
                    stats_keylist.append(stats_mode_str_upper)
            elif stats_mode_str_upper in ("TSTAT"):
                if stats_mode_str_upper not in stats_keylist:
                    # Make sure we do not add something twice
                    stats_keylist.append(stats_mode_str_upper)
            elif stats_mode_str_upper in ("MAX_DRAWDOWN"):
                if stats_mode_str_upper not in stats_keylist:
                    # Make sure we do not add something twice
                    stats_keylist.append(stats_mode_str_upper)
            else:
                raise Exception(f"Invalid stats_mode component:{stats_mode_str_tmp}")

        # If no stats we requested,
        # return an empty Quble
        # -------------------------
        if len(stats_keylist) == 0:
            return Quble()

        # Set-Up Qubles Environment
        RootLib().set_control("ignore_add", False)
        RootLib().set_control("ignore_mult", False)
        RootLib().set_control("auto_squeeze", True)

        # ---------------------------------
        # Apply sub_ranges to subject...
        # ---------------------------------
        if sub_ranges is None:
            pass
        elif not isinstance(sub_ranges, Quble):
            raise Exception(f"Invalid sub_ranges:{sub_ranges}...Quble expected")
        elif sub_ranges.is_undefined:
            pass
        else:
            # Apply auto_link (as directed)
            # Verify presence of necessary keyspaces within sub_ranges
            # -------------------------------
            if auto_link:
                sub_ranges = sub_ranges.link_keyspaces(
                    subject.keyspaces,
                    link_check=link_check,
                    link_dupe_grace=link_dupe_grace,
                    deep_copy=False,
                    grace=True,
                )

            if sub_ranges.is_nonvariate:
                # Here, we wish to inherit subject (not index) context_freq
                subject = subject.inner_project(
                    index=sub_ranges, index_context_freq_flag=False
                )
            else:
                if (
                    subrange_keyspace is not None
                    and subrange_keyspace not in sub_ranges.keyspaces
                ):
                    # Here, subrange_keyspace is absent from sub_ranges.keyspaces
                    # so we interpret this scenario as inserting a new subrange_keyspace
                    # through then unpivoting of the sub_ranges valuespaces
                    sub_ranges = sub_ranges.unpivot(
                        new_keyspace=subrange_keyspace,
                        valuespaces_to_unpivot="<valuespaces>",
                        compress=True,
                        treat_false_as_null=True,
                    )
                # Apply primary valuespace (bool or numeric case) of sub_ranges
                # Here, we wish to inherit subject (not index) context_freq
                subject = subject.inner_project(
                    index=sub_ranges.variate_to_index(), index_context_freq_flag=False
                )

        local_stats_dict = {}

        # Computes local_count REGARDLESS of stats_keylist as this is used in many statistics
        # -----------------------------------------------------------------------------------
        local_stats_dict["NUM"] = subject.count1d(
            keyspace=keyspace, ignore_missing=ignore_missing, auto_squeeze=True
        )
        # These "fx" and "time_basis" issues
        # are already handled within the Quble.count1d method
        # if local_stats_dict["NUM"].is_variate:
        #     for info_type1 in ["time_basis","fx"]:
        #         local_stats_dict["NUM"].set_space_info(space="<valuespaces>", info_type=info_type1, info_value=None)

        # Computes & Store "Geometric" Statistics...
        # ---------------------------------------------
        if has_geo_stats:
            # Computes geo_prod as this is used in many geo statistics
            local_stats_dict["GEO_PROD"] = (subject + 1.0).prod1d(
                keyspace=keyspace, ignore_missing=ignore_missing, auto_squeeze=True
            )

        if "GEO_CUME" in stats_keylist and "GEO_CUME" not in local_stats_dict:
            local_stats_dict["GEO_CUME"] = local_stats_dict["GEO_PROD"] - 1.0

        if "GEO_MEAN" in stats_keylist and "GEO_MEAN" not in local_stats_dict:
            local_stats_dict["GEO_MEAN"] = (
                local_stats_dict["GEO_PROD"] ** (1.0 / local_stats_dict["NUM"])
            ) - 1.0

        if (
            ("GEO_MEAN_ANN" in stats_keylist)
            and (periods_per_yr is not None)
            and "GEO_MEAN_ANN" not in local_stats_dict
        ):
            local_stats_dict["GEO_MEAN_ANN"] = (
                local_stats_dict["GEO_PROD"]
                ** ((1.0 * periods_per_yr) / local_stats_dict["NUM"])
            ) - 1.0

        if (
            ("GEO_STD_ANN" in stats_keylist)
            and (periods_per_yr is not None)
            and "GEO_STD_ANN" not in local_stats_dict
        ):
            local_stats_dict["GEO_STD_ANN"] = subject.std1d(
                keyspace=keyspace, ignore_missing=ignore_missing, auto_squeeze=True
            ) * np.sqrt(1.0 * periods_per_yr)

        if (
            ("GEO_IR" in stats_keylist)
            and (periods_per_yr is not None)
            and "GEO_IR" not in local_stats_dict
        ):
            if "GEO_MEAN_ANN" not in local_stats_dict:
                local_stats_dict["GEO_MEAN_ANN"] = (
                    local_stats_dict["GEO_PROD"]
                    ** ((1.0 * periods_per_yr) / local_stats_dict["NUM"])
                ) - 1.0
            if "GEO_STD_ANN" not in local_stats_dict:
                local_stats_dict["GEO_STD_ANN"] = subject.std1d(
                    keyspace=keyspace, ignore_missing=ignore_missing, auto_squeeze=True
                ) * np.sqrt(1.0 * periods_per_yr)

            local_stats_dict["GEO_IR"] = (
                local_stats_dict["GEO_MEAN_ANN"] / local_stats_dict["GEO_STD_ANN"]
            )
            if local_stats_dict["GEO_IR"].is_variate:
                for info_type1 in ["time_basis", "fx"]:
                    local_stats_dict["GEO_IR"].set_space_info(
                        space="<valuespaces>", info_type=info_type1, info_value=None
                    )

        if "MAX_DRAWDOWN" in stats_keylist and "MAX_DRAWDOWN" not in local_stats_dict:
            local_stats_dict["MAX_DRAWDOWN"] = subject.max_drawdown1d(
                geo_cume_src_flag=False
            )

        # Compute & Store "Arithmetic" Statistics...
        # ---------------------------------------------
        if "SUM" in stats_keylist and "SUM" not in local_stats_dict:
            local_stats_dict["SUM"] = subject.sum1d(
                keyspace=keyspace, ignore_missing=ignore_missing, auto_squeeze=True
            )

        if "MEAN" in stats_keylist and "MEAN" not in local_stats_dict:
            local_stats_dict["MEAN"] = subject.mean1d(
                keyspace=keyspace, ignore_missing=ignore_missing, auto_squeeze=True
            )

        if "MEDIAN" in stats_keylist and "MEDIAN" not in local_stats_dict:
            local_stats_dict["MEDIAN"] = subject.median1d(
                keyspace=keyspace, ignore_missing=ignore_missing, auto_squeeze=True
            )

        if "STD" in stats_keylist and "STD" not in local_stats_dict:
            local_stats_dict["STD"] = subject.std1d(
                keyspace=keyspace, ignore_missing=ignore_missing, auto_squeeze=True
            )

        if "S2N" in stats_keylist and "S2N" not in local_stats_dict:
            if "MEAN" not in local_stats_dict:
                local_stats_dict["MEAN"] = subject.mean1d(
                    keyspace=keyspace, ignore_missing=ignore_missing, auto_squeeze=True
                )
            if "STD" not in local_stats_dict:
                local_stats_dict["STD"] = subject.std1d(
                    keyspace=keyspace, ignore_missing=ignore_missing, auto_squeeze=True
                )

            local_stats_dict["S2N"] = local_stats_dict["MEAN"] / local_stats_dict["STD"]
            if local_stats_dict["S2N"].is_variate:
                for info_type1 in ["time_basis", "fx"]:
                    local_stats_dict["S2N"].set_space_info(
                        space="<valuespaces>", info_type=info_type1, info_value=None
                    )

        # Compute & Store T-Stat Statistics...
        # --------------------------------------
        if "TSTAT" in stats_keylist and "TSTAT" not in local_stats_dict:
            unioned_subject2 = subject.insert_keyspace(
                keyspace="EXTRA_DIM", key="Y", col_type="varchar(8)"
            )
            offset_key = "CONSTANT"
            yxkeys = {"EXTRA_DIM": ["Y", offset_key]}
            (ols_details, _, _, _) = unioned_subject2.estimate_ols(
                yxkeys,
                sample_keyspace=keyspace,
                offset_key=offset_key,
                ignore_missing=ignore_missing,
                detail_keyspace="OLS_DETAIL",
            )
            tstat_array_dict = {}
            tstat_array_dict["OLS_DETAIL"] = np.array(["TSTATS"], dtype=np.unicode_)
            tstat_array_dict["EXTRA_DIM"] = np.array(["CONSTANT"], dtype=np.unicode_)
            tstat_keys = Quble.from_array_dict(tstat_array_dict)
            local_stats_dict["TSTAT"] = ols_details.get(tstat_keys, auto_squeeze=True)
            if local_stats_dict["TSTAT"].is_variate:
                for info_type1 in ["time_basis", "fx"]:
                    local_stats_dict["TSTAT"].set_space_info(
                        space="<valuespaces>", info_type=info_type1, info_value=None
                    )

        # # Clear the time_basis for the valuespaces
        # # for specific stats: ["GEO_IR","S2N","TSTAT"]
        # NORMALIZED_STATS = ["GEO_IR","S2N","TSTAT"]
        # INFO_STATS_TO_CLEAR = ["time_basis","fx"]
        # for stats_key in NORMALIZED_STATS:
        #     if stats_key in local_stats_dict \
        #         and isinstance(local_stats_dict[stats_key], Quble) \
        #         and local_stats_dict[stats_key].is_variate:
        #         for info_type1 in INFO_STATS_TO_CLEAR:
        #             local_stats_dict[stats_key].set_space_info(space="<valuespaces>", info_type=info_type1, info_value=None)

        # -------------------------------------------------
        # CASE #1: NO stats_keyspace
        #   ==> PIVOTED, MULTI-VARIATE QUBLE
        #   ==> Each valuespace+stat is separate valuespace
        # -------------------------------------------------
        if stats_keyspace is None:

            valuespaces_join_op = []
            base_quble = None
            qubles_to_join = []

            if stats_keylist is not None:
                for stats_key in stats_keylist:
                    if stats_key not in local_stats_dict:
                        raise Exception(
                            "Internal inconsistency...stats_key:{0} not present in local_stats_dict"
                        )
                    elif local_stats_dict[stats_key] is None:
                        continue
                    elif not isinstance(local_stats_dict[stats_key], Quble):
                        raise Exception(
                            f"type(local_stats_dict[{stats_key}]):{type(local_stats_dict[stats_key])}...Quble expected"
                        )

                    quble1 = local_stats_dict[stats_key]
                    if quble1.is_undefined:
                        continue
                    elif quble1.is_nonvariate:
                        raise Exception(
                            f"local_stats_dict[{stats_key}] unexpected non-variate Quble: {quble1}"
                        )
                    else:
                        if base_quble is None:
                            base_quble = quble1
                        else:
                            qubles_to_join.append(quble1)
                        vs_dict1 = {}
                        for vs in quble1.valuespaces:
                            if vs_prefix_delimiter is None:
                                if quble1.is_multivariate:
                                    raise Exception(
                                        f"vs_prefix_delimiter required for multi-variate analysis when stats_keyspace is None"
                                    )
                                tgt_vs = stats_key
                            elif not isinstance(vs_prefix_delimiter, str):
                                raise Exception(
                                    f"Invalid vs_prefix_delimiter:{vs_prefix_delimiter}...str (on None) expected"
                                )
                            else:
                                tgt_vs = vs + vs_prefix_delimiter + stats_key
                            vs_dict1[vs] = tgt_vs

                        valuespaces_join_op.append(vs_dict1)

            # Join stats Qubles...
            if base_quble is None:
                summary = Quble()
            elif len(qubles_to_join) == 0:
                summary = base_quble
            else:
                summary = base_quble.join(
                    other=qubles_to_join,
                    keyspaces_join_op="union",
                    valuespaces_join_op=valuespaces_join_op,
                )
        # ---------------------------------------
        # CASE #2: Non-trivial stats_keyspace
        #   ==> Apply local_stats to summary
        # ---------------------------------------
        else:
            summary = Quble.undefined_instance()  # <-- Intialization

            num_chars_longest_stats_key = 1  # <-- Initialize
            for stats_key in stats_keylist:
                num_chars_curr_stats_key = len(stats_key)
                if num_chars_curr_stats_key > num_chars_longest_stats_key:
                    num_chars_longest_stats_key = num_chars_curr_stats_key

            for stats_key in stats_keylist:
                if stats_key not in local_stats_dict:
                    raise Exception(
                        "Internal inconsistency...stats_key:{0} not present in local_stats_dict"
                    )
                local_stats = local_stats_dict[stats_key]
                if local_stats is None or local_stats.is_empty:
                    continue
                local_stats = local_stats.insert_keyspace(
                    keyspace=stats_keyspace,
                    key=stats_key,
                    col_type=f"varchar({str(num_chars_longest_stats_key)})",
                )
                if summary is None or summary.is_undefined or summary.is_empty:
                    summary = local_stats
                else:
                    summary.merge_inplace(local_stats, self_precedence=True)
            # Squeeze away the stats_keyspace (if directed)
            if (
                stats_keyspace_squeeze
                and (stats_keyspace in summary.keyspaces)
                and (summary.distinct_key_count(keyspace=stats_keyspace) == 1)
            ):
                summary = summary.squeeze(keyspace=stats_keyspace)

        return summary

    def insert_from_query(
        self,
        query,
        inplace=False,
        generated_table_name=None,
        col_info=None,
        valuespace=None,
    ):
        session = SnowparkSessionManager.get_snowpark_session()
        src_df = session.sql(f""" {query} """)

        if not self.is_undefined:
            try:
                src_df.write.mode("append").save_as_table(self.table_name)
                self._clear_num_records_caches()
            except:
                _logger.error("Something went wrong processing the query")
        else:
            if generated_table_name is None:
                table_name = generate_random_table_name(dquote=True)
                execute(f"CREATE TABLE {table_name}")
            else:
                table_name = generated_table_name

            _logger.debug(
                f"The table is not defined on snowflake, so creating a table {table_name}"
            )
            src_df.write.mode("append").save_as_table(
                table_name,
            )

            self._swap_table(table_name, col_info=col_info, valuespace=valuespace)

    def corr1d_multiprocessing_loop(
        self,
        ortho_index1,
        dummy_ortho,
        subject,
        sub_ranges,
        dummy_sr_ortho,
        sr_iterator,
        keyspace,
    ):
        corr = Quble.undefined_instance()
        if dummy_ortho:
            local_history = subject
        else:
            local_history = subject.get(ortho_index1, auto_squeeze=False)

        # NOTE: Use copy.deepcopy(sr_iterator) here for multiple inner loop usage
        # Remember that sr_iterator here may either be:
        #      1) an instance of QubleRecordIterator class
        #  OR  2) ['dummy']
        # [as such, we cannot simply use a copy method of the QubleRecordIterator class]
        if dummy_sr_ortho:
            sr_iterator_copy = sr_iterator
        else:
            sr_iterator_copy = sr_iterator.copy()

        for ortho_sr_ctr, sr_index1 in enumerate(sr_iterator_copy):
            if dummy_sr_ortho:
                local_history2 = local_history
                local_corr = local_history2.corr(aggr_keyspaces=keyspace)
            else:
                # NOTE: we are using auto_squeeze=True below so that subrange_keyspace will be absent from local_history2
                sub_range1 = sub_ranges.get(sr_index1, auto_squeeze=True)
                if sub_range1.is_nonvariate:
                    local_history2 = local_history.inner_project(index=sub_range1)
                elif sub_range1.is_bool():
                    sub_range1 = sub_range1.bool_to_index()
                    local_history2 = local_history.inner_project(index=sub_range1)
                else:
                    local_history2 = local_history.conditional_keep(
                        condition=sub_range1,
                        auto_squeeze=False,
                        auto_expand=True,
                    )

                local_corr = local_history2.corr(aggr_keyspaces=keyspace)

                # Add sr_index1 back to local_corr
                local_corr = local_corr.join(
                    sr_index1,
                    keys_join_op="leftmost",
                    keyspaces_join_op="union",
                    valuespaces_join_op="left",
                )
                if corr is None or corr.is_empty:
                    corr = local_corr
                else:
                    corr.merge_inplace(local_corr, self_precedence=True)
        return corr

    @RootLib.temp_frame()
    def multi_corr1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        valuespace="<numeric_valuespaces>",
        sub_ranges=None,
        subrange_keyspace: str = None,
    ) -> Quble:
        """
        Multi-correlations across by (time) keyspace (removed)
        """
        # Validate self
        # ----------------
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_empty:
            return Quble()
        elif self.is_index:
            raise Exception("non-Index (valued) Quble required")

        keyspace = self.validate_keyspace(
            keyspace, grace=False, solo_required=True, time_space_required=True
        )

        # Validate valuespace (numeric valuespace(s) only)
        valuespace = self.validate_valuespace(
            valuespace, grace=False, coerce_to_list=True, numeric_required=True
        )

        # Isolate valuespaces as subject [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        valuespace_dtype = subject.get_space_info(
            info_type="dtype", space=subject.valuespace
        )

        # Set-Up Quble Environment...
        # ---------------------------
        controls = {}
        controls["ignore_add"] = False
        controls["ignore_mult"] = False
        controls["auto_squeeze"] = True
        with ControlContextManager(controls=controls) as ccm:
            # Verify presence of necessary keyspaces within sub_ranges
            if sub_ranges is None:
                ortho_sr_keyspaces = None
            elif not isinstance(sub_ranges, Quble):
                raise Exception(f"Invalid sub_ranges:{sub_ranges}...Quble expected")
            elif keyspace not in sub_ranges.keyspaces:
                raise Exception(f"sub_ranges does not contain keyspace: {keyspace}")
            elif subrange_keyspace not in sub_ranges.keyspaces:
                raise Exception(
                    "sub_ranges does not contain subrange_keyspace: {0}".format(
                        subrange_keyspace
                    )
                )
            else:
                # Verify that ortho_sr_keyspaces within sub_ranges are present in subject
                # [mainly for cases where sub_ranges externally provided]
                ortho_sr_keyspaces = sub_ranges.ortho_keyspaces(subrange_keyspace)
                for ortho_sr_keyspace1 in ortho_sr_keyspaces:
                    if ortho_sr_keyspace1 not in subject.keyspaces:
                        raise Exception(
                            "ortho sub_ranges keyspace:{0} absent from subject".format(
                                ortho_sr_keyspace1
                            )
                        )

            # ------------------------
            # Create ortho iterator
            # ------------------------
            ortho_keyspaces = subject.ortho_keyspaces(keyspace)

            # Currently commenting out the below check, defaulting to a dummy_ortho (this makes some logic in the loop below unnecessary) - to review
            if True:
                dummy_ortho = True
                ortho_index_iterator = ["dummy"]
            else:
                dummy_ortho = False
                ortho_index_iterator = DistinctOrthoIndexIterator(
                    subject,
                    ortho_keyspaces,
                    contiguous_flag=False,
                    key_ordering=None,
                    dummy_instance=None,
                )

            # -----------------------------
            # Create sub_ranges iterator
            # -----------------------------
            if (
                sub_ranges is None
                or ortho_sr_keyspaces is None
                or len(ortho_sr_keyspaces) == 0
            ):
                dummy_sr_ortho = True
                sr_iterator = ["dummy"]
            elif not isinstance(sub_ranges, Quble):
                raise Exception("Invalid sub_ranges...Quble or None expected")
            elif not sub_ranges.is_index and not sub_ranges.is_bool():
                raise Exception(
                    "Invalid sub_ranges...index or bool-valued Quble expected"
                )
            else:
                dummy_sr_ortho = False
                sr_iterator = QubleRecordIterator(
                    sub_ranges.distinct_index(keyspaces=subrange_keyspace)
                )

            # ----------------------------------------
            # Loop through the orthogonal keys...
            # ----------------------------------------
            corr = Quble.undefined_instance()  # <-- Intialization
            """
            final_corr = Quble.undefined_instance()  # <-- Intialization

            func = partial(
                self.corr1d_multiprocessing_loop,
                dummy_ortho=dummy_ortho,
                subject=subject,
                sub_ranges=sub_ranges,
                dummy_sr_ortho=dummy_sr_ortho,
                sr_iterator=sr_iterator,
                keyspace=keyspace,
            )
            result_list = []
            for i in range(0, 3):
                try:
                    with Pool() as pool:
                        result_list = pool.map(
                            func,
                            [ortho_index1 for ortho_index1 in ortho_index_iterator],
                        )
                except:
                    _logger.debug("multi-corr1d for loop excepted, retrying..")
                    continue
                break

            for resultant_quble in result_list:
                final_corr = final_corr.merge(
                    resultant_quble, self_precedence=True, variate_mode="multi"
                )
            return final_corr
            """
            for ortho_ctr, ortho_index1 in enumerate(ortho_index_iterator):
                if dummy_ortho:
                    local_history = subject
                else:
                    local_history = subject.get(ortho_index1, auto_squeeze=False)

                # Note: Use copy.deepcopy(sr_iterator) here for multiple inner loop usage
                # Remember that sr_iterator here may either be:
                #      1) an instance of QubleRecordIterator class
                #  OR  2) ['dummy']
                # [as such, we cannot simply use a copy method of the QubleRecordIterator class]
                if dummy_sr_ortho:
                    sr_iterator_copy = sr_iterator
                else:
                    sr_iterator_copy = sr_iterator.copy()

                for ortho_sr_ctr, sr_index1 in enumerate(sr_iterator_copy):
                    if dummy_sr_ortho:
                        local_history2 = local_history
                        local_corr = local_history2.corr(aggr_keyspaces=keyspace)
                    else:
                        # Note: we are using auto_squeeze=True below
                        # so that subrange_keyspace will be absent from local_history2
                        sub_range1 = sub_ranges.get(sr_index1, auto_squeeze=True)
                        if sub_range1.is_nonvariate:
                            local_history2 = local_history.inner_project(
                                index=sub_range1
                            )
                        elif sub_range1.is_bool():
                            sub_range1 = sub_range1.bool_to_index()
                            local_history2 = local_history.inner_project(
                                index=sub_range1
                            )
                        else:
                            local_history2 = local_history.conditional_keep(
                                condition=sub_range1,
                                auto_squeeze=False,
                                auto_expand=True,
                            )

                        local_corr = local_history2.corr(aggr_keyspaces=keyspace)

                        # Add sr_index1 back to local_corr
                        local_corr = local_corr.join(
                            sr_index1,
                            keys_join_op="leftmost",
                            keyspaces_join_op="union",
                            valuespaces_join_op="left",
                        )
                        if corr is None or corr.is_empty:
                            corr = local_corr
                        else:
                            corr.merge_inplace(local_corr, self_precedence=True)
            return corr

    @RootLib.lazy_kwargs()
    def corr1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        ortho_keyspaces=None,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        replace_value: float = 0.0,
        replace_level: int = 0,
        bias: bool = False,
        ddof: int = None,
    ) -> Quble:
        """
        Cross-correlation method that
        aggregates across a single keyspace
        See :meth:`~qubles.core.quble.Quble.cross_stats`
        """
        return self.cross_stats(
            aggr_keyspaces=keyspace,
            valuespace=valuespace,
            op_str="corr",
            ortho_keyspaces=ortho_keyspaces,
            ignore_missing=ignore_missing,
            replace_value=replace_value,
            replace_level=replace_level,
            bias=bias,
            ddof=ddof,
        )

    @RootLib.lazy_kwargs()
    def corr(
        self,
        aggr_keyspaces: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        ortho_keyspaces=None,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        replace_value: float = 0.0,
        replace_level: int = 0,
        bias: bool = False,
        ddof: int = None,
    ) -> Quble:
        """
        Cross-correlation method that
        aggregates across multiple keyspaces
        See :meth:`~qubles.core.quble.Quble.cross_stats`
        """
        return self.cross_stats(
            aggr_keyspaces=aggr_keyspaces,
            valuespace=valuespace,
            op_str="corr",
            ortho_keyspaces=ortho_keyspaces,
            ignore_missing=ignore_missing,
            replace_value=replace_value,
            replace_level=replace_level,
            bias=bias,
            ddof=ddof,
        )

    @RootLib.lazy_kwargs()
    def cov1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        ortho_keyspaces=None,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        replace_value: float = 0.0,
        replace_level: int = 0,
        bias: bool = False,
        ddof: int = None,
    ) -> Quble:
        """
        Cross-covariance method that
        aggregates across a single keyspace
        See :meth:`~qubles.core.quble.Quble.cross_stats`
        """
        return self.cross_stats(
            aggr_keyspaces=keyspace,
            valuespace=valuespace,
            op_str="cov",
            ortho_keyspaces=ortho_keyspaces,
            ignore_missing=ignore_missing,
            replace_value=replace_value,
            replace_level=replace_level,
            bias=bias,
            ddof=ddof,
        )

    @RootLib.lazy_kwargs()
    def cov(
        self,
        aggr_keyspaces: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        ortho_keyspaces=None,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        replace_value: float = 0.0,
        replace_level: int = 0,
        bias: bool = False,
        ddof: int = None,
    ) -> Quble:
        """
        Cross-covariance method that
        aggregates across multiple keyspaces
        See :meth:`~qubles.core.quble.Quble.cross_stats`
        """
        return self.cross_stats(
            aggr_keyspaces=aggr_keyspaces,
            valuespace=valuespace,
            op_str="cov",
            ortho_keyspaces=ortho_keyspaces,
            ignore_missing=ignore_missing,
            replace_value=replace_value,
            replace_level=replace_level,
            bias=bias,
            ddof=ddof,
        )

    @RootLib.lazy_kwargs()
    def cross_stats_num1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        ortho_keyspaces=None,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        replace_value: float = 0.0,
        replace_level: int = 0,
        bias: bool = False,
        ddof: int = None,
    ) -> Quble:
        """
        Cross-stats num (count) method that
        aggregates across a single keyspace
        See :meth:`~qubles.core.quble.Quble.cross_stats`
        """
        return self.cross_stats(
            aggr_keyspaces=keyspace,
            valuespace=valuespace,
            op_str="num",
            ortho_keyspaces=ortho_keyspaces,
            ignore_missing=ignore_missing,
            replace_value=replace_value,
            replace_level=replace_level,
            bias=bias,
            ddof=ddof,
        )

    @RootLib.lazy_kwargs()
    def cross_stats_num(
        self,
        aggr_keyspaces: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        ortho_keyspaces=None,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        replace_value: float = 0.0,
        replace_level: int = 0,
        bias: bool = False,
        ddof: int = None,
    ) -> Quble:
        """
        Cross-stats num (count) method that
        aggregates across multiple keyspaces
        See :meth:`~qubles.core.quble.Quble.cross_stats`
        """
        return self.cross_stats(
            aggr_keyspaces=aggr_keyspaces,
            valuespace=valuespace,
            op_str="num",
            ortho_keyspaces=ortho_keyspaces,
            ignore_missing=ignore_missing,
            replace_value=replace_value,
            replace_level=replace_level,
            bias=bias,
            ddof=ddof,
        )

    @RootLib.lazy_kwargs()
    def cross_stats1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        op_str: str = "corr",
        ortho_keyspaces=None,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        replace_value: float = 0.0,
        replace_level: int = 0,
        bias: bool = False,
        ddof: int = None,
    ) -> Quble:
        """
        Cross-stats general method that
        aggregates across a single keyspace
        See :meth:`~qubles.core.quble.Quble.cross_stats`
        """
        return self.cross_stats(
            aggr_keyspaces=keyspace,
            valuespace=valuespace,
            op_str=op_str,
            ortho_keyspaces=ortho_keyspaces,
            ignore_missing=ignore_missing,
            replace_value=replace_value,
            replace_level=replace_level,
            bias=bias,
            ddof=ddof,
        )

    @RootLib.lazy_kwargs()
    def cross_stats(
        self,
        aggr_keyspaces: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        op_str: str = "corr",
        ortho_keyspaces=None,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        replace_value: float = 0.0,
        replace_level: int = 0,
        bias: bool = False,
        ddof: int = None,
    ) -> Quble:
        """
        Computes pairwise correlation (or covariance)
        across the specified aggregation keyspaces,
        excluding missing values as directed

        The non-aggregation keyspaces and non-ortho keyspaces
        will define the 'cross keyspaces' for the operation

        The resultant Quble WILL NOT RETAIN the aggregation keyspaces
        but WILL RETAIN the orthogonal keyspaces
        PLUS PAIRS FOR EACH cross keyspace

        The keyspace dimensionality of the result is:
            2 x % cross_keyspaces + #ortho_keyspaces

        Each 'cross keyspace' will be appear in the result twice
        first in their orginal forms and again as a related 'cohort cross' dimension suffixed by '(2)'

        The resultant Quble WILL RETAIN numeric valuespaces
        [Non-numeric valuespaces will be dropped from the result]

        Example: Input Quble (self)

          Tickers   Factor      Delay      Exchange     Values1      Values2
        (aggr_ks) (cross_ks)  (cross_ks)  (ortho_ks)  (valuespace) (valuespace)
        ---------- ---------- ----------  ---------- ------------  ------------
        IBM       MOM          0         NYSE          X            X
        IBM       MOM          1         NYSE          X            X
        IBM       B2P          0         NYSE          X            X
        IBM       B2P          1         NYSE          X            X
        MSFT      MOM          0         NYSE          X            X
        MSFT      MOM          1         NYSE          X            X
        MSFT      B2P          0         NYSE          X            X
        MSFT      B2P          1         NYSE          X            X

        Example Result:
           self.cross_stats(aggr_keyspaces='Tickers', ortho_keyspaces='Exchange')

        Factor   Delay   Factor(2)  Delay(2)  Exchange  Values1  Values2
        -------  ------  ---------  --------  --------  -------  -------
        MOM        0       MOM        0        NYSE       Z        Z
        MOM        0       MOM        1        NYSE       Z        Z
        MOM        1       MOM        0        NYSE       Z        Z
        MOM        1       MOM        1        NYSE       Z        Z
        B2P        0       MOM        0        NYSE       Z        Z
        B2P        0       MOM        1        NYSE       Z        Z
        B2P        1       MOM        0        NYSE       Z        Z
        B2P        1       MOM        1        NYSE       Z        Z
        MOM        0       B2P        0        NYSE       Z        Z
        MOM        0       B2P        1        NYSE       Z        Z
        MOM        1       B2P        0        NYSE       Z        Z
        MOM        1       B2P        1        NYSE       Z        Z
        B2P        0       B2P        0        NYSE       Z        Z
        B2P        0       B2P        1        NYSE       Z        Z
        B2P        1       B2P        0        NYSE       Z        Z
        B2P        1       B2P        1        NYSE       Z        Z

         **Arguments**
        :param aggr_keyspaces: The (sample) keyspace(s) across which stats will be generated
                 ==> These keyspaces will NOT appear in result
                 ==> Each 'orthogonal' keyspace will appear in the result with a sibling dimension augmented with "(2)" suffix
        :type keyspace: str, or list/tuple of strings

        :params: ortho_keyspaces: keyspaces(s) that do not participate in crossing
        :type ortho_keyspaces: str, or list/tuple of strings or None

        :param op_str: Operation to be performed: 'corr' or 'cov' or 'num'
        :type op_str: {string}

        :param ignore_missing: Flag that controls the ignore_missing
                               for statistical calcs (for implicit aggregation)
        :type ignore_missing: bool

        :param replace_value: Replacement value for null values
                              according to replace_level!=0 policy
        :type replace_value: {float}

        :param replace_level: Replacement level for null value replacement
             ==> replace_level=0: No replacement of null-values (replace_value will be ignored)
             ==> replace_level=1: Replace all nulls in table prior to cross-stats operation
             ==> replace_level=2: Replace null values in table AND within each 2D cross-array computation
        :type replace_level: {int}

        :param bias: # Normalization flag to use in calculation
                     [see numpy documentation for corrcoef() or cov()]
        :type bias: {bool}

        :param ddof: # Degrees of freedom in calculation
                     [see numpy documentation for corrcoef() or cov()]
        :type ddof: {None,<integer>}

        :returns: 2-D valued Quble containing the correlation or co-variance results
        :rtype: qubles.core.quble.Quble

        """
        # Validate self
        # ----------------
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_empty:
            return Quble()
        elif self.is_scalar:
            return Quble()

        # Validate op_str
        if op_str not in ("corr", "cov", "num"):
            raise Exception(f"Bad op_str:{op_str}...expected: 'corr' or 'cov' or 'num'")

        # Validate aggr_keyspaces, May perform auto-linking
        aggr_keyspaces = self.validate_keyspace(
            aggr_keyspaces,
            grace=False,
            coerce_to_list=True,
        )
        if aggr_keyspaces is None or len(aggr_keyspaces) == 0:
            raise Exception("At least one aggregation keyspace is required")

        # Validate ortho_keyspaces, May perform auto-linking
        if ortho_keyspaces is None:
            ortho_keyspaces = []
        else:
            ortho_keyspaces = self.validate_keyspace(
                keyspace=ortho_keyspaces, grace=False, coerce_to_list=True
            )

        # Ensure no duplication of keyspaces
        # between aggr_keyspaces & ortho_keyspaces
        if any(i in aggr_keyspaces for i in ortho_keyspaces):
            raise Exception(
                f"Duplicates disallowed between aggr_keyspaces:{aggr_keyspaces} and ortho_keyspaces:{ortho_keyspaces}"
            )

        # Procure cross_keyspaces: These are those keyspaces that are
        # not aggr_keyspaces nor ortho_keyspaces
        cross_keyspaces = self.ortho_keyspaces(
            keyspace=aggr_keyspaces + ortho_keyspaces, grace=False
        )
        if cross_keyspaces is None or len(cross_keyspaces) == 0:
            raise Exception("At least one cross-keyspace is required")

        # Validate valuespace (numeric valuespace(s) only)
        valuespace = self.validate_valuespace(
            valuespace, grace=False, coerce_to_list=True, numeric_required=True
        )

        # Isolate valuespaces as subject [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # Establish column types
        coltypes = subject.get_space_info(info_type="type", space="<all>", grace=False)

        aggr_coltypes = {}
        for aggr_keyspace in aggr_keyspaces:
            aggr_coltypes[aggr_keyspace] = coltypes[aggr_keyspace]

        cross_coltypes = {}
        for cross_keyspace in cross_keyspaces:
            cross_coltypes[cross_keyspace] = coltypes[cross_keyspace]

        ortho_coltypes = {}
        for ortho_keyspace in ortho_keyspaces:
            ortho_coltypes[ortho_keyspace] = coltypes[ortho_keyspace]

        value_coltypes = {}
        for vs in subject.valuespaces:
            value_coltypes[vs] = coltypes[vs]

        if op_str == "corr":
            cross_stats_fn_name = "cross_stats_corr"
            stat_coltype = "double"
        elif op_str == "cov":
            cross_stats_fn_name = "cross_stats_cov"
            stat_coltype = "double"
        elif op_str == "num":
            cross_stats_fn_name = "cross_stats_num"
            stat_coltype = "int"
        else:
            raise Exception(f"Invalid op_str:{op_str}")

        # Since we are calling SQL function: cross_stats_cov/corr/num
        # We are required to give non-None bias & ddof args to SQL conduit...
        # --------------------------------------------------------------------
        if bias is None:
            bias = False

        # Here, we need to give a non-None ddof arg to SQL conduit
        # When ddof=None and not bias: we use ddof=1
        # When ddof=None and bias: we use ddof=0
        #  ==> per documentation for np.cov()
        if ddof is not None:
            pass
        elif not bias:
            ddof = 1
        else:
            ddof = 0

        # Validate replace_level
        if replace_level not in (0, 1, 2):
            raise Exception(
                f"Invalid replace_level arg:{replace_level}...0 or 1 or 2 required"
            )

        # Validate replace_value
        if replace_value is not None:
            pass
        elif replace_level == 0:
            replace_value = 0.0  # <-- Innocuous (replace_value ignored) in this case
        else:
            raise Exception(
                f"Non-trivial replace_value required when replace_level={replace_level}"
            )

        # Render & Execute SQL command to utilize the cross_stats UDF
        # -----------------------------------
        tgt_table_name = generate_random_table_name()
        # Constructing input dictionary
        input_dict = dict(
            zip(
                [
                    "aggr_input_dict",
                    "cross_input_dict",
                    "ortho_input_dict",
                    "value_input_dict",
                ],
                [aggr_coltypes, cross_coltypes, ortho_coltypes, value_coltypes],
            )
        )
        # bias & ddof will not be None because of logic above
        execute(
            f"""
            CALL CROSS_STATS_SP(
                '{dumps(input_dict)}',
                {ignore_missing},
                {replace_value},
                {replace_level},
                {bias},
                {ddof},
                '{subject.table_name}',
                '{tgt_table_name}',
                '{cross_stats_fn_name}'
            )
        """
        )

        # Copy over table & custom column info
        # --------------------------------------------
        col_name_map = {}
        for ks in cross_keyspaces:
            # Here, we map each cross-keyspace
            # to associated new keyspace pairs
            col_name_map[ks] = (ks, f"{ks}(2)")
        for ks in ortho_keyspaces:
            col_name_map[ks] = ks
        for vs in subject.valuespaces:
            col_name_map[vs] = vs

        # 'fx' stays (not excluded) in the 'cov' case
        info_type_exclusions = (
            ["time_basis"] if (op_str == "cov") else ["fx", "time_basis"]
        )

        # Establish col_info for copy
        if tgt_table_name == self.table_name:
            col_info = None
        else:
            col_info = self.get_space_info(
                info_type=[
                    it1 for it1 in CUSTOM_INFO_TYPES if it1 not in info_type_exclusions
                ],
                space=cross_keyspaces + ortho_keyspaces + subject.valuespaces,
                omit_unassigned=True,
            )
            # Remap col_info to new column names
            if col_info is not None:
                col_info = custom_col_info_rename(col_info, col_name_map)

        # Instantiate Quble from the new table
        return Quble.from_table(
            tgt_table_name,
            col_info=col_info,
        )

    @RootLib.lazy_kwargs()
    def trans_basis(
        self,
        security_keyspace: str,
        dates_keyspace: str,
        trans_quantity_space: str,
        trans_prices_space: str,
        asset_prices_space: str,
        lot_mode: str = "lifo",
        held_quantity_space: str = "HELD_QUANTITY",
        cost_basis_space: str = "COST_BASIS",
        unreal_gl_space: str = "UNREAL_GL",
        real_gl_space: str = "REAL_GL",
        total_gl_space: str = "TOTAL_GL",
    ) -> Quble:
        """
        Computes 'transaction basis' information given a trade history
        according to a lot_mode accounting methodology.

        Trade history (self) is a variate Quble with following INPUT spaces:

            security_keyspace (keyspace)
            dates_keyspace (keyspace)
            trans_quantity_space (valuespace) [assumed split-adjusted]
            trans_prices_space (valuespace) [assumed split-adjusted]
            asset_prices_space (valuespace) [assumed split-adjusted]

        Computes / introduces the following OUTPUT valuespaces:

            held_quantity_space: resultant quantity held
            cost_basis_space: running cost-basis
            unreal_gl_space: unrealized gain/loss
            real_gl_space: realized gain/loss
            total_gl_space: unrealized gain/loss

        :param security_keyspace: Asset (security) keyspace
        :type security_keyspace: {str}

        :param dates_keyspace: dates (datetime) keyspace
        :type dates_keyspace: {str}

        :param trans_quantity_space: valuespace for transaction quantity history
        :type trans_quantity_space: {str}

        :param trans_prices_space: valuespace for transaction price history
        :type trans_prices_space: {str}

        :param asset_prices_space: valuespace for asset price history
        :type asset_prices_space: {str}

        :param lot_mode: Lot mode for cost-basis calculation
        :type lot_mode: {str}('lifo', 'fifo')

        :returns: 2-D (asset x dates) multi-valued Quble
                  containing cost-basis related input & output valuespaces
        :rtype: qubles.core.quble.Quble

        """
        # Validate self
        # ----------------
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_scalar:
            return Quble()

        # Check for necessary input spaces
        if security_keyspace not in self.keyspaces:
            raise Exception(f"Absent security_keyspace:{security_keyspace}")
        elif dates_keyspace not in self.keyspaces:
            raise Exception(f"Absent dates_keyspace:{dates_keyspace}")
        elif trans_quantity_space not in self.valuespaces:
            raise Exception(
                f"Absent (valuespace) trans_quantity_space:{trans_quantity_space}"
            )
        elif trans_prices_space not in self.valuespaces:
            raise Exception(
                f"Absent (valuespace) trans_prices_space:{trans_prices_space}"
            )
        elif asset_prices_space not in self.valuespaces:
            raise Exception(
                f"Absent (valuespace) asset_prices_space:{asset_prices_space}"
            )

        # Assign col_types
        asset_coltype = self.get_column_type(security_keyspace)
        dates_coltype = self.get_column_type(dates_keyspace)
        trans_quantity_coltype = self.get_column_type(trans_quantity_space)
        trans_prices_coltype = self.get_column_type(trans_prices_space)
        asset_prices_coltype = self.get_column_type(asset_prices_space)

        # Validate lot_mode arg
        if lot_mode is None:
            lot_mode = "lifo"
        elif not isinstance(lot_mode, str):
            raise Exception(f"Invalid lot_mode:{lot_mode}...str expected")
        elif lot_mode.lower() not in ("lifo", "fifo"):
            raise Exception(f"Invalid lot_mode:{lot_mode}...lifo/fifo expected")

        # Render & Execute SQL command to utilize the cross_stats UDF
        # -----------------------------------
        tgt_table_name = generate_random_table_name()
        sql_template = JINJA_ENV.get_template("trans_basis.j2")
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            tgt_table_name=tgt_table_name,
            security_keyspace=security_keyspace,
            dates_keyspace=dates_keyspace,
            trans_quantity_space=trans_quantity_space,
            trans_prices_space=trans_prices_space,
            asset_prices_space=asset_prices_space,
            held_quantity_space=held_quantity_space,
            cost_basis_space=cost_basis_space,
            unreal_gl_space=unreal_gl_space,
            real_gl_space=real_gl_space,
            total_gl_space=total_gl_space,
            asset_coltype=asset_coltype,
            dates_coltype=dates_coltype,
            trans_quantity_coltype=trans_quantity_coltype,
            trans_prices_coltype=trans_prices_coltype,
            asset_prices_coltype=asset_prices_coltype,
            lot_mode=f"{lot_mode}",
        )
        execute(sql_command, format_flag=False)

        # Establish col_info for copy
        if tgt_table_name == self.table_name:
            col_info = None
        else:
            col_info = self.get_space_info(
                info_type=CUSTOM_INFO_TYPES,
                space=[
                    security_keyspace,
                    dates_keyspace,
                    trans_quantity_space,
                    trans_prices_space,
                    asset_prices_space,
                ],
                omit_unassigned=True,
            )

            if (
                "fx" in col_info
                and col_info["fx"] is not None
                and trans_prices_space is not None
                and trans_prices_space in col_info["fx"]
                and col_info["fx"][trans_prices_space] is not None
            ):
                trans_prc_fx = col_info["fx"][trans_prices_space]
            else:
                trans_prc_fx = None

            for vs in [
                held_quantity_space,
                cost_basis_space,
                unreal_gl_space,
                real_gl_space,
                total_gl_space,
            ]:
                col_info["role"][vs] = "valuespace"
                if trans_prc_fx is None:
                    pass
                elif vs == held_quantity_space:
                    # This new valuespace does not exhibit fx
                    pass
                else:
                    col_info["fx"][vs] = trans_prc_fx

        # Instantiate Quble from the new table
        result = Quble.from_table(
            tgt_table_name,
            valuespace=held_quantity_space,
            col_info=col_info,
        )
        return result

    # =========================================================================
    #                             COVERAGE METHODS
    # =========================================================================

    def density(self):
        """
        Density of a Quble as defined by:

        (number records / full multi-dimensional grid size)

        where: grid size determined by distinct key counts across each keyspace

        ==> density will be a float betweeen [0.0, 1.0] inclusive
        ==> density will be None for undefined or empty Qubles
        ==> Non-empty, single-dimensional Qubles should have a density of 1.0
        ==> scalar (non-empty, no keyspaces) Qubles should have a density of 1.0
        """
        # Access num_records
        num_records = self.num_records

        # Handle corner-cases
        if num_records is None:
            return None
        elif num_records == 0:
            # What should we return here?
            return None
        elif self.num_keyspaces == 0:
            if num_records > 1:
                raise Exception(
                    f"Invalid Quble configuration: self.num_keyspaces:{self.num_keyspaces}, num_records:{num_records}"
                )
            # scalar / multi-scalar Qubles have unity density
            return 1.0
        elif self.num_keyspaces == 1:
            # Non-empty, single-dimensional Qubles have unity density
            return 1.0

        # Compute grid_size
        distinct_key_counts = self.distinct_key_counts
        if distinct_key_counts is None:
            return None
        elif len(distinct_key_counts) == 0:
            # scalar / multi-scalar Qubles have unity density
            return 1.0
        elif not isinstance(distinct_key_counts, dict):
            raise Exception(
                f"Invalid distinct_key_counts...expected dict but type(distinct_key_counts):{type(distinct_key_counts)}"
            )

        grid_size = np.prod(np.array(list(distinct_key_counts.values()), dtype="float"))
        if grid_size is None:
            return None
        elif np.isnan(grid_size) or np.isinf(grid_size):
            return None
        elif grid_size <= 0:
            # Should not happen
            return None

        # Calculate density as ratio of num_records to grid_size
        if num_records > grid_size:
            raise Exception(
                f"Error...num_records:{num_records} > grid_size:{grid_size}...possible duplicate keys?"
            )

        # Compute density from num_records & grid_size
        density = float(num_records) / float(grid_size)

        # Validate the computed density
        if density is None:
            pass
        elif np.isnan(density) or np.isinf(density):
            density = None
        elif density > 1.0:
            if density > 1.00001:
                _logger.warning(f"density:{density} unexpectedly > 1.0")
            ity = min(density, 1.0)
        elif density < 0.0:
            if density < -0.00001:
                _logger.warning(f"density:{density} unexpectedly < 0.0")
            density = max(density, 0.0)

        return density

    def sparseness(self):
        """
        Sparseness of a Quble a defined by:

        [1.0 - (number records / full multi-dimensional grid size)]

        where: grid size determined by distinct key counts across each keyspace

        Sparseness is the complement to the density of Quble
        sparseness = (1.0 - density)

        ==> sparseness will be a float betweeen [0.0, 1.0] inclusive
        ==> sparseness will be None for undefined or empty Qubles

        See: :meth:`~qubles.core.quble.Quble.density`
        """
        # First, compute density
        density = self.density()

        # Next, compute sparsenesss from density
        if density is None:
            sparseness = None
        elif np.isnan(density) or np.isinf(density):
            sparseness = None
        else:
            # NOTE: density is verified to be [0.0, 1.0] inclusive
            sparseness = 1.0 - density

        return sparseness

    @RootLib.lazy_kwargs()
    def coverage(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Percent of records that are non-missing (not null)
        across the specified aggregation keyspaces
        for specified valuespace(s) column(s) of the Quble
        """
        return self.pct_non_missing(
            aggr_keyspaces=aggr_keyspaces,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def coverage1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Percent of records that are non-missing (not null)
        across the specified keyspace
        for the specified valuespace(s) column(s) of the Quble
        """
        return self.pct_non_missing1d(
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def coveragex1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Percent of records that are non-missing (not null)
        across the orthogonal dimensions to the specified keyspace
        for the specified valuespace(s) column(s) of the Quble
        """
        return self.pct_non_missingx1d(
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def _pct_conditional_count(
        self,
        aggr_method: str,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        numeric_required: bool = False,
        epsilon: float = None,
    ) -> Quble:
        """
        Percent of conditional count (e.g.,positive) records
        across the aggregation keyspaces
        for specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]

        Here, aggr_method should represent a "conditional count"
        such as aggr_method='num_positive"
        """
        # Handle trivial cases
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate aggr_keyspaces
        aggr_keyspaces = self.validate_keyspace(
            aggr_keyspaces, grace=False, coerce_to_list=True
        )

        # Validate valuespace (numeric valuespace(s) only)
        valuespace = self.validate_valuespace(
            valuespace,
            grace=False,
            coerce_to_list=True,
            numeric_required=numeric_required,
        )

        # Isolate valuespaces as subject
        # [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # NOTE: Apply pre_cross_fill BEFORE pre_fill
        if pre_cross_fill:
            subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)

        if pre_fill:
            subject = subject._apply_pre_fill(allow_shallow_copy=True)

        # Apply view to subject
        # ------------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)
        if subject.is_empty:
            remaining_keyspaces = subject.ortho_keyspaces(aggr_keyspaces)
            return subject.select(
                column_names=remaining_keyspaces + subject.valuespaces,
                cast_dict=dict(
                    list(zip(subject.valuespaces, ["float"] * len(subject.valuespaces)))
                ),
            )

        # Perform calculation
        num_condition = subject.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method=aggr_method,
            valuespace=subject.valuespaces,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            epsilon=epsilon,
        ).change_type("float", space="<valuespaces>")

        num_total = subject.count(
            aggr_keyspaces=aggr_keyspaces,
            valuespace=subject.valuespaces,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            view=None,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=False,
            pre_fill=False,
        ).change_type("float", space="<valuespaces>")

        # Set controls...
        controls = {"ignore_mult": False, "ignore_add": False}
        if subject.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            return num_condition / num_total

    @RootLib.lazy_kwargs()
    def _pct_conditional_count1d(
        self,
        aggr_method: str,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        numeric_required: bool = False,
        epsilon: float = None,
    ) -> Quble:
        # Handle trivial cases
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate keyspace
        keyspace = self.validate_keyspace(keyspace, grace=False, solo_required=True)

        # Validate valuespace (numeric valuespace(s) only)
        valuespace = self.validate_valuespace(
            valuespace,
            grace=False,
            coerce_to_list=True,
            numeric_required=numeric_required,
        )

        # Isolate valuespaces as subject
        # [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # NOTE: Apply pre_cross_fill BEFORE pre_fill
        if pre_cross_fill:
            subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)

        if pre_fill:
            subject = subject._apply_pre_fill(allow_shallow_copy=True)

        # Apply view to subject
        # ------------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)
        if subject.is_empty:
            remaining_keyspaces = subject.ortho_keyspaces(keyspace)
            return subject.select(
                column_names=remaining_keyspaces + subject.valuespaces,
                cast_dict=dict(
                    list(zip(subject.valuespaces, ["float"] * len(subject.valuespaces)))
                ),
            )
        num_condition1D = subject.aggregate1d(
            keyspace=keyspace,
            aggr_method=aggr_method,
            valuespace=subject.valuespaces,
            view=None,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=False,
            pre_fill=False,
            epsilon=epsilon,
        ).change_type("float", space="<valuespaces>")

        num_total1D = subject.count1d(
            keyspace=keyspace,
            valuespace=subject.valuespaces,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            view=None,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=False,
            pre_fill=False,
        ).change_type("float", space="<valuespaces>")

        # Set controls...
        controls = {"ignore_mult": False, "ignore_add": False}
        if subject.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            return num_condition1D / num_total1D

    @RootLib.lazy_kwargs()
    def _pct_conditional_countx1d(
        self,
        aggr_method: str,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        numeric_required: bool = False,
        epsilon: float = None,
    ) -> Quble:
        # Handle trivial cases
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate keyspace [Here, keyspace will be the only remaining keyspace in result]
        keyspace = self.validate_keyspace(keyspace, grace=False, solo_required=True)

        # Validate valuespace (numeric valuespace(s) only)
        valuespace = self.validate_valuespace(
            valuespace,
            grace=False,
            coerce_to_list=True,
            numeric_required=numeric_required,
        )
        # Isolate valuespaces as subject [Only refer to subject subsequently!]
        # ---------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # NOTE: Apply pre_cross_fill BEFORE pre_fill
        if pre_cross_fill:
            subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)

        if pre_fill:
            subject = subject._apply_pre_fill(allow_shallow_copy=True)

        # Apply view to subject
        # ------------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)
        if subject.is_empty:
            return subject.select(
                column_names=[keyspace] + valuespace,
                cast_dict=dict(
                    list(zip(subject.valuespaces, ["float"] * len(subject.valuespaces)))
                ),
            )

        xnum_conditon1D = subject.aggregatex1d(
            keyspace=keyspace,
            aggr_method=aggr_method,
            valuespace=valuespace,
            view=None,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=False,
            pre_fill=False,
            epsilon=epsilon,
        ).change_type("float", space="<valuespaces>")

        xnum_total1D = subject.countx1d(
            keyspace=keyspace,
            valuespace=valuespace,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            view=None,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=False,
            pre_fill=False,
        ).change_type("float", space="<valuespaces>")

        # Set controls...
        controls = {"ignore_mult": False, "ignore_add": False}
        if subject.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            return xnum_conditon1D / xnum_total1D

    @RootLib.lazy_kwargs()
    def pct_positive(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Percent of positive records
        across the aggregation keyspaces
        for specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._pct_conditional_count(
            aggr_method="num_positive",
            aggr_keyspaces=aggr_keyspaces,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=True,
        )

    @RootLib.lazy_kwargs()
    def pct_positive1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Percent of positive records across the specified keyspace
        for the specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._pct_conditional_count1d(
            aggr_method="num_positive",
            keyspace=keyspace,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=True,
        )

    @RootLib.lazy_kwargs()
    def pct_positivex1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Percent of positive records
        across the orthogonal keyspaces to the specified keyspace
        for the specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._pct_conditional_countx1d(
            aggr_method="num_positive",
            keyspace=keyspace,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=True,
        )

    @RootLib.lazy_kwargs()
    def pct_negative(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Percent of negative records
        across the aggregation keyspaces
        for specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._pct_conditional_count(
            aggr_method="num_negative",
            aggr_keyspaces=aggr_keyspaces,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=True,
        )

    @RootLib.lazy_kwargs()
    def pct_negative1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Percent of negative records across the specified keyspace
        for the specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._pct_conditional_count1d(
            aggr_method="num_negative",
            keyspace=keyspace,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=True,
        )

    @RootLib.lazy_kwargs()
    def pct_negativex1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Percent of negative records
        across the orthogonal keyspaces to the specified keyspace
        for the specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._pct_conditional_countx1d(
            aggr_method="num_negative",
            keyspace=keyspace,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=True,
        )

    @RootLib.lazy_kwargs()
    def pct_nonnegative(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Percent of non-negative records
        across the aggregation keyspaces
        for specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._pct_conditional_count(
            aggr_method="num_nonnegative",
            aggr_keyspaces=aggr_keyspaces,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=True,
        )

    @RootLib.lazy_kwargs()
    def pct_nonnegative1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Percent of non-negative records across the specified keyspace
        for the specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._pct_conditional_count1d(
            aggr_method="num_nonnegative",
            keyspace=keyspace,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=True,
        )

    @RootLib.lazy_kwargs()
    def pct_nonnegativex1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Percent of non-negative records
        across the orthogonal keyspaces to the specified keyspace
        for the specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._pct_conditional_countx1d(
            aggr_method="num_nonnegative",
            keyspace=keyspace,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=True,
        )

    @RootLib.lazy_kwargs()
    def pct_nonpositive(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Percent of non-positive records
        across the aggregation keyspaces
        for specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._pct_conditional_count(
            aggr_method="num_nonpositive",
            aggr_keyspaces=aggr_keyspaces,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=True,
        )

    @RootLib.lazy_kwargs()
    def pct_nonpositive1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Percent of non-positive records across the specified keyspace
        for the specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._pct_conditional_count1d(
            aggr_method="num_nonpositive",
            keyspace=keyspace,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=True,
        )

    @RootLib.lazy_kwargs()
    def pct_nonpositivex1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Percent of non-positive records
        across the orthogonal keyspaces to the specified keyspace
        for the specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._pct_conditional_countx1d(
            aggr_method="num_nonpositive",
            keyspace=keyspace,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=True,
        )

    @RootLib.lazy_kwargs()
    def num_positive(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Number of positive records within the Quble
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="num_positive",
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def num_positive1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of positive records
        across the specified dimension (at each key orthogonal key)
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="num_positive",
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def num_positivex1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of positive orthogonal records
        for each key along the specified dimension
        """
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="num_positive",
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def _has_conditional_count(
        self,
        aggr_method,
        aggr_keyspaces="<keyspaces>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        epsilon: float = None,
    ) -> Quble:
        """
        Helper method indicating whether each of the specified valuespace(s)
        has atleast one instance of a condition across the specified keyspace(s)
        """
        num_conditional_count = self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method=aggr_method,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
            epsilon=epsilon,
        )
        # Set controls...
        controls = {"ignore_fn": False}
        if self.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            return num_conditional_count > 0

    @RootLib.lazy_kwargs()
    def _has_conditional_count1d(
        self,
        aggr_method,
        keyspace: str = "<first_keyspace>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        epsilon: float = None,
    ) -> Quble:
        """
        Helper method indicating whether each of the specified valuespace(s)
        has atleast one instance of a condition across the specified keyspace
        """
        num_conditional_count1D = self.aggregate1d(
            keyspace=keyspace,
            aggr_method=aggr_method,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
            epsilon=epsilon,
        )
        # Set controls...
        controls = {"ignore_fn": False}
        if self.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            return num_conditional_count1D > 0

    @RootLib.lazy_kwargs()
    def _xhas_conditional_count1d(
        self,
        aggr_method,
        keyspace: str = "<first_keyspace>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        epsilon: float = None,
    ) -> Quble:
        """
        Helper method indicating whether each of the specified valuespace(s)
        has atleast one instance of a condition
        across the orthogonals to the specified keyspace
        """
        xnum_conditional_count1D = self.aggregatex1d(
            keyspace=keyspace,
            aggr_method=aggr_method,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
            epsilon=epsilon,
        )
        # Set controls...
        controls = {"ignore_fn": False}
        if self.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            return xnum_conditional_count1D > 0

    @RootLib.lazy_kwargs()
    def has_positive(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Has (atleast one) positive record within the Quble
        across the specified keyspace(s) for the specified valuespaces
        [Requires specification of numeric valuespace(s)]
        """
        return self._has_conditional_count(
            aggr_method="num_positive",
            aggr_keyspaces=aggr_keyspaces,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def has_positive1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Has (atleast one) positive record
        across the specified keyspace (at each key orthogonal key)
        [Requires specification of numeric valuespace(s)]
        """
        return self._has_conditional_count1d(
            aggr_method="num_positive",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def has_positivex1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Has (atleast one) positive orthogonal record
        for each key along the specified dimension
        [Requires specification of numeric valuespace(s)]
        """
        return self._xhas_conditional_count1d(
            aggr_method="num_positive",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def num_negative(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Number of negative records within the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="num_negative",
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def num_negative1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of negative record
        across the specified dimension (at each key orthogonal key)
        [Requires specification of numeric valuespace(s)]
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="num_negative",
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def num_negativex1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of negative orthogonal records
        for each key along the specified dimension
        [Requires specification of numeric valuespace(s)]
        """
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="num_negative",
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def has_negative(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Has (atleast one) negative records within the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._has_conditional_count(
            aggr_method="num_negative",
            aggr_keyspaces=aggr_keyspaces,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def has_negative1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Has (atleast one) negative record
        across the specified dimension (at each key orthogonal key)
        [Requires specification of numeric valuespace(s)]
        """
        return self._has_conditional_count1d(
            aggr_method="num_negative",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def has_negativex1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Has (atleast one) negative orthogonal record
        for each key along the specified dimension
        [Requires specification of numeric valuespace(s)]
        """
        return self._xhas_conditional_count1d(
            aggr_method="num_negative",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def num_nonpositive(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of non-positive records within the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="num_nonpositive",
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def num_nonpositive1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of non-positive records
        across the specified dimension (at each key orthogonal key)
        [Requires specification of numeric valuespace(s)]
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="num_nonpositive",
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def num_nonpositivex1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of non-positive orthogonal records
        for each key along the specified dimension
        [Requires specification of numeric valuespace(s)]
        """
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="num_nonpositive",
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def has_nonpositive(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Has (atleast one) non-positive records within the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._has_conditional_count(
            aggr_method="num_nonpositive",
            aggr_keyspaces=aggr_keyspaces,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def has_nonpositive1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Has (atleast one) non-positive record
        across the specified dimension (at each key orthogonal key)
        [Requires specification of numeric valuespace(s)]
        """
        return self._has_conditional_count1d(
            aggr_method="num_nonpositive",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def has_nonpositivex1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Has (atleast one) non-positive orthogonal record
        for each key along the specified dimension
        [Requires specification of numeric valuespace(s)]
        """
        return self._xhas_conditional_count1d(
            aggr_method="num_nonpositive",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def num_nonnegative(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of non-negative records within the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="num_nonnegative",
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def num_nonnegative1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of non-negative records
        across the specified dimension (at each key orthogonal key)
        [Requires specification of numeric valuespace(s)]
        """
        return self.aggregate1d(
            keyspace=keyspace,
            aggr_method="num_nonnegative",
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def num_nonnegativex1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of non-negative orthogonal records
        for each key along the specified dimension
        [Requires specification of numeric valuespace(s)]
        """
        return self.aggregatex1d(
            keyspace=keyspace,
            aggr_method="num_nonnegative",
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def has_nonnegative(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Has (atleast one) non-negative records within the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._has_conditional_count(
            aggr_method="num_nonnegative",
            aggr_keyspaces=aggr_keyspaces,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def has_nonnegative1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Has (atleast one) non-negative record
        across the specified dimension (at each key orthogonal key)
        [Requires specification of numeric valuespace(s)]
        """
        return self._has_conditional_count1d(
            aggr_method="num_nonnegative",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def has_nonnegativex1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Has (atleast one) non-negative orthogonal record
        for each key along the specified dimension
        [Requires specification of numeric valuespace(s)]
        """
        return self._xhas_conditional_count1d(
            aggr_method="num_nonnegative",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def pct_zero(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        epsilon: float = None,
    ) -> Quble:
        """
        Percent of zero records
        across the aggregation keyspaces
        for specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._pct_conditional_count(
            aggr_method="num_zero",
            aggr_keyspaces=aggr_keyspaces,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=True,
            epsilon=epsilon,
        )

    @RootLib.lazy_kwargs()
    def pct_zero1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        epsilon: float = None,
    ) -> Quble:
        """
        Percent of zero records across the specified keyspace
        for the specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._pct_conditional_count1d(
            aggr_method="num_zero",
            keyspace=keyspace,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=True,
            epsilon=epsilon,
        )

    @RootLib.lazy_kwargs()
    def pct_zerox1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        epsilon: float = None,
    ) -> Quble:
        """
        Percent of zero records
        for each key along the specified dimension
        for the specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._pct_conditional_countx1d(
            aggr_method="num_zero",
            keyspace=keyspace,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=True,
            epsilon=epsilon,
        )

    @RootLib.lazy_kwargs()
    def num_zero(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        epsilon=None,
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Number of zero valued records within the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="num_zero",
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            epsilon=epsilon,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def has_zeros(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        epsilon: float = None,
    ) -> Quble:
        """
        Has (atleast one) zero record within the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._has_conditional_count(
            aggr_method="num_zero",
            aggr_keyspaces=aggr_keyspaces,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
            epsilon=epsilon,
        )

    @RootLib.lazy_kwargs()
    def has_zeros1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        epsilon: float = None,
    ) -> Quble:
        """
        Has (atleast one) zero record
        across the specified dimension (at each key orthogonal key)
        [Requires specification of numeric valuespace(s)]
        """
        return self._has_conditional_count1d(
            aggr_method="num_zero",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
            epsilon=epsilon,
        )

    @RootLib.lazy_kwargs()
    def has_zerosx1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        epsilon: float = None,
    ) -> Quble:
        """
        Has (atleast one) zero orthogonal record
        for each key along the specified dimension
        [Requires specification of numeric valuespace(s)]
        """
        return self._xhas_conditional_count1d(
            aggr_method="num_zero",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
            epsilon=epsilon,
        )

    @RootLib.lazy_kwargs()
    def num_non_zero(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        epsilon=None,
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of non-zero valued records within the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="num_non_zero",
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            epsilon=epsilon,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def has_non_zeros(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        epsilon: float = None,
    ) -> Quble:
        """
        Has (atleast one) non-zero record within the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._has_conditional_count(
            aggr_method="num_non_zero",
            aggr_keyspaces=aggr_keyspaces,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
            epsilon=epsilon,
        )

    @RootLib.lazy_kwargs()
    def has_non_zeros1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        epsilon: float = None,
    ) -> Quble:
        """
        Has (atleast one) non-zero record
        across the specified dimension (at each key orthogonal key)
        [Requires specification of numeric valuespace(s)]
        """
        return self._has_conditional_count1d(
            aggr_method="num_non_zero",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
            epsilon=epsilon,
        )

    @RootLib.lazy_kwargs()
    def has_non_zerosx1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        epsilon: float = None,
    ) -> Quble:
        """
        Has (atleast one) non-zero orthogonal record
        for each key along the specified dimension
        [Requires specification of numeric valuespace(s)]
        """
        return self._xhas_conditional_count1d(
            aggr_method="num_non_zero",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
            epsilon=epsilon,
        )

    @RootLib.lazy_kwargs()
    def pct_non_zero(
        self,
        aggr_keyspaces="<keyspaces>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        epsilon: float = None,
    ) -> Quble:
        """
        Percent of non-zero records
        across the aggregation keyspaces
        for specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._pct_conditional_count(
            aggr_method="num_non_zero",
            aggr_keyspaces=aggr_keyspaces,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=True,
            epsilon=epsilon,
        )

    @RootLib.lazy_kwargs()
    def pct_non_zero1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        epsilon: float = None,
    ) -> Quble:
        """
        Percent of non-zero records across the specified keyspace
        for the specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._pct_conditional_count1d(
            aggr_method="num_non_zero",
            keyspace=keyspace,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=True,
            epsilon=epsilon,
        )

    @RootLib.lazy_kwargs()
    def pct_non_zerox1d(
        self,
        keyspace: str = "<first_keyspace>",
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        pct_required: float = 0.0,
        num_required: int = 0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        epsilon: float = None,
    ) -> Quble:
        """
        Percent of non-zero records
        for each key along the specified dimension
        for the specified valuespace(s) column(s) of the Quble
        [Requires specification of numeric valuespace(s)]
        """
        return self._pct_conditional_countx1d(
            aggr_method="num_non_zero",
            keyspace=keyspace,
            ignore_missing=ignore_missing,
            pct_required=pct_required,
            num_required=num_required,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=True,
            epsilon=epsilon,
        )

    @RootLib.lazy_kwargs()
    def num_non_missing(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag=True,
    ) -> Quble:
        """
        Number of non-missing/non-null records
        across the valuespace

        :param quble_flag: Control if a Quble should be returned or alternatively, a scalar value
        """
        return self.aggregate(
            aggr_keyspaces=aggr_keyspaces,
            aggr_method="num_not_null",
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            quble_flag=quble_flag,
        )

    @RootLib.lazy_kwargs()
    def num_non_missing1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of non-missing records in the Quble
        across the specified dimension (at each key orthogonal key)
        """
        return self.aggregate1d(
            aggr_method="num_not_null",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def num_non_zero1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        epsilon=None,
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of non-zero records in the Quble
        across the specified dimension (at each key orthogonal key)
        [Requires specification of numeric valuespace(s)]
        """
        return self.aggregate1d(
            aggr_method="num_non_zero",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            epsilon=epsilon,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def num_non_zerox1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        epsilon=None,
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of non-zero records in the Quble
        for each key along the specified dimension
        [Requires specification of numeric valuespace(s)]
        """
        return self.aggregatex1d(
            aggr_method="num_non_zero",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            epsilon=epsilon,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def num_zero1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        epsilon=None,
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of zero records in the Quble
        across the specified dimension (at each key orthogonal key)
        [Requires specification of numeric valuespace(s)]
        """
        return self.aggregate1d(
            aggr_method="num_zero",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            epsilon=epsilon,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def num_zerox1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        epsilon=None,
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of zero records in the Quble
        for each key along the specified dimension
        [Requires specification of numeric valuespace(s)]
        """
        return self.aggregatex1d(
            aggr_method="num_zero",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            epsilon=epsilon,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def has_no_non_zeros1d(
        self,
        keyspace: str = "<first_keyspace>",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        epsilon=None,
        nulls_as_non_zeros=True,
    ) -> Quble:
        """
        Flag for lack of non-zero records in the Quble
        across the specified dimension (at each key orthogonal key)
        [Requires specification of numeric valuespace(s)]

        nulls_as_non_zeros: controls whether a null record
                            constitues a non-zero record
        """
        has_non_zeros1D = self.has_non_zeros1d(
            keyspace=keyspace,
            auto_squeeze=auto_squeeze,
            valuespace=valuespace,
            view=view,
            epsilon=epsilon,
        )

        # Set controls...
        controls = {"ignore_mult": False, "ignore_add": False, "ignore_fn": False}
        if self.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            return has_non_zeros1D._not(treat_null_as_false=nulls_as_non_zeros)

    @RootLib.lazy_kwargs()
    def has_no_non_zerosx1d(
        self,
        keyspace: str = "<first_keyspace>",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        epsilon=None,
        nulls_as_non_zeros=True,
    ) -> Quble:
        """
        Flag for lack of non-zero records in the Quble
        for each key along the specified dimension
        [Requires specification of numeric valuespace(s)]

        nulls_as_non_zeros: controls whether a null record
                            constitues a non-zero record
        """
        has_non_zerosx1D = self.has_non_zerosx1d(
            keyspace=keyspace,
            auto_squeeze=auto_squeeze,
            valuespace=valuespace,
            view=view,
            epsilon=epsilon,
        )

        # Set controls...
        controls = {"ignore_mult": False, "ignore_add": False, "ignore_fn": False}
        if self.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            return has_non_zerosx1D._not(treat_null_as_false=nulls_as_non_zeros)

    @RootLib.lazy_kwargs()
    def has_no_non_zeros(
        self,
        aggr_keyspaces="<keyspaces>",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        epsilon=None,
        nulls_as_non_zeros=True,
    ) -> Quble:
        """
        Flag for lack of non-zero records in the Quble
        across all dimensions
        [Requires specification of numeric valuespace(s)]

        nulls_as_non_zeros: controls whether a null record
                            constitues a non-zero record
        """
        has_non_zeros = self.has_non_zeros(
            aggr_keyspaces=aggr_keyspaces,
            auto_squeeze=auto_squeeze,
            valuespace=valuespace,
            view=view,
            epsilon=epsilon,
        )

        # Set controls...
        controls = {"ignore_mult": False, "ignore_add": False, "ignore_fn": False}
        if self.is_multivariate:
            controls["variate_mode"] = "multi"
        with ControlContextManager(controls=controls) as ccm:
            return has_non_zeros._not(treat_null_as_false=nulls_as_non_zeros)

    @RootLib.lazy_kwargs()
    def num_non_missingx1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of orthogonal records that are non-missing
        for each key along the specified dimension
        """
        return self.aggregatex1d(
            aggr_method="num_not_null",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
        )

    @RootLib.lazy_kwargs()
    def has_non_missing(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Has (atleast one) non-missing record within the Quble
        """
        return self._has_conditional_count(
            aggr_method="num_not_null",
            aggr_keyspaces=aggr_keyspaces,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def has_non_missing1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Has (atleast one) non-missing record
        across the specified dimension (at each key orthogonal key)
        """
        return self._has_conditional_count1d(
            aggr_method="num_not_null",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def has_non_missingx1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Has (atleast one) non-missing orthogonal record
        for each key along the specified dimension
        """
        return self._xhas_conditional_count1d(
            aggr_method="num_not_null",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def num_missing(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Number of non-missing/non-null records
        across the specified valuespace(s)
        """
        if not unfolded:
            return self.aggregate(
                aggr_keyspaces=aggr_keyspaces,
                aggr_method="num_null",
                valuespace=valuespace,
                view=view,
                key_ordering=key_ordering,
                auto_squeeze=auto_squeeze,
                pre_cross_fill=pre_cross_fill,
                pre_fill=pre_fill,
                quble_flag=quble_flag,
            )
        else:
            aggr_keyspaces = self.validate_keyspace(
                aggr_keyspaces, grace=False, coerce_to_list=True
            )

            # Restrict Quble to only the single valuespace of interest
            # (allow for shallow copy when valuespaces are unchanged)
            # ==> Only refer to subject (not self) hereafter
            # ------------------------------------------------------
            subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
            if subject.is_nonvariate:
                raise NoValuespaceError(
                    "Variate Quble required...No valuespaces present"
                )

            # NOTE: Apply pre_cross_fill BEFORE pre_fill
            if pre_cross_fill:
                subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)

            if pre_fill:
                subject = subject._apply_pre_fill(allow_shallow_copy=True)

            # Apply view to subject
            # ------------------------
            subject = subject.apply_view(view, allow_shallow_copy=True)
            if subject.is_empty:
                remaining_keyspaces = subject.ortho_keyspaces(aggr_keyspaces)
                return subject.select(
                    column_names=remaining_keyspaces + subject.valuespaces,
                    cast_dict=dict(
                        list(
                            zip(subject.valuespaces, ["int"] * len(subject.valuespaces))
                        )
                    ),
                )

            num_non_missing = subject.aggregate(
                aggr_keyspaces=aggr_keyspaces,
                aggr_method="num_not_null",
                valuespace=valuespace,
                view=None,
                key_ordering=key_ordering,
                auto_squeeze=auto_squeeze,
                pre_cross_fill=pre_cross_fill,
                pre_fill=pre_fill,
                quble_flag=quble_flag,
            )

            unfolded_count = subject.count(
                aggr_keyspaces=aggr_keyspaces,
                valuespace=subject.valuespaces,
                view=None,
                ignore_missing=False,
                unfolded=unfolded,
                key_ordering=key_ordering,
                auto_squeeze=auto_squeeze,
                pre_cross_fill=pre_cross_fill,
                pre_fill=pre_fill,
                quble_flag=quble_flag,
            )

            # Set controls...
            controls = {"ignore_mult": False, "ignore_add": False}
            if subject.is_multivariate:
                controls["variate_mode"] = "multi"
            with ControlContextManager(controls=controls) as ccm:
                return unfolded_count - num_non_missing

    @RootLib.lazy_kwargs()
    def num_missing1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of non-missing/non-null records
        across the specified valuespace(s)
        for each key along the specified dimension
        """
        if not unfolded:
            return self.aggregate1d(
                aggr_method="num_null",
                keyspace=keyspace,
                valuespace=valuespace,
                view=view,
                key_ordering=key_ordering,
                auto_squeeze=auto_squeeze,
                pre_cross_fill=pre_cross_fill,
                pre_fill=pre_fill,
            )
        else:
            keyspace = self.validate_keyspace(keyspace, grace=False, solo_required=True)

            # Restrict Quble to only the single valuespace of interest
            # (allow for shallow copy when valuespaces are unchanged)
            # ==> Only refer to subject (not self) hereafter
            # ------------------------------------------------------
            subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
            if subject.is_nonvariate:
                raise NoValuespaceError(
                    "Variate Quble required...No valuespaces present"
                )

            # NOTE: Apply pre_cross_fill BEFORE pre_fill
            if pre_cross_fill:
                subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)

            if pre_fill:
                subject = subject._apply_pre_fill(allow_shallow_copy=True)

            # Apply view to subject
            # -----------------------
            subject = subject.apply_view(view, allow_shallow_copy=True)
            if subject.is_empty:
                remaining_keyspaces = subject.ortho_keyspaces(keyspace)
                return subject.select(
                    column_names=remaining_keyspaces + subject.valuespaces,
                    cast_dict=dict(
                        list(
                            zip(subject.valuespaces, ["int"] * len(subject.valuespaces))
                        )
                    ),
                )

            num_non_missing1D = subject.aggregate1d(
                aggr_method="num_not_null",
                keyspace=keyspace,
                valuespace=subject.valuespaces,
                view=None,
                key_ordering=key_ordering,
                auto_squeeze=auto_squeeze,
                pre_cross_fill=False,
                pre_fill=False,
            )
            unfolded_count1D = subject.count1d(
                keyspace=keyspace,
                valuespace=subject.valuespaces,
                view=None,
                ignore_missing=False,
                unfolded=unfolded,
                key_ordering=key_ordering,
                auto_squeeze=auto_squeeze,
                pre_cross_fill=False,
                pre_fill=False,
            )

            # Set controls...
            controls = {"ignore_mult": False, "ignore_add": False}
            if subject.is_multivariate:
                controls["variate_mode"] = "multi"
            with ControlContextManager(controls=controls) as ccm:
                # Assumes no duplicate index keys across keyspaces!!!
                return unfolded_count1D - num_non_missing1D

    @RootLib.lazy_kwargs()
    def num_missingx1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Number of non-missing/non-null records
        across the specified valuespace(s)
        for each key along the specified dimension
        """
        if not unfolded:
            return self.aggregatex1d(
                aggr_method="num_null",
                keyspace=keyspace,
                valuespace=valuespace,
                view=view,
                key_ordering=key_ordering,
                auto_squeeze=auto_squeeze,
            )
        else:
            # Restrict Quble to only the single valuespace of interest
            # (allow for shallow copy when valuespaces are unchanged)
            # ==> Only refer to subject (not self) hereafter
            # ------------------------------------------------------
            subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
            if subject.is_nonvariate:
                raise NoValuespaceError(
                    "Variate Quble required...No valuespaces present"
                )

            # NOTE: Apply pre_cross_fill BEFORE pre_fill
            if pre_cross_fill:
                subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)
            if pre_fill:
                subject = subject._apply_pre_fill(allow_shallow_copy=True)

            # Apply view to subject
            # -----------------------
            subject = subject.apply_view(view, allow_shallow_copy=True)
            if subject.is_empty:
                return subject.select(
                    column_names=[keyspace] + subject.valuespaces,
                    cast_dict=dict(
                        list(
                            zip(subject.valuespaces, ["int"] * len(subject.valuespaces))
                        )
                    ),
                )

            num_non_missingx1D = subject.aggregatex1d(
                aggr_method="num_not_null",
                keyspace=keyspace,
                valuespace=subject.valuespaces,
                view=None,
                key_ordering=key_ordering,
                auto_squeeze=auto_squeeze,
                pre_cross_fill=False,
                pre_fill=False,
            )
            unfolded_countx1D = subject.countx1d(
                keyspace=keyspace,
                valuespace=subject.valuespaces,
                view=None,
                ignore_missing=False,
                unfolded=unfolded,
                key_ordering=key_ordering,
                auto_squeeze=auto_squeeze,
                pre_cross_fill=False,
                pre_fill=False,
            )

            # Set controls...
            controls = {"ignore_mult": False, "ignore_add": False}
            if subject.is_multivariate:
                controls["variate_mode"] = "multi"
            with ControlContextManager(controls=controls) as ccm:
                return unfolded_countx1D - num_non_missingx1D

    @RootLib.lazy_kwargs()
    def pct_non_missing(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Percent of non-missing (non-null) records
        across the aggregation keyspaces
        for specified valuespace(s) column(s) of the Quble
        """
        return self._pct_conditional_count(
            aggr_method="num_not_null",
            aggr_keyspaces=aggr_keyspaces,
            ignore_missing=False,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=False,
        )

    @RootLib.lazy_kwargs()
    def pct_non_missing1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Percent of non-missing (non-null) records across the specified keyspace
        for the specified valuespace(s) column(s) of the Quble
        """
        return self._pct_conditional_count1d(
            aggr_method="num_not_null",
            keyspace=keyspace,
            ignore_missing=False,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=False,
        )

    @RootLib.lazy_kwargs()
    def pct_non_missingx1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Percent of non-missing (non-null) records
        across the orthogonal keyspaces to the specified keyspace
        for the specified valuespace(s) column(s) of the Quble
        """
        return self._pct_conditional_countx1d(
            aggr_method="num_not_null",
            keyspace=keyspace,
            ignore_missing=False,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=False,
        )

    @RootLib.lazy_kwargs()
    def pct_missing(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Percent of missing records
        across the aggregation keyspaces
        for specified valuespace(s) column(s) of the Quble
        """
        return self._pct_conditional_count(
            aggr_method="num_null",
            aggr_keyspaces=aggr_keyspaces,
            ignore_missing=False,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=False,
        )

    @RootLib.lazy_kwargs()
    def pct_missing1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Percent of missing records across the specified keyspace
        for the specified valuespace(s) column(s) of the Quble
        """
        return self._pct_conditional_count1d(
            aggr_method="num_null",
            keyspace=keyspace,
            ignore_missing=False,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=False,
        )

    @RootLib.lazy_kwargs()
    def pct_missingx1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfolded: bool = False,
        key_ordering="asc",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
    ) -> Quble:
        """
        Percent of missing records
        across the orthogonal keyspaces to the specified keyspace
        for the specified valuespace(s) column(s) of the Quble
        """
        return self._pct_conditional_countx1d(
            aggr_method="num_null",
            keyspace=keyspace,
            ignore_missing=False,
            valuespace=valuespace,
            view=view,
            unfolded=unfolded,
            key_ordering=key_ordering,
            auto_squeeze=auto_squeeze,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            numeric_required=False,
        )

    @RootLib.lazy_kwargs()
    def has_missing(
        self,
        aggr_keyspaces="<keyspaces>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Has (atleast one) missing record within the Quble
        """
        return self._has_conditional_count(
            aggr_method="num_null",
            aggr_keyspaces=aggr_keyspaces,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def has_missing1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Has (atleast one) missing record
        across the specified dimension (at each key orthogonal key)
        """
        return self._has_conditional_count1d(
            aggr_method="num_null",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def has_missingx1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ) -> Quble:
        """
        Has (atleast one) missing orthogonal record
        for each key along the specified dimension
        """
        return self._xhas_conditional_count1d(
            aggr_method="num_null",
            keyspace=keyspace,
            valuespace=valuespace,
            view=view,
            auto_squeeze=auto_squeeze,
        )

    def is_barren(
        self,
        valuespace="<valuespaces>",
    ) -> Quble:
        """
        Flag indicating if the Quble's specified
        valuespace(s) column(s) have all null records
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        # <-- Since this is a property, we make it independent of view (for now)
        return self.has_non_missing(valuespace=valuespace, view=None)._not()

    # =================================================
    #                     COALESCE
    # =================================================

    @RootLib.lazy_kwargs()
    def coalesce(
        self,
        other: Quble,
        keyspaces_join_op: str = "union",
        keys_join_op: str = RootLib.lazy_eval("keys_join_op"),
        compress: bool = RootLib.lazy_eval("auto_compress"),
        fx: str = RootLib.lazy_eval("fx"),
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        auto_fx: bool = RootLib.lazy_eval("auto_fx"),
        variate_mode: str = RootLib.lazy_eval("variate_mode"),
    ) -> Quble:
        """
        Coalesces the valuespaces of two Qubles (non-null overlay)
        based on variate_mode.

        Indices of the resultant Quble will be the union/intersection
        of both Quble's key structures.

        Will manage (raise or reconcile) any currency conflicts
        according to auto_fx & fx arguments

        :param other: Quble to be merged
        :type other: qubles.core.quble.Quble

        :param allow_dtype_conversion:flag to allow/disallow dtype conversion of other (if needed)
        :type allow_dtype_conversion: boolean

        keyspaces_join_op: See: :meth:`~qubles.core.quble.Quble.join`

        keys_join_op: See: :meth:`~qubles.core.quble.Quble.join`

        :param compress: compression controls
        :type compress: True or False or None or str
                [See: :meth:`~qubles.core.quble.Quble.compress`]
                ==> If string contains word 'any': Quble.compress(summarize='any',...)
                ==> If string contains word 'all': Quble.compress(summarize='all',...)
                ==> If string contains word 'drop': Quble.compress(drop=True,...)

        :param fx: fx resolver for currency conflict handling
        :type fx: str
        ==> Assignments can be traditional (three-character ISO) fx (e.g., 'USD','EUR', ...)
            or an security-specific fx "scheme" (e.g., 'PRC','REP','EST','HRP')

        :param auto_link: Control for auto-linking (keyspace affiliation)
        :type auto_link: bool

        :param auto_fx: Flag for automated fx (currency) reconciliation
        :type auto_fx: bool (True*/False)
            auto_fx=True: automatically reconciles fx conflicts between valuespaces of self & other
            auto_fx=False: fx conflicts between valuespaces of self & other yield an Exception

        :param variate_mode: controls valuespace pairings
        'uni': single pair using primary valuespace if each Quble (despite valuespace names)
        ==> univariate result will attempt to retain sel.valeuspace name
        ==> otherwise will use target valuespace: DEFAULT_VALUESPACE
        'multi': pair valuespaces by name(allow for None counterparts when a specific valuespace only exists on one of the source Qubles)
        ==> possible multivariate result w/union of all source valuespaces
        'mixed': pairs univariate source valuespace against all multivariate counterparts
        ==> possible multivariate result w/valuespaces from multivariate source Quble
        :type variate_mode: str

        :returns: The Coalesced Quble
        :rtype: qubles.core.quble.Quble

        """
        # ---------------------------------------
        # Consolidate Qubles into a single list
        # ---------------------------------------
        if isinstance(other, (list, tuple)):
            raise Exception("other should not be a list/tuple")
            # qubles = [self] + other
        elif not isinstance(other, Quble):
            other = Quble(other)

        # ----------------------------------------
        # Handle trial cases (undefined Qubles)
        # ----------------------------------------
        if self.is_undefined:
            return Quble.undefined_instance()
        elif other.is_undefined:
            return Quble.undefined_instance()

        if self.is_nonvariate and other.is_nonvariate:
            return self.copy()

        # ---------------------------------------------
        # Join the two Qubles and their valuespaces
        # ---------------------------------------------
        joined = self.join(
            other,
            keys_join_op=keys_join_op,
            keyspaces_join_op=keyspaces_join_op,
            auto_link=auto_link,
            valuespaces_join_op="primaries" if variate_mode == "uni" else "all",
            valuespace_num_suffix_delimiter="_",
        )

        # -----------------------
        # Record variate_state
        # -----------------------
        if self.is_multivariate:
            if other.is_multivariate:
                variate_state = "multi"
            else:
                variate_state = "mixed"
        elif other.is_multivariate:
            variate_state = "mixed"
        else:
            variate_state = "uni"

        # ------------------------------------------------------
        # Construct valuespace_pairs dictionary
        # Outer dict keys: target valuespaces
        # Inner dict keys: 'src_vs'
        # Inner dict values: paired tuple info for coalesce
        # ==> NOTE: similar approach to Quble._perform_operation()
        # ------------------------------------------------------
        valuespace_pairs = {}
        tgt_fx_dict = {}  # <-- dictionary of post-op fx (keys will be tgt_valuespace)

        # =============================== MULTI-MODE =================================
        if variate_mode == "multi" or (
            variate_mode == "mixed" and variate_state == "multi"
        ):
            # Create src_vs_list
            src_vs_list = []
            for src_vs in self.valuespaces:
                if src_vs not in src_vs_list:
                    src_vs_list.append(src_vs)
            for src_vs in other.valuespaces:
                if src_vs not in src_vs_list:
                    src_vs_list.append(src_vs)

            for src_vs in src_vs_list:
                valuespace1 = f"{src_vs}_0"
                valuespace2 = f"{src_vs}_1"
                if valuespace1 in joined.valuespaces:
                    if valuespace2 in joined.valuespaces:
                        valuespace_pairs[src_vs] = {}
                        valuespace_pairs[src_vs]["src_vs"] = (
                            valuespace1,
                            valuespace2,
                        )
                    else:
                        valuespace_pairs[src_vs] = {}
                        valuespace_pairs[src_vs]["src_vs"] = (valuespace1, None)
                elif valuespace2 in joined.valuespaces:
                    valuespace_pairs[src_vs] = {}
                    valuespace_pairs[src_vs]["src_vs"] = (None, valuespace2)
                else:
                    # Do not create a valuespace pair if neither Quble contributes a valuespace
                    pass
        # =============================== MIXED-MODE =================================
        elif variate_mode == "mixed" and variate_state == "mixed":
            if self.is_multivariate and not other.is_multivariate:
                valuespace2 = (
                    f"{other.valuespaces[0]}_1" if other.is_univariate else None
                )
                for src_vs in self.valuespaces:
                    valuespace1 = f"{src_vs}_0"
                    if (valuespace1 is not None) or (valuespace2 is not None):
                        # Do not create a valuespace pair if neither Quble contributes a valuespace
                        valuespace_pairs[src_vs] = {}
                        valuespace_pairs[src_vs]["src_vs"] = (valuespace1, valuespace2)
            elif not self.is_multivariate and other.is_multivariate:
                valuespace1 = f"{self.valuespaces[0]}_0" if self.is_univariate else None
                for src_vs in other.valuespaces:
                    valuespace2 = f"{src_vs}_1"
                    if (valuespace1 is not None) or (valuespace2 is not None):
                        # Do not create a valuespace pair if neither Quble contributes a valuespace
                        valuespace_pairs[src_vs] = {}
                        valuespace_pairs[src_vs]["src_vs"] = (valuespace1, valuespace2)
            else:
                raise Exception("Inconsistent mixed state")
        # =============================== UNI-MODE =================================
        else:
            # Could also consider valuespace inferring from joined
            tgt_valuespace = (
                DEFAULT_VALUESPACE if self.valuespace is None else self.valuespace
            )
            valuespace1 = (
                f"{self.valuespace}_0" if self.valuespace is not None else None
            )
            valuespace2 = (
                f"{other.valuespace}_1" if other.valuespace is not None else None
            )
            if (valuespace1 is not None) or (valuespace2 is not None):
                # Do not create a valuespace pair if neither Quble contributes a valuespace
                valuespace_pairs[tgt_valuespace] = {}
                valuespace_pairs[tgt_valuespace]["src_vs"] = (valuespace1, valuespace2)

        # =========================== START: TARGET VALUESPACES LOOP =============================
        conversion_fx_dict = (
            {}
        )  # <-- dictionary for fx conversion of pre-op (joined) valuespaces (keys will be valuespace1 and/or valuespace2)

        for tgt_valuespace in valuespace_pairs:
            if tgt_valuespace not in valuespace_pairs:
                continue

            (valuespace1, valuespace2) = valuespace_pairs[tgt_valuespace]["src_vs"]

            # Set coltype1 & fx1
            if valuespace1 is None:
                coltype1 = None
                fx1 = None
            else:
                coltype1 = joined.get_column_type(valuespace1)
                fx1 = joined._get_valuespace_attr(
                    vs_attr_name="fx", valuespace=valuespace1
                )

            # Set coltype2 & fx2
            if valuespace2 is None:
                coltype2 = None
                fx2 = None
            else:
                coltype2 = joined.get_column_type(valuespace2)
                fx2 = joined._get_valuespace_attr(
                    vs_attr_name="fx", valuespace=valuespace2
                )

            # Assign additional information for this valuespace_pairs
            valuespace_pairs[tgt_valuespace]["coltype"] = (coltype1, coltype2)
            valuespace_pairs[tgt_valuespace]["orig_fx"] = (fx1, fx2)

            # ----------------------------
            #        F/X HANDLING
            # ----------------------------
            # Reconcile fx (if required)
            # ----------------------------
            if valuespace1 is None:
                if valuespace2 is not None:
                    tgt_fx_dict[tgt_valuespace] = fx2
            elif valuespace2 is None:
                tgt_fx_dict[tgt_valuespace] = fx1
            # We have a proper valuespace pair
            elif fx1 is None:
                tgt_fx_dict[tgt_valuespace] = fx2
            elif fx2 is None:
                tgt_fx_dict[tgt_valuespace] = fx1
            elif fx1 == fx2:
                # Already fx compatible
                tgt_fx_dict[tgt_valuespace] = fx1
            elif isinstance(auto_fx, str) and auto_fx == "ignore":
                # Here, currency conflict exists... fx1 & fx2 are not None (non-trivial fx) and are not the same
                # Ignoring fx conflict, but still want to mark result with no fx (as fx result will be ambiguous in this case)
                pass
            elif (isinstance(auto_fx, str) and auto_fx == "on") or (
                not isinstance(auto_fx, str) and auto_fx
            ):
                # For reconciliation, take direction from input arg:
                # fx=RootLib().get_control('fx') if possible, otherwise, prioritize fx1 (left-side fx1)
                if fx is not None:
                    conversion_fx = fx
                elif valuespace1 is not None:
                    conversion_fx = fx1
                else:
                    conversion_fx = fx2

                # Modify conversion_fx_dict
                if valuespace1 is not None and fx1 != conversion_fx:
                    # Left side needs fx conversion
                    conversion_fx_dict[valuespace1] = conversion_fx

                if valuespace2 is not None and fx2 != conversion_fx:
                    # Right side needs fx conversion
                    conversion_fx_dict[valuespace2] = conversion_fx

                # Handle final tgt_fx
                tgt_fx_dict[tgt_valuespace] = conversion_fx
            else:
                # Raise Exception due to FX conflict
                raise Exception(
                    "F/X conflict: valuespace1:{0} w/fx1:{1} INCONSISTENT WITH valuespace2:{2} w/fx2:{3}".format(
                        valuespace1, fx1, valuespace2, fx2
                    )
                )

        # =========================== END: TARGET VALUESPACES LOOP =============================

        # ------------------------------------------
        # Apply currency conversion (if required)
        # ------------------------------------------
        if len(conversion_fx_dict) > 0:
            joined = joined.convert_fx(
                fx=conversion_fx_dict, valuespace=list(conversion_fx_dict.keys())
            )

        # --------------------------------------------------------------------------
        #              coalesce.j2 template arguments
        # --------------------------------------------------------------------------
        # src_table_name: Pre-joined source table
        # keyspaces: Keyspace columns in the pre-joined table
        # valuespace_pairs: dictionary of dictionaries per target valuespace
        #    outer keys: target valuespaces
        #    inner keys: 'src_vs'
        #    inner values: pairs for left/right info
        #        'src_vs': The valuespace (column name) of the left/right side of the operational pair
        # tgt_table_name: Name of the table in which to write the result
        # --------------------------------------------------------------------------
        tgt_table_name = generate_random_table_name()
        sql_template = JINJA_ENV.get_template("coalesce.j2")
        sql_command = sql_template.render(
            src_table_name=joined.table_name,  # <-- should match other.table_name
            keyspaces=joined.keyspaces,
            valuespace_pairs=valuespace_pairs,
            tgt_table_name=tgt_table_name,
        )
        execute(sql_command)

        # ---------------------------------------
        # COPY CUSTOM INFO FROM
        # joined.table_name -> tgt_table_name
        # ---------------------------------------
        # FOR BOOL YIELDING OPS,
        # SUPPRESS NON-BOOL INFO_TYPES
        # [Example: fx]
        # ---------------------------------------

        column_map = {}
        # Transfer joined keyspaces
        for ks in joined.keyspaces:
            column_map[ks] = ks
        # Transfer joined valuespaces info to tgt_valuespace
        for tgt_valuespace in valuespace_pairs:
            if valuespace_pairs[tgt_valuespace] is None:
                raise Exception(f"valuespace_pairs[{tgt_valuespace}] is None")
            elif "src_vs" not in valuespace_pairs[tgt_valuespace]:
                raise Exception(
                    f"'src_vs' absent from valuespace_pairs[{tgt_valuespace}]"
                )
            elif isinstance(valuespace_pairs[tgt_valuespace]["src_vs"], (tuple, list)):
                for src_vs in valuespace_pairs[tgt_valuespace]["src_vs"]:
                    if src_vs is not None:
                        column_map[src_vs] = tgt_valuespace
                        break
            elif valuespace_pairs[tgt_valuespace]["src_vs"] is not None:
                column_map[valuespace_pairs[tgt_valuespace]["src_vs"]] = tgt_valuespace

        # Establish col_info for copy
        if tgt_table_name == joined.table_name:
            col_info = None
        else:
            col_info = joined.get_space_info(
                info_type=[it1 for it1 in CUSTOM_INFO_TYPES if it1 != "fx"],
                space=column_map,
                omit_unassigned=True,
            )
            # Assign final fx...
            if len(tgt_fx_dict) > 0:
                if col_info is None:
                    col_info = {}
                col_info["fx"] = tgt_fx_dict

        # Instantiate Quble from the new table
        result = Quble.from_table(
            tgt_table_name,
            col_info=col_info,
        )

        # Compress the result (if requested)
        if compress:
            # Could possibly rethink auto_squeeze=False here
            summarize = (
                "all"
                if isinstance(compress, str) and (compress.find("all") >= 0)
                else "any"
            )
            drop = (
                True
                if isinstance(compress, str) and (compress.find("drop") >= 0)
                else False
            )
            result.compress(
                summarize=summarize,
                treat_false_as_null=True,
                drop=drop,
                key_ordering=None,
                auto_squeeze=False,
                inplace=True,
            )

        return result

    def intra_coalesce_inplace(
        self,
        coalesce_map: dict,
        valuespaces_to_keep="<valuespaces>",
        grace: bool = True,
        custom_info_overrides: dict = None,
        preferred_vs: str = None,
        insert_after_last_keyspace: bool = False,
    ) -> Quble:
        """
        See: :meth:`~qubles.core.quble.Quble.intra_coalesce`
        """
        return self.intra_coalesce(
            coalesce_map=coalesce_map,
            valuespaces_to_keep=valuespaces_to_keep,
            grace=grace,
            custom_info_overrides=custom_info_overrides,
            preferred_vs=preferred_vs,
            insert_after_last_keyspace=insert_after_last_keyspace,
            inplace=True,
        )

    def intra_coalesce(
        self,
        coalesce_map: dict,
        valuespaces_to_keep="<valuespaces>",
        grace: bool = True,
        custom_info_overrides: dict = None,
        preferred_vs: str = None,
        insert_after_last_keyspace: bool = False,
        inplace=False,
    ) -> Quble:
        """
        Applies a "coalesce" operation across groupings of spaces
        to create a new columns(s) for each group

        It is presumed (required) that the data types
        of the columns to be coalesced are compatible

        These new columns will serve (be assigned) as valuespaces
        unless otherwise directed via the custom_info_overrides dict arg

        Note that newly introduced columns may (or may not) necessarily
        become primary valuespaces when valuespaces_to_keep arg is non-trivial...
        Use preferred_vs arg to force a specific new valuespace to be primary

        Some, all, or none of the existing valuespaces can be retained
        according to the valuespaces_to_keep arg

        :param coalesce_map: mapping from each new column to associated
                    groups of (original) columns/spaces to be coalesced
            dictionary keys: new spaces to be introduced via coalation
            dictionary values: list/tuple of existing spaces to coalesce

            IMPORTANT: Can assign a latter dict value to match an earlier dict key
            to yield source column name of the coalesce result

            Example:
            ==> coalesce_map = {"NewVals": ["ValA","ValB"], "SrcCol":"NewSrcVals"}
            ==> "NewVals" yields the coalesced value
            ==> "NewSrcVals" yields source column of the coalesce operation
            ==> Where "ValA" and "ValB" are original columns
            ==> and "NewVals" and "NewSrcVals" are newly introduced columns

        :type coalesce_map: dict

        :param valuespaces_to_keep: original valuespaces to retain
                        [By default, all original valuespaces are retained]
                        [Use None to NOT retain any existing valuespaces]
        :type valuespaces_to_keep: list (of strings) or str or None

        :param grace: flag to gracefully handle failures/contingencies
        :type grace: bool (True*/False)

        :param custom_info_overrides: Overrides to custom column info assignments
        :type custom_info_overrides: dictionary of dictionaries

            outer dictionary keys: info_type
            outer dictionary values: inner dictionary
            inner dictionary keys: column_name (post-renamed convention when applicable)
            inner dictionary values: associated info_type_assignment

            ==> NOTE: when using custom_info_overrides arg
                in conjunction with dict version of column_names (for column renaming)
                the custom_info_overrides should be specified using new/target column names

        :type preferred_vs: str or None
        :param preferred_vs: preferred valuespace (may use None)
                             None ==> primary valuespace = None (makes index Quble)
                             '<inspect>' ==> no preference..inspect valuespaces

        :param insert_after_last_keyspace: Flag to insert any new columns after the last keyspace
            ==> Use this option to elevate new (value)space(s) ahead of existing valuespaces
            ==> Otherwise, newly introduced spaces will be appended to end of spaces/columns
        :type insert_after_last_keyspace: bool (False*/True)

        :param inplace: Controls self-modification vs returning a modified copy
        :type inplace: bool (False*/True)
        """
        # Handle trivial corner cases
        if self.is_undefined:
            return self.copy()
        elif coalesce_map is None:
            coalesce_map = {}
        elif not isinstance(coalesce_map, dict):
            raise Exception(
                f"Invalid coalesce_map..dict required but received type:{type(coalesce_map)}"
            )

        # Validate valuespaces_to_keep
        if valuespaces_to_keep is None:
            # In this case, no existing valuespaces will be retained
            valuespaces_to_keep = []
        else:
            valuespaces_to_keep = self.validate_valuespace(
                valuespaces_to_keep,
                grace=False,
                coerce_to_list=True,
            )

        # Validate custom_info_overrides
        if custom_info_overrides is None:
            custom_info_overrides = {}
        elif not isinstance(custom_info_overrides, dict):
            raise Exception(
                f"Invalid custom_info_overrides...dict (or None) expected yet type(custom_info_overrides):{type(custom_info_overrides)}"
            )

        # Loop through coalesce_map and build new_col_expressions
        # =============== START: NEW COLUMN (new_col) LOOP ================
        new_col_expressions = {}
        for new_col, cols_to_coalesce_orig in coalesce_map.items():
            if new_col is None:
                continue
            elif new_col in self.spaces:
                # Make sure dict keys do not clash with existing columns
                raise Exception(
                    f"new_col:{new_col} alerady present in self.spaces:{self.spaces}"
                )
            elif cols_to_coalesce_orig is not None and not isinstance(
                cols_to_coalesce_orig, (list, tuple, str)
            ):
                # cols_to_coalesce_orig must be list,tuple or None
                raise Exception(
                    f"Invalid map value...list/tuple/str/None expected yet coalesce_map[{new_col}]: {cols_to_coalesce_orig}"
                )
            else:
                # Remove any trivial elements from the group
                src_col_name_logic = False
                if cols_to_coalesce_orig is None:
                    cols_to_coalesce_cleaned = []
                elif isinstance(cols_to_coalesce_orig, str):
                    if cols_to_coalesce_orig == new_col:
                        raise Exception(
                            f"dict key:{new_col} must not match dict value:{cols_to_coalesce_orig}"
                        )
                    elif cols_to_coalesce_orig in coalesce_map:
                        # Here, we prepare for src_col_name_logic using coalesce_map[cols_to_coalesce_orig]
                        src_col_name_logic = True
                        if coalesce_map[cols_to_coalesce_orig] is None:
                            cols_to_coalesce_cleaned = []
                        elif not isinstance(
                            coalesce_map[cols_to_coalesce_orig], (list, tuple)
                        ):
                            raise Exception(
                                f"Invalid dict value:{coalesce_map[cols_to_coalesce_orig]}...list/tuple expected"
                            )
                        else:
                            cols_to_coalesce_cleaned = [
                                space1
                                for space1 in coalesce_map[cols_to_coalesce_orig]
                                if space1 is not None
                            ]
                    else:
                        cols_to_coalesce_cleaned = [cols_to_coalesce_orig]
                else:
                    cols_to_coalesce_cleaned = [
                        space1 for space1 in cols_to_coalesce_orig if space1 is not None
                    ]

                if len(cols_to_coalesce_cleaned) == 0:
                    # Create a column of NULLs here (arbitrarily assigning to float type)
                    if src_col_name_logic:
                        new_col_expressions[new_col] = "CAST(NULL AS VARCHAR(16))"
                    else:
                        new_col_expressions[new_col] = (
                            "CAST(NULL AS FLOAT)"  # AS "' + new_col + '"'
                        )
                elif len(cols_to_coalesce_cleaned) == 1:
                    # No coalesce logic required here (as only one source column to be coalesced)
                    if src_col_name_logic:
                        new_col_expressions[new_col] = (
                            "'" + cols_to_coalesce_cleaned[-1] + "'"
                        )
                    else:
                        new_col_expressions[new_col] = (
                            '"' + cols_to_coalesce_cleaned[-1] + '"'
                        )
                else:
                    # Here, there are multiple columns to coalesce
                    new_col_expression1 = "CASE "
                    for old_col in cols_to_coalesce_cleaned:
                        # Validate each old_col
                        if old_col in coalesce_map:
                            # The old_col to be coalesced cannot also be used as a new column
                            raise Exception(
                                f"Invalid coalesce_map...existing column:{old_col} cannot be used as a new/tgt column (dict key)"
                            )
                        elif old_col not in self.spaces:
                            # Here, the old_col to be coalesced is absent
                            # Alternatively, could handle according to grace here
                            raise Exception(
                                f"Invalid coalesce_map...existing column:{old_col} is absent from self.spaces:{self.spaces}"
                            )
                        elif src_col_name_logic:
                            # Here we assign the name of the source column [Note the value of the source column]
                            new_col_expression1 += (
                                ' WHEN ("'
                                + old_col
                                + '" IS NOT NULL) THEN '
                                + "'"
                                + old_col
                                + "'"
                            )
                        else:
                            # Here we assign the value from the source column
                            new_col_expression1 += (
                                ' WHEN ("'
                                + old_col
                                + '" IS NOT NULL) THEN "'
                                + old_col
                                + '"'
                            )

                    if src_col_name_logic:
                        new_col_expression1 += (
                            " ELSE " + "'" + cols_to_coalesce_cleaned[-1] + "'" + " END"
                        )
                    else:
                        new_col_expression1 += (
                            ' ELSE "' + cols_to_coalesce_cleaned[-1] + '" END'
                        )

                    new_col_expressions[new_col] = new_col_expression1

                # Manage custom_info_overrides for this new column (new_col)
                if new_col not in custom_info_overrides:
                    custom_info_overrides[new_col] = {}
                elif not isinstance(custom_info_overrides[new_col], dict):
                    raise Exception(
                        f"Invalid custom_info_overrides[new_col]:{custom_info_overrides[new_col]}...dict expected"
                    )

                # Ensure 'role' is present in custom_info_overrides
                if "role" not in custom_info_overrides:
                    custom_info_overrides["role"] = {}

                # Force the new column (new_col) to be a valuespace (unless explicitly directed otherwise)
                if new_col not in custom_info_overrides["role"]:
                    custom_info_overrides["role"][new_col] = "valuespace"

        # ================ END: NEW COLUMN (new_col) LOOP =================

        # Establish final_columns list by inserting any new columns where directed
        if len(new_col_expressions) > 0 and insert_after_last_keyspace:
            final_columns = (
                self.keyspaces + list(new_col_expressions.keys()) + valuespaces_to_keep
            )
        else:
            final_columns = (
                self.keyspaces + valuespaces_to_keep + list(new_col_expressions.keys())
            )

        # Apply the selection according to the new_col_expressions
        result = self.select(
            column_names=final_columns,
            column_expressions=new_col_expressions,
            custom_info_overrides=custom_info_overrides,
            preferred_vs=preferred_vs,
        )

        if inplace:
            self._swap_table(result)
        else:
            return result

    def shift1d(
        self,
        periods: int,
        keyspace: str = "<first_time_keyspace>",
        valuespace="<valuespaces>",
        original_dates_only=False,
        tfill_end_mode="<space_root>",
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        key_ordering=None,
    ) -> Quble:
        """
        Shifts the results by the specified number of periods [Time-keyspace required]

        :param periods: # periods to shift
            ==> periods>0: lag the data
            ==> periods<0: lead the data (Warning: may be non-causal)
        :type periods: integer

        :param keyspace: The index keyspace where key is to be applied
        :type keyspace: {q_keyspace_type}

        :param valuespace: Specific valuespace(s) column(s) to be shifted
                           (only the specified valuespaces will be retained)
        :type valuespace: {q_keyspace_type}

        :param key_ordering: controls row ordering by key
        :type key_ordering: None, str or dictionary
           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace
           dictionary: dict keys (str): keyspaces, dict values (str): 'asc' or 'desc'
           ==> allows for assigning key ordering (ascending/descending)
           ==> (and relative priority) for each keyspace individually

        :param tfill_end_mode: Controls extension/limits beyond original dates
        :type tfill_end_mode: string (None or 'unconstrained', 'no_future', 'in_progress', 'no_extension', 'full_extension')

        :type original_dates_only: bool
        :param original_dates_only:
            Controls whether restrict the result
            to only those dates originally present

        :param tfill_method: Method to use for filling time/date data holes using the index
                             (only applies when original_dates_only=True)
        :type tfill_method: {q_fill_method} limited to one of -> ['backfill', 'pad'] or None

        :type tfill_max: int or str (indirection case)
                         (only applies when original_dates_only=True)
        :param tfill_max: The tfill_max parameter of the associated space

        :returns: The current Quble (or a copy of it) with the shift operation completed.
        :rtype: qubles.core.quble.Quble

        """
        # Validate table
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_empty:
            return self.copy()
        elif self.is_variate:
            # Validate valuespace
            valuespace = self.validate_valuespace(valuespace, coerce_to_list=True)

            # Isolate valuespaces as subject
            # [Only refer to subject subsequently!]
            # --------------------------------------
            subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        elif valuespace not in ("<valuespace>", "<valuespaces>"):
            raise NoValuespaceError("variate Quble required for valuespace arg:{}")
        else:
            # We accommodate non-variate (index) Qubles for certain arg cases
            subject = self

        # Validate the (time)keyspace
        keyspace = subject.validate_keyspace(
            keyspace, grace=False, solo_required=True, time_space_required=True
        )

        # Establish & validate existing freq
        freq = subject.get_freq(keyspace, allow_infer=True, assign_inferred=True)

        if freq is None:
            raise Exception("Unable to establish existing freq")
        elif freq not in PPY:
            raise Exception(f"Invalid freq:{freq}")

        table_name = generate_random_table_name()

        # Build key_ordering dictionary when applicable
        if key_ordering is not None and not isinstance(key_ordering, str):
            key_ordering = build_key_ordering_dict(
                key_ordering, keyspaces=subject.keyspaces
            )

        # Procure tfill_end_mode_scalar (from first resolved)
        tfill_end_mode_scalar = (
            None  # <-- Not implemented as valuespace-specific (for practical reasons)
        )

        for vs in subject.valuespaces:
            if tfill_end_mode_scalar is None:
                # Evaluate tfill_end_mode_scalar until it is assigned a non-trivial value
                tfill_end_mode_scalar = subject._space_info_indirection(
                    info_type="tfill_end_mode",
                    space=vs,
                    info_assignment=tfill_end_mode,
                    grace=True,
                )
                if tfill_end_mode_scalar is not None:
                    break

        # Validate tfill_end_mode_scalar
        # ---------------------------------
        if tfill_end_mode_scalar is None:
            tfill_end_mode_scalar = (
                "no_extension" if original_dates_only else "no_future"
            )
        elif tfill_end_mode_scalar not in (
            "no_future",
            "in_progress",
            "no_extension",
            "full_extension",
            "unconstrained",
        ):
            raise ValueError(f"Invalid tfill_end_mode: {tfill_end_mode_scalar}")

        sql_template = JINJA_ENV.get_template("shift.j2")
        sql_command = sql_template.render(
            src_table_name=subject.table_name,
            tgt_table_name=table_name,
            freq=freq,
            calendar_table_name=RootLib().get_control("calendar_table_name"),
            keyspace=keyspace,
            periods=periods,
            keyspaces=subject.keyspaces,
            valuespaces=subject.valuespaces,
            fill_end_mode=tfill_end_mode_scalar,
            key_ordering=key_ordering,
        )

        execute(sql_command, format_flag=False)

        # Establish col_info for copy
        if table_name == subject.table_name:
            col_info = None
        else:
            col_info = subject.get_space_info(
                info_type=CUSTOM_INFO_TYPES,
                space=subject.keyspaces + subject.valuespaces,
                omit_unassigned=True,
            )

        # Instantiate Quble from the new table
        result = Quble.from_table(
            table_name,
            col_info=col_info,
        )

        # Re-impose original dates when requested
        if original_dates_only:
            result = result.project(
                index=self,
                auto_fill=True,
                tfill_method=tfill_method,
                tfill_max=tfill_max,
                tfill_end_mode=None,  # <-- To exactly replicate orig dates
                tfill_honor_nulls=True,
                # tdistribute_mode should not apply here as the frequency should already match
                key_ordering=key_ordering,
            )

        return result

    def apply_date_limits(
        self,
        start_date=None,
        end_date=None,
        space: str = "<first_time_keyspace>",
        include_endpoints: bool = True,
        allow_shallow_copy: bool = False,
    ) -> Quble:
        """
        Applies min/max date limits to the specified date_keyspace
        ==> If both start_date and end_date are None, simply returns self (or copy thereof)

        :param start_date: (optional) start/min date
        :type start_date: datetime, date, np.datetime64, None,
                     or (SQL-friendly) string
                     or 'now' (will substitute current datetime)

        :param end_date: end/max date (optional)
        :type end_date: datetime, date, np.datetime64, None,
                     or (SQL-friendly) string
                     or 'now' (will substitute current datetime)

        :param space: time-space where to apply date limits
        :type space: str (will default to first time keyspace)

        :param include_endpoints: flag whether to include/exclude endpoints
        :type include_endpoints: (boolean) True*/False

        :param allow_shallow_copy: permission flag to return a shallow copy
                                   of original self Quble for trivial cases
        :type allow_shallow_copy: bool (True*/False)
        """
        # Trap for undefined Quble
        if not self.is_undefined and space is not None:
            pass
        else:
            return self if allow_shallow_copy else self.copy()

        # Validate space (must be a time-space)
        space = self.validate_space(
            space, grace=False, solo_required=True, time_space_required=True
        )

        # Convert start_date to start_datestr [Use high resolution sql-compatible format (when necessary)]
        # -------------------------------------------------------------
        if start_date is None:
            start_datestr = None
        elif isinstance(start_date, str):
            start_datestr = (
                str(datetime.now()) if start_date.lower() == "now" else start_date
            )
        elif isinstance(start_date, (datetime, date)):
            # start_datestr = str(start_date)
            start_datestr = datetime_to_str(start_date, fmt="%Y-%m-%dT%H:%M:%S.%f")
        elif hasattr(start_date, "dtype") and np.issubdtype(start_date, np.datetime64):
            start_datestr = str(start_date)
        else:
            raise Exception(
                f"Invalid start_date:{start_date}...datetime, date, np.datetime64 or str or 'now' or None"
            )

        # Convert end_date to end_datestr [Use high resolution sql-compatible format (when necessary)]
        # -------------------------------------------------------------
        if end_date is None:
            end_datestr = None
        elif isinstance(end_date, str):
            end_datestr = str(datetime.now()) if end_date.lower() == "now" else end_date
        elif isinstance(end_date, (datetime, date)):
            # end_datestr = str(end_date)
            end_datestr = datetime_to_str(end_date, fmt="%Y-%m-%dT%H:%M:%S.%f")
        elif hasattr(end_date, "dtype") and np.issubdtype(end_date, np.datetime64):
            end_datestr = str(end_date)
        else:
            raise Exception(
                f"Invalid end_date:{end_date}...datetime, date, np.datetime64 or str or 'now' or None"
            )

        # Construct operators based on include_endpoints arg
        less_than_op = "<=" if include_endpoints else "<"
        greater_than_op = ">=" if include_endpoints else ">"

        # Build where_clause
        where_clause = None
        if self.is_empty:
            pass
        elif space not in self.spaces:
            pass
        elif start_datestr is not None:
            if end_datestr is not None:
                where_clause = (
                    'WHERE ("'
                    + space
                    + '" '
                    + greater_than_op
                    + " '"
                    + start_datestr
                    + "')"
                    + ' AND ("'
                    + space
                    + '" '
                    + less_than_op
                    + " '"
                    + end_datestr
                    + "')"
                )
            else:
                where_clause = (
                    f"""WHERE ("{space}" {greater_than_op} '{start_datestr}')"""
                )
        elif end_datestr is not None:
            where_clause = f"""WHERE ("{space}" {less_than_op} '{end_datestr}')"""

        # Return result accordingly
        if where_clause is not None:
            return self.select(where_clause=where_clause)
        else:
            return self if allow_shallow_copy else self.copy()

    @classmethod
    def ppy(
        cls,
        freq: str,
    ) -> Quble:
        """
        Yields (approximate) number of periods-per-year (as a float scalar)
        for the time-frequency argument (str) provided

        :param freq: frequency for which periods-per-year is requested
        :type freq: str

        :returns: number of periods-per-year at the specified frequency
                (possibly with a fractional component)
        :rtype: float
        """
        return PPY[freq] if freq else None

    @classmethod
    def date_range(
        cls,
        start,
        end,
        freq: str,
        timespace="Dates",
        freq_idx_space: str = None,
        dual_case_dates_as_values: bool = False,
    ) -> Quble:
        """
        Generates either a single-dimensional index Quble
        (or a one-dimensional valued Quble)
        representing a contiguous date-range
        between the start & end datetimes (inclusive)
        at the specified frequency

        :param start: start date/time for daterange
        :type start: datetime, date, np.datetime64, None,
                     or (SQL-friendly) string
                     or 'now' (will substitute current datetime)


        :param end: end date/time for daterange
        :type end:datetime.datetime, date, np.datetime64, None
                  or (SQL-friendly) string
                  or 'now' (will substitute current datetime)

        :param freq: desired frequency for the date range
        :type freq: str

        :param timespace: time-keyspace name (defaults to calendar table's 'Dates' column name)
        :type dates_space: str

        :param freq_idx_space: (optional) target freq idx keyspace or valuespace name
                        (defaults to calendar table's 'freq_idx' column name)
        :type freq_idx_space: str

        :param dual_case_dates_as_values: flag to dates as valuespace
                ==> ONLY APPLICABLE when both dates_space & freq_idx_space are provided
        :type dual_case_dates_as_values: bool (True/False*)

        :returns: 1-D index Quble (or a 1-D valued Quble)
        :rtype: qubles.core.quble.Quble
        """
        # Convert start to start_timekey_str
        if start is None:
            raise Exception("start arg required")
        elif isinstance(start, str):
            start_timekey_str = str(datetime.now()) if start == "now" else start
        elif isinstance(start, (datetime, date)):
            # datetime.datetime or datetime.date scalar
            start_timekey_str = str(start)
        elif hasattr(start, "dtype") and np.issubdtype(start, np.datetime64):
            # np.datetime64
            start_timekey_str = str(start)
        else:
            raise Exception(
                f"Invalid start:{start}...datetime, date, np.datetime64 or str or 'now' or None"
            )

        # Convert end to end_timekey_str
        if end is None:
            raise Exception("end arg required")
        elif isinstance(end, str):
            end_timekey_str = str(datetime.now()) if end == "now" else end
        elif isinstance(end, (datetime, date)):
            # datetime.datetime or datetime.date scalar
            end_timekey_str = str(end)
        elif hasattr(end, "dtype") and np.issubdtype(end, np.datetime64):
            # np.datetime64 scalar
            end_timekey_str = str(end)
        else:
            raise Exception(
                f"Invalid end:{end}...datetime, date, np.datetime64 or str or 'now' or None"
            )

        # Validate freq arg
        if freq is None:
            raise Exception("freq not specified")
        elif freq not in PPY:
            raise Exception(f"Invalid freq:{freq}")

        table_name = generate_random_table_name()

        # --------------------------------------------------------
        # Establish tgt_spaces & tgt_valuespace & space_map
        # --------------------------------------------------------
        # cal_space_map is an dictionary where:
        #   ==> keys correspond to actual calendar table columns
        #   ==> values correspond to the desired column names
        # The key ordering will control query column ordering
        # --------------------------------------------------------
        cal_space_map = {}
        if timespace is not None and freq_idx_space is not None:
            if dual_case_dates_as_values:
                # This case yields (integer/freq_idx-indexed, dates-valued) 1D valued Quble
                cal_space_map["Freq_idx"] = freq_idx_space
                cal_space_map["Dates"] = timespace  # <-- timespace will be valuespace
            else:
                # This case yields (dates-indexed, integer/freq_idx-valued) 1D valued Quble
                cal_space_map["Dates"] = timespace
                cal_space_map["Freq_idx"] = (
                    freq_idx_space  # <-- freq_idx_space will be valuespace
                )
        elif timespace is not None:
            # This case yields (datetime-indexed, non-valued) 1D index Quble
            cal_space_map["Dates"] = (
                timespace  # <-- This will be sole keyspace (no valuespace)
            )
        elif freq_idx_space is not None:
            # This case yields (integer-indexed, non-valued) 1D index Quble
            cal_space_map["Freq_idx"] = (
                freq_idx_space  # <-- This will be sole keyspace (no valuespace)
            )
        else:
            # RaiseException unless atleast one of timespace & freq_idx_space is provided
            raise Exception(
                "One of timespace or freq_idx_space must be provided (non-trivial)"
            )

        # Verify that the cal_space_map is not empty
        # [otherwise, the query is undefined]
        if len(cal_space_map) == 0:
            raise Exception(
                "cal_space_map is empty...atleast one of timespace or freq_idx_space must be provided"
            )

        # Render & execute SQL command
        sql_template = JINJA_ENV.get_template("date_range.j2")
        sql_command = sql_template.render(
            tgt_table_name=table_name,
            start_timekey_str=start_timekey_str,
            end_timekey_str=end_timekey_str,
            freq=freq,
            cal_space_map=cal_space_map,
            calendar_table_name=RootLib().get_control("calendar_table_name"),
        )

        execute(sql_command)

        # Set the freq of the dates column (if present) accordingly
        # [regardless of whether dates column is a keyspace or valuespace]
        col_info = None
        if timespace is not None:
            if col_info is None:
                col_info = {}
            col_info["freq"] = {timespace: freq}

        # For dual column space_map case,
        # identify the tgt_valuespace
        # as the last element of the space map
        if len(cal_space_map) == 2:
            if col_info is None:
                col_info = {}
            col_info["role"] = {list(cal_space_map.values())[-1]: "valuespace"}

        # Instantiate Quble from the new table
        return Quble.from_table(
            table_name,
            col_info=col_info,
        )

    def datetime_to_freq_idx1d(
        self,
        space: str = "<first_time_keyspace>",
        freq_idx_space: str = "freq_idx",
        as_new_valuespace_flag: bool = False,
    ) -> Quble:
        """
        Given a Quble with a specified (time)space
        (and possibly other 'orthogonal' spaces), this method either:

           1) If as_new_valuespace_flag==False:
              replaces original (time)space as an integer-keyed column
              [Here, retains/assumes the original column's role]

        OR 2) If as_new_valuespace_flag==True:
              keeps original time-column and also adds a new valuespace w/integer-keys
              Here, result has one additional valuespace than original Quble.
              The newly added space assumes valuespace role.

        Here, the translated integer-key freq_idx_space (frequency counters)
        reflects the frequency counter from the calendar table profile
        according to the frequency of the original time-space.

        :param space: timespace for which freq_idx are requested
        :type space: str

        :param freq_idx_space: (optional) target freq idx space name
                        (defaults to calendar table's 'freq_idx' column name)
        :type freq_idx_space: string

        :param as_new_valuespace_flag: flag indicating column replacement (False)
                                       or an addition column (True) operation
        :type as_new_valuespace_flag: bool (False*/True)

        :returns: The Quble with calendar-translated spaces
        :rtype: qubles.core.quble.Quble

        """
        # Validate self
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate space
        space = self.validate_space(space, time_space_required=True, grace=False)

        # Remember the original valuespace
        orig_valuespace = self.valuespace

        # Establish freq_idx_space arg
        if freq_idx_space is None:
            freq_idx_space = "freq_idx"

        # Validate freq_idx_space
        if freq_idx_space in self.spaces:
            raise Exception(
                f"freq_idx_space:{freq_idx_space}...already present in Quble"
            )

        # Build column_map from old to new column names
        column_map = {}
        for space1 in self.spaces:
            if space1 == space and not as_new_valuespace_flag:
                column_map[space1] = freq_idx_space
            else:
                column_map[space1] = space1

        # Establish & validate existing freq
        freq = self.get_freq(space, allow_infer=True, assign_inferred=True, grace=False)

        if freq is None:
            raise Exception("Unable to establish existing freq")
        elif freq not in PPY:
            raise Exception(f"Invalid freq:{freq}")

        table_name = generate_random_table_name()

        # Render & execute SQL command
        sql_template = JINJA_ENV.get_template("datetime_to_freq_idx.j2")
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            tgt_table_name=table_name,
            freq=freq,
            calendar_table_name=RootLib().get_control("calendar_table_name"),
            timespace=space,
            spaces=self.spaces,
            freq_idx_space=freq_idx_space,
            as_new_valuespace_flag=as_new_valuespace_flag,
        )
        execute(sql_command, format_flag=False)

        # NOTE: Choosing not to remove 'freq' info type for space column
        # NOTE: use of column_map dict will cause new column (freq_idx_space) to inherit information from old column (space)
        col_info = self.get_space_info(
            info_type=CUSTOM_INFO_TYPES,
            space=column_map,
            omit_unassigned=True,
        )
        # Add col_info for new_valuespace (freq_idx_space) (if applicable)
        if as_new_valuespace_flag:
            if col_info is None:
                col_info = {}

            # Assign col_info['role'][freq_idx_space] = True
            if "role" not in col_info or col_info["role"] is None:
                col_info["role"] = {freq_idx_space: "valuespace"}
            else:
                col_info["role"][freq_idx_space] = "valuespace"

            # Assign col_info['freq'][freq_idx_space] = freq
            # Here, we trust/honor the freq [Potential break from convention by assigning 'freq' meta data to integer column]
            if freq is None:
                pass
            elif "freq" not in col_info or col_info["freq"] is None:
                col_info["freq"] = {freq_idx_space: freq}
            else:
                col_info["freq"][freq_idx_space] = freq

        # Instantiate Quble from the new table
        result = Quble.from_table(
            table_name,
            col_info=col_info,
        )

        # Try to retain original valuespace (if possible)
        if (
            result.valuespace != orig_valuespace
            and result.is_variate
            and orig_valuespace is not None
            and orig_valuespace in result.valuespaces
        ):
            result.valuespace = orig_valuespace

        return result

    def freq_idx_to_datetime1d(
        self,
        space: str,
        timespace: str = "Dates",
        freq: str = None,
        as_new_valuespace_flag: bool = False,
    ) -> Quble:
        """
        Given a Quble with a specified freq_idx (integer) space
        (and possibly other 'orthogonal' spaces), this method either:

           1) If as_new_valuespace_flag==False:
              replaces original (integer)space as a datetime-keyed column
              [Here, retains/assumes the original column's role]

        OR 2) If as_new_valuespace_flag==True:
              keeps original (integer)space and also adds a new valuespace w/datetime-keys
              Here, result has one additional valuespace than original Quble.
              The newly added space assumes valuespace role.

        Here, the translated datetime-key timespace
        is constricted from the frequency counter integer column
        using from the calendar table profile
        according to the frequency of the original time-space.

        :param space: freq_idx (frequency counters) integer column
                      for which datetimes are requested
        :type space: string

        :param timespace: (optional) target timespace name
                 (otherwise defaults to calendar table's 'Dates' column name)
        :type timespace: string

        :param as_new_valuespace_flag:flag indicating column replacement (False)
                                      or an addition column (True) operation
        :type as_new_valuespace_flag: bool (False*/True)

        :param freq: associated freq for freq_idx integer column
                 (if None, seeks freq meta-data assignment for this column)
        :type freq: string

        :returns: The Quble with calendar-translated spaces
        :rtype: qubles.core.quble.Quble

        """
        # Validate self
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate space
        space = self.validate_space(space, grace=False)
        if not self.is_int(space):
            raise Exception(f"Non-integer space:{space}")

        # Remember the original valuespace
        orig_valuespace = self.valuespace

        # Establish timespace
        if timespace is None:
            timespace = "Dates"

        # Validate freq_idx_space
        if timespace in self.spaces:
            raise Exception(
                f"timespace:{timespace}...already present in Quble spaces:{self.spaces}"
            )

        # Build column_map from old to new column names
        column_map = {}
        for space1 in self.spaces:
            if space1 == space and not as_new_valuespace_flag:
                column_map[space1] = timespace
            else:
                column_map[space1] = space1

        # Establish & validate existing freq
        if freq is None:
            # Inference not possible here since space/column keys are actually integers (not datetimes)
            freq = self.get_freq(space, time_space_required=False, grace=False)

        if freq is None:
            raise Exception("Unable to establish existing freq")
        elif freq not in PPY:
            raise Exception(f"Invalid freq:{freq}")

        table_name = generate_random_table_name()

        # Render & execute SQL command
        sql_template = JINJA_ENV.get_template("freq_idx_to_datetime.j2")
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            tgt_table_name=table_name,
            freq=freq,
            calendar_table_name=RootLib().get_control("calendar_table_name"),
            freq_idx_space=space,
            spaces=self.spaces,
            timespace=timespace,
            as_new_valuespace_flag=as_new_valuespace_flag,
        )

        execute(sql_command)

        # NOTE: Choosing not to remove 'freq' info type for space column
        # NOTE: use of column_map dict will cause new column (freq_idx_space) to inherit information from old column (space)
        col_info = self.get_space_info(
            info_type=CUSTOM_INFO_TYPES,
            space=column_map,
            omit_unassigned=True,
        )
        # Add col_info for new_valuespace (timespace) (if applicable)
        if as_new_valuespace_flag:
            if col_info is None:
                col_info = {}

            # Assign col_info['role'][timespace] = True
            if "role" not in col_info or col_info["role"] is None:
                col_info["role"] = {timespace: "valuespace"}
            else:
                col_info["role"][timespace] = "valuespace"

            # Assign col_info['freq'][timespace] = freq
            if freq is None:
                pass
            elif "freq" not in col_info or col_info["freq"] is None:
                col_info["freq"] = {timespace: freq}
            else:
                col_info["freq"][timespace] = freq

        # Instantiate Quble from the new table
        result = Quble.from_table(
            table_name,
            col_info=col_info,
        )

        # Try to retain original valuespace (if possible)
        if (
            result.valuespace != orig_valuespace
            and result.is_variate
            and orig_valuespace is not None
            and orig_valuespace in result.valuespaces
        ):
            result.valuespace = orig_valuespace

        return result

    def _validate_and_convert_aggr_method(
        self,
        aggr_method: str,
        column_name: str,
        ignore_missing: bool,
        num_required: int,
        percentile: float,
        epsilon: float,
        weightspace: str = None,
        clob_export_mode: str = "unicode",
        blob_export_mode: str = "object",
    ) -> tuple:
        """
        Validates aggregation method and converts to a SQL-compatible analog aggregation function
        returns: (sql_aggr_fn, extra_fn_args, is_custom, is_weighted, aggr_keyspaces_presort_needed)
        """
        if aggr_method is None or not isinstance(aggr_method, str):
            raise Exception(f"Invalid aggr_method:{aggr_method}")

        aggr_method = aggr_method.lower().strip()
        # QUANTILE(<COLUMN>,[0,1])
        # CORR(<COLUMN A>,<COLUMN B>)

        # NOTE: Custom aggregations may be processed in the embedded Python session running inside SQL
        # As such, the specification of output_dtype (in CUSTOM_AGGR_CONFIGS as string but rendered by Jinja2 template literally)
        # needs to be consistent with the embedded Python session [which uses "numpy." prefix (not "np." prefix)]
        # -------------------------------------------------------------------------------------------------
        #  Example: For output_coltype:'double' (SQL type) ==> use output_dtype:"'float'" or 'numpy.float64'
        #  Example: For output_coltype:'integer' (SQL type) ==> use output_dtype:"'int'" or 'numpy.int32'
        # -------------------------------------------------------------------------------------------------
        extra_fn_args = None
        is_custom = False  # <-- Initialization

        # Assign is_weighted
        if aggr_method not in WTD_TO_UNWTD_AGGR_DICT:
            is_weighted = False
        elif weightspace is None:
            # Convert to non-weighted aggr_method
            aggr_method = WTD_TO_UNWTD_AGGR_DICT[aggr_method]
            is_weighted = False
        else:
            is_weighted = True

        # ====================================================
        # CASE #1: CUSTOM (PYTHON-BASED) AGGREGATION METHOD
        # ====================================================
        if aggr_method in CUSTOM_AGGR_CONFIGS:
            is_custom = True
            sql_aggr_fn = aggr_method
            aggr_pyfunc = CUSTOM_AGGR_CONFIGS[aggr_method]["aggr_pyfunc"]
            # NOTE: BASIC EXTRA FUNCTION ARGS: ignore_missing (BOOLEAN), num_required (INT)
            extra_fn_args = [ignore_missing, num_required]
            if aggr_pyfunc == "percentile_level":
                extra_fn_args.append(percentile)
            elif aggr_pyfunc in ("num_zero", "num_non_zero") and epsilon:
                extra_fn_args.append(epsilon)

            # (Re)Declare custom function for each unique column_type
            if column_name is not None:
                input_coltype = self.get_column_type(column_name)

                # Set output_coltype & output_dtype
                # [If output_dtype remains None,
                # the aggregate_udf.j2 will have output_dtype
                # match input column's dtype
                # ----------------------------------------
                if "output_coltype" in CUSTOM_AGGR_CONFIGS[aggr_method]:
                    # We only need to set output_dtype when not present
                    # (when the output_coltype != input_coltype)
                    output_coltype = CUSTOM_AGGR_CONFIGS[aggr_method]["output_coltype"]
                    if "output_dtype" in CUSTOM_AGGR_CONFIGS[aggr_method]:
                        output_dtype = CUSTOM_AGGR_CONFIGS[aggr_method]["output_dtype"]
                    else:
                        try:
                            output_dtype = coltype_to_dtype(
                                output_coltype,
                                clob_export_mode=clob_export_mode,
                                blob_export_mode=blob_export_mode,
                            )
                        except:
                            output_dtype = None
                else:
                    output_coltype = input_coltype
                    output_dtype = None

                # Create SQL Aggregation function (if needed)
                # NOTE: has_sql_function(aggr_method, types_signature)
                # WHERE: types_signature[0]: output arg type,
                #        types_signature[1]: first input arg type
                #        types_signature[2]: second input arg type
                if is_weighted:
                    if weightspace is None:
                        raise Exception(
                            "weightspace (weight column) required when is_weighted:{0} and aggr_method:{1}".format(
                                is_weighted, aggr_method
                            )
                        )
                    weight_coltype = self.get_column_type(weightspace)

                    # Weighted custom function declaration
                    # ------------------------------------------------------
                    # OUTPUTS (1): output_coltype
                    # INPUTS (5): input_coltype, weight_coltype, 'bool', 'double'
                    # ------------------------------------------------------
                    if aggr_pyfunc == "percentile_level":
                        # For 'percentile_level', we need an additional input arg for percentile
                        input_types_signature = [
                            input_coltype,
                            weight_coltype,
                            "boolean",
                            "int",
                            "double",
                        ]
                    elif aggr_pyfunc in ("num_zero", "num_non_zero") and epsilon:
                        # For 'num_zero' or 'num_non_zero' with non-trivial epsilon,
                        # we need an additional SQL input arg for epsilon
                        input_types_signature = [
                            input_coltype,
                            weight_coltype,
                            "boolean",
                            "int",
                            "double",
                        ]
                    else:
                        input_types_signature = [
                            input_coltype,
                            weight_coltype,
                            "boolean",
                            "int",
                        ]
                else:
                    # Non-Weighted custom function declaration
                    # ------------------------------------------------------
                    if aggr_pyfunc == "percentile_level":
                        # For 'percentile_level', we need an additional input arg for percentile
                        input_types_signature = [
                            input_coltype,
                            "boolean",
                            "int",
                            "double",
                        ]
                    elif aggr_pyfunc in ("num_zero", "num_non_zero") and epsilon:
                        # For 'num_zero' or 'num_non_zero' with non-trivial epsilon,
                        # we need an additional SQL input arg for epsilon
                        input_types_signature = [
                            input_coltype,
                            "boolean",
                            "int",
                            "double",
                        ]
                    else:
                        input_types_signature = [input_coltype, "boolean", "int"]
                    with open(
                        f"{os.environ['QUOTIENT_PATH']}/qubles/templates/udf/aggregate_udf.sql",
                        "r",
                    ) as file:
                        execute(file.read(), format_flag=False)
        elif aggr_method not in NATIVE_AGGR_DICT:
            raise Exception(f"Invalid aggr_method():{aggr_method}")
        # =================================================
        # CASE #2: NATIVE (SQL-BASED) AGGREGATION METHOD
        # =================================================
        # BY NUMPY CONVENTION, std YIELDS POPULATION STANDARD DEVIATION
        else:
            sql_aggr_fn = NATIVE_AGGR_DICT[aggr_method]
            if aggr_method in ("percentile_level", "percentile", "quantile"):
                if percentile is None:
                    raise Exception(
                        "Non-trivial percentile required for aggr_method:{0}".format(
                            aggr_method
                        )
                    )
                # Quble percentile convention [0,100]
                # Snowflake percentile_cont, percentile_disc convention: [0,1]
                extra_fn_args = [0.01 * percentile]
            if aggr_method in "num_zero":
                extra_fn_args = ["= 0"]
            elif aggr_method in "num_non_zero":
                extra_fn_args = ["!= 0"]
            elif aggr_method in "num_positive":
                extra_fn_args = ["> 0"]
            elif aggr_method in "num_negative":
                extra_fn_args = ["< 0"]
            elif aggr_method in "num_null":
                extra_fn_args = ["is NULL"]
            elif aggr_method in "num_not_null":
                extra_fn_args = ["is not NULL"]
            elif aggr_method in "num_nonpositive":
                extra_fn_args = ["<= 0"]
            elif aggr_method in "num_nonnegative":
                extra_fn_args = [">= 0"]
            elif aggr_method in "count_all":
                extra_fn_args = ["True"]

        # Aggregation keyspace pre-sort needed when aggr_method in ('first','last')
        aggr_keyspaces_presort_needed = aggr_method in ("first", "last")

        return (
            sql_aggr_fn,
            extra_fn_args,
            is_custom,
            is_weighted,
            aggr_keyspaces_presort_needed,
        )

    def _validate_periods(self, periods):
        """
        Helper method for Quble.maggregate1d()
        """
        if periods is None:
            raise Exception(f"Invalid periods:{periods}")
        elif isinstance(periods, str):
            if periods.upper() == "UNBOUNDED":
                pass
            else:
                raise Exception(f"Invalid periods:{periods}")
        elif isinstance(periods, int):
            if periods > 0:
                pass
            else:
                raise Exception(f"Invalid periods:{periods}")
        else:
            raise Exception(f"Invalid periods:{periods}")

        return periods

    # =================================== UNISTATS ====================================

    def absolute(self, space="<valuespace>", key_ordering="asc") -> Quble:
        return self._unistat(unistat="abs", space=space, key_ordering=key_ordering)

    def sqrt(self, space="<valuespace>", key_ordering="asc") -> Quble:
        return self._unistat(unistat="sqrt", space=space, key_ordering=key_ordering)

    def exp(self, space="<valuespace>", key_ordering="asc") -> Quble:
        return self._unistat(unistat="exp", space=space, key_ordering=key_ordering)

    def sign(self, space="<valuespace>", key_ordering="asc") -> Quble:
        return self._unistat(unistat="sign", space=space, key_ordering=key_ordering)

    def log(self, space="<valuespace>", key_ordering="asc") -> Quble:
        return self._unistat(unistat="ln", space=space, key_ordering=key_ordering)

    def log10(self, space="<valuespace>", key_ordering="asc") -> Quble:
        return self._unistat(
            unistat="log", space=space, param1=10, key_ordering=key_ordering
        )

    def floor(self, space="<valuespace>", key_ordering="asc") -> Quble:
        return self._unistat(unistat="floor", space=space, key_ordering=key_ordering)

    def ceil(self, space="<valuespace>", key_ordering="asc") -> Quble:
        return self._unistat(unistat="ceil", space=space, key_ordering=key_ordering)

    def sin(self, space="<valuespace>", key_ordering="asc") -> Quble:
        return self._unistat(unistat="sin", space=space, key_ordering=key_ordering)

    def cos(self, space="<valuespace>", key_ordering="asc") -> Quble:
        return self._unistat(unistat="cos", space=space, key_ordering=key_ordering)

    def tan(self, space="<valuespace>", key_ordering="asc") -> Quble:
        return self._unistat(unistat="tan", space=space, key_ordering=key_ordering)

    def atan(self, space="<valuespace>", key_ordering="asc") -> Quble:
        return self._unistat(unistat="atan", space=space, key_ordering=key_ordering)

    def upper(self, space="<valuespace>", key_ordering="asc") -> Quble:
        return self._unistat(unistat="upper", space=space, key_ordering=key_ordering)

    def lower(self, space="<valuespace>", key_ordering="asc") -> Quble:
        return self._unistat(unistat="lower", space=space, key_ordering=key_ordering)

    def trim(self, space="<valuespace>", key_ordering="asc") -> Quble:
        return self._unistat(unistat="trim", space=space, key_ordering=key_ordering)

    def ltrim(self, space="<valuespace>", key_ordering="asc") -> Quble:
        return self._unistat(unistat="ltrim", space=space, key_ordering=key_ordering)

    def rtrim(self, space="<valuespace>", key_ordering="asc") -> Quble:
        return self._unistat(unistat="rtrim", space=space, key_ordering=key_ordering)

    def num_chars(self, space="<valuespace>", key_ordering="asc") -> Quble:
        return self._unistat(unistat="length", space=space, key_ordering=key_ordering)

    def _unistat(
        self,
        unistat,
        space="<valuespace>",
        param1=None,
        param2=None,
        key_ordering="asc",
    ) -> Quble:
        """
        Unistat operation (Ex: square root) of each element
        of a specified space(s)/column(s) of a Quble

        NOTE: Retains all spaces/columns and roles of the original Quble
        but only applies uni-stat operation to the specified spaces
        """
        # List of supported numeric sql unistat functions
        SQL_NUMERIC_UNISTAT_FNS = [
            "abs",
            "sqrt",
            "exp",
            "sign",
            "ln",
            "log",
            "floor",
            "ceil",
            "ceiling",
            "sin",
            "cos",
            "tan",
            "atan",
        ] + [
            "round"
        ]  # <-- round uses two params

        # List of supported string sql unistat functions
        # [ <------------------------- No params -----------------------------> ] + [<--------- One param --------->] + [Two params]
        SQL_STRING_UNISTAT_FNS = (
            [
                "upper",
                "lower",
                "trim",
                "ltrim",
                "rtrim",
                "length",
                "char_length",
                "ascii",
            ]
            + ["left", "right", "lpad", "rpad"]
            + ["substr"]
        )

        SQL_UNISTAT_POSVAL_FNS = ["log", "ln"]
        SQL_UNISTAT_NONNEGVAL_FNS = ["sqrt"]

        SQL_UNISTAT_FNS = SQL_NUMERIC_UNISTAT_FNS + SQL_STRING_UNISTAT_FNS
        if self.is_empty or self.is_undefined:
            return self.copy()

        # Establish/validate space
        unistat_spaces = self.validate_space(space, grace=False, coerce_to_list=True)

        # Validate unistat arg
        if unistat is None or not isinstance(unistat, str):
            raise Exception("Invalid unistat...string expected")

        unistat = unistat.lower()
        if unistat not in SQL_UNISTAT_FNS:
            raise Exception(f"Invalid unistat:{unistat}")
        elif self.is_binary():
            raise Exception(
                f"unistat function:{unistat} not defined for binary column types"
            )
        elif unistat in SQL_STRING_UNISTAT_FNS and not self.is_str(unistat_spaces):
            raise Exception(
                f"string valuespace required for unistat function:{unistat}"
            )

        table_name = generate_random_table_name()

        # Build key_ordering dictionary when applicable
        if key_ordering is not None and not isinstance(key_ordering, str):
            key_ordering = build_key_ordering_dict(
                key_ordering, keyspaces=self.keyspaces
            )

        sql_template = JINJA_ENV.get_template("unistat_kipi.j2")
        sql_command = sql_template.render(
            unistat=unistat,
            src_table_name=self.table_name,
            tgt_table_name=table_name,
            spaces=self.spaces,
            unistat_spaces=unistat_spaces,
            param1=(
                param1 if (param1 is None or isinstance(param1, str)) else str(param1)
            ),
            param2=(
                param2 if (param2 is None or isinstance(param2, str)) else str(param2)
            ),
            posvals_required=unistat in SQL_UNISTAT_POSVAL_FNS,
            nonnegvals_required=unistat in SQL_UNISTAT_NONNEGVAL_FNS,
            key_ordering=key_ordering,
        )
        execute(sql_command, format_flag=False)

        return Quble.from_table(
            table_name,
            col_info=self.get_space_info(
                info_type=CUSTOM_INFO_TYPES,
                space=self.column_names,
                omit_unassigned=True,
            ),
        )

    def left_chars(self, num_left, space="<valuespace>", key_ordering="asc") -> Quble:
        """
        Returns the left-most specified # characters from a Quble of strings
        """
        return self._unistat(
            unistat="left", space=space, param1=num_left, key_ordering=key_ordering
        )

    def right_chars(self, num_right, space="<valuespace>", key_ordering="asc") -> Quble:
        """
        Returns the right-most specified # characters from a Quble of strings
        """
        return self._unistat(
            unistat="right", space=space, param1=num_right, key_ordering=key_ordering
        )

    def lpad(self, num_chars, space="<valuespace>", key_ordering="asc") -> Quble:
        """
        Left pads the values of a Quble of strings to the specified length
        """
        return self._unistat(
            unistat="lpad", space=space, param1=num_chars, key_ordering=key_ordering
        )

    def rpad(self, num_chars, space="<valuespace>", key_ordering="asc") -> Quble:
        """
        Right pads the values of a Quble of strings to the specified length
        """
        return self._unistat(
            unistat="rpad", space=space, param1=num_chars, key_ordering=key_ordering
        )

    def round(self, num_decimals=0, space="<valuespace>", key_ordering="asc") -> Quble:
        """
        Rounds the values of a Quble to the specified resolution (# of decimal places)
        """
        return self._unistat(
            unistat="round", space=space, param1=num_decimals, key_ordering=key_ordering
        )

    def sub_chars(
        self,
        start_posn,
        end_posn=None,
        num_chars=None,
        space="<valuespace>",
        key_ordering="asc",
    ) -> Quble:
        """
        Returns a subset of characters across the specified string-based column(s)
        The result will retain all original spaces/columns of the Quble,
        but will only apply the unistat operation to the specified space(s)

        The start_posn (int) of the sub-string is a required arg

        The desired end of the string can be specified by ONLY ONE OF THESE OPTIONS:
           1) end_posn
           2) num_chars
        Important: If either of these is not None, the other cohort MUST be None!!

        :param start_posn: (required) starting position within the string
        :type start_posn: int

        :param end_posn: ending position within the string
        :type end_posn: int
           ==> If end_posn arg is not None, then num_chars arg MUST be None

        :param num_chars: number of characters for the sub-string
        :type num_chars: int
           ==> If num_chars arg is not None, then end_posn arg MUST be None

        :param space: column(s)/space(s) to apply the sub-string operation
        :type space: str

        :param key_ordering: (optional) key ordering directive
        :type key_ordering: str

        :returns: modified Quble
        :rtype: Quble
        """
        # Validate end_posn and num_chars args
        if start_posn is None:
            raise Exception(f"start_posn:{start_posn} must not be None")

        # Validate end_posn and num_chars args [Only one of the can be specified]
        if end_posn is not None and num_chars is not None:
            raise Exception(
                f"Must specify exactly one of following args:{end_posn}, num_chars:{num_chars}...one must be None"
            )
        elif end_posn is not None:
            # Here, num_chars is None and end_posn is not None
            # According to Python convention...
            # Example: 'Hello World'[2:5] yields 'llo' which has three characters
            num_chars = end_posn - start_posn
        elif num_chars is not None:
            # Here, num_chars is not None and end_posn is None
            pass
        else:
            # Here, num_chars is None and end_posn is None
            raise Exception(
                f"Must specify exactly one of following args: end_posn:{end_posn}, num_chars:{num_chars}...one must be None"
            )

        # Adding one to start_posn below since SQL refers to first character of a string as index=1 (where Python's first index=0)
        return self._unistat(
            unistat="substr",
            space=space,
            param1=start_posn + 1,
            param2=num_chars,
            key_ordering=key_ordering,
        )

    def increment(self, step=1, space: str = "<valuespace>") -> Quble:
        """
        Increments values in the specified numeric space (column)
        by the amount specified by the step arg
        """
        # Validate self
        if self.is_undefined:
            raise UndefinedQubleError("Quble is undefined")

        # Validate step
        if step is None:
            raise Exception("No step arg provided")

        # Test whether step is a numeric (int or float) scalar
        try:
            float(step)
        except Exception:
            raise Exception(f"Invalid step: {step}...numeric scalar expected")

        # Validate space (numeric required)
        space = self.validate_space(
            space=space, grace=False, solo_required=True, numeric_required=True
        )

        # Make selections using column_expression to increment the specified (numeric) column
        column_expressions = {}
        column_expressions[space] = f'("{space}" + {str(step)})'
        return self.select(column_names="<all>", column_expressions=column_expressions)

    def clip(
        self,
        lower=None,
        upper=None,
        space: str = "<valuespace>",
        outliers_to_missing=False,
        compress: bool = RootLib.lazy_eval("auto_compress"),
        key_ordering=None,
    ) -> Quble:
        """
        See :meth:`~qubles.core.quble.Quble.truncate`
        """
        return self.truncate(
            min_value=lower,
            max_value=upper,
            space=space,
            outliers_to_missing=outliers_to_missing,
            compress=compress,
            key_ordering=key_ordering,
        )

    @RootLib.lazy_kwargs()
    def truncate(
        self,
        min_value=None,
        max_value=None,
        space="<numeric_valuespaces>",
        outliers_to_missing: bool = False,
        compress: bool = RootLib.lazy_eval("auto_compress"),
        key_ordering=None,
    ) -> Quble:
        """
        Truncates the specified space(s) of the Quble's valuespace
        But retains all original spaces of the Quble

             ==> Requires that the spaces to be truncated be numeric spaces

        :param min_value: minimum data value (None for not applying a minimum level)

        :param max_value: maximum data value (None for not applying a maximum level)

        :param space: the space/column where values are to be truncated
                      should be a legitimate numeric space(s) of the Quble (or '<valuespace>')

        :param outliers_to_missing (bool): Outlier treatment...
               False (default): set outliers to min/max parameters
               True: set outliers to null / missing value

        :param compress: flag for compressing resultant Quble(only applicable if outliers_to_missing=True)
               False (default): DO NOT remove records where the specified space / column is null/missing_value
               True: Remove records where the specified space / column is null/missing_value

        :param key_ordering: controls row ordering by key
               None: do not re-sort records in result
               str: sort keys in ascending/descending ('asc'/'desc') order per each keyspace
               dict w/keys: keyspaces, values: 'asc' or 'desc'
               ==> allows for assigning key ordering (ascending/descending)
               ==> (and relative priority) for each keyspace individually

        :returns: Truncated Quble
        :rtype: qubles.core.quble.Quble

        """
        # Hanle trivial cases
        if self.is_empty or self.is_undefined:
            return self.copy()

        # Establish/validate space
        truncation_spaces = self.validate_space(
            space, grace=False, coerce_to_list=True, numeric_required=True
        )
        # Handle no truncate case
        if truncation_spaces is None or len(truncation_spaces) == 0:
            return self.copy()

        # Prevent setting outliers to missing when truncating a keyspace
        # [Otherwise the keyspace may become non usable as an index column]
        for space1 in truncation_spaces:
            if space1 in self.keyspaces and outliers_to_missing and not compress:
                raise Exception(
                    "When truncating a keyspace:{0}...Cannot set outliers_to_missing={1} when compress={2}".format(
                        space1, outliers_to_missing, compress
                    )
                )

        table_name = generate_random_table_name()

        # Build key_ordering dictionary when applicable
        if key_ordering is not None and not isinstance(key_ordering, str):
            key_ordering = build_key_ordering_dict(
                key_ordering, keyspaces=self.keyspaces
            )

        sql_template = JINJA_ENV.get_template("truncate.j2")
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            tgt_table_name=table_name,
            spaces=self.spaces,
            truncation_spaces=truncation_spaces,
            valuespaces=self.valuespaces,
            min_value=(
                min_value
                if (min_value is None or isinstance(min_value, str))
                else str(min_value)
            ),
            max_value=(
                max_value
                if (max_value is None or isinstance(max_value, str))
                else str(max_value)
            ),
            outliers_to_missing=outliers_to_missing,
            compress=compress,
            key_ordering=key_ordering,
        )
        execute(sql_command)

        # Instantiate Quble from the new table
        return Quble.from_table(
            table_name,
            col_info=self.get_space_info(
                info_type=CUSTOM_INFO_TYPES,
                space=self.column_names,
                omit_unassigned=True,
            ),
        )

    # =================================== OPERATORS ===================================

    # ----------------------
    # Boolean operators
    # ----------------------

    def __and__(self, other) -> Quble:
        return self._perform_operation(other, op_name="__and__", op_symbol="and")

    def __or__(self, other) -> Quble:
        return self._perform_operation(other, op_name="__or__", op_symbol="or")

    def __xor__(self, other) -> Quble:
        return self._perform_operation(
            other, function=True, op_name="__xor__", op_symbol="bitxor"
        )

    # ----------------------
    # Equality operators
    # ----------------------

    def __eq__(self, other) -> Quble:
        return self._perform_operation(other, op_name="__eq__", op_symbol="=")

    def __ne__(self, other) -> Quble:
        return self._perform_operation(
            other, op_name="__ne__", op_symbol="=", negate=True
        )

    # ----------------------
    # Numeric operators
    # ----------------------

    def __add__(self, other) -> Quble:
        return self._perform_operation(other, op_name="__add__", op_symbol="+")

    def __sub__(self, other) -> Quble:
        return self._perform_operation(other, op_name="__sub__", op_symbol="-")

    def __mul__(self, other) -> Quble:
        return self._perform_operation(other, op_name="__mul__", op_symbol="*")

    def __truediv__(self, other) -> Quble:
        return self._perform_operation(other, op_name="__truediv__", op_symbol="/")

    def __pow__(self, other) -> Quble:
        return self._perform_operation(
            other, op_name="__pow__", op_symbol="power", function=True
        )

    def __mod__(self, other) -> Quble:
        return self._perform_operation(other, op_name="__mod__", op_symbol="%")

    def __lt__(self, other) -> Quble:
        return self._perform_operation(other, op_name="__lt__", op_symbol="<")

    def __le__(self, other) -> Quble:
        return self._perform_operation(other, op_name="__le__", op_symbol="<=")

    def __gt__(self, other) -> Quble:
        return self._perform_operation(other, op_name="__gt__", op_symbol=">")

    def __ge__(self, other) -> Quble:
        return self._perform_operation(other, op_name="__ge__", op_symbol=">=")

    def __radd__(self, other) -> Quble:
        return self._perform_operation(other, op_name="__radd__", op_symbol="+")

    def __rsub__(self, other) -> Quble:
        if not isinstance(other, Quble):
            other = Quble(other)
        return other._perform_operation(self, op_name="__sub__", op_symbol="-")

    def __rmul__(self, other) -> Quble:
        return self._perform_operation(other, op_name="__rmul__", op_symbol="*")

    def __rdiv__(self, other) -> Quble:
        if not isinstance(other, Quble):
            other = Quble(other)
        return other._perform_operation(self, op_name="__div__", op_symbol="/")

    def __rtruediv__(self, other) -> Quble:
        if not isinstance(other, Quble):
            # Could consider haveing Quble other match valuespaces from self and then performing operation using variate_mode='multi'
            other = Quble(other)
        return other._perform_operation(self, op_name="__truediv__", op_symbol="/")

    def __rpow__(self, other) -> Quble:
        if not isinstance(other, Quble):
            other = Quble(other)
        return other._perform_operation(
            self, op_name="__pow__", op_symbol="power", function=True
        )

    def __neg__(self) -> Quble:
        if self.is_empty:
            return self.copy()
        elif self.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # Make sure there are no non-numeric colums
        self.validate_valuespace(
            self.valuespaces, coerce_to_list=True, numeric_required=True
        )

        return self * -1

    def _not(self, valuespace="<valuespaces>", treat_null_as_false=False) -> Quble:
        valuespaces_to_negate = self.validate_valuespace(
            valuespace, coerce_to_list=True
        )
        column_expressions = {}
        for vs in valuespaces_to_negate:
            if treat_null_as_false:
                column_expressions[vs] = (
                    'CASE WHEN ("{0}" IS NULL) OR (NOT "{0}") THEN TRUE ELSE FALSE END'.format(
                        vs
                    )
                )
            else:
                column_expressions[vs] = (
                    'CASE WHEN "{0}" IS NULL THEN "{0}" WHEN NOT "{0}" THEN TRUE ELSE FALSE END'.format(
                        vs
                    )
                )
        return self.select(column_names="<all>", column_expressions=column_expressions)

    # ========================================== operator =============================

    @RootLib.lazy_kwargs()
    def _perform_operation(
        self,
        other,
        op_name: str,
        op_symbol: str,
        negate: bool = False,
        function=False,
        compress: bool = RootLib.lazy_eval("auto_compress"),
        fx: str = RootLib.lazy_eval("fx"),
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        auto_fx: bool = RootLib.lazy_eval("auto_fx"),
        variate_mode: str = RootLib.lazy_eval("variate_mode"),
    ) -> Quble:
        """
        Performs (mathematical) operation on pair/series of Quble (like) objects

        :param other: cohort for operation
        :type other: Quble, Python literal scalar or list/tuple of Qubles

        :param op_name: Python class operator name [Example: '__add__']
        :type op_name: str

        :param op_symbol: (optional) SQL operator symbol (used within SQL query)
        :type op_symbol: str or None

        :param negate: negation flag (flag to negate the result)
        :type negate: bool

        :param function: flag to use op_symbol arg as a SQL function in query
        :type function: bool (False*/True)

        :param compress: compression controls
        :type compress: True or False or None or str
                [See: :meth:`~qubles.core.quble.Quble.compress`]
                ==> If string contains word 'any': Quble.compress(summarize='any',...)
                ==> If string contains word 'all': Quble.compress(summarize='all',...)
                ==> If string contains word 'drop': Quble.compress(drop=True,...)

        :param fx: fx resolver for currency conflict handling
        :type fx: str
             ==> Assignments can be traditional (three-character ISO) fx (e.g., 'USD','EUR', ...)
                 or an security-specific fx "scheme" (e.g., 'PRC','REP','EST','HRP')

        :param auto_link: Control for auto-linking (keyspace affiliation)
        :type auto_link: bool

        :param auto_fx: Flag for automated fx (currency) reconciliation
        :type auto_fx: bool (True*/False)
            auto_fx=True: automatically reconciles fx conflicts between valuespaces of self & other
            auto_fx=False: fx conflicts between valuespaces of self & other yield an Exception

        :param variate_mode: controls valuespace pairings
            'uni': single primary valuespace pair (despite valuespace names)
                   ==> univariate result w/target valuespace: DEFAULT_VALUESPACE
            'multi': pair valuespaces by name
                      (allow for None counterparts when a specific valuespace
                      only exists on one of the source Qubles)
                   ==> possible multivariate result w/union of all source valuespaces
            'mixed': pairs univariate source valuespace against all multivariate counterparts
                   ==> possible multivariate result w/valuespaces from multivariate source Quble
        :type variate_mode: str
        """
        # Validate variate_mode
        if variate_mode not in ("uni", "mixed", "multi"):
            raise Exception(
                "Invalid variate_mode:{0}...valid options: 'uni','mixed','multi'".format(
                    variate_mode
                )
            )
        # Trap for list/tuple other case and allow for single Quble element case
        # [For single Quble element case, convert other to the first element]
        if isinstance(other, (list, tuple)):
            if len(other) == 0:
                return self.copy()
            elif len(other) > 1:
                result = self.copy()
                for other1 in other:
                    result = result._perform_operation(
                        other=other1,
                        op_name=op_name,
                        op_symbol=op_symbol,
                        negate=negate,
                        function=function,
                        compress=compress,
                        fx=fx,
                        auto_link=auto_link,
                        auto_fx=auto_fx,
                        variate_mode=variate_mode,
                    )
                return result
            else:
                other = other[0]

        # ---------------------------------------
        # Consolidate Qubles into a single list
        # ---------------------------------------
        if other is None:
            return self.copy()

        # Identify/enforce other as either:  1) a literal_scalar or 2) a Quble
        other_is_literal_scalar = False
        if (
            isinstance(other, str)
            or np.isscalar(other)
            or isinstance(other, datetime)
            or isinstance(other, np.datetime64)
        ):
            other_is_literal_scalar = True
            # When given a string scalar other to be applied against a numeric (self) Quble
            # attempt to convert the string scalar to a int or float scalar
            if isinstance(other, str) and self.is_variate and self.is_numeric():
                try:
                    other = int(other)
                except ValueError:
                    try:
                        other = float(other)
                    except ValueError:
                        pass
                    except:
                        pass
                except:
                    pass
        elif not isinstance(other, Quble):
            # Otherwise, try to coerce any non-Quble other input to a univariate scalar Quble
            other = Quble(other)
        elif self.equals(other):
            other = other.copy()

        # Handle Dual-Undefined/Empty Case
        # ---------------------------------
        if (
            (self.is_undefined or self.is_empty)
            and not other_is_literal_scalar
            and (other.is_undefined or other.is_empty)
        ):
            # Identify the preferred defined cohort
            if self.is_undefined:
                if other.is_undefined:
                    # Dual Undefined Case
                    return Quble.undefined_instance()
                else:
                    defined_cohort = other
            else:
                defined_cohort = self

            if defined_cohort.is_nonvariate:
                return defined_cohort.clear()
            elif defined_cohort.is_multivariate and variate_mode == "uni":
                if op.yields_bool(op_name):
                    return (
                        defined_cohort.clear()
                        .to_univariate()
                        .change_type("boolean", space="<valuespaces>")
                    )
                else:
                    return defined_cohort.clear().to_univariate()
            elif op.yields_bool(op_name):
                return defined_cohort.clear().change_type(
                    "boolean", space="<valuespaces>"
                )
            else:
                return defined_cohort.clear()

        fill_value_left = None
        fill_value_right = None
        left_is_required = True  # <-- Initialization
        right_is_required = True  # <-- Initialization

        ignore_val = False
        ignore_add = RootLib().get_control("ignore_add")
        ignore_mult = RootLib().get_control("ignore_mult")
        ignore_compare = RootLib().get_control("ignore_compare")
        epsilon = RootLib().get_control("epsilon")
        if not epsilon:
            epsilon = 1e-6  # <-- default
        elif epsilon < 0:
            raise Exception(f"Invalid epsilon:{epsilon}...non-negative value required")

        # ----------------------------
        #     OPS: ADD/SUBTRACT
        #  Directed by: ignore_add
        # ----------------------------
        if op.is_add(op_name) or op.is_sub(op_name):
            if isinstance(ignore_add, str):
                ignore_val = ignore_add.lower()
                if ignore_add.lower() == "right":
                    keys_join_op = "leftmost_tunionpostleft"
                    fill_value_right = 0
                    left_is_required = True
                    right_is_required = False
                    # Handle mixed-empty/undefined cases
                    if (
                        not self.is_undefined
                        and not self.is_empty
                        and not other_is_literal_scalar
                        and (other.is_undefined or other.is_empty)
                    ):
                        if self.is_multivariate and variate_mode == "uni":
                            return self.to_univariate()
                        else:
                            return self.copy()

                    elif (self.is_undefined or self.is_empty) and (
                        other_is_literal_scalar
                        or (not other.is_undefined and not other.is_empty)
                    ):
                        # We CANNOT ignore missing result on left (self) here
                        if self.is_undefined:
                            return Quble.undefined_instance()
                        elif self.is_multivariate and variate_mode == "uni":
                            return self.clear().to_univariate()
                        else:
                            return self.clear()

                elif ignore_add.lower() in ("left", "left0"):
                    keys_join_op = "rightmost_tunionpostright"
                    fill_value_left = 0
                    left_is_required = False
                    right_is_required = True
                    # Mixed-empty cases
                    if (
                        not other_is_literal_scalar
                        and not self.is_undefined
                        and not self.is_empty
                        and (other.is_undefined or other.is_empty)
                    ):
                        return self.clear()
                    elif (self.is_undefined or self.is_empty) and (
                        other_is_literal_scalar
                        or (not other.is_undefined and not other.is_empty)
                    ):
                        if other_is_literal_scalar:
                            other = Quble(other)
                        return (-1 * other) if op.is_sub(op_name) else other.copy()
                elif ignore_add.lower() == "right_epsilon":
                    keys_join_op = "leftmost_tunionpostleft"
                    fill_value_right = RootLib().get_control("epsilon")
                    if fill_value_right is None:
                        fill_value_right = 1e-6
                    left_is_required = True
                    right_is_required = False
                    # Mixed-empty cases
                    if (
                        not self.is_undefined
                        and not self.is_empty
                        and not other_is_literal_scalar
                        and (other.is_undefined or other.is_empty)
                    ):
                        if self.is_multivariate and variate_mode == "uni":
                            return self.to_univariate()
                        else:
                            return self.copy()
                    elif (self.is_undefined or self.is_empty) and (
                        other_is_literal_scalar
                        or (not other.is_undefined and not other.is_empty)
                    ):
                        # We CANNOT ignore missing result on left (self) here
                        if self.is_undefined:
                            return Quble.undefined_instance()
                        elif self.is_multivariate and variate_mode == "uni":
                            return self.clear().to_univariate()
                        else:
                            return self.clear()
                else:
                    raise Exception(
                        "Invalid RootLib().get_control('ignore_add'): boolean or "
                        "'right' or 'left' allowed"
                    )
            elif ignore_add:
                keys_join_op = "union"
                ignore_val = ignore_add
                fill_value_left = 0
                fill_value_right = 0
                left_is_required = False
                right_is_required = False
                # Mixed-empty cases
                if (
                    not self.is_undefined
                    and not self.is_empty
                    and not other_is_literal_scalar
                    and (other.is_undefined or other.is_empty)
                ):
                    if self.is_multivariate and variate_mode == "uni":
                        return self.to_univariate()
                    else:
                        return self.copy()
                elif self.is_undefined or self.is_empty:
                    if other_is_literal_scalar:
                        # other is literal scalar, self is undefined or empty
                        # Ideally want to create a scalar with self's valuespaces if possible
                        if len(self.valuespaces) == 0:
                            tgt_vs = DEFAULT_VALUESPACE
                        elif variate_mode == "multi":
                            tgt_vs = self.valuespaces
                        else:
                            tgt_vs = self.valuespace
                        return Quble(other, valuespace=tgt_vs)
                    elif other.is_undefined:
                        # other is undefined, self is undefined or empty
                        return self.copy()
                    elif not other.is_empty:
                        # other is defined and empty, self is undefined or empty
                        if other.is_multivariate and variate_mode == "uni":
                            return other.to_univariate()
                        else:
                            return other.copy()
                    elif not self.is_undefined:
                        # other is defined and empty, self is defined and empty
                        return self.copy()
                    else:
                        # other is defined and empty, self is undefined
                        return other.copy()
            else:
                keys_join_op = "inter_tunionpostall"
                ignore_val = ignore_add
                left_is_required = True
                right_is_required = True
                # Mixed-empty cases
                if not self.is_empty and not other_is_literal_scalar and other.is_empty:
                    if self.is_multivariate and variate_mode == "uni":
                        return self.clear().to_univariate()
                    else:
                        return self.clear()
                elif self.is_empty and (other_is_literal_scalar or not other.is_empty):
                    if self.is_multivariate and variate_mode == "uni":
                        return self.clear().to_univariate()
                    else:
                        return self.clear()
        # --------------------------------
        #     OPS: MULT,DIV,POW,MOD
        #  Directed by: ignore_mult
        # --------------------------------
        elif (
            op.is_mul(op_name)
            or op.is_div(op_name)
            or op.is_pow(op_name)
            or op.is_mod(op_name)
        ):
            if (
                not op.is_div(op_name)
                and isinstance(ignore_mult, str)
                and ignore_mult.lower() == "right_nullify_small_div"
            ):
                # These options only apply to division operations,
                # For non-division operations here, use ignore_mult=False
                ignore_mult = False

            if isinstance(ignore_mult, str):
                ignore_val = ignore_mult.lower()
                if ignore_mult.lower() == "right":
                    keys_join_op = "leftmost_tunionpostleft"
                    fill_value_right = 1
                    left_is_required = True
                    right_is_required = False
                    # Mixed-empty cases
                    if (
                        not self.is_empty
                        and not other_is_literal_scalar
                        and other.is_empty
                    ):
                        if self.is_multivariate and variate_mode == "uni":
                            return self.to_univariate()
                        else:
                            return self.copy()
                    elif self.is_empty and (
                        other_is_literal_scalar or not other.is_empty
                    ):
                        if self.is_multivariate and variate_mode == "uni":
                            return self.clear().to_univariate()
                        else:
                            return self.clear()
                elif ignore_mult.lower() == "left":
                    keys_join_op = "rightmost_tunionpostright"
                    fill_value_left = 1
                    left_is_required = False
                    right_is_required = True
                    # Mixed-empty cases
                    if (
                        not self.is_empty
                        and not other_is_literal_scalar
                        and other.is_empty
                    ):
                        if self.is_multivariate and variate_mode == "uni":
                            return self.clear().to_univariate()
                        else:
                            return self.clear()
                    elif self.is_empty and (
                        other_is_literal_scalar or not other.is_empty
                    ):
                        # multiplication case is simpler here
                        if op.is_mul(op_name):
                            if other_is_literal_scalar:
                                # Ideally want to create a scalar with self's valuespaces if possible
                                if len(self.valuespaces) == 0:
                                    tgt_vs = DEFAULT_VALUESPACE
                                elif variate_mode == "multi":
                                    tgt_vs = self.valuespaces
                                else:
                                    tgt_vs = self.valuespace
                                return Quble(other, valuespace=tgt_vs)
                            elif other.is_multivariate and variate_mode == "uni":
                                return other.to_univariate()
                            else:
                                return other.copy()
                        else:
                            return Quble(fill_value_left)._perform_operation(
                                other=other,
                                op_name=op_name,
                                op_symbol=op_symbol,
                                negate=negate,
                                function=function,
                                compress=compress,
                                fx=fx,
                                auto_link=auto_link,
                                auto_fx=auto_fx,
                                variate_mode=variate_mode,
                            )
                elif ignore_mult.lower() == "left0":
                    keys_join_op = "rightmost_tunionpostright"
                    fill_value_left = 0
                    left_is_required = False
                    right_is_required = True
                    # Mixed-empty cases
                    if (
                        not self.is_empty
                        and not other_is_literal_scalar
                        and other.is_empty
                    ):
                        if self.is_multivariate and variate_mode == "uni":
                            return self.clear().to_univariate()
                        else:
                            return self.clear()
                    elif self.is_empty and (
                        other_is_literal_scalar or not other.is_empty
                    ):
                        # return 0 * other # <-- This works for multiplication case only!
                        if len(self.valuespaces) == 0:
                            tgt_vs = DEFAULT_VALUESPACE
                        elif variate_mode == "multi":
                            tgt_vs = self.valuespaces
                        else:
                            tgt_vs = self.valuespace
                        self_serrogate = Quble(fill_value_left, valuespace=tgt_vs)
                        return self_serrogate._perform_operation(
                            other=other,
                            op_name=op_name,
                            op_symbol=op_symbol,
                            negate=negate,
                            function=function,
                            compress=compress,
                            fx=fx,
                            auto_link=auto_link,
                            auto_fx=auto_fx,
                            variate_mode=variate_mode,
                        )
                elif ignore_mult.lower() == "right_epsilon":
                    keys_join_op = "leftmost_tunionpostleft"
                    fill_value_right = RootLib().get_control("epsilon")
                    if fill_value_right is None:
                        fill_value_right = 1e-6
                    left_is_required = True
                    right_is_required = False
                    # Mixed-empty cases
                    if (
                        not self.is_empty
                        and not other_is_literal_scalar
                        and other.is_empty
                    ):
                        if len(other.valuespaces) == 0:
                            tgt_vs = DEFAULT_VALUESPACE
                        elif variate_mode == "multi":
                            tgt_vs = other.valuespaces
                        else:
                            tgt_vs = other.valuespace
                        other_serrogate = Quble(fill_value_right, valuespace=tgt_vs)
                        return self._perform_operation(
                            other=other_serrogate,
                            op_name=op_name,
                            op_symbol=op_symbol,
                            negate=negate,
                            function=function,
                            compress=compress,
                            fx=fx,
                            auto_link=auto_link,
                            auto_fx=auto_fx,
                            variate_mode=variate_mode,
                        )
                    elif self.is_empty and (
                        other_is_literal_scalar or not other.is_empty
                    ):
                        if self.is_multivariate and variate_mode == "uni":
                            return self.clear().to_univariate(valuespace="<valuespace>")
                        else:
                            return self.clear()
                elif ignore_mult.lower() == "right_nullify_small_div":
                    keys_join_op = "inter_tunionpostall"
                    if not op.is_div(op_name):
                        # Treat non-division operators as ignore_val = False
                        ignore_val = False
                    left_is_required = True
                    right_is_required = True
                    # Mixed-empty cases
                    if (
                        not self.is_empty
                        and not other_is_literal_scalar
                        and other.is_empty
                    ):
                        if self.is_multivariate and variate_mode == "uni":
                            return self.clear().to_univariate()
                        else:
                            return self.clear()
                    elif self.is_empty and (
                        other_is_literal_scalar or not other.is_empty
                    ):
                        if self.is_multivariate and variate_mode == "uni":
                            return self.clear().to_univariate()
                        else:
                            return self.clear()
                else:
                    raise ValueError(
                        "Invalid RootLib().get_control('ignore_mult'): boolean or "
                        "'right' or 'left' or 'left0' or 'right_epsilon' or 'right_nullify_small_div' allowed"
                    )
            elif ignore_mult:
                keys_join_op = "union"
                ignore_val = ignore_mult
                fill_value_left = 1
                fill_value_right = 1
                left_is_required = False
                right_is_required = False
                # Mixed-empty cases
                if not self.is_empty and not other_is_literal_scalar and other.is_empty:
                    if self.is_multivariate and variate_mode == "uni":
                        return self.to_univariate()
                    else:
                        return self.copy()
                elif self.is_empty:
                    if other_is_literal_scalar:
                        if len(self.valuespaces) == 0:
                            tgt_vs = DEFAULT_VALUESPACE
                        elif variate_mode == "multi":
                            tgt_vs = self.valuespaces
                        else:
                            tgt_vs = self.valuespace
                        other_serrogate = Quble(other, valuespace=tgt_vs)
                        return other_serrogate
                    elif other.is_empty:
                        pass
                    elif other.is_multivariate and variate_mode == "uni":
                        return other.to_univariate()
                    else:
                        return other.copy()
            else:
                keys_join_op = "inter_tunionpostall"
                ignore_val = ignore_mult
                left_is_required = True
                right_is_required = True
                # Mixed-empty cases
                if not self.is_empty and not other_is_literal_scalar and other.is_empty:
                    if self.is_multivariate and variate_mode == "uni":
                        return self.clear().to_univariate()
                    else:
                        return self.clear()
                elif self.is_empty and (other_is_literal_scalar or not other.is_empty):
                    if self.is_multivariate and variate_mode == "uni":
                        return self.clear().to_univariate()
                    else:
                        return self.clear()
        # ------------------------------
        #     OPS: <, <=
        #  Directed by: ignore_compare
        # ------------------------------
        elif op.is_lt(op_name) or op.is_le(op_name):
            ignore_val = ignore_compare
            if ignore_compare:
                if not self.is_empty and len(self.valuespaces) > 0:
                    fill_value_left = min_val_by_type(
                        self.column_info["type"][self.valuespace]
                    )
                    fill_value_right = max_val_by_type(
                        self.column_info["type"][self.valuespace]
                    )
                keys_join_op = "union"
                left_is_required = False
                right_is_required = False
                # Mixed-empty cases
                if not self.is_empty and not other_is_literal_scalar and other.is_empty:
                    if self.is_multivariate and variate_mode == "uni":
                        return self.to_univariate().where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
                    else:
                        return self.where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
                elif self.is_empty:
                    if other_is_literal_scalar:
                        if len(self.valuespaces) == 0:
                            tgt_vs = DEFAULT_VALUESPACE
                        elif variate_mode == "multi":
                            tgt_vs = self.valuespaces
                        else:
                            tgt_vs = self.valuespace
                        other_serrogate = Quble(other, valuespace=tgt_vs)
                        return Quble(other_serrogate).where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
                    elif other.is_empty:
                        pass
                    elif other.is_multivariate and variate_mode == "uni":
                        return other.to_univariate().where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
                    else:
                        return other.where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
            else:
                keys_join_op = "inter_tunionpostall"
                left_is_required = True
                right_is_required = True
                # Mixed-empty cases
                if (
                    not self.is_empty and not other_is_literal_scalar and other.is_empty
                ) or (
                    self.is_empty and (other_is_literal_scalar or not other.is_empty)
                ):
                    if self.is_nonvariate:
                        return self.clear()
                    elif self.is_multivariate and variate_mode == "uni":
                        return (
                            self.clear()
                            .to_univariate()
                            .change_type("boolean", space="<valuespaces>")
                        )
                    else:
                        return self.clear().change_type(
                            "boolean", space="<valuespaces>"
                        )
        # ------------------------------
        #     OPS: >, >=
        #  Directed by: ignore_compare
        # ------------------------------
        elif op.is_gt(op_name) or op.is_ge(op_name):
            ignore_val = ignore_compare
            if ignore_compare:
                if not self.is_empty and len(self.valuespaces) > 0:
                    fill_value_left = max_val_by_type(
                        self.column_info["type"][self.valuespace]
                    )
                    fill_value_right = min_val_by_type(
                        self.column_info["type"][self.valuespace]
                    )
                keys_join_op = "union"
                left_is_required = False
                right_is_required = False
                # Mixed-empty cases
                if not self.is_empty and not other_is_literal_scalar and other.is_empty:
                    if self.is_multivariate and variate_mode == "uni":
                        return self.to_univariate().where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
                    else:
                        return self.where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
                elif self.is_empty:
                    if other_is_literal_scalar:
                        if len(self.valuespaces) == 0:
                            tgt_vs = DEFAULT_VALUESPACE
                        elif variate_mode == "multi":
                            tgt_vs = self.valuespaces
                        else:
                            tgt_vs = self.valuespace
                        other_serrogate = Quble(other, valuespace=tgt_vs)
                        return Quble(other_serrogate).where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
                    elif other.is_empty:
                        pass
                    elif other.is_multivariate and variate_mode == "uni":
                        return other.to_univariate().where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
                    else:
                        return other.where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
            else:
                keys_join_op = "inter_tunionpostall"
                left_is_required = True
                right_is_required = True
                # Mixed-empty cases
                if (
                    not self.is_empty and not other_is_literal_scalar and other.is_empty
                ) or (
                    self.is_empty and (other_is_literal_scalar or not other.is_empty)
                ):
                    if self.is_nonvariate:
                        return self.clear()
                    elif self.is_multivariate and variate_mode == "uni":
                        return (
                            self.clear()
                            .to_univariate()
                            .change_type("boolean", space="<valuespaces>")
                        )
                    else:
                        return self.clear().change_type(
                            "boolean", space="<valuespaces>"
                        )
        # ------------------------------
        #     OPS: ==
        #  Directed by: ignore_compare
        # ------------------------------
        elif op.is_eq(op_name):
            ignore_val = ignore_compare
            if ignore_compare:
                keys_join_op = "union"
                left_is_required = False
                right_is_required = False
                # Mixed-empty cases
                if not self.is_empty and not other_is_literal_scalar and other.is_empty:
                    if self.is_multivariate and variate_mode == "uni":
                        return self.to_univariate().where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
                    else:
                        return self.where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
                elif self.is_empty:
                    if other_is_literal_scalar:
                        if len(self.valuespaces) == 0:
                            tgt_vs = DEFAULT_VALUESPACE
                        elif variate_mode == "multi":
                            tgt_vs = self.valuespaces
                        else:
                            tgt_vs = self.valuespace
                        other_serrogate = Quble(other, valuespace=tgt_vs)
                        return Quble(other_serrogate).where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
                    elif other.is_empty:
                        pass
                    elif other.is_multivariate and variate_mode == "uni":
                        return other.to_univariate().where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
                    else:
                        return other.where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
            else:
                keys_join_op = "inter_tunionpostall"
                left_is_required = True
                right_is_required = True
                # Mixed-empty cases
                if (
                    not self.is_empty and not other_is_literal_scalar and other.is_empty
                ) or (
                    self.is_empty and (other_is_literal_scalar or not other.is_empty)
                ):
                    if self.is_nonvariate:
                        return self.clear()
                    elif self.is_multivariate and variate_mode == "uni":
                        return (
                            self.clear()
                            .to_univariate()
                            .change_type("boolean", space="<valuespaces>")
                        )
                    else:
                        return self.clear().change_type(
                            "boolean", space="<valuespaces>"
                        )
        # ------------------------------
        #     OPS: !=
        #  Directed by: ignore_compare
        # ------------------------------
        elif op.is_ne(op_name):
            ignore_val = ignore_compare
            if ignore_compare:
                if not self.is_empty and len(self.valuespaces) > 0:
                    fill_value_left = max_val_by_type(
                        self.column_info["type"][self.valuespace]
                    )
                    fill_value_right = min_val_by_type(
                        self.column_info["type"][self.valuespace]
                    )
                keys_join_op = "union"
                left_is_required = False
                right_is_required = False
                # Mixed-empty cases
                if not self.is_empty and not other_is_literal_scalar and other.is_empty:
                    if self.is_multivariate and variate_mode == "uni":
                        return self.to_univariate().where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
                    else:
                        return self.where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
                elif self.is_empty:
                    if other_is_literal_scalar:
                        if len(self.valuespaces) == 0:
                            tgt_vs = DEFAULT_VALUESPACE
                        elif variate_mode == "multi":
                            tgt_vs = self.valuespaces
                        else:
                            tgt_vs = self.valuespace
                        other_serrogate = Quble(other, valuespace=tgt_vs)
                        return Quble(other_serrogate).where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
                    elif other.is_empty:
                        pass
                    elif other.is_multivariate and variate_mode == "uni":
                        return other.to_univariate().where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
                    else:
                        return other.where_not_missing(
                            compress=None, treat_false_as_null=False, grace=True
                        )
            else:
                keys_join_op = "inter_tunionpostall"
                left_is_required = True
                right_is_required = True
                # Mixed-empty cases
                if (
                    not self.is_empty and not other_is_literal_scalar and other.is_empty
                ) or (
                    self.is_empty and (other_is_literal_scalar or not other.is_empty)
                ):
                    if self.is_nonvariate:
                        return self.clear()
                    elif self.is_multivariate and variate_mode == "uni":
                        return (
                            self.clear()
                            .to_univariate()
                            .change_type("boolean", space="<valuespaces>")
                        )
                    else:
                        return self.clear().change_type(
                            "boolean", space="<valuespaces>"
                        )
        # ------------------------------
        #     OPS: AND
        #  Directed by: N/A
        # ------------------------------
        elif op.is_and(op_name):
            keys_join_op = "union"
            left_is_required = True
            right_is_required = True
            # Mixed-empty cases
            if not self.is_empty and not other_is_literal_scalar and other.is_empty:
                if self.is_multivariate and variate_mode == "uni":
                    return self.to_univariate().clear()
                else:
                    return self.clear()
            elif self.is_empty:
                if other_is_literal_scalar:
                    if len(self.valuespaces) == 0:
                        tgt_vs = DEFAULT_VALUESPACE
                    elif variate_mode == "multi":
                        tgt_vs = self.valuespaces
                    else:
                        tgt_vs = self.valuespace
                    other_serrogate = Quble(other, valuespace=tgt_vs)
                    return Quble(other_serrogate).where_not_missing(
                        compress=None, treat_false_as_null=False, grace=True
                    )
                elif other.is_empty:
                    pass
                elif other.is_multivariate and variate_mode == "uni":
                    return other.to_univariate().clear()
                else:
                    return other.clear()
        # ------------------------------
        #     OPS: OR
        #  Directed by: N/A
        # ------------------------------
        elif op.is_or(op_name):
            keys_join_op = "union"
            left_is_required = False
            right_is_required = False
            ignore_val = True
            # Mixed-empty cases
            if not self.is_empty and not other_is_literal_scalar and other.is_empty:
                if self.is_multivariate and variate_mode == "uni":
                    return self.to_univariate().where_not_missing(
                        compress=None, treat_false_as_null=False, grace=True
                    )
                else:
                    return self.where_not_missing(
                        compress=None, treat_false_as_null=False, grace=True
                    )
            elif self.is_empty:
                if other_is_literal_scalar:
                    if len(self.valuespaces) == 0:
                        tgt_vs = DEFAULT_VALUESPACE
                    elif variate_mode == "multi":
                        tgt_vs = self.valuespaces
                    else:
                        tgt_vs = self.valuespace
                    other_serrogate = Quble(other, valuespace=tgt_vs)
                    return Quble(other_serrogate).where_not_missing(
                        compress=None, treat_false_as_null=False, grace=True
                    )
                elif other.is_empty:
                    pass
                elif other.is_multivariate and variate_mode == "uni":
                    return other.to_univariate().where_not_missing(
                        compress=None, treat_false_as_null=False, grace=True
                    )
                else:
                    return other.where_not_missing(
                        compress=None, treat_false_as_null=False, grace=True
                    )
        # ------------------------------
        #     OPS: XOR
        #  Directed by: N/A
        # ------------------------------
        elif op.is_xor(op_name):
            keys_join_op = "union"
            left_is_required = True
            right_is_required = True
            # Mixed-empty cases
            if not self.is_empty and not other_is_literal_scalar and other.is_empty:
                if self.is_multivariate and variate_mode == "uni":
                    return self.to_univariate().where_not_missing(
                        compress=None, treat_false_as_null=False, grace=True
                    )
                else:
                    return self.where_not_missing(
                        compress=None, treat_false_as_null=False, grace=True
                    )
            elif self.is_empty:
                if other_is_literal_scalar:
                    if len(self.valuespaces) == 0:
                        tgt_vs = DEFAULT_VALUESPACE
                    elif variate_mode == "multi":
                        tgt_vs = self.valuespaces
                    else:
                        tgt_vs = self.valuespace
                    other_serrogate = Quble(other, valuespace=tgt_vs)
                    return Quble(other_serrogate).where_not_missing(
                        compress=None, treat_false_as_null=False, grace=True
                    )
                elif other.is_empty:
                    pass
                elif other.is_multivariate and variate_mode == "uni":
                    return other.to_univariate().where_not_missing(
                        compress=None, treat_false_as_null=False, grace=True
                    )
                else:
                    return other.where_not_missing(
                        compress=None, treat_false_as_null=False, grace=True
                    )
        # ----------------------
        #   UNSUPPORTED OP
        # ----------------------
        else:
            raise Exception(f"Could not determine op_family for op_name:{op_name}")

        # ===========================================================
        # Handle mixed-empty/undefined cases when left_is_required
        # ===========================================================
        if left_is_required and (self.is_undefined or self.is_empty):
            # We CANNOT ignore missing result on left (self) here
            if self.is_undefined:
                return Quble.undefined_instance()
            elif not self.is_empty:
                pass
            elif self.is_multivariate and variate_mode == "uni":
                if op.yields_bool(op_name):
                    return (
                        self.clear()
                        .to_univariate()
                        .change_type("boolean", space="<valuespaces>")
                    )
                else:
                    return self.clear().to_univariate()
            else:
                if op.yields_bool(op_name):
                    return self.clear().change_type("boolean", space="<valuespaces>")
                else:
                    return self.clear()

        # ===========================================================
        # Handle mixed-empty/undefined cases when right_is_required
        # ===========================================================
        if (
            right_is_required
            and not other_is_literal_scalar
            and (other.is_undefined or other.is_empty)
        ):
            # We CANNOT ignore missing result on right (other) here
            if self.is_undefined:
                return Quble.undefined_instance()
            elif self.is_nonvariate:
                return self.clear()
            elif self.is_multivariate and variate_mode == "uni":
                if op.yields_bool(op_name):
                    return (
                        self.clear(deep_copy=False)
                        .to_univariate()
                        .change_type("boolean", space="<valuespaces>")
                    )
                else:
                    return self.clear(deep_copy=False).to_univariate()
            elif op.yields_bool(op_name):
                return self.clear(deep_copy=False).change_type(
                    "boolean", space="<valuespaces>"
                )
            else:
                return self.clear()

        # ======================================
        # CREATE ALIASES q1 & q2
        # --------------------------------------
        # Do not refer to self & other again
        # NOTE: To perform operation,
        # we should first convert any index Qubles to boolean Qubles
        # ======================================
        # q2: alias for other
        # Due to steps above,
        # other should either be a literal_scalar or a Quble
        q2_was_index = False  # <-- Initialization
        if other is None:
            q2 = other  # <-- should have already been trapped above
        elif other_is_literal_scalar:
            q2 = None
        elif not isinstance(other, Quble):
            raise Exception(
                "other should be a Quble here"
            )  # <-- should have already been trapped above
        elif other.is_index:
            q2 = other.index_to_bool()
            q2_was_index = True
        else:
            q2 = other

        # q1: alias for self
        q1_was_index = False  # <-- Initialization
        if self.is_index:
            # Handle trivial case when index-only self == True
            # In this case, we merely return a copy of (index-only) self
            if op.is_eq(op_name) and other_is_literal_scalar and (other == True):
                return self.copy()
            q1 = self.index_to_bool()
            q1_was_index = True
        else:
            q1 = self

        # ------------------
        #     CAST TYPE
        # ------------------
        if op.yields_bool(op_name):
            cast_type = "BOOLEAN"
        else:
            cast_type = None

        # Generate (random) target table name
        # ---------------------------------------
        tgt_table_name = generate_random_table_name()

        # Construct valuespace_pairs dictionary
        # Outer dict keys: target valuespaces
        # Inner dict keys: 'src_vs', 'falsey', 'coltype'
        # Inner dict values: paired tuple info for operation
        valuespace_pairs = {}
        tgt_fx_dict = {}  # <-- dictionary of post-op fx (keys will be tgt_valuespace)
        drop_time_basis = False  # <-- Initialization

        # ==============================================
        # CASE #1: OTHER IS A QUBLE (q2 is not None)
        # ==============================================
        if q2 is not None:
            # Drop time_basis col_info for valuespaces when:
            #    1) operator yeilds a boolean
            # OR 2) both Qubles being operation share same time-keyspace
            if op.yields_bool(op_name):
                drop_time_basis = True
            else:
                for tks1 in q1.time_keyspaces:
                    if tks1 in q2.time_keyspaces:
                        drop_time_basis = True
                        break

            joined = q1.join(
                q2,
                keys_join_op=keys_join_op,
                keyspaces_join_op="union",
                auto_link=auto_link,
                valuespaces_join_op="primaries" if variate_mode == "uni" else "all",
                valuespace_num_suffix_delimiter="_",
            )

            # Record variate_state
            # ---------------------
            if q1.is_multivariate:
                if q2.is_multivariate:
                    variate_state = "multi"
                else:
                    variate_state = "mixed"
            elif q2.is_multivariate:
                variate_state = "mixed"
            else:
                variate_state = "uni"

            # =============================== MULTI-MODE =================================
            if variate_mode == "multi" or (
                variate_mode == "mixed" and variate_state == "multi"
            ):
                # Create src_vs_list
                src_vs_list = []
                for src_vs in q1.valuespaces:
                    if src_vs not in src_vs_list:
                        src_vs_list.append(src_vs)
                for src_vs in q2.valuespaces:
                    if src_vs not in src_vs_list:
                        src_vs_list.append(src_vs)

                for src_vs in src_vs_list:
                    tgt_valuespace = src_vs
                    valuespace_pairs[tgt_valuespace] = {}
                    valuespace1 = f"{src_vs}_0"
                    valuespace2 = f"{src_vs}_1"
                    if valuespace1 in joined.valuespaces:
                        if valuespace2 in joined.valuespaces:
                            valuespace_pairs[tgt_valuespace]["src_vs"] = (
                                valuespace1,
                                valuespace2,
                            )
                        else:
                            valuespace_pairs[tgt_valuespace]["src_vs"] = (
                                valuespace1,
                                None,
                            )
                    elif valuespace2 in joined.valuespaces:
                        valuespace_pairs[tgt_valuespace]["src_vs"] = (None, valuespace2)
                    else:
                        # Should not happen...thrown an Exception?
                        pass
            # =============================== MIXED-MODE =================================
            elif variate_mode == "mixed" and variate_state == "mixed":
                if q1.is_multivariate and not q2.is_multivariate:
                    valuespace2 = f"{q2.valuespaces[0]}_1" if q2.is_univariate else None
                    for src_vs in q1.valuespaces:
                        valuespace_pairs[src_vs] = {}
                        valuespace1 = f"{src_vs}_0"
                        valuespace_pairs[src_vs]["src_vs"] = (valuespace1, valuespace2)
                elif not q1.is_multivariate and q2.is_multivariate:
                    valuespace1 = f"{q1.valuespaces[0]}_0" if q1.is_univariate else None
                    for src_vs in q2.valuespaces:
                        valuespace_pairs[src_vs] = {}
                        valuespace2 = f"{src_vs}_1"
                        valuespace_pairs[src_vs]["src_vs"] = (valuespace1, valuespace2)
                else:
                    raise Exception("Inconsistent mixed state")

            # =============================== UNI-MODE =================================
            else:
                # Make sure the joined table exhibits two valuespaces
                if len(joined.valuespaces) != 2:
                    raise Exception(
                        "len(joined.valuespaces):{0}...two expected".format(
                            len(joined.valuespaces)
                        )
                    )

                # Could also consider valuespace inferring from joined
                tgt_valuespace = (
                    DEFAULT_VALUESPACE if self.valuespace is None else self.valuespace
                )
                valuespace1 = f"{q1.valuespace}_0"
                valuespace2 = f"{q2.valuespace}_1"
                valuespace_pairs[tgt_valuespace] = {}
                valuespace_pairs[tgt_valuespace]["src_vs"] = (valuespace1, valuespace2)

            # =========================== START: TARGET VALUESPACES LOOP =============================

            # dictionary for fx conversion of pre-op (joined) valuespaces (keys will be valuespace1 and/or valuespace2)
            conversion_fx_dict = {}

            for tgt_valuespace in valuespace_pairs:
                (valuespace1, valuespace2) = valuespace_pairs[tgt_valuespace]["src_vs"]
                # Set coltype1 & falsey1
                if valuespace1 is None:
                    coltype1 = None
                    falsey_val1 = None
                    fx1 = None
                else:
                    coltype1 = joined.get_column_type(valuespace1)
                    fx1 = joined._get_valuespace_attr(
                        vs_attr_name="fx", valuespace=valuespace1
                    )
                    falsey_val1 = None
                    if coltype_is_bool(coltype1):
                        falsey_val1 = "false"
                    elif coltype_is_numeric(coltype1):
                        falsey_val1 = "0"
                    elif coltype_is_str(coltype1):
                        falsey_val1 = "''"
                    elif coltype_is_binary(coltype1):
                        falsey_val1 = "''"

                # Set coltype2 & falsey2
                if valuespace2 is None:
                    coltype2 = None
                    falsey_val2 = None
                    fx2 = None
                else:
                    coltype2 = joined.get_column_type(valuespace2)
                    fx2 = joined._get_valuespace_attr(
                        vs_attr_name="fx", valuespace=valuespace2
                    )
                    falsey_val2 = None
                    if coltype_is_bool(coltype2):
                        falsey_val2 = "false"
                    elif coltype_is_numeric(coltype2):
                        falsey_val2 = "0"
                    elif coltype_is_str(coltype2):
                        falsey_val2 = "''"
                    elif coltype_is_binary(coltype2):
                        falsey_val2 = "''"

                # Assign valuespace_pairs
                valuespace_pairs[tgt_valuespace]["falsey"] = (falsey_val1, falsey_val2)
                valuespace_pairs[tgt_valuespace]["coltype"] = (coltype1, coltype2)
                valuespace_pairs[tgt_valuespace]["orig_fx"] = (fx1, fx2)
                valuespace_pairs[tgt_valuespace]["fill_value"] = (
                    fill_value_left,
                    fill_value_right,
                )

                # Validate coltype pairs against op_name
                if valuespace1 is None:
                    if valuespace2 is not None:
                        # valuespace2 is not None
                        if op.operates_on_numbers(op_name):
                            error = not joined.is_numeric(valuespace2)
                elif valuespace2 is None:
                    # valuespace1 is not None
                    if op.operates_on_numbers(op_name):
                        error = not joined.is_numeric(valuespace1)
                else:
                    # valuespace1 & valuespace2 are not None
                    if op.operates_on_numbers(op_name):
                        error = not joined.is_numeric(
                            valuespace1
                        ) or not joined.is_numeric(valuespace2)
                    elif (
                        op.is_lt(op_name)
                        or op.is_le(op_name)
                        or op.is_gt(op_name)
                        or op.is_ge(op_name)
                    ):
                        error = not (
                            (
                                joined.is_numeric(valuespace1)
                                and joined.is_numeric(valuespace2)
                            )
                            or (
                                joined.is_str(valuespace1)
                                and joined.is_str(valuespace2)
                            )
                            or (
                                joined.is_binary(valuespace1)
                                and joined.is_binary(valuespace2)
                            )
                            or (coltype1 == coltype2)
                        )
                    else:
                        error = False

                if error:
                    raise TypeError(
                        "Unable to perform operation '{}' on valuespaces of types '{}' and '{}'".format(
                            op_name, coltype1, coltype2
                        )
                    )

                # ----------------------------
                #        F/X HANDLING
                # ----------------------------
                # Reconcile fx (if required)
                # ----------------------------
                if valuespace1 is None:
                    # No pre-op conversion needed
                    if (
                        valuespace2 is not None
                        and fx2 is not None
                        and not op.yields_bool(op_name)
                    ):
                        tgt_fx_dict[tgt_valuespace] = fx2
                elif valuespace2 is None:
                    # No pre-op conversion needed
                    if fx1 is not None and not op.yields_bool(op_name):
                        tgt_fx_dict[tgt_valuespace] = fx1
                # We have a proper valuespace pair
                elif fx1 is None:
                    # No conflict...No pre-op conversion needed
                    if fx2 is not None and not op.yields_bool(op_name):
                        tgt_fx_dict[tgt_valuespace] = fx2
                elif fx2 is None:
                    # No conflict...No pre-op conversion needed
                    if not op.yields_bool(op_name):
                        tgt_fx_dict[tgt_valuespace] = fx1
                elif fx1 == fx2:
                    # Already fx compatible...No pre-op conversion needed
                    if not op.yields_bool(op_name) and not op.is_div(op_name):
                        tgt_fx_dict[tgt_valuespace] = fx1
                # Here, currency conflict exists...
                # fx1 & fx2 are not None (non-trivial fx) and are not the same
                elif isinstance(auto_fx, str) and auto_fx == "ignore":
                    # Ignoring fx conflict, but still want to mark result with no fx
                    # (as fx result will be ambiguous in this case)
                    pass
                elif (isinstance(auto_fx, str) and auto_fx == "on") or (
                    not isinstance(auto_fx, str) and auto_fx
                ):
                    # For reconciliation, take direction from input arg:
                    # fx=RootLib().get_control('fx') if possible,
                    # otherwise, prioritize fx1 (left-side fx1)
                    if fx is not None:
                        conversion_fx = fx
                    elif valuespace1 is not None:
                        conversion_fx = fx1
                    else:
                        conversion_fx = fx2

                    # Modify conversion_fx_dict
                    if valuespace1 is not None and fx1 != conversion_fx:
                        # Left side needs fx conversion
                        conversion_fx_dict[valuespace1] = conversion_fx

                    if valuespace2 is not None and fx2 != conversion_fx:
                        # Right side needs fx conversion
                        conversion_fx_dict[valuespace2] = conversion_fx

                    # Handle final tgt_fx
                    if not op.yields_bool(op_name) and not op.is_div(op_name):
                        tgt_fx_dict[tgt_valuespace] = conversion_fx
                else:
                    # Raise Exception due to FX conflict
                    raise Exception(
                        "F/X conflict: valuespace1:{0} w/fx1:{1} INCONSISTENT WITH valuespace2:{2} w/fx2:{3}".format(
                            valuespace1, fx1, valuespace2, fx2
                        )
                    )

            # =========================== END: TARGET VALUESPACES LOOP =============================

            # ------------------------------------------
            # Apply currency conversion (if required)
            # ------------------------------------------
            if len(conversion_fx_dict) > 0:
                joined = joined.convert_fx(
                    fx=conversion_fx_dict, valuespace=list(conversion_fx_dict.keys())
                )
            # --------------------------------------------------------------------------
            #              operators.j2 template arguments
            # --------------------------------------------------------------------------
            # src_table_name: Pre-joined source table
            # keyspaces: Keyspace columns in the pre-joined table
            # valuespace_pairs: dictionary of dictionaries per target valuespace
            #    outer keys: target valuespaces
            #    inner keys: 'src_vs', 'falsey', 'fill_value'
            #    inner values: pairs for left/right info
            #        'src_vs': The valuespace (column name) of the left/right side of the operational pair
            #        'falsey': The falsey value for the left/right side of the operation (e.g. "" or 0)
            #        'fill_value': Use this value when left/right is ignored and missing
            # operation: The SQL symbol of the operation to perform (e.g. +)
            # function: True if the given operation is a function
            # ignore: Missing value ignore setting (e.g. "left")
            # cast_type: Cast the result to this type
            # negate: Negate the operation
            # tgt_table_name: Name of the table in which to write the result
            # epsilon: small value (applies when ignore == "right_nullify_small_div" and operation == "/")
            # --------------------------------------------------------------------------
            sql_template = JINJA_ENV.get_template("operators.j2")
            sql_command = sql_template.render(
                src_table_name=joined.table_name,  # <-- should match q2.table_name
                keyspaces=joined.keyspaces,
                valuespace_pairs=valuespace_pairs,
                operation=op_symbol,
                function=function,
                ignore=ignore_val,
                cast_type=cast_type,
                negate=negate,
                tgt_table_name=tgt_table_name,
                compress=compress,
                epsilon=epsilon,
            )
            execute(sql_command, format_flag=False)

        # ====================================================
        # CASE #2: OTHER IS A LITERAL SCALAR (q2 is None)
        # ====================================================
        else:
            # Determine type of the literal scalar
            other_is_string = False
            other_is_binary = False
            other_is_datetime = False
            other_is_numeric = False
            falsey_val2 = None
            if other is None:
                raise Exception("other is None...should have been pre-trapped earlier")
            elif isinstance(other, str):
                other_is_string = True
                other_for_template = f"'{other}'"
                # Here, falsey_val2 needs leading/trailing quotes
                # for proper interpretation in SQL after template rendering
                falsey_val2 = "''"
            elif isinstance(other, bytes):
                other_is_binary = True
                other_for_template = f"'{other}'"
                # Here, falsey_val2 needs leading/trailing quotes
                # for proper interpretation in SQL after template rendering
                falsey_val2 = "''"
            elif isinstance(other, bool):
                other_for_template = "true" if other else "false"
                falsey_val2 = "false"
            elif isinstance(other, (int, float)):
                other_is_numeric = True
                other_for_template = other
                falsey_val2 = "0"
            elif isinstance(other, datetime):
                other_is_datetime = True
                if q1.is_date():  # <-- Want format: '%Y-%m-%d'
                    other_for_template = f"'{other.strftime('%Y-%m-%d')}'"
                    if isinstance(fill_value_left, datetime) and isinstance(
                        fill_value_right, datetime
                    ):
                        fill_value_left = f"'{fill_value_left.strftime('%Y-%m-%d')}'"
                        fill_value_right = f"'{fill_value_right.strftime('%Y-%m-%d')}'"
                else:  # <-- Want format: '%Y-%m-%dT%H:%M:%S.%f'
                    other_for_template = f"'{other.strftime('%Y-%m-%dT%H:%M:%S.%f')}'"
                    if isinstance(fill_value_left, datetime) and isinstance(
                        fill_value_right, datetime
                    ):
                        fill_value_left = (
                            f"'{fill_value_left.strftime('%Y-%m-%dT%H:%M:%S.%f')}'"
                        )
                        fill_value_right = (
                            f"'{fill_value_right.strftime('%Y-%m-%dT%H:%M:%S.%f')}'"
                        )

            elif isinstance(other, np.datetime64):
                other_is_datetime = True
                if q1.is_date():  # <-- Want format: '%Y-%m-%d'
                    other_dt = datetime.strptime(str(other), "%Y-%m-%dT%H:%M:%S.%f")
                    other_for_template = f"'{other_dt.strftime('%Y-%m-%d')}'"
                    if isinstance(fill_value_left, datetime) and isinstance(
                        fill_value_right, datetime
                    ):
                        fill_value_left = f"'{fill_value_left.strftime('%Y-%m-%d')}'"
                        fill_value_right = f"'{fill_value_right.strftime('%Y-%m-%d')}'"
                else:  # <-- Want format: '%Y-%m-%dT%H:%M:%S.%f'
                    other_for_template = f"'{str(other)}'"
                    if isinstance(fill_value_left, datetime) and isinstance(
                        fill_value_right, datetime
                    ):
                        fill_value_left = (
                            f"'{fill_value_left.strftime('%Y-%m-%dT%H:%M:%S.%f')}'"
                        )
                        fill_value_right = (
                            f"'{fill_value_right.strftime('%Y-%m-%dT%H:%M:%S.%f')}'"
                        )
            else:
                raise Exception(
                    "Unsuported literal scalar type: other={0} w/type={1}".format(
                        other, type(other)
                    )
                )

            # Create joined Quble
            if not q1.is_variate:
                raise ValuespaceRefError(
                    "Trying to perform (math) op on valueless Quble"
                )
            elif q1.is_univariate or variate_mode in ("multi", "mixed"):
                joined = q1
            else:
                joined = q1.to_univariate(allow_shallow_copy=True)

            # =========================== START: TARGET VALUESPACES LOOP =============================
            for tgt_valuespace in joined.valuespaces:
                valuespace_pairs[tgt_valuespace] = {}
                valuespace_pairs[tgt_valuespace]["src_vs"] = (tgt_valuespace, None)

                coltype1 = joined.get_column_type(tgt_valuespace)
                fx1 = joined._get_valuespace_attr(
                    vs_attr_name="fx", valuespace=tgt_valuespace
                )
                falsey_val1 = None
                if coltype_is_bool(coltype1):
                    falsey_val1 = "false"
                elif coltype_is_numeric(coltype1):
                    falsey_val1 = "0"
                elif coltype_is_str(coltype1):
                    falsey_val1 = "''"
                elif coltype_is_binary(coltype1):
                    falsey_val1 = "''"

                valuespace_pairs[tgt_valuespace]["falsey"] = (falsey_val1, falsey_val2)
                valuespace_pairs[tgt_valuespace]["coltype"] = (coltype1, None)
                valuespace_pairs[tgt_valuespace]["orig_fx"] = (fx1, None)
                valuespace_pairs[tgt_valuespace]["fill_value"] = (
                    fill_value_left,
                    fill_value_right,
                )

                # Check for errors
                if op.operates_on_numbers(op_name):
                    error = (
                        not joined.is_numeric(tgt_valuespace) or not other_is_numeric
                    )
                elif (
                    op.is_lt(op_name)
                    or op.is_le(op_name)
                    or op.is_gt(op_name)
                    or op.is_ge(op_name)
                ):
                    # Allow testing a datetime or date valuespace1 column
                    # against an (approriately formatted) scalar string
                    error = not (
                        (joined.is_numeric(tgt_valuespace) and other_is_numeric)
                        or (joined.is_str(tgt_valuespace) and other_is_string)
                        or (joined.is_binary(tgt_valuespace) and other_is_binary)
                        or (joined.is_date(tgt_valuespace) and other_is_datetime)
                        or (joined.is_datetime(tgt_valuespace) and other_is_datetime)
                        or (joined.is_date(tgt_valuespace) and other_is_string)
                        or (joined.is_datetime(tgt_valuespace) and other_is_string)
                    )
                else:
                    error = False

                if error:
                    raise TypeError(
                        "Unable to perform operation '{}' on self's valuespace of coltype:'{}' and (literal scalar) other type:'{}'".format(
                            op_name, coltype1, other
                        )
                    )

                # ------------------
                #   F/X HANDLING
                # ------------------
                if not op.yields_bool(op_name):
                    tgt_fx_dict[tgt_valuespace] = fx1

            # =========================== END: TARGET VALUESPACES LOOP =============================

            # --------------------------------------------------------------------------
            #              scalar_operators.j2 template arguments
            # --------------------------------------------------------------------------
            # src_table_name: Pre-joined source table
            # keyspaces: Keyspace columns in the pre-joined table
            # valuespace_pairs: dictionary of dictionaries per target valuespace
            #    outer keys: target valuespaces
            #    inner keys: 'src_vs', 'falsey', 'fill_value'
            #    inner values: pairs of left/right info (tuples of length two)
            #        'src_vs': The valuespace (column name) of the left/right side of the operational pair
            #        'falsey': The falsey value for the left/right side of the operation (e.g. "" or 0)
            #        'fill_value': Use this value when left/right is ignored and missing
            # scalar2: right side scalar value of the operation
            #          [set scalar to None to invoke NULL funcvtionality]
            # operation: The SQL symbol of the operation to perform (e.g. +)
            # function: True if the given operation is a function
            # ignore: Missing value ignore setting (e.g. "left")
            # cast_type: Cast the result to this type
            # negate: Negate the operation
            # tgt_table_name: Name of the table in which to write the result
            # epsilon: small value (applies when ignore == "right_nullify_small_div" and operation == "/")
            # --------------------------------------------------------------------------
            sql_command = JINJA_ENV.get_template("scalar_operators.j2").render(
                src_table_name=q1.table_name,
                keyspaces=q1.keyspaces,
                valuespace_pairs=valuespace_pairs,
                scalar2=other_for_template,
                operation=op_symbol,
                function=function,
                ignore=ignore_val,
                cast_type=cast_type,
                negate=negate,
                tgt_table_name=tgt_table_name,
                epsilon=epsilon,
            )
            execute(sql_command, format_flag=False)

        # ---------------------------------------
        # COPY CUSTOM INFO FROM
        # joined.table_name -> tgt_table_name
        # ---------------------------------------
        # FOR BOOL YIELDING OPS,
        # SUPPRESS NON-BOOL INFO_TYPES
        # [Example: fx]
        # ---------------------------------------

        column_map = {}
        # Transfer joined keyspaces
        for ks in joined.keyspaces:
            column_map[ks] = ks
        # Transfer joined valuespaces info to tgt_valuespace
        for tgt_valuespace in valuespace_pairs:
            if valuespace_pairs[tgt_valuespace] is None:
                raise Exception(f"valuespace_pairs[{tgt_valuespace}] is None")
            elif "src_vs" not in valuespace_pairs[tgt_valuespace]:
                raise Exception(
                    f"'src_vs' absent from valuespace_pairs[{tgt_valuespace}]"
                )
            elif isinstance(valuespace_pairs[tgt_valuespace]["src_vs"], (tuple, list)):
                for src_vs in valuespace_pairs[tgt_valuespace]["src_vs"]:
                    if src_vs is not None:
                        # Map col_info from first available src_vs
                        column_map[src_vs] = tgt_valuespace
                        break
            elif valuespace_pairs[tgt_valuespace]["src_vs"] is not None:
                column_map[valuespace_pairs[tgt_valuespace]["src_vs"]] = tgt_valuespace

        # Establish col_info for copy
        if tgt_table_name == joined.table_name:
            col_info = joined._column_info
        else:
            info_types_to_exclude = ["fx", "time_basis"] if drop_time_basis else ["fx"]
            col_info = joined.get_space_info(
                info_type=[
                    it1 for it1 in CUSTOM_INFO_TYPES if it1 not in info_types_to_exclude
                ],
                space=column_map,
                omit_unassigned=True,
            )
            # Assign final fx...
            if len(tgt_fx_dict) > 0:
                if col_info is None:
                    col_info = {}
                col_info["fx"] = tgt_fx_dict

        # updating col info - purge freq/fx for boolean valuespaces
        if op.yields_bool(op_name):
            # List of info types to update
            info_types_to_update = ["freq", "fx"]

            for info_type in info_types_to_update:
                if info_type in col_info:
                    for space in valuespace_pairs:
                        if space in col_info[info_type]:
                            del col_info[info_type][space]

                    # Check if all values are None in the sub-dictionary
                    if all(value is None for value in col_info[info_type].values()):
                        del col_info[info_type]

        # Instantiate Quble from the new table
        result = Quble.from_table(tgt_table_name, col_info=col_info)

        if compress:
            # Could possibly rethink auto_squeeze=False here
            summarize = (
                "all"
                if isinstance(compress, str) and (compress.find("all") >= 0)
                else "any"
            )
            drop = (
                True
                if isinstance(compress, str) and (compress.find("drop") >= 0)
                else False
            )
            # Choosing to keep falses in the operations that yield booleans
            # Because of unintuitive comparison output (ex. quble >= 0 would
            # return a quble with only the True rows)
            result = result.compress(
                summarize=summarize,
                treat_false_as_null=not op.yields_bool(op_name),
                drop=drop,
                key_ordering=None,
                auto_squeeze=False,
                inplace=True,
            )

        # If the input Qubles (q1 & q2) were both originally index Qubles
        # AND the final result is a bool (boolean-valued) Quble,
        # we convert the bool (boolean-valued) Quble result to an index form
        # -----------------------------------------------------------
        # [Implicitly removes False valued records
        # and then drops the valuespace column]
        # -----------------------------------------------------------
        if (
            q1_was_index
            and (q2_was_index or other_is_literal_scalar)
            and result.is_bool()
        ):
            result = result.bool_to_index()

        return result

    # ================================ FILTERING METHODS ==============================

    def variate_to_index(
        self,
        valuespace: str = "<valuespace>",
        key_ordering=None,
        allow_shallow_copy: bool = False,
        new_keyspace="levels",
        force_new_keyspace=False,
        null_replacement_key=None,
        variate_keyspace=None,
        categorical=None,
    ) -> Quble:
        """
        Converts a boolean OR numeric OR string valued (or index) Quble
        (for the primary or specified valuespace) to an index

        For bool values: records/keys where bool values are True will be retained in the index

        For numeric values: first be casted to bool values before subsequent conversion to index
        then only the records/keys where bool values are True will be retained in the index
        (In other words, only records with non-zero numeric values will be retained in index)
        ==> NOTE: this method merely indirectly calls bool_to_index()

        For string values: will introduce a new keyspace to denote each original str value
        New keyspace will reflect original valuespace
        (unless original valuespace==DEFAULT_VALUESPACE and not force_new_keyspace)
        :param null_replacement_key: Specify a value to replace NULL records with instead of eliminating the NULL record.
        :param variate_keyspace: Specify the name of the variate keyspace to be added as a result of the unpivot operation
                NOTE: The unpivot operation requires that all participating valuespaces have compatible data types.
        :param categorical: Specify whether the data is to be treated as categorical data or not.
                NOTE: When categorical is None and string or date data is given, categorical method will be used
                      When categorical is None and numeric or boolean data is given, filter method will be used
                      When categorical is True, categorical method will be used
                      When categorical is False, filter method will be used
                      When categorical is False and string or date data is given, an exception will be thrown
                      When data is not string, date, boolean nor, numeric, an exception will be thrown
        :raises Exception: When categorical is False and string or date data is given
        :raises Exception: When data is neither string, date, boolean, nor numeric
        :raises Exception: When unable to coerce non-numeric Quble to bool
        :raises Exception: When attempting to convert uni or multi scalar to an index
        :raises Exception: When a single valuespace is not provided and variate_keyspace is None
        :raises Exception: When variate_keyspace is set but zero valuespaces are provided
        :raises Exception: When the subject is non-variate
        :raises Exception: When categorical is set to True but string or date data is not provided
        :raises Exception: When new_keyspace is None and data is categorical (after unpivot)
        [See: :meth:`~qubles.core.quble.Quble.bool_to_index`]
        """
        if self.is_undefined:
            return self
        elif self.is_index:
            # Trap for pre-existing index case
            return self if allow_shallow_copy else self.copy()
        elif self.is_scalar or self.is_multiscalar:
            raise Exception("Cannot convert uni/multi scalar to an index")

        # Multivariate vs Univariate Quble logic
        valuespaces_to_analyze = self.validate_valuespace(
            valuespace, coerce_to_list=True, grace=False
        )
        # If we are working with a Univariate Quble, we expect to only be working on one valuespace and for
        # variate_keyspace to not be set.
        if variate_keyspace is None:
            if len(valuespaces_to_analyze) != 1:
                raise Exception(
                    "Single valuespace required when variate_keyspace is None"
                )
            subject = self
            valuespace = valuespaces_to_analyze[0]
        # If we are working with a Multivariate Quble, we expect variate_keyspace to be set and to be working with
        # one or more valuespaces
        else:
            if len(valuespaces_to_analyze) == 0:
                raise Exception(
                    f"At least one valuespace required for variate_keyspace: {variate_keyspace}"
                )
            subject = self.unpivot(
                new_keyspace=variate_keyspace,
                valuespaces_to_unpivot=valuespaces_to_analyze,
                new_valuespace=DEFAULT_VALUESPACE,
            )
            if not subject.is_variate:
                raise Exception("Subject is non_variate")
            valuespace = subject.valuespace

        # Default to categorical approach (i.e. set categorical to True) if the data is a string or date,
        # even if categorical is initialized to False.
        if (
            is_string := subject.is_string(space=valuespace, grace=True)
        ) or subject.is_time_space(space=valuespace, grace=True):
            categorical_type = str if is_string else datetime
            if categorical == False:
                raise Exception(
                    f"categorical set to False but data provided is of {categorical_type}"
                )
            categorical = True
        # If categorical was provided as True, then we need to figure out if the data is of booleans or numerics
        elif categorical:
            if subject.is_numeric(space=valuespace, grace=True):
                categorical_type = float
            elif subject.is_bool(space=valuespace, grace=True):
                categorical_type = bool
            else:
                raise Exception(
                    f"Expected: BOOLEAN or FLOAT column type when categorical flag is set to {categorical}. Got: {subject.get_column_type(space=valuespace)}"
                )

        column_expressions = None
        where_clause = None
        # Only reference subject (not self) after this line
        if categorical:
            # Here, we rename the valuespace and change this column's role to serve as new keyspace
            if not force_new_keyspace and valuespace != DEFAULT_VALUESPACE:
                # Honor the valuespace parameter as the name of the new keyspace
                new_keyspace = valuespace
            elif new_keyspace is None:
                raise Exception(f"new_keyspace must not be None")
            column_names = {
                space: space for space in subject.keyspaces + [new_keyspace]
            }
            custom_info_overrides = {"role": {new_keyspace: "keyspace"}}
            if null_replacement_key:
                if categorical_type == str:
                    column_expressions = {
                        new_keyspace: f'CASE WHEN "{valuespace}" IS NULL OR "{valuespace}" = \'\' THEN \'{null_replacement_key}\' ELSE "{valuespace}" END'
                    }
                else:
                    column_expressions = {
                        new_keyspace: f'CASE WHEN "{valuespace}" IS NULL THEN \'{null_replacement_key}\' ELSE "{valuespace}" END'
                    }
            else:
                where_clause = (
                    f'"{valuespace}" IS NOT NULL AND "{valuespace}" <> \'\''
                    if categorical_type == str
                    else f'"{valuespace}" IS NOT NULL'
                )
        # NON-CATEGORICAL CASES
        elif subject.is_bool(space=valuespace, grace=True):
            column_names = subject.keyspaces
            where_clause = (
                f'WHERE "{valuespace}" IS NOT NULL AND "{valuespace}" <> False'
            )
            custom_info_overrides = {}
        elif subject.is_numeric(space=valuespace, grace=True):
            column_names = subject.keyspaces
            where_clause = f'WHERE "{valuespace}" IS NOT NULL AND "{valuespace}" != 0'
            custom_info_overrides = {}
        else:
            raise Exception(
                "Unable to coerce non-numeric Quble -> bool for valuespace:{0}".format(
                    valuespace
                )
            )

        return subject.select(
            column_names=column_names,
            custom_info_overrides=custom_info_overrides,
            column_expressions=column_expressions,
            where_clause=where_clause,
            key_ordering=key_ordering,
            preferred_vs=None,
        )

    def bool_to_index(
        self,
        valuespace: str = "<valuespace>",
        coerce_to_bool=False,
        key_ordering=None,
        allow_shallow_copy: bool = False,
    ) -> Quble:
        """
        Converts a boolean-valued (or index) Quble
        (for the primary or specified valuespace) to an index Quble by:

           1) First removing all the False (or NULL) records (compress w/treat_false_as_null=True)
           2) Then dropping the valuespace of the remaining True values

        :param valuespace: the (boolean) valuespace to use for index creation
        :type valuespace: str (defaults to primary valuespace)

        :param coerce_to_bool: flag allowing for casting of non-bool, numeric valuespace
        ==> coerce_to_bool=True:
        allows for casting of non-bool, numeric values
        to booleans before conversion to index
        ==> coerce_to_bool=False: raise Exception for non-bool valuespace
        :type coerce_to_bool: bool (True*/False)

        :param key_ordering: controls subsequent key ordering of result
        :type key_ordering: None or str

        :param allow_shallow_copy: flag to allow a shallow copy
        :type bool: False*/True

           ==> If allow_shallow_copy==True and self.is_index,
           ==> then a shallow copy (i.e., self) is returned

        """
        # Trap for pre-existing index case
        if self.is_undefined:
            return self
        elif self.is_index:
            return self if allow_shallow_copy else self.copy()
        elif self.is_scalar or self.is_multiscalar:
            raise Exception("Cannot convert (boolean) uni/multi scalar to an index")

        valuespace = self.validate_valuespace(
            valuespace,
            grace=False,
            allow_auxvalspaces=True,
            coerce_to_list=False,
            solo_required=True,
        )

        # Confirm (coerce) to boolean valued Quble
        if not self.is_bool(space=valuespace, grace=True):
            if not coerce_to_bool:
                raise Exception(f"boolean Quble expected for valuespace:{valuespace}")
            elif not self.is_numeric(space=valuespace, grace=True):
                raise Exception(
                    "Unable to coerce non-numeric Quble -> bool for valuespace:{0}".format(
                        valuespace
                    )
                )

        return self.variate_to_index(valuespace, allow_shallow_copy=allow_shallow_copy)

    def index_to_bool(self, valuespace: str = DEFAULT_VALUESPACE) -> Quble:
        """
        Converts a index Quble to an boolean Quble with all True values
        """
        return self.index_to_valued(valuespace=valuespace)

    def index_to_valued(
        self,
        valuespace: str = DEFAULT_VALUESPACE,
        valuespace_type: str = None,
    ) -> Quble:
        """
        Converts a index Quble to an valued Quble with all True values

        :param valuespace: the target valuespace column name
                            (must not be present in Quble spaces)
        :type valuespace: str

        :param valuespace_type:  target valuespace column SQL type
        :type keyspace: str or None
        ==> If None, then a bool valuespace will be generated
        """
        if not self.is_index:
            raise Exception("index Quble required")
        elif valuespace is None:
            raise Exception("(new) valuespace must not be None")
        elif valuespace in self.spaces:
            # Check for conflict to be extra safe
            raise Exception(
                f"valuespace:{valuespace} already present in self.spaces:{self.spaces}"
            )
        spaces = self.spaces + [valuespace]

        if valuespace_type is None:
            valued_result = self.select(
                column_names=spaces,
                # The quotes in column_expressions below will not be used
                # within self.select SQL command
                column_expressions={valuespace: "true"},
                preferred_vs=valuespace,
            )
        elif valuespace_type in SQL_FLOAT_TYPES:
            # For float types, we must cast to int as intermediate step
            valued_result = self.select(
                column_names=spaces,
                # The quotes in column_expressions below will not be used
                # within self.select SQL command
                column_expressions={
                    valuespace: f"(CAST(CAST(true AS INT) AS {valuespace_type}))"
                },
                preferred_vs=valuespace,
            )
        else:
            valued_result = self.select(
                column_names=spaces,
                # The quotes in column_expressions below will not be used
                # within self.select SQL command
                column_expressions={valuespace: f"(CAST(true AS {valuespace_type}))"},
                preferred_vs=valuespace,
            )

        return valued_result

    def sub_variate(
        self, valuespace="<valuespace>", allow_shallow_copy: bool = False
    ) -> Quble:
        """
        Reduces valuespaces of a Quble to the specified subset

        :param valuespace: the target valuespace(s) column(s)
                            (must all be present in Quble spaces)
        :type valuespace: str or list of strings
                      (keywords may be used such as '<valuespaces>', '<valuespace>', etc.
                      [See: :meth:`~qubles.core.quble.Quble.validate_valuespace`]

        :param allow_shallow_copy: flag to allow a shallow copy
        :type bool: False*/True

           ==> If allow_shallow_copy==True and valuespace==self.valuespaces,
           ==> then a shallow copy (i.e., self) is returned
        """
        valuespace_to_retain = self.validate_valuespace(
            valuespace, grace=False, allow_auxvalspaces=True, coerce_to_list=True
        )
        # Is a deep copy required?
        # If not, are we changing the list/ordering of the valuespaces?
        if valuespace_to_retain == self.valuespaces:
            # We are not changing the valuespaces list nor their ordering
            # and a deep copy is not required, therefore merely return self
            return self if allow_shallow_copy else self.copy()
        else:
            # What is the preferred primary valuespace in the result?
            if self.valuespace in valuespace_to_retain:
                preferred_vs = self.valuespace
            elif len(valuespace_to_retain) == 0:
                raise Exception(
                    f"Empty valuespace_to_retain...perhaps the requested valuespace:{valuespace} is absent from self.valeuspaces:{self.valuespaces}"
                )
            else:
                preferred_vs = valuespace_to_retain[0]

            return self.select(
                column_names=self.keyspaces + valuespace_to_retain,
                preferred_vs=preferred_vs,
            )

    def to_univariate(
        self,
        valuespace="<valuespace>",
        allow_shallow_copy: bool = False,
        allow_index: bool = True,
    ) -> Quble:
        """
        Ensures a univariate Quble by keeping only the specified valuespace
        and dropping any extra valuespaces
        A single target valuespace is required

        :param valuespace: the target valuespace column
                            (must be present in Quble spaces)
        :type valuespace: string
                      (keywords may be used such as '<valuespace>', etc.
                      [See: :meth:`~qubles.core.quble.Quble.validate_valuespace`]

        :param allow_shallow_copy: flag to allow a shallow copy
        :type bool: False*/True

        :param allow_index: flag to allow index (valueless) Quble
        :type bool: True*/False
        If allow_index==True, will convert index Quble to boolean Quble (all True values)
        """
        # TODO: Support dict form for valuespace arg of Quble.to_univariate to support renaming
        # Handle index (valueless) Quble case
        if self.is_index:
            if valuespace != "<valuespace>":
                raise Exception(
                    "Requesting univariate conversion of index (valueless) Quble yet non-trivial valuespace arg:{0}".format(
                        valuespace
                    )
                )
            elif not allow_index:
                raise Exception(
                    "Requesting univariate conversion of index (valueless) Quble yet allow_index arg:{0}".format(
                        allow_index
                    )
                )
            else:
                return self.index_to_bool()

        # Validate valuespace arg
        valuespace = self.validate_valuespace(
            valuespace,
            grace=False,
            allow_auxvalspaces=True,
            coerce_to_list=False,
            solo_required=True,
        )

        # Qualify valuespace
        if valuespace is None:
            raise Exception(
                "Internal inconsistency...valuespace is None post validate_valuespace() call"
            )
        elif isinstance(valuespace, (list, tuple)):
            raise Exception(
                "Internal inconsistency...valuespace is list/tuple post validate_valuespace() call"
            )

        return self.sub_variate(valuespace, allow_shallow_copy=allow_shallow_copy)

    def squeeze(self, keyspace: str = None, deep_copy: bool = True) -> Quble:
        """
        Removes specified (or all) dimensions with length of one

        :param keyspace: keyspace (or axis number) to be squeezed
        :type keyspace: str or None
        [If keyspace=None, then all keyspaces will be squeezed and result will be a scalar Quble]

        :param deep_copy: If True: leaves original object unchanged, False: changes original object
        :type deep_copy: bool

        :returns: This Quble (or a copy of it) with empty dimensions removed.
        :rtype: qubles.core.quble.Quble
        """
        # Handle trivial case
        if self.is_undefined:
            return Quble.undefined_instance() if deep_copy else self

        # Establish squeeze_candidates
        if keyspace is not None:
            # Using grace=False: raises Exception if non-None keyspace could not be identified
            squeeze_candidates = self.validate_keyspace(
                keyspace, coerce_to_list=True, grace=False
            )
        else:
            # Otherwise, all keyspaces are squeeze candidates
            squeeze_candidates = self.keyspaces

        # Handle trivial squeeze_candidates
        if squeeze_candidates is None or len(squeeze_candidates) == 0:
            return self.copy() if deep_copy else self

        # Establish distinct_key_counts (dictionary)
        distinct_key_counts = self.get_distinct_key_counts(squeeze_candidates)
        if distinct_key_counts is None or len(distinct_key_counts) == 0:
            return self.copy() if deep_copy else self

        spaces_to_keep = []
        squeezing_applied = False
        for ks in self.keyspaces:
            if (
                ks in squeeze_candidates
                and ks in distinct_key_counts
                and distinct_key_counts[ks] == 1
            ):
                # Squeeze those candidates with only one distinct key
                squeezing_applied = True
            else:
                spaces_to_keep.append(ks)

        # Also, keep any/all valuespaces
        # [May include primary valuespace and possibly other auxvalspaces]
        for space1 in self.valuespaces:
            if space1 not in spaces_to_keep:  # <-- To be extra safe
                spaces_to_keep.append(space1)

        # Return result accordingly
        if squeezing_applied:
            # Keep appropriate spaces only
            return self.select(column_names=spaces_to_keep, deep_copy=deep_copy)
        elif deep_copy:
            return self.copy()
        else:
            self._clear_num_records_caches()
            return self

    def compress(
        self,
        valuespace="<valuespaces>",
        treat_false_as_null: bool = False,
        drop: bool = False,
        auto_squeeze: bool = False,
        summarize: str = "any",
        key_ordering=None,
        exceptions_flag: bool = False,
        inplace: bool = False,
    ) -> Quble:
        """
        Keeps only non-null valued records
        'summarized' (see summarize arg) across 'any' ('all')
        of the specified (filtering) valuespace(s)
        according to the following logic:

        If self has no specified valuespaces and not auto_squeeze, then simply return a copy
        If self is a scalar Quble, then simply returns a copy

        **If drop == False**
        Keeps only those records where 'any' ('all') specified valuespace(s) are non-missing/not-null
        Here, the resultant Quble will have the same valuespaces
        and the same primary valuespace as original Quble [but may have fewer records]

        **If drop == True**
        Keeps only those records where 'any' ('all') specified valuespace(s) are non-missing/not-null
        Here, drops all valuespaces from result
        and returns a non-variate, index Quble (no valuespaces)

        :param valuespace: valuespace(s) to compress across
                           [may be a subset of Quble's valuespaces]
        :type valuespace: str (a specific valuespace)
                        OR list of string (specific valuespaces)
                        OR '<all>' OR '<valuespaces> (all valuespaces)
                        OR '<valuespace>' (primary valuespace)

        :param treat_false_as_null: For boolean values, controls how to
                                     treat/remove False values (when applicable)
        :type treat_false_as_null: boolean

        :param drop: Flag for dropping valuespaces after compression
                     (after keeping only non-missing/non-null valued records)
                     [requires that only one valuespace is being filtered]
        :type drop: boolean

        :param auto_squeeze: Indicates whether to remove
                             single-element dimensions from compression result
        :type auto_squeeze: bool or None

        :param summarize: compression control for multi-variate non-null state
                           summarization across filtering valuespaces
        :type summarize: 'any' or 'all' (string) [default: 'any']
        ==> summarize == 'any': keeps rows where ANY valuespace is NOT NULL
        ==> summarize == 'all': ONLY keeps rows where ALL valuespaces are NOT NULL
        a.k.a. Removes rows where NOT ALL valuespaces are NOT NULL
        a.k.a. Removes rows where SOME valuespaces are NULL

        :param key_ordering: controls subsequent key ordering of result
        :type key_ordering: None or str

        :param exceptions_flag: flag whether to generate exceptions Quble
        :type exceptions_flag: (boolean) False*/True

        :param inplace: flag whether to generate exceptions Quble, stored under compress key in quble exceptions dict
        :type inplace: (boolean) False*/True

        :rtype: Quble
        :returns: compressed Quble
        """
        # Handle trivial cases
        if self.is_undefined:
            if inplace:
                return self
            # Cannot compress an undefined Quble
            return Quble.undefined_instance()
        elif self.is_scalar or self.is_multiscalar:
            if inplace:
                return self
            # Cannot compress a scalar
            return self.copy()

        # Validate summarize arg
        if summarize not in ("all", "any"):
            raise Exception("Invalid summarize:{0}...valid options: 'any' or 'all'")

        # Determine valuespaces_to_filter
        valuespaces_to_filter = self.validate_valuespace(
            valuespace=valuespace, grace=False, coerce_to_list=True
        )

        # Droppage requires single valuespace filtering [No longer implemented]
        if drop and len(valuespaces_to_filter) > 1:
            raise Exception(
                "drop:{0} requires single valuespace filtering yet valuespaces_to_filter:{1}".format(
                    drop, valuespaces_to_filter
                )
            )

        # Populate null_conditions (list)
        null_conditions = []
        for vs in valuespaces_to_filter:
            if vs is None:
                continue

            # Build local_null_clause for current vs
            local_null_clause = f'"{vs}" IS NULL'
            if self.is_bool(space=vs) and treat_false_as_null:
                local_null_clause += f' OR "{vs}" = False'

            # Wrap the local_null_clause with parenthesis then append to null_conditions list
            null_conditions.append(f"({local_null_clause})")

        # ----------------------------------------------
        # Construct null_clause from null_conditions
        # ----------------------------------------------
        if len(null_conditions) == 0:
            null_clause = None
        elif summarize == "all":
            # Here, compress will keep records where ALL valuespaces are not null
            # Here, exceptions reflect records where ANY valuespace is null
            null_clause = f"WHERE {' OR '.join(null_conditions)}"
        else:
            # Here, compress will keep records where ANY valuespace is not null
            # Here, exceptions reflect records where ALL valuespaces are null
            null_clause = f"WHERE {' AND '.join(null_conditions)}"

        # First, check if any records are slated for removal
        # (if not, we may be able to bail early to save time)
        # ----------------------------------------------------
        if drop:
            # For drop case, we DO NOT want to allow early bail-out
            pass

        elif (
            execute(
                f"SELECT COUNT(*) FROM {dquote_dot(self.table_name)} {null_clause}",
                fetch="one",
                format_flag=False,
            )[0]
            == 0
        ):
            # Othersie, bail early if no matches for null_clause
            if inplace:
                return self
            return self.copy()

        # ================== START: EXCEPTIONS LOGIC ==================

        # ------------------------------------
        # Generate exceptions (if requested)
        # ------------------------------------
        exceptions = None
        if exceptions_flag:
            # ----------------------------------
            # Apply filtering when applicable
            # ----------------------------------
            if null_clause is None:
                # Here, there are no exceptions, so we simply just remove all records to generate exceptions
                exceptions = self.clear()
            else:
                # Here, exceptions are identified by null_clause
                exceptions = self.select(
                    column_names=self.column_names,
                    column_expressions=None,
                    where_clause=null_clause,
                    custom_info_overrides=None,
                    cast_dict=None,
                    tgt_insertions=None,
                    data_exclusion=None,
                    deep_copy=True,
                    exceptions_flag=exceptions_flag,
                )

        # ================== END: EXCEPTIONS LOGIC ==================

        # Populate where_conditions (list)
        not_null_conditions = []
        for vs in valuespaces_to_filter:
            if vs is None:
                continue

            # Build local_not_null_clause for current vs
            local_not_null_clause = f'"{vs}" IS NOT NULL'
            if treat_false_as_null and self.is_bool(space=vs):
                local_not_null_clause += f' AND "{vs}" <> False'

            # Wrap the local_not_null_clause with parenthesis then append to not_null_conditions list
            not_null_conditions.append(f"({local_not_null_clause})")

        # -------------------------------------------------
        # Construct where_clause from not_null_conditions
        # -------------------------------------------------
        if len(not_null_conditions) == 0:
            not_null_clause = None
        elif summarize == "all":
            # Here, compress will keep records where ALL valuespaces are not null
            not_null_clause = f"WHERE {' AND '.join(not_null_conditions)}"
        else:
            # Here, compress will keep records where ANY valuespace is not null
            not_null_clause = f"WHERE {' OR '.join(not_null_conditions)}"

        # ----------------------------------
        # Apply filtering when applicable
        # ----------------------------------
        if not drop and not_null_clause is None:
            # Shallow copy here...will perform a deep copy below if needed
            result = self
        else:
            # Droppage and/or sub-selection required
            # NOTE: if not drop, ALL valuespaces are retained
            #       (not merely the valuespaces being filtered)
            result = self.select(
                column_names=self.column_names if not drop else self.keyspaces,
                column_expressions=None,
                where_clause=not_null_clause,
                custom_info_overrides=None,
                cast_dict=None,
                tgt_insertions=None,
                data_exclusion=None,
                deep_copy=not inplace,
                exceptions_flag=exceptions_flag,
            )

        # ---------------------------------------------------------------
        # Finally, apply auto_squeeze (when requested) regardless of
        # whether filtering (where_clause) has been applied
        # ---------------------------------------------------------------
        # NOTE: We need to do this AFTER filtering has occurred
        # ==> Therefore we cannot combine the two select() method calls
        # ---------------------------------------------------------------
        if auto_squeeze:
            distinct_key_counts = result.distinct_key_counts
            if distinct_key_counts is not None:
                spaces_to_keep = []
                spaces_to_squeeze = []
                for ks in result.keyspaces:
                    if ks in distinct_key_counts and distinct_key_counts[ks] == 1:
                        spaces_to_squeeze.append(ks)
                    else:
                        spaces_to_keep.append(ks)

                # Is squeezing required?
                if len(spaces_to_squeeze) > 0:
                    # Add the valuespaces to spaces_to_keep (if present)
                    for vs in result.valuespaces:
                        if vs is not None:
                            spaces_to_keep.append(vs)

                    # We cannot squeeze all spaces would yield an undefinable table/Quble)
                    # In this case, we attempt to reintroduce an arbtrary/first keyspace from spaces_to_squeeze
                    # [In this case, the Quble does not have a valuespace]
                    if len(spaces_to_keep) == 0:
                        spaces_to_keep.append(spaces_to_squeeze[0])

                    result = result.select(
                        column_names=spaces_to_keep, deep_copy=not inplace
                    )

        # Apply key ordering (when applicable)
        if key_ordering is not None:
            result = result.key_sort(key_ordering=key_ordering, deep_copy=not inplace)

        # Prevent returning an unchanged self
        if inplace:
            self._clear_num_records_caches()
            result = self
        elif result.shares_table_with(self):
            result = result.copy()

        # Finally, assign the exceptions if generated
        if exceptions:
            self._extend_exceptions("Compress", exceptions)

        return result

    def filter_records(self, filter_cmd: str = "<valuespace> IS NOT NULL") -> Quble:
        """
        Isolates a sub-set of records according to specified filter_cmd
        Here, filter_cmd should be a SQL construct
        applied to columns of the underlying table

        :param filter_cmd: The associated test as a string
                               recognizes the 'AND' 'OR' delimiters
                               and will apply the rules in a complex manner

                ==> '<valuespace>' (primary valuespace reference) construct can be included in the filter_cmd string
                ==> For example: filter_cmd = '<valuespace> IS NOT NULL OR <valuespace> = FALSE'
                ==> filter_cmd need not reference <valuespace> and can also include index columns
                ==> This method can be applied to index-only Qubles so long as filter_cmd does not reference <valuespace>
                ==> filter_cmd must be SQL/table column friendly and utilize necessary quoting syntax For example:  filter_cmd = '"Dates" >= \'2018-01-01\''

        :type filter_cmd: str
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate filter_cmd
        if filter_cmd is None:
            return self.copy()
        elif not isinstance(filter_cmd, str):
            raise Exception("Invalid filter_cmd...str expected")
        elif len(filter_cmd) == 0:
            return self.copy()

        # Replace '<valuespace>' within filter_cmd if applicable
        if search("<valuespace>", filter_cmd) is not None:
            if self.valuespace is None:
                raise Exception(f"self has no valuespace, yet filter_cmd:{filter_cmd}")
            elif not isinstance(self.valuespace, str):
                raise Exception(f"Invalid valuespace:{self.valuespace}...str expected")
            elif len(self.valuespace) == 0:
                raise Exception(
                    f"Invalid valuespace:{self.valuespace}...len(valuespace) == 0"
                )

            filter_cmd = filter_cmd.replace("<valuespace>", f'"{self.valuespace}"')

        table_name = generate_random_table_name()

        sql_template = JINJA_ENV.get_template("filter_records.j2")

        # Here, valuespaces_for_testing is a list of the valuespace(s) to be tested
        # [may be a subset of the original valuespaces]
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            tgt_table_name=table_name,
            # Here, we maintain all columns of underlying table
            # [not specifying keyspaces or valuespaces]
            spaces=self.spaces,
            filter_cmd=filter_cmd,
        )
        execute(sql_command)

        return Quble.from_table(
            table_name,
            col_info=self.get_space_info(
                info_type=CUSTOM_INFO_TYPES,
                space=self.spaces,
                omit_unassigned=True,
            ),
        )

    def apply_filter(
        self,
        filter_cmd: str = "<valuespace> IS NOT NULL",
        compress_drop: str = "compress",
        key_ordering="asc",
    ) -> Quble:
        """
        Applies the specified filter_cmd and returns either:
              1) univariate boolean-valued Quble
                 (inherits self's primary valuespace if possible)
           or 2) non-valued, index-only Quble
                 (depending on compress_drop arg).

        Here, filter_cmd should be a SQL construct
        applied to columns of the underlying table

        :param filter_cmd: The associated test as a string
                           recognizes the 'AND' 'OR' delimiters
                           and will apply the rules in a complex manner

                NOTE: column references in filter_cmd should be wrapped by double quotes
                (for case sensitivity) and string /date scalars should be wrapped by single-quotes
                ==> For example: filter_cmd = ' "Dates" >= \'2020-03-31\' '

                ==> '<valuespace>' construct can be included in the filter_cmd string
                ==> For example: filter_cmd = '<valuespace> IS NOT NULL OR <valuespace> = FALSE'
        :type filter_cmd: string

        compress_drop: controls record compression of False tests and valuespace droppage of results
                ==> None: all test records (True/False) are returned within an associated valuespace
                ==> 'compress' removes False records from results...only keeps records where results are True
                ==> 'drop' both removes False records and also removes the resultant valuespace from results (i.e., results is a valueless index)
        :type compress_drop: str

        :param key_ordering: controls row ordering by key
        :type key_ordering: None, str or dictionary
           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace
           dictionary: dict keys (str): keyspaces, dict values (str): 'asc' or 'desc'
           ==> allows for assigning key ordering (ascending/descending)
           ==> (and relative priority) for each keyspace individually
        """
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_scalar or self.is_multiscalar:
            raise Exception("Cannot apply filter to scalar...requires keyspaces")

        # Validate filter_cmd
        if filter_cmd is None:
            # NOTE: we need a filter, otherwise we cannot necessarily
            # yield the desired/expected boolean/index-only result
            # [i.e., returning self.copy() would not be appropriate]
            raise Exception("No filter_cmd provided")
        elif not isinstance(filter_cmd, str):
            raise Exception("Invalid filter_cmd...str expected")
        elif len(filter_cmd) == 0:
            raise Exception("len(filter_cmd) == 0")

        # Replace '<valuespace>' within filter_cmd if applicable
        if search("<valuespace>", filter_cmd) is not None:
            if self.valuespace is None:
                raise Exception(f"self has no valuespace, yet filter_cmd:{filter_cmd}")
            elif not isinstance(self.valuespace, str):
                raise Exception(f"Invalid valuespace:{self.valuespace}...str expected")
            elif len(self.valuespace) == 0:
                raise Exception(
                    f"Invalid valuespace:{self.valuespace}...len(valuespace) == 0"
                )

            filter_cmd = filter_cmd.replace("<valuespace>", f'"{self.valuespace}"')

        # Validate compress_drop
        valid_compress_drop = (None, "compress", "drop")
        if compress_drop not in valid_compress_drop:
            raise Exception(
                "Invalid compress_drop arg:{0}...must be in: {1}".format(
                    compress_drop, valid_compress_drop
                )
            )

        table_name = generate_random_table_name()

        # Build key_ordering dictionary when applicable
        if key_ordering is not None and not isinstance(key_ordering, str):
            key_ordering = build_key_ordering_dict(
                key_ordering, keyspaces=self.keyspaces
            )

        sql_template = JINJA_ENV.get_template("apply_filter.j2")

        tgt_valuespace = (
            self.valuespace if self.valuespace is not None else DEFAULT_VALUESPACE
        )

        # Here, valuespaces_for_testing is a list of the valuespace(s) to be tested
        # [may be a subset of the original valuespaces]
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            tgt_table_name=table_name,
            keyspaces=self.keyspaces,
            valuespace=tgt_valuespace,
            filter_cmd=filter_cmd,
            compress_drop=compress_drop,
            key_ordering=key_ordering,
        )
        execute(sql_command)

        col_info = self.get_space_info(
            info_type=CUSTOM_INFO_TYPES,
            space=self.keyspaces,
            omit_unassigned=True,
        )

        # Yields boolean valuespaces...only assign info_type='role'
        # For valuespace to be dropped, compress_drop == 'drop'
        if self.valuespace is not None and compress_drop != "drop":
            update_column_info(col_info, {"role": {tgt_valuespace: True}})

        return Quble.from_table(
            table_name,
            col_info=col_info,
        )

    def where_missing(
        self,
        valuespace="<valuespaces>",
        treat_false_as_null: bool = False,
        compress="any",
        grace: bool = True,
        as_type=None,
    ) -> Quble:
        """
        Yields boolean-valued Quble (for the specified valuespace columns)
        indicating where values are missing

        :param valuespace: valuespace(s) to compress across
        :type valuespace: str (a specific valuespace)
                        OR list of string (specific valuespaces)
                        OR '<all>' OR '<valuespaces> (all valuespaces)
                        OR '<numeric_valuespaces> (all numeric valuespaces)
                        OR '<valuespace>' (primary valuespace)

        :param treat_false_as_null: For boolean values, controls how to
                                     treat/remove False values (when applicable)
        :type treat_false_as_null: boolean

        :param compress: compression controls
        :type compress: True or False or None or str
                [See: :meth:`~qubles.core.quble.Quble.compress`]
                ==> If string contains word 'any': Quble.compress(summarize='any',...)
                ==> If string contains word 'all': Quble.compress(summarize='all',...)
                ==> If string contains word 'drop': Quble.compress(drop=True,...)

        :param grace: grace flag for non-variate case
        :type grace: boolean (True*/False)

        :param as_type: optional SQL type for casting from boolean to int/float/etc
        :type as_type: str or None
            ==> If as_type=None, yields boolean results (no casting applied)
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate the valuespace arg
        valuespace = self.validate_valuespace(
            valuespace=valuespace, grace=False, coerce_to_list=True
        )

        # Limit subject to valuespaces of interest
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)

        # Handle variate Quble subject
        cast_dict = {} if as_type else None
        if subject.is_variate:
            column_expressions = {}
            for vs in subject.valuespaces:
                if self.is_bool(space=vs) and treat_false_as_null:
                    column_expressions[vs] = f'"{vs}" IS NULL OR "{vs}" = False'
                else:
                    column_expressions[vs] = f'"{vs}" IS NULL'

                if as_type:
                    cast_dict[vs] = as_type

            condition = subject.select(
                column_names="<all>",
                column_expressions=column_expressions,
                where_clause=None,
                cast_dict=cast_dict,
                info_type_exclusions=["fx", "time_basis"],
            )
            if compress:
                summarize = (
                    "all"
                    if isinstance(compress, str) and (compress.find("all") >= 0)
                    else "any"
                )
                drop = (
                    True
                    if isinstance(compress, str) and (compress.find("drop") >= 0)
                    else False
                )
                condition.compress(
                    valuespace=condition.valuespaces,
                    # NOTE: We wish to drop where condition==False (or None) given summarize op
                    treat_false_as_null=True,
                    drop=drop,
                    summarize=summarize,
                    inplace=True,
                )
            return condition
        # Handle non-variate (index) Quble subject
        elif grace:
            # Treat is if values were all boolean Trues (no missings)
            return subject.clear()
        else:
            raise NoValuespaceError(f"no valuespace and grace={grace}")

    def where_not_missing(
        self,
        valuespace="<valuespaces>",
        treat_false_as_null: bool = False,
        compress="any",
        grace: bool = True,
        as_type=None,
    ) -> Quble:
        """
        See :meth:`~qubles.core.quble.Quble.where_missing`
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate the valuespace arg
        valuespace = self.validate_valuespace(
            valuespace=valuespace, grace=False, coerce_to_list=True
        )

        # Limit subject to valuespaces of interest
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)

        # Handle variate Quble subject
        if subject.is_variate:
            column_expressions = {}
            cast_dict = {} if as_type else None
            for vs in subject.valuespaces:
                if self.is_bool(space=vs) and treat_false_as_null:
                    column_expressions[vs] = f'"{vs}" IS NOT NULL AND "{vs}" <> False'
                else:
                    column_expressions[vs] = f'"{vs}" IS NOT NULL'

                if as_type:
                    cast_dict[vs] = as_type

            condition = subject.select(
                column_names="<all>",
                column_expressions=column_expressions,
                where_clause=None,
                cast_dict=cast_dict,
                info_type_exclusions=["fx", "time_basis"],
            )
            if compress:
                summarize = (
                    "all"
                    if isinstance(compress, str) and (compress.find("all") >= 0)
                    else "any"
                )
                drop = (
                    True
                    if isinstance(compress, str) and (compress.find("drop") >= 0)
                    else False
                )
                condition.compress(
                    valuespace=condition.valuespaces,
                    # NOTE: We wish to drop where condition==False (or None) given summarize op
                    treat_false_as_null=True,
                    drop=drop,
                    summarize=summarize,
                    inplace=True,
                )
            return condition

        # Handle non-variate (index) Quble subject
        elif grace:
            # Treat is if values were all boolean Trues (all not missings)
            return subject.copy() if subject.shares_table_with(self) else subject
        else:
            raise NoValuespaceError(f"no valuespace and grace={grace}")

    def where_zero(
        self,
        valuespace="<numeric_valuespaces>",
        compress="any",
        grace: bool = True,
        as_type=None,
    ) -> Quble:
        """
        See :meth:`~qubles.core.quble.Quble.where_missing`
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate the valuespace arg
        valuespace = self.validate_valuespace(
            valuespace=valuespace, grace=False, coerce_to_list=True
        )

        # Limit subject to valuespaces of interest
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)

        # Handle variate Quble subject
        if subject.is_variate:
            column_expressions = {}
            cast_dict = {} if as_type else None
            for vs in subject.valuespaces:
                column_expressions[vs] = f'"{vs}" = 0'
                if as_type:
                    cast_dict[vs] = as_type

            condition = subject.select(
                column_names="<all>",
                column_expressions=column_expressions,
                where_clause=None,
                cast_dict=cast_dict,
                info_type_exclusions=["fx", "time_basis"],
            )
            if compress:
                summarize = (
                    "all"
                    if isinstance(compress, str) and (compress.find("all") >= 0)
                    else "any"
                )
                drop = (
                    True
                    if isinstance(compress, str) and (compress.find("drop") >= 0)
                    else False
                )
                condition.compress(
                    valuespace=condition.valuespaces,
                    # NOTE: We wish to drop where condition==False (or None) given summarize op
                    treat_false_as_null=True,
                    drop=drop,
                    summarize=summarize,
                    inplace=True,
                )

            return condition

        # Handle non-variate (index) Quble subject
        elif grace:
            # Treat is if values were all boolean Trues (no zeros)
            return subject.clear()
        else:
            raise NoValuespaceError(f"no valuespace and grace={grace}")

    def where_non_zero(
        self,
        valuespace="<numeric_valuespaces>",
        compress="any",
        grace: bool = True,
        as_type=None,
    ) -> Quble:
        """
        See :meth:`~qubles.core.quble.Quble.where_missing`
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate the valuespace arg
        valuespace = self.validate_valuespace(
            valuespace=valuespace, grace=False, coerce_to_list=True
        )

        # Limit subject to valuespaces of interest
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)

        # Handle variate Quble subject
        if subject.is_variate:
            column_expressions = {}
            cast_dict = {} if as_type else None
            for vs in subject.valuespaces:
                column_expressions[vs] = f'"{vs}" <> 0'
                if as_type:
                    cast_dict[vs] = as_type

            condition = subject.select(
                column_names="<all>",
                column_expressions=column_expressions,
                where_clause=None,
                cast_dict=cast_dict,
                info_type_exclusions=["fx", "time_basis"],
            )
            if compress:
                summarize = (
                    "all"
                    if isinstance(compress, str) and (compress.find("all") >= 0)
                    else "any"
                )
                drop = (
                    True
                    if isinstance(compress, str) and (compress.find("drop") >= 0)
                    else False
                )
                condition.compress(
                    valuespace=condition.valuespaces,
                    # NOTE: We wish to drop where condition==False (or None) given summarize op
                    treat_false_as_null=True,
                    drop=drop,
                    summarize=summarize,
                    inplace=True,
                )

            return condition

        # Handle non-variate (index) Quble subject
        elif grace:
            # Treat is if values were all boolean Trues (all non-zero)
            return subject.copy() if subject.shares_table_with(self) else subject
        else:
            raise NoValuespaceError(f"no valuespace and grace={grace}")

    def where_pos(
        self,
        valuespace="<numeric_valuespaces>",
        compress="any",
        grace: bool = True,
        as_type=None,
    ) -> Quble:
        """
        See :meth:`~qubles.core.quble.Quble.where_missing`
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate the valuespace arg
        valuespace = self.validate_valuespace(
            valuespace=valuespace, grace=False, coerce_to_list=True
        )

        # Limit subject to valuespaces of interest
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)

        # Handle variate Quble subject
        if subject.is_variate:
            column_expressions = {}
            cast_dict = {} if as_type else None
            for vs in subject.valuespaces:
                column_expressions[vs] = f'"{vs}" > 0'
                if as_type:
                    cast_dict[vs] = as_type

            condition = subject.select(
                column_names="<all>",
                column_expressions=column_expressions,
                where_clause=None,
                cast_dict=cast_dict,
                info_type_exclusions=["fx", "time_basis"],
            )
            if compress:
                summarize = (
                    "all"
                    if isinstance(compress, str) and (compress.find("all") >= 0)
                    else "any"
                )
                drop = (
                    True
                    if isinstance(compress, str) and (compress.find("drop") >= 0)
                    else False
                )
                condition.compress(
                    valuespace=condition.valuespaces,
                    # NOTE: We wish to drop where condition==False (or None) given summarize op
                    treat_false_as_null=True,
                    drop=drop,
                    summarize=summarize,
                    inplace=True,
                )

            return condition

        # Handle non-variate (index) Quble subject
        elif grace:
            # Treat is if values were all boolean Trues (all positive)
            return subject.copy() if subject.shares_table_with(self) else subject
        else:
            raise NoValuespaceError(f"no valuespace and grace={grace}")

    def where_non_pos(
        self,
        valuespace="<numeric_valuespaces>",
        compress="any",
        grace: bool = True,
        as_type=None,
    ) -> Quble:
        """
        See :meth:`~qubles.core.quble.Quble.where_missing`
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate the valuespace arg
        valuespace = self.validate_valuespace(
            valuespace=valuespace, grace=False, coerce_to_list=True
        )

        # Limit subject to valuespaces of interest
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)

        # Handle variate Quble subject
        if subject.is_variate:
            column_expressions = {}
            cast_dict = {} if as_type else None
            for vs in subject.valuespaces:
                column_expressions[vs] = f'"{vs}" <= 0'
                if as_type:
                    cast_dict[vs] = as_type

            condition = subject.select(
                column_names="<all>",
                column_expressions=column_expressions,
                where_clause=None,
                cast_dict=cast_dict,
                info_type_exclusions=["fx", "time_basis"],
            )
            if compress:
                summarize = (
                    "all"
                    if isinstance(compress, str) and (compress.find("all") >= 0)
                    else "any"
                )
                drop = (
                    True
                    if isinstance(compress, str) and (compress.find("drop") >= 0)
                    else False
                )
                condition.compress(
                    valuespace=condition.valuespaces,
                    # NOTE: We wish to drop where condition==False (or None) given summarize op
                    treat_false_as_null=True,
                    drop=drop,
                    summarize=summarize,
                    inplace=True,
                )

            return condition

        # Handle non-variate (index) Quble subject
        elif grace:
            # Treat is if values were all boolean Trues (no non-positive)
            return subject.clear()
        else:
            raise NoValuespaceError(f"no valuespace and grace={grace}")

    def where_neg(
        self,
        valuespace="<numeric_valuespaces>",
        compress="any",
        grace: bool = True,
        as_type=None,
    ) -> Quble:
        """
        See :meth:`~qubles.core.quble.Quble.where_missing`
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate the valuespace arg
        valuespace = self.validate_valuespace(
            valuespace=valuespace, grace=False, coerce_to_list=True
        )

        # Limit subject to valuespaces of interest
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)

        # Handle variate Quble subject
        if subject.is_variate:
            column_expressions = {}
            cast_dict = {} if as_type else None
            for vs in subject.valuespaces:
                column_expressions[vs] = f'"{vs}" < 0'
                if as_type:
                    cast_dict[vs] = as_type

            condition = subject.select(
                column_names="<all>",
                column_expressions=column_expressions,
                where_clause=None,
                cast_dict=cast_dict,
                info_type_exclusions=["fx", "time_basis"],
            )
            if compress:
                summarize = (
                    "all"
                    if isinstance(compress, str) and (compress.find("all") >= 0)
                    else "any"
                )
                drop = (
                    True
                    if isinstance(compress, str) and (compress.find("drop") >= 0)
                    else False
                )
                condition.compress(
                    valuespace=condition.valuespaces,
                    # NOTE: We wish to drop where condition==False (or None) given summarize op
                    treat_false_as_null=True,
                    drop=drop,
                    summarize=summarize,
                    inplace=True,
                )

            return condition

        # Handle non-variate (index) Quble subject
        elif grace:
            # Treat is if values were all boolean Trues (no negative)
            return subject.clear()

    def where_non_neg(
        self,
        valuespace="<numeric_valuespaces>",
        compress="any",
        grace: bool = True,
        as_type=None,
    ) -> Quble:
        """
        See :meth:`~qubles.core.quble.Quble.where_missing`
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate the valuespace arg
        valuespace = self.validate_valuespace(
            valuespace=valuespace, grace=False, coerce_to_list=True
        )

        # Limit subject to valuespaces of interest
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)

        # Handle variate Quble subject
        if subject.is_variate:
            column_expressions = {}
            cast_dict = {} if as_type else None
            for vs in subject.valuespaces:
                column_expressions[vs] = f'"{vs}" >= 0'
                if as_type:
                    cast_dict[vs] = as_type

            condition = subject.select(
                column_names="<all>",
                column_expressions=column_expressions,
                where_clause=None,
                cast_dict=cast_dict,
                info_type_exclusions=["fx", "time_basis"],
            )
            if compress:
                summarize = (
                    "all"
                    if isinstance(compress, str) and (compress.find("all") >= 0)
                    else "any"
                )
                drop = (
                    True
                    if isinstance(compress, str) and (compress.find("drop") >= 0)
                    else False
                )
                condition.compress(
                    valuespace=condition.valuespaces,
                    # NOTE: We wish to drop where condition==False (or None) given summarize op
                    treat_false_as_null=True,
                    drop=drop,
                    summarize=summarize,
                    inplace=True,
                )

            return condition

        # Handle non-variate (index) Quble subject
        elif grace:
            # Treat is if values were all boolean Trues (all non-negative)
            return subject.copy() if subject.shares_table_with(self) else subject
        else:
            raise NoValuespaceError(f"no valuespace and grace={grace}")

    def null_scalar(self, space="<valuespace>") -> Quble:
        """
        Makes a null (scalar Quble)
        from the specified space(s) / column(s)
        of the Quble's table
        """
        if self.is_undefined:
            raise UndefinedQubleError("Undefined Quble (no table)")

        # Validate space arg and coerce to a list
        space = self.validate_space(space=space, grace=False, coerce_to_list=True)

        # SELECT THE COLUMN W/O DATA THEN INSERT A SINGLE NULL RECORD
        result = self.select(
            column_names=space,
            where_clause=None,
            tgt_insertions=[["NULL"] * len(space)],
            data_exclusion="WITH NO DATA",
        )

        # Loop through result's spaces...
        for space1 in result.spaces:
            # ----------------------------------------------
            # In the case of time-spaces,
            # to remove info_type='freq'
            # as this information will have changed
            # [null timestamps do not conform to a freq]
            # ----------------------------------------------
            if result.has_space_info(info_type="freq", space=space1):
                result.remove_space_info(space=space1, info_type="freq")

            # Also, we may need to mark the
            # scalar's column(s) as valuespace column(s)
            # ----------------------------------------------
            if not result.has_space_info(info_type="role", space=space1):
                result.set_space_info(
                    space=space1, info_type="role", info_value="valuespace"
                )

        return result

    def random_sampler(
        self,
        num_samples: int = 1000,
        sampling_keyspaces: str | list = "<keyspaces>",
        space_retention_role: str = None,
        sample_number_keyspace: str = "sample_number",
        allow_oversampling: bool = True,
        zero_base: bool = False,
    ):
        """
        Randomly samples a Quble
        Here, the random samles are drawn from
        across the specified sampling_keyspaces

        New <sample_number_keyspace> column (type:integer/numeric) will appear in result.
        Any 'orthogonal' keyspaces (not included in sampling_keyspaces) will be retained.
        The sampling keyspaces may (or may not) be retained - depending on space_retention_role arg.

        When there are no orthogonal keyspaces:
            ===> # resultant rows: num_samples

        When orthogonal keyspaces are present:
            ===> # resultant rows: (num_ortho_key_combos) * num_samples

        When allow_oversampling==True: num_samples arg may be larger than
        the number of original subset 'orthogonal records' for each orthogonal key combinations

        :param num_samples: The number of samples to draw from each 'ortho' key combination
        :type num_samples: int

        :param sampling_keyspaces: keyspaces (index columns) for sampling
        :type sampling_keyspaces: list (of strings) or str

        :param space_retention_role: (optional) role of retained sampling keyspaces (if applicable)
            ==> If space_retention_role is None: sampling keyspaces WILL NOT be retained
        :type space_retention_role: None or str ("keyspace" or "valuespace")

        :param sample_number_keyspace: new keyspace/index column (type:integer/numeric) for sample numbers
        :type sample_number_keyspace: str

        :param allow_oversampling: flag to allow 'oversampling'
            ==> oversampling: more random samples than original samples
        :type allow_oversampling: bool (True*/False)

        :param zero_base: flag to impose zero-base for sampling numbers
        :type zero_base: bool (False*/True)
            zero_base:True ==> lowest sample number will be zero
            zero_base:False ==> lowest sample number will be one
        """
        # Validate self/subject Quble
        if self.is_undefined:
            return self.copy()
        elif self.is_empty:
            # What is best way to handle this case?
            # return self.copy()
            num_samples = 0
        elif self.is_scalar or self.is_multiscalar:
            # TODO: If/how to handle scalar Quble case
            raise Exception(f"Quble must not be scalar/multi-scalar")

        # Validate num_samples arg
        if num_samples is None or not isinstance(num_samples, int) or num_samples < 0:
            raise Exception(
                f"Invalid num_samples:{num_samples}...non-negative integer required"
            )

        # Validate sampling_keyspaces arg
        sampling_keyspaces = self.validate_keyspace(
            sampling_keyspaces, coerce_to_list=True, grace=False
        )
        if sampling_keyspaces is None or len(sampling_keyspaces) == 0:
            raise Exception("No sampling_keyspaces present/identified")

        # Validate sample_number_keyspace arg
        if sample_number_keyspace is None:
            raise Exception(f"sample_number_keyspace arg required")
        elif not isinstance(sample_number_keyspace, str):
            raise Exception(
                f"Invalid sample_number_keyspace:{sample_number_keyspace}...string required"
            )

        # Establish orthogonal keyspaces (if present)
        ortho_keyspaces = self.ortho_keyspaces(sampling_keyspaces)

        # Determine the number of 'ortho_records'
        # and number of crossers needed for each orthogonal keyset
        if self.is_variate:
            # Since we are using ignore_missing=True, the actual valuespace arh is arbitrary
            ortho_counts = self.count(
                aggr_keyspaces=sampling_keyspaces,
                valuespace=self.valuespace,
                ignore_missing=True,
            )
            orig_vs = self.valuespace
        else:
            # Add an arbitrary (boolean) valuespace here in order to construct count
            orig_vs = None
            valued_subject = self.index_to_bool()
            ortho_counts = valued_subject.count(
                aggr_keyspaces=sampling_keyspaces,
                valued_subject=self.valuespace,
                ignore_missing=True,
            )

        # Establish min_ortho_count (Paython literal integer/floaf)
        # NOTE: When there are no ortho_keyspaces, ortho_counts will be a uni-variate scalar Quble
        # NOTE: When there are ortho_keyspaces, ortho_counts will be a multi-dimensional, uni-variate Quble

        if ortho_counts.is_undefined:
            raise Exception(f"ortho_counts is unexpectedly an undefined Quble")
        elif ortho_counts.is_nonvariate:
            raise Exception(f"ortho_counts is unexpectedly non-variate Quble")

        # Investigate over-sampling violation
        if allow_oversampling:
            pass
        else:
            # Here, we need to preclude oversampling condition
            if ortho_counts.is_empty:
                # What is best way to handle this case?
                min_count_literal = 0
            elif ortho_counts.is_scalar or ortho_counts.is_multiscalar:
                min_count_df = ortho_counts.to_pandas_df()
                min_count_literal = min_count_df[ortho_counts.valuespace][0]
            else:
                min_count_df = ortho_counts.max().to_pandas_df()
                min_count_literal = min_count_df[ortho_counts.valuespace][0]

            if min_count_literal >= 0 and min_count_literal < num_samples:
                raise Exception(
                    f"min_count_literal:{min_count_literal} < num_samples:{num_samples} yet allow_oversampling:{allow_oversampling}"
                )

        # Perform random sampler query accordingly
        table_name = generate_random_table_name()

        sql_template = JINJA_ENV.get_template("random_sampler.j2")

        sql_command = sql_template.render(
            src_table_name=self.table_name,
            tgt_table_name=table_name,
            num_samples=num_samples,
            sampling_keyspaces=sampling_keyspaces,
            ortho_keyspaces=ortho_keyspaces,
            valuespaces=self.valuespaces,
            sample_number_keyspace=sample_number_keyspace,
            space_retention_role=space_retention_role is not None,
            zero_base=zero_base,
        )
        execute(sql_command)

        # Establish desired col_info (dictionary)
        if space_retention_role is None:
            retained_columns = [
                space1 for space1 in self.spaces if space1 not in sampling_keyspaces
            ]
        else:
            retained_columns = self.spaces

        col_info = self.get_space_info(
            info_type=CUSTOM_INFO_TYPES,
            space=retained_columns,
            omit_unassigned=True,
        )
        if col_info is None:
            col_info = {}
        if "role" not in col_info:
            col_info["role"] = {}
        # Add role for newly inserted column: sample_number_keyspace
        col_info["role"][sample_number_keyspace] = "keyspace"

        # When retaining sampling_keyspaces,
        # assign the appropriate role accordingly
        if space_retention_role is None:
            pass
        elif not isinstance(space_retention_role, str):
            raise Exception(
                f"Invalid space_retention_role:{space_retention_role}...string required"
            )
        elif space_retention_role not in ("keyspace", "valuespace"):
            raise Exception(
                f"Invalid space_retention_role:{space_retention_role}...must be either 'keyspace' or 'valuespace'"
            )
        else:
            for ks in sampling_keyspaces:
                col_info["role"][ks] = space_retention_role

        # Build a new Quble from the newly populated table accordingly
        result = Quble.from_table(
            table_name,
            col_info=col_info,
        )
        # Confirm/impose original valuespace
        if (
            result.is_defined
            and result.valuespace is not None
            and orig_vs is not None
            and orig_vs in result.valuespaces
            and result.valuespace != orig_vs
        ):
            result.valuespace = orig_vs

        # Return the resultant Quble
        return result

    # =========================== CONDITIONAL SETTING =============================
    @RootLib.lazy_kwargs()
    def conditional_nullify_inplace(
        self,
        condition: Quble,
        valuespace="<valuespace>",
        variate_mode: str = RootLib.lazy_eval("variate_mode"),
        allow_float_conditions: bool = True,
    ):
        """
        See :meth:`~qubles.core.quble.Quble.conditional_nullify`
        """
        return self.conditional_nullify(
            condition,
            valuespace=valuespace,
            variate_mode=variate_mode,
            inplace=True,
            allow_float_conditions=allow_float_conditions,
        )

    @RootLib.lazy_kwargs()
    def conditional_nullify(
        self,
        condition: Quble,
        valuespace="<valuespace>",
        variate_mode: str = RootLib.lazy_eval("variate_mode"),
        inplace: bool = False,
        allow_float_conditions: bool = True,
    ):
        """
        Nullifies values across the specified valuespace(s) column(s)
        according to the condition Quble depending on variate_mode.

        :param valuespace: target valuespace to be assigned
                           (only applies when variate_mode=='uni')
                           [If variate_mode != 'uni': valuespace arg is ignored]
        :type valuespace: str

        :param variate_mode: Controls uni-variate / multi-variate assignment
        :type variate_mode: str ('uni','mixed','multi')

        :param inplace: Controls self-modification vs returning a modified copy
        :type inplace: bool (False*/True)

        :param allow_float_conditions: Flag to allow float/numeric conditions
        :type allow_float_conditions: bool (True*/False)

        See :meth:`~qubles.core.quble.Quble.set`
        """
        # Handle trivial cases
        if self.is_undefined or self.is_nonvariate or self.is_empty:
            return self if inplace else self.copy()

        # Validate the valuespace arg and coerce to a list
        valuespace = self.validate_valuespace(valuespace, coerce_to_list=True)

        # Validate condition
        # ----------------------
        if not isinstance(condition, Quble):
            raise Exception("Invalid condition....Quble required")
        elif condition.is_index:
            condition = condition.index_to_bool()
        else:
            # Isolate the relevant valuespaces from condition Quble (per variate_mode)
            relevant_condition_valuespaces = (
                [condition.valuespace]
                if variate_mode == "uni"
                else condition.valuespaces
            )

            # Are all relevant conditional valuespaces boolean?
            if not condition.is_bool(
                space=relevant_condition_valuespaces, grace=True, summarize="all"
            ):
                if not allow_float_conditions:
                    raise Exception(
                        "Invalid condition valuespace types:{0}...bool values required".format(
                            condition.get_space_info(
                                info_type=type, space=relevant_condition_valuespaces
                            )
                        )
                    )
                else:
                    # Try to coerce any numeric valuespaces to bool
                    cast_dict = {}
                    for vs in relevant_condition_valuespaces:
                        if condition.is_bool(space=vs):
                            pass
                        elif condition.is_numeric(space=vs):
                            cast_dict[vs] = "boolean"
                        else:
                            raise Exception(
                                "Invalid condition valuespace type:{0}...bool (or numeric) required".format(
                                    condition.get_space_info(info_type="type", space=vs)
                                )
                            )
                    condition = condition.select(
                        column_names="<all>", cast_dict=cast_dict
                    )

        # -----------------------------------------------------------------------
        # Build a null_scalar Quble for self's valuespaces
        # -----------------------------------------------------------------------
        # NOTE: use all self's valuespaces here (regardless of variate_mode)
        # ==>Quble.set() will only utilize relevant valuespaces from null_scalar
        # -----------------------------------------------------------------------
        null_scalar = self.null_scalar(space=self.valuespaces)

        # Replace condition locations
        # with null values from null_scalar Quble
        subject = self if inplace else self.copy()
        subject.set(
            condition, null_scalar, valuespace=valuespace, variate_mode=variate_mode
        )
        if inplace:
            subject._clear_num_records_caches()
            return subject
        else:
            return subject

    @RootLib.lazy_kwargs()
    def conditional_replace_inplace(
        self,
        condition: Quble,
        new_value,
        valuespace="<valuespace>",
        variate_mode: str = RootLib.lazy_eval("variate_mode"),
        allow_float_conditions: bool = True,
    ):
        """
        See :meth:`~qubles.core.quble.Quble.conditional_replace`
        """
        return self.conditional_replace(
            condition,
            new_value=new_value,
            valuespace=valuespace,
            variate_mode=variate_mode,
            inplace=True,
            allow_float_conditions=allow_float_conditions,
        )

    def conditional_replace(
        self,
        condition: Quble,
        new_value,
        valuespace="<valuespace>",
        variate_mode: str = RootLib.lazy_eval("variate_mode"),
        inplace: bool = False,
        allow_float_conditions: bool = True,
    ):
        """
        If variate_mode == "uni":
           Replaces values in the specified valuespace
           with specified replacement value from the
           primary valuespace of new_value Quble
           at the condition where the provided (boolean)
           'conditional' Quble's PRIMARY valuespace is True

        If variate_mode in ("multi","mixed"):
           Replaces values in multiple valuespaces of self
           with specified replacement value from the
           the valuespaces of new_value Quble
           at the condition where the provided (boolean)
           'conditional' Quble's PRIMARY valuespace is True
           Here, the valuespaces to be replaced are those in condition Quble
           [IMPORTANT: In this case, valuespace arg is IGNORED]

        .. note::
            Will convert/reindex index of 'condition' argument to that of self object

        :param condition: A Quble of boolean values with matching dimensions in which True values indicate
            the value with the same index in self should be replaced.
        :type condition: qubles.core.quble.Quble of bool

        :param new_value : The new value with which items matching the condition function should be replaced.
        :type new_value: varies (should be same as values array dtype)

        :param valuespace: target valuespace to be assigned
                           (only applies when variate_mode=='uni')
                           [If variate_mode != 'uni': valuespace arg is ignored]
        :type valuespace: str

        :param variate_mode: Controls uni-variate / multi-variate assignment
        :type variate_mode: str ('uni','mixed','multi')

        :param inplace: Controls self-modification vs returning a modified copy
        :type inplace: bool (False*/True)

        :param allow_float_conditions: Flag to allow float/numeric conditions
        :type allow_float_conditions: bool (True*/False)

        :returns: Quble with instances replaced accordingly filled
        :rtype: qubles.core.quble.Quble

        See :meth:`~qubles.core.quble.Quble.conditional_nullify`
        """
        # Handle trivial cases
        if self.is_undefined or self.is_nonvariate or self.is_empty:
            return self if inplace else self.copy()
        elif condition.is_undefined:
            return self if inplace else self.copy()
        elif condition.is_empty:
            # Empty condition with no orthogonal keyspaces to insert no replacement <==> leave everything unchanged simply return trivial result according to inplace arg
            conditional_ortho_keyspaces = condition.ortho_keyspaces(
                self.keyspaces, grace=True
            )
            if (
                conditional_ortho_keyspaces is None
                or len(conditional_ortho_keyspaces) == 0
            ):
                return self if inplace else self.copy()

        # Validate the valuespace arg and coerce to a list
        valuespace = self.validate_valuespace(valuespace, coerce_to_list=True)

        # Validate condition
        # ----------------------
        if not isinstance(condition, Quble):
            raise Exception("Invalid condition....Quble required")
        elif condition.is_index:
            condition = condition.index_to_bool()
        else:
            # Validate variate_mode and build relevant_condition_valuespaces
            # [To isolate the relevant valuespaces from condition Quble (per variate_mode)]
            if variate_mode in ("multi", "mixed"):
                # Isolate the common valuespaces between condition (Quble) and subject (Quble)
                relevant_condition_valuespaces = condition.valuespaces
            elif variate_mode != "uni":
                raise Exception(
                    f"Invalid variate_mode:{variate_mode}...'uni', 'multi' or 'mixed' required"
                )
            else:
                relevant_condition_valuespaces = [condition.valuespace]

            # Are all relevant conditional valuespaces boolean?
            if not condition.is_bool(
                space=relevant_condition_valuespaces, grace=True, summarize="all"
            ):
                if not allow_float_conditions:
                    raise Exception(
                        "Invalid condition valuespace types:{0}...bool values required".format(
                            condition.get_space_info(
                                info_type="type", space=relevant_condition_valuespaces
                            )
                        )
                    )
                else:
                    # Try to coerce any numeric valuespaces to bool
                    cast_dict = {}
                    for vs in relevant_condition_valuespaces:
                        if condition.is_bool(space=vs):
                            pass
                        elif condition.is_numeric(space=vs):
                            cast_dict[vs] = "boolean"
                        else:
                            raise Exception(
                                "Invalid condition valuespace type:{0}...bool (or numeric) required".format(
                                    condition.get_space_info(info_type="type", space=vs)
                                )
                            )
                    condition = condition.select(
                        column_names="<all>", cast_dict=cast_dict
                    )

        # Replace condition locations
        # with values from new_value Quble
        subject = self if inplace else self.copy()
        subject.set(
            condition, new_value, valuespace=valuespace, variate_mode=variate_mode
        )

        if inplace:
            subject._clear_num_records_caches()
            return subject
        else:
            return subject

    @RootLib.lazy_kwargs()
    def complementary_replace_inplace(
        self,
        condition: Quble,
        new_value,
        valuespace="<valuespace>",
        variate_mode: str = RootLib.lazy_eval("variate_mode"),
        allow_float_conditions: bool = True,
    ):
        """
        See :meth:`~qubles.core.quble.Quble.complementary_replace`
        """
        return self.complementary_replace(
            condition,
            new_value=new_value,
            valuespace=valuespace,
            variate_mode=variate_mode,
            inplace=True,
            allow_float_conditions=allow_float_conditions,
        )

    def complementary_replace(
        self,
        condition: Quble,
        new_value,
        valuespace="<valuespace>",
        variate_mode: str = RootLib.lazy_eval("variate_mode"),
        inplace: bool = False,
        allow_float_conditions: bool = True,
    ):
        """
        Replaces values with specified replacement value at hyper_index
        where a provided (boolean) 'conditional' Quble is NOT True

        :param condition: 'conditional' (boolean)  Quble
        :type condition: qubles.core.quble.Quble of bool

        :param new_value: new value of similar kind (should be same type as self's valuespace)
        :type new_values: varies

        :param valuespace: target valuespace to be assigned
                           (only applies when variate_mode=='uni')
                           [If variate_mode != 'uni': valuespace arg is ignored]
        :type valuespace: str

        :param variate_mode: Controls uni-variate / multi-variate assignment
        :type variate_mode: str ('uni','mixed','multi')

        :param inplace: Controls self-modification vs returning a modified copy
        :type inplace: bool (False*/True)

        :param allow_float_conditions: Flag to allow float/numeric conditions
        :type allow_float_conditions: bool (True*/False)

        :returns: Quble with instances replaced accordingly filled
        :rtype: qubles.core.quble.Quble

        See :meth:`~qubles.core.quble.Quble.conditional_nullify`
        """
        # Handle trivial cases
        if self.is_undefined or self.is_nonvariate or self.is_empty:
            return self if inplace else self.copy()

        # Validate the valuespace arg and coerce to a list
        valuespace = self.validate_valuespace(valuespace, coerce_to_list=True)

        # Validate condition
        # ----------------------
        if not isinstance(condition, Quble):
            raise Exception("Invalid condition....Quble required")
        elif condition.is_index:
            condition = condition.index_to_bool()
            relevant_condition_valuespaces = [condition.valuespace]
        else:
            # Isolate the relevant valuespaces from condition Quble (per variate_mode)
            relevant_condition_valuespaces = (
                [condition.valuespace]
                if variate_mode == "uni"
                else condition.valuespaces
            )

            # Are all relevant conditional valuespaces boolean?
            if not condition.is_bool(
                space=relevant_condition_valuespaces, grace=True, summarize="all"
            ):
                if not allow_float_conditions:
                    raise Exception(
                        "Invalid condition valuespace types:{0}...bool values required".format(
                            condition.get_space_info(
                                info_type="type", space=relevant_condition_valuespaces
                            )
                        )
                    )
                else:
                    # Try to coerce any numeric valuespaces to bool
                    cast_dict = {}
                    for vs in relevant_condition_valuespaces:
                        if condition.is_bool(space=vs):
                            pass
                        elif condition.is_numeric(space=vs):
                            cast_dict[vs] = "boolean"
                        else:
                            raise Exception(
                                "Invalid condition valuespace type:{0}...bool (or numeric) required".format(
                                    condition.get_space_info(info_type="type", space=vs)
                                )
                            )
                    condition = condition.select(
                        column_names="<all>", cast_dict=cast_dict
                    )

        # Expand condition to include self's key's & keyspaces
        # TODO: In join method below: freq=self.context_freq()
        condition = condition.outer_project(self)

        # Loop through relevant condition valuespaces
        column_expressions = {}
        for vs in relevant_condition_valuespaces:
            # Generate complement by swapping True/False boolean values
            bool_convert_expression = (
                'CASE WHEN "'
                + vs
                + '" = false THEN true '
                + 'WHEN "'
                + vs
                + '" = true THEN false '
                + 'WHEN "'
                + vs
                + '" IS NULL THEN NULL '
                + " END"
            )
            column_expressions[vs] = bool_convert_expression

        # Invoke column_expressions to generate complement Quble
        complement = condition.select(
            column_names="<all>", column_expressions=column_expressions
        )

        # Replace complement locations
        # with values from new_value Quble
        subject = self if inplace else self.copy()
        subject.set(
            complement, new_value, valuespace=valuespace, variate_mode=variate_mode
        )
        if inplace:
            subject._clear_num_records_caches()
            return subject
        else:
            return subject

    # =========================== CONDITIONAL GETTING =============================

    @RootLib.lazy_kwargs()
    def conditional_keep_inplace(
        self,
        condition: Quble,
        allow_float_conditions: bool = True,
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        auto_expand: bool = RootLib.lazy_eval("auto_expand"),
    ):
        """
        See :meth:`~qubles.core.quble.Quble.conditional_keep`
        """
        return self.conditional_keep(
            condition=condition,
            inplace=True,
            allow_float_conditions=allow_float_conditions,
            auto_squeeze=auto_squeeze,
            auto_expand=auto_expand,
        )

    @RootLib.lazy_kwargs()
    def conditional_keep(
        self,
        condition: Quble,
        inplace: bool = False,
        allow_float_conditions: bool = True,
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        auto_expand: bool = RootLib.lazy_eval("auto_expand"),
    ):
        """
        Keeps records where a provided 'conditional' Quble is True
        ==> All original valuespaces of self will be preserved!
        ==> NOT affected/dependent on variate_mode
        ==> When condition is a variate Quble: directed by the (boolean) PRIMARY valuespace of condition

        :param condition: 'conditional' (boolean)  Quble
        :type condition: qubles.core.quble.Quble of bool

        :param inplace: Controls self-modification vs returning a modified copy
        :type inplace: bool (False*/True)

        :param valuespace: target valuespace to be assigned
                           (only applies when variate_mode=='uni')
                           [If variate_mode != 'uni': valuespace arg is ignored]
        :type valuespace: str

        :param variate_mode: Controls uni-variate / multi-variate assignment
        :type variate_mode: str ('uni','mixed','multi')

        :param allow_float_conditions: Flag to allow float/numeric conditions
        :type allow_float_conditions: bool (True*/False)

        :param allow_float_conditions: flag to allow float conditions
        :type allow_float_conditions: bool

        :param auto_squeeze: flag to squueze dimensions of for single key keeping
        :type auto_squeeze: bool

        :param auto_expand: flag to allow dimensional expansion
        :type auto_expand: bool

        :returns: Quble with instances replaced accordingly filled
        :rtype: qubles.core.quble.Quble

        See :meth:`~qubles.core.quble.Quble.conditional_nullify`
        """
        # Handle trivial cases
        if self.is_undefined or self.is_empty:
            return self if inplace else self.copy()

        # Validate condition
        # ----------------------
        if not isinstance(condition, Quble):
            raise Exception("Invalid condition....Quble required")
        elif condition.is_index:
            pass
        # Otherwise, convert condition to an index Quble
        elif condition.is_bool():
            condition = condition.bool_to_index()
        elif allow_float_conditions and condition.is_numeric():
            condition = condition.select(
                cast_dict={condition.valuespace: "boolean"}
            ).bool_to_index()
        else:
            raise Exception(
                "Invalid condition.valuespace type:{0}...bool values required".format(
                    condition.get_space_info(
                        info_type="type", space=condition.valuespace
                    )
                )
            )

        # Extract the values to keep
        result = self.get(condition, auto_squeeze=auto_squeeze, auto_expand=auto_expand)

        # Handle return according to inplace arg
        if inplace:
            self._swap_table(result)
            return None
        else:
            return result

    @RootLib.lazy_kwargs()
    def conditional_remove_inplace(
        self,
        condition: Quble,
        allow_float_conditions: bool = True,
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ):
        """
        See :meth:`~qubles.core.quble.Quble.conditional_remove`
        """
        return self.conditional_remove(
            condition=condition,
            inplace=True,
            allow_float_conditions=allow_float_conditions,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def conditional_remove(
        self,
        condition: Quble,
        inplace: bool = False,
        allow_float_conditions: bool = True,
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ):
        """
        Removes records where a provided (index or univariate boolean) 'conditional' Quble is True
        Keeps values where a provided (boolean) 'conditional' Quble's primary valuespace is NOT True

        ==> All original valuespaces of self will be preserved!
        ==> NOT affected/dependent on variate_mode
        ==> When condition is a variate Quble: directed by the (boolean) PRIMARY valuespace of condition

        :param condition: 'conditional' (boolean)  Quble
        :type conditional: qubles.core.quble.Quble of bool

        :param inplace: Controls self-modification vs returning a modified copy
        :type inplace: bool (False*/True)

        :param allow_float_conditions: flag to allow float conditions
        :type allow_float_conditions: bool

        :param auto_squeeze: flag to squueze dimensions of for single key keeping
        :type auto_squeeze: bool

        :returns: Quble with records removed accordingly
        :rtype: qubles.core.quble.Quble

        """
        return self.complementary_keep(
            condition=condition,
            inplace=inplace,
            allow_float_conditions=allow_float_conditions,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def complementary_keep_inplace(
        self,
        condition: Quble,
        allow_float_conditions: bool = True,
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ):
        """
        See :meth:`~qubles.core.quble.Quble.complementary_keep`
        """
        return self.complementary_keep(
            condition=condition,
            inplace=True,
            allow_float_conditions=allow_float_conditions,
            auto_squeeze=auto_squeeze,
        )

    @RootLib.lazy_kwargs()
    def complementary_keep(
        self,
        condition: Quble,
        inplace: bool = False,
        allow_float_conditions: bool = True,
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
    ):
        """
        Keeps records where a provided (index or univariate boolean) 'conditional' Quble is NOT True
        Removes records where a provided (index or univariate boolean) 'conditional' Quble is True

        ==> All original valuespaces of self will be preserved!
        ==> NOT affected/dependent on variate_mode
        ==> When condition is a variate Quble: directed by the (boolean) PRIMARY valuespace of condition

        :param condition: 'conditional' (index or boolean valued)  Quble
        :type conditional: qubles.core.quble.Quble of bool

        :param inplace: Controls self-modification vs returning a modified copy
        :type inplace: bool (False*/True)

        :param allow_float_conditions: flag to allow float conditions
        :type allow_float_conditions: bool

        :param auto_squeeze: flag to squueze dimensions of for single key keeping
        :type auto_squeeze: bool

        :returns: Quble with records removed accordingly
        :rtype: qubles.core.quble.Quble

        """
        # Handle trivial cases
        if self.is_undefined or self.is_empty:
            return self if inplace else self.copy()
        elif condition.is_undefined:
            return self if inplace else self.copy()
        elif condition.is_empty:
            # Empty condition with no orthogonal keyspaces to insert no complement <==> keep everything
            # simply return trivial result according to inplace arg
            conditional_ortho_keyspaces = condition.ortho_keyspaces(
                self.keyspaces, grace=True
            )
            if (
                conditional_ortho_keyspaces is None
                or len(conditional_ortho_keyspaces) == 0
            ):
                return self if inplace else self.copy()

        # Validate condition and ensure bool variate
        # --------------------------------------------
        if not isinstance(condition, Quble):
            raise Exception("Invalid condition....Quble required")
        elif condition.is_index:
            condition = condition.index_to_bool()
        # Otherwise, convert condition to an index Quble
        elif condition.is_bool():
            pass
        elif allow_float_conditions and condition.is_numeric():
            condition = condition.select(cast_dict={condition.valuespace: "boolean"})
        else:
            raise Exception(
                "Invalid condition valuespace type:{0}...bool values required".format(
                    condition.get_space_info(
                        info_type="type", space=condition.valuespace
                    )
                )
            )

        # Expand condition to include self's key's & keyspaces
        # [This step may introduce new records into condition Quble]
        # TODO: In join method below: freq=self.context_freq()
        condition = condition.outer_project(self)

        # Make sure condition has a non-trivial primary valuespace
        if condition.valuespace is None:
            raise Exception("Internal inconsistency...condition.valuespace is None")

        # Generate complement by swapping True/False boolean values with some extra logic to handle NULL conditions
        bool_convert_expression = (
            'CASE WHEN "'
            + condition.valuespace
            + '" = false THEN true '
            + 'WHEN "'
            + condition.valuespace
            + '" = true THEN false '
            + 'WHEN "'
            + condition.valuespace
            + '" IS NULL THEN NULL '
            + " END"
        )
        column_expressions = {condition.valuespace: bool_convert_expression}

        # Create complement Quble using bool_convert_expression against condition's primary valuespace
        # [Here, we are implicitly dropping any auxvalspaces from condition Quble when we create complement]
        # ------------------------------------------------
        complement = condition.select(
            column_names=condition.keyspaces + [condition.valuespace],
            column_expressions=column_expressions,
        )

        # Finally replace subject's values for complementary entries
        result = self.get(complement, auto_squeeze=auto_squeeze)

        # Handle return according to inplace arg
        if inplace:
            self._swap_table(result)
            return None
        else:
            return result

    # ============================================ RE-MAPPING OPERATIONS =============================================

    @RootLib.lazy_kwargs()
    def remap1d(
        self,
        keymap: Quble,
        keyspace: str,
        tgt_keyspace: str = None,
        map_type: str = "<space>",
        map_basis: str = "<space>",
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        force_tgt_keys=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        rank_direction: str = "asc",
        include_endpoints: bool = True,
        prevent_null_keys: bool = False,
        unmap_flag=False,
        startend_historical_mode=False,
        exceptions_flag: bool = False,
        exceptions_type: str = None,
    ) -> Quble:
        """
        Remaps (translates) the specified valuespaces of Quble (self)
        using the primary valuespace of the keymap (Quble) provided
        Frequency conflicts are resolved using self's frequency

        If keymap has columns "StartDate" and "EndDate",
        this mapping algorithm will consider the presence
        of "Rank" (rankspace) and "IsPrimary" utility columns

        :param keymap (Quble): mapping where values provide target keys for the specified keyspace.
                               The primary valuespace of the keymap will be applied

            .. note::
                If tgt_keyspace=None, then new/target keyspace is derived from the valuespace property of each keymap Quble
            .. note::
                The given keymap Quble object must have the same values dtype as the original Quble's corresponding keyspace index.
            .. note::
                It is assumed that for each key of the orthogonal hyper_index there is no duplication of key values.
        :type keymap: qubles.core.quble.Quble

        :param keyspace: The keyspace of the dimension to be remapped against
        :type keyspace: str (or list of strings)

        :param tgt_keyspace: The new keyspace to be created for the remapped index.

            .. note::
                Will be ascertained from the primary valuespace of the keymap argument if omitted.
        :type tgt_keyspace: str (or list of strings)

        :param map_type: the type of mapping

            ==>  None: will perform a (simple) one-to-one or (simple) one-to-many mapping [will ignore map_basis arg]
                 [If a one-to-many keymap is provide, map_type=None, map_basis=None is equivalent to map_type='distribute', map_basis=None]
            ==> 'aggregate': many-to-one mapping [NOTE: non-trivial map_basis arg required]
            ==> 'distribute': one-to-many mapping [Both trivial & non-trivial map_basis arg supported]
            ==> 'aggregate_distribute': aggregate (N->1) then redistribute (1->N) [NOTE: non-trivial map_basis arg required]

        :param map_basis: aggregation/distribution basis (optional)
        :type map_basis: str

           For map_type='distribute' (non-basis/plain one-to-many): ==> map_basis: None
           For map_type='distribute' (with binning): ==> map_basis: 'min','max','mean','ave','avg','average'
           For map_type='distribute' (with binning): ==> map_basis: 'median','sum','cume','prod',
           For map_type='distribute' (with binning): ==> map_basis: 'geo_cume','geo_prod','geo_mean'
           For map_type='distribute' (with binning): ==> map_basis: 'geo100_cume','geo100_prod','geo100_mean'
           For map_type='distribute' (with ranking): ==> map_basis: 'first','first:<rankspace>','last',last:<rankspace>'
           [Here, <rankspace> arg is assumed to be a keyspace of the keymap] [if no rankspace provided, then row number is used]

           For map_type='aggregate' (with ranking): ==> map_basis: 'first','first:<rankspace>','last',last:<rankspace>'
                                    [Here, <rankspace> arg is assumed to be a keyspace of the keymap]]
                                    [if no rankspace provided, then row number is used]

           For map_type='aggregate' or 'aggregate_distribute':
                ==> map_basis: 'min','max','mean','ave','avg','average',
                               'median','sum','cume','prod',
                               'geo_cume','geo_prod','geo_mean',
                               'geo100_cume','geo100_prod','geo100_mean',
                               'skew','kurtosis','stddev_samp','stddev_pop',
                               'pos_std','neg_std','stddev','std','var_samp',
                               'var_pop','var','pos_var','neg_var'

           For map_type='aggregate' (valuespace ranking):  ==> map_basis: 'rank','pct_rank','uniform_rank','biuniform_rank'

        :param tfill_method: The method to be used when filling time/date data against the new keyspace index
        :type tfill_method: {q_fill_method}

        :param tfill_max: The maximum number of consecutive value fill-ins for time/dates(using the previously supplied
            fill_method) along a single slice/section of the resulting valuespace.
        :type tfill_max: int

        :type tfill_end_mode: str
        :param tfill_end_mode:
            Controls extension/limits beyond original dates.
            Can be 'unconstrained' or 'no_future' or 'in_progress' or 'no_extension' or 'full_extension'
            'unconstrained': Fill (for each orthogonal key) until fill_max is reached
            'no_future': Fill (for each orthogonal key) until fill_max or current date is reached
            'in_progress': Fill (for each orthogonal key) until fill_max or 'in-progress' period is reached
            [Here, 'in-progress' period means period/interval containing current date]
            'no_extension': Fill (for each orthogonal key) minimum of (fill_max or last original, orthogonal date) is reached
            'full_extension': Fill (for each orthogonal key) until minimum of (fill_max or maximum original date ACROSS ALL ORTHO KEYSPACES) is reached

        :type tfill_honor_nulls: bool
        :param tfill_honor_nulls:
            Flag to honor any existing null values

        :param aggr_method: The method that will be used for implicit aggregation.
        :type aggr_method: {q_aggr_method}

        :param link_check: Flag that indicates whether or not all original keys
                           in the specified keyspace must be covered by the keymap argument.
        :type link_check: bool

        :param valuespace: the valuespace(s) to be aggregated
                           (only these valuespaces will remain in result)
        :type valuespace: str or list of strings
                      (keywords may be used such as '<valuespaces>', '<valuespace>', etc.
                      [See: :meth:`~qubles.core.quble.Quble.validate_valuespace`]

        :param view: Quble indicating conditional elements
                     for which aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :param force_tgt_keys: scalar, np.ndarray, list, tuple (or None) of target keys
                             that are to be forceably included in new target index
                             [Defunct...included for legacy purposes but now defunct]
        :type force_tgt_keys: scalar, np.ndarray, list, tuple, or None

        :param rank_direction: direction of ranking when map_basis in ('rank','pct_rank','uniform_rank','biuniform_rank')
        :type rank_direction: (string) 'asc' or 'desc'

        :param include_endpoints: flag whether to include/exclude endpoints when map_basis='pct_rank','uniform_rank','biuniform_rank'
        :type include_endpoints: (boolean) True/False

        :param key_ordering: controls row ordering by key
        :type key_ordering: None, str or dictionary
           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace
           dictionary: dict keys (str): keyspaces, dict values (str): 'asc' or 'desc'
           ==> allows for assigning key ordering (ascending/descending)
           ==> (and relative priority) for each keyspace individually

        :param unmap_flag: flag whether to unmap
        :type unmap_flag: (boolean) False*/True

        :param startend_historical_mode: flag whether to apply StartDate & EndDate
        :type startend_historical_mode: (boolean) False*/True
                ==> startend_historical_mode=False: Use latest keymap info

        :param exceptions_flag: flag whether to generate exceptions Quble
        :type exceptions_flag: (boolean) False*/True
                ==> exceptions_flag=False: returns modified Quble result
                ==> exceptions_flag=True: returns a tuple: (result,exceptions)

        :param exceptions: Initial exceptions Quble (seed)
        :type exceptions: Quble (or None)

        :rtype: Quble
        :returns: compressed Quble

        :returns: Modified Quble (exceptions_flag=False)
                  with affiliated index/keyspace remapped accordingly
                  OR tuple of Qubles (results,exceptions) (exceptions_flag=True)
        :rtype: qubles.core.quble.Quble

        """
        exceptions = None
        # Validate table
        if self.is_undefined:
            # Undefined Qubles cannot be remapped
            result = Quble.undefined_instance()
            return (result, exceptions) if exceptions_flag else result

        # ----------------------------------------------------------
        # Restrict Quble to only the valuespace(s) of interest
        # [valuespace arg is validated within sub_variate method]
        # (allow for shallow copy when valuespaces are unchanged)
        # ==> Only refer to subject (not self) hereafter
        # ----------------------------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)

        # Set freq reconciliation based on subject's context
        freq = subject.context_freq()

        # -----------------------------------
        # Validate keyspace
        # ==> (src)keyspace MUST be present
        # ==> in subject.keyspaces
        # -----------------------------------
        if keyspace is None:
            raise Exception("No keyspace provided")
        keyspace = subject.validate_keyspace(keyspace, grace=False)
        if keyspace not in subject.keyspaces:
            raise Exception(
                f"keyspace:{keyspace} absent from subject.keyspaces:{subject.keyspaces}"
            )

        time_remap_flag = True if self.is_time_space(space=keyspace) else False

        # -----------------
        # Procure keymap
        # -----------------
        if (keymap is None) and (tgt_keyspace is not None) and auto_link:
            # NOTE: If src_keyspace=keyspace is None (not provided), will search subject.keyspaces for a supported keyspace across resident Security Master(s)
            #       In src_keyspace=keyspace is None, RootLib().rekey_ids() will return an (unchanged) copy of subject if no relevant maps are found, otherwise with throw an Exception
            result = RootLib().remap(
                subject,
                src_keyspaces=keyspace,
                tgt_keyspaces=tgt_keyspace,
                link_check=link_check,
                link_dupe_grace=link_dupe_grace,
            )
            return result
        elif keymap is None:
            result = subject.copy()
            return result
        elif not isinstance(keymap, Quble):
            raise Exception("Invalid keymap...Quble expected")
        elif keymap.is_undefined:
            raise Exception("Undefined keymap")
        elif keymap.is_empty:  # or keymap.has_no_values:
            # Need to think about handling for this case
            result = subject.clear()
            return result
        elif keymap.valuespace is None:
            # Here, keymap is a (value-less) index Quble
            raise NoValuespaceError("keymap.valuespace required")

        # Consider space-based re-direction for map_type and map_basis
        # --------------------------------
        map_type = keymap._space_info_indirection(
            info_type="map_type",
            space=keymap.valuespace,
            info_assignment=map_type,
            grace=True,
        )
        map_basis = keymap._space_info_indirection(
            info_type="map_basis",
            space=keymap.valuespace,
            info_assignment=map_basis,
            grace=True,
        )

        # ------------------------------------------------
        # Establish map_direction & applicable_keymap_vs
        # ------------------------------------------------
        map_direction = None  # <-- Initialization
        applicable_keymap_vs = None  # <-- Initialization
        if keyspace in keymap.keyspaces:
            # forward mapping case
            # -----------------------
            # Establish / validate tgt_keyspace
            if tgt_keyspace is None:
                # Assume that we will map to the primary valuespace of keymap?
                if keymap.valuespace is None:
                    raise NoValuespaceError("keymap.valuespace required")
                tgt_keyspace = keymap.valuespace
                applicable_keymap_vs = keymap.valuespace
            elif tgt_keyspace in keymap.valuespaces:
                applicable_keymap_vs = tgt_keyspace
            else:
                # Assume we wish to impose tgt_valuespace against keymap.valuespace
                keymap.rename_space(
                    space=keymap.valuespace, tgt_space=tgt_keyspace, inplace=True
                )
                applicable_keymap_vs = tgt_keyspace

            # At this point, tgt_keyspace is verified to be a valuespace of keymap
            map_direction = "forward"
        elif keyspace not in keymap.valuespaces:
            raise Exception(
                f"keyspace:{keyspace} absent from keymap.spaces:{keymap.spaces}"
            )

        # Reverse mapping cases
        # At this point, we have verified keyspace is in keymap.valuespaces (i.e., a reverse map operation)
        elif tgt_keyspace in keymap.keyspaces:
            applicable_keymap_vs = keyspace
            map_direction = "reverse"

        elif tgt_keyspace is not None:
            raise Exception(
                f"Neither keyspace:{keyspace} nor tgt_keyspace:{tgt_keyspace} are present in keymap.keyspaces:{keymap.keyspaces}"
            )

        # Try to handle case when tgt_keyspace is None
        elif len(keymap.keyspaces) != 1:
            # Here tgt_keyspace not provided, but distribution keymap has multiple keyspaces,
            # so it is ambiguous which one should to be used as tgt_keyspace
            raise Exception(
                f"keyspace:{keyspace} present in keymap.valuespaces:{keymap.valuespaces} (aka reverse map) but unable to infer tgt_keyspace from keymap.keyspaces:{keymap.keyspaces}"
            )
        else:
            applicable_keymap_vs = keyspace
            map_direction = "reverse"
            tgt_keyspace = keymap.keyspaces[0]

        # ----------------------------------------------
        # Verify map_direction & applicable_keymap_vs
        # ----------------------------------------------
        if tgt_keyspace not in keymap.spaces:
            raise Exception(
                f"Internal inconsistency: tgt_keyspace:{'None' if tgt_keyspace == '' else tgt_keyspace} absent from keymap.spaces:{keymap.spaces}"
            )

        elif map_direction not in ("forward", "reverse"):
            raise Exception(
                f"Internal inconsistency: map_direction:{map_direction}...'forward' or 'reverse' expected"
            )

        elif applicable_keymap_vs is None:
            raise Exception(
                f"Internal inconsistency: Could not infer applicable_keymap_vs"
            )

        elif applicable_keymap_vs not in keymap.valuespaces:
            raise Exception(
                f"Internal inconsistency: applicable_keymap_vs:{applicable_keymap_vs} absent from keymap.valuespaces:{keymap.valuespaces}"
            )

        # ------------------------------
        # Procure & validate map_type
        # ------------------------------
        # Check for existence of keymap's valuespace property 'map_type'
        if keymap.has_space_info(info_type="map_type", space=applicable_keymap_vs):
            map_type = keymap.get_space_info(
                info_type="map_type", space=applicable_keymap_vs, grace=True
            )

        # Validate map_type (after stipping rankspace suffix)
        if map_type not in (None, "aggregate", "distribute"):
            raise Exception(f"Invalid/unsupported map_type:{map_type}")

        # -------------------------------------------------------------
        # Given map_basis (keymap.keyspace -> keymap.valuespace) as one of:
        #   None: one-to-one mapping
        #   'aggregate': aggregate (many-to-one) keymap.keyspace -> keymap.valuespace
        #   'distribute': distribute (one-to-many) keymap.keyspace -> keymap.valuespace
        #
        # Determine map_mode as one of:
        #
        #   None: one-to-one mapping
        #   'aggregate': aggregate (many-to-one) from keyspace -> tgt_keyspace
        #   'distribute': distribute (one-to-many) from keyspace -> tgt_keyspace
        #   'aggregate_distribute'; aggregating then redistributing (unmap_flag=True)
        #            from keyspace -> tgt_keyspace -> keyspace
        # -------------------------------------------------------------

        # Here, we are performing a forward map: keymap.keyspace(s) -> keymap.valuespace
        if map_type is None:
            # One-to-one mapping
            map_mode = map_type
        elif map_type == "aggregate":
            if map_direction == "forward":
                map_mode = "aggregate_distribute" if unmap_flag else "aggregate"
            elif map_direction != "reverse":
                raise Exception(
                    f"Internal inconsistency: map_direction:{map_direction}...'forward' or 'reverse' expected"
                )
            elif unmap_flag:
                raise Exception(
                    f"unmap_flag:{unmap_flag} disallowed when map_type:{map_type} & map_direction:{map_direction} & keyspace:{keyspace} & tgt_keyspace:{tgt_keyspace}"
                )
            else:
                map_mode = "distribute"
        elif map_type == "distribute":
            if map_direction == "reverse":
                map_mode = "aggregate_distribute" if unmap_flag else "aggregate"
            elif map_direction != "forward":
                raise Exception(
                    f"Internal inconsistency: map_direction:{map_direction}...'forward' or 'reverse' expected"
                )
            elif unmap_flag:
                raise Exception(
                    f"unmap_flag:{unmap_flag} disallowed when map_type:{map_type} & map_direction:{map_direction} & keyspace:{keyspace} & tgt_keyspace:{tgt_keyspace}"
                )
            else:
                map_mode = "distribute"
        else:
            raise Exception(f"Invalid/unsupported map_type:{map_type}")

        # ----------------------------
        # Try to procure map_basis
        # ----------------------------
        # Check for existence of keymap's valuespace property 'map_type'
        if keymap.has_space_info(info_type="map_basis", space=applicable_keymap_vs):
            map_basis = keymap.get_space_info(
                info_type="map_basis", space=applicable_keymap_vs, grace=True
            )

        # --------------------------------------
        # Try to procure rankspace of keymap
        # --------------------------------------
        # First, strip off rankspace from map_basis if possible
        rankspace = None
        if isinstance(map_basis, str):
            if map_basis[0:6] == "first:":
                rankspace = map_basis[6:].strip()
                map_basis = "first"
            elif map_basis[0:5] == "last:":
                rankspace = map_basis[5:].strip()
                map_basis = "last"

        # Validate map_basis (after stripping rankspace suffix)
        if map_basis not in MAP_BASIS_LIST:
            raise Exception(f"Invalid/unsupported map_basis:{map_basis}")

        if (
            map_basis in ("rank", "pct_rank", "uniform_rank", "biuniform_rank")
            and map_mode != "aggregate"
        ):
            raise Exception(
                f"When map_basis:{map_basis}, map_mode=='aggregate' required yet map_mode:{map_mode}"
            )

        # Secondly, check for existence of keymap's rankspace by looking at 'is_rankspace'
        if rankspace is None:
            is_rankspace_dict = keymap.get_space_info(
                info_type="is_rankspace", space="<all>", grace=True
            )
            for space, is_rankspace in is_rankspace_dict.items():
                # rankspace must be a keyspace of keymap
                if is_rankspace and space != keymap.valuespace:
                    rankspace = space
                    break

        # As a last resort, see if 'RANK' exists in keymap.spaces, if so, assume this space is to be used as the rankspace
        if rankspace is not None:
            pass
        elif "RANK" in keymap.spaces:
            rankspace = "RANK"
        elif "Rank" in keymap.spaces:
            rankspace = "Rank"

        # ----------------------------------------------
        # Validate rankspace in keymap (if applicable)
        # [must be present in keymap.keyspaces and not in subject.spaces]
        # Also, set keyspaces_join_op accordingly
        # ----------------------------------------------
        if (
            rankspace is None
            or map_basis is None
            or (map_basis[0:5] != "first" and map_basis[0:4] != "last")
        ):
            pass
        elif not isinstance(rankspace, str) or (len(rankspace) == 0):
            raise Exception(
                f"Invalid rankspace:{rankspace}...non-trivial string expected w/map_basis:{map_basis}"
            )
        elif rankspace not in keymap.spaces:
            raise Exception(
                f"rankspace:{rankspace} is absent from keymap.spaces:{keymap.spaces}"
            )
        elif rankspace == keyspace:
            pass
        elif rankspace in subject.spaces:
            raise Exception(
                f"(keymap's) rankspace:{rankspace} clashes with subject.spaces:{subject.spaces}"
            )

        # ======================================================
        # Verified facts at this point:
        #  1) We know that tgt_keyspace is in keymap.spaces
        #  2) We know that keyspace is in keymap.spaces
        #  3) We know that keyspace is in subject.keyspaces
        #  4) We have identified applicable_keymap_vs
        #  5) We have also established the map direction:
        #  ==> 'forward': keyspace in keymap.keyspaces and tgt_keyspace in keymap.valuespaces
        #  ==> 'reverse': keyspace in keymap.valuespaces and tgt_keyspace in keymap.keyspaces
        # ======================================================

        # =======================================
        # Try to avoid column name clashes
        # where tgt_keyspace present in subject.spaces
        # Pre-remap: subject.spaces = [keyspaces] + [valuespaces] = [<subject.ortho_keyspaces> + <subject.keyspace>] + [<subject.valuespaces>]
        # =======================================
        if tgt_keyspace not in subject.spaces:
            # No clashes here
            pass
        elif (map_mode == "aggregate_distribute") or map_basis in (
            "rank",
            "pct_rank",
            "uniform_rank",
            "biuniform_rank",
        ):
            # Here, the tgt_keyspace will eventually disappear as such, tgt_keyspace is arbitrary and can be changed
            # If necessary to avoid column name clashes for intermediate state
            # Post-remap: result.spaces = [<subject.keyspaces>] + [<subject.valuespaces>]
            if tgt_keyspace is None:
                # This case should not happen due to earlier logic above
                tgt_keyspace = keymap.valuespace

            if tgt_keyspace in subject.valuespaces and tgt_keyspace in keymap.spaces:
                # The latter condition should always be True here due to logic/validation checks above
                # Impose an arbitraty new_tgt_keyspace to avoid clashes with subject.valuespaces
                new_tgt_keyspace = f"tgt_{keyspace}"
                if applicable_keymap_vs == tgt_keyspace:
                    applicable_keymap_vs = new_tgt_keyspace
                keymap.rename_space(
                    space=tgt_keyspace, tgt_space=new_tgt_keyspace, inplace=True
                )
                tgt_keyspace = new_tgt_keyspace
        elif tgt_keyspace == keyspace:
            # Post-remap: result.spaces = [<subject.ortho_keyspaces> + <tgt_keyspace=keymap.valuespace] + [<subject.valuespaces>]
            # ------------------------------------------------------------------------
            # Since the (original) keyspace will eventually disappear after remap,
            # [Not true for (map_type  == 'aggregate_distribute') or map_basis in ('rank','pct_rank','uniform_rank','biuniform_rank') ]
            # we have the option of (temporarily) renaming
            # the keyspace of subject if it clashes with <tgt_keyspace>
            # We still want to proceed with remap (despite tgt_keyspace == keyspace)
            # ------------------------------------------------------------------------
            # ==> This can sometimes happen intentionally
            #     such as remapping time dimensions
            #      but reusing same time keyspspace before & after remap]
            # ------------------------------------------------------------------------
            # Here, the (original) keyspace will eventually disappear after remap but the tgt_keyspace will remain
            subject = subject.rename_space(space=keyspace, tgt_space=f"src_{keyspace}")
            keymap.rename_space(
                space=keyspace, tgt_space=f"src_{keyspace}", inplace=True
            )
            keyspace = f"src_{keyspace}"

        # For forward maps, make sure tgt_keyspace does not clash with existing subject's spaces
        # During remap: coindexed table spaces (conduit for remap) must (temporarily) support:
        # During remap: spaces = [<subject.ortho_keyspaces> + <subject.keyspace> + <tgt_keyspace=keymap.valuespace>] + [<subject.valuespace>] coindicdentally
        # tgt_keyspace & <subject.valuespace> MUST NOT have name clash
        else:
            raise Exception(
                f"tgt_keyspace:{tgt_keyspace} present in subject.spaces:{subject.spaces}"
            )

        # ======================================================
        # START CASE #1: keymap involving StartDate & EndDate
        # ======================================================
        drop_joined_table_needed = False  # <-- Initialization

        if "StartDate" in keymap.spaces:
            if "EndDate" not in keymap.spaces:
                # keymap.StartDate column requires associated keymap.EndDate
                raise Exception(
                    f"keymap inconsistency: keymap contains 'StartDate' column but no 'EndDate' column"
                )

            # Aggregate away any ortho keyspaces excluding keyspace & tgt_keyspace
            # ----------------------------------
            for ks in keymap.ortho_keyspaces(subject.keyspaces):
                if ks not in (
                    keyspace,
                    tgt_keyspace,
                    "StartDate",
                    "EndDate",
                    rankspace,
                ):
                    # NOTE:  keymap.aggregate1d() CANNOT BE PERFORMED AGAINST StartDate/EndDate keymaps
                    raise Exception(
                        f"StartDate/EndDate keymap has orthogonal keymap.keyspace:{ks} against subject.keyspaces:{subject.keyspaces} w/rankspace:{rankspace}"
                    )

            # Make sure keyspace & tgt_keyspace are present in keymap.spaces
            if keyspace not in keymap.spaces:
                raise Exception(
                    f"keyspace:{keyspace} absent from (secmstr) keymap.spaces:{keymap.spaces}"
                )
            elif tgt_keyspace not in keymap.spaces:
                raise Exception(
                    f"tgt_keyspace:{tgt_keyspace} absent from (secmstr) keymap.spaces:{keymap.spaces}"
                )

            # Establish historical_time_space (if applicable)
            # ------------------------------------------------
            if startend_historical_mode:
                historical_time_space = subject.first_time_keyspace(grace=True)
            else:
                historical_time_space = None

            # Build tgt_keyspaces & tgt_valuespaces
            # ---------------------------------------

            # Build list of src_keyspaces, tgt_keyspaces & tgt_valuespaces
            src_keyspaces = []
            tgt_keyspaces = []
            for ks in subject.keyspaces:
                if ks == keyspace:
                    src_keyspaces.append(ks)
                    tgt_keyspaces.append(
                        tgt_keyspace
                    )  # <-- NOTE: For aggregation: q2.valuespace = tgt_keyspace
                # Exclude the rankspace from the output
                elif ks == rankspace:
                    pass
                else:
                    src_keyspaces.append(ks)
                    tgt_keyspaces.append(ks)

            tgt_valuespaces = [
                tgt_vs
                for tgt_vs in subject.valuespaces
                if tgt_vs != tgt_keyspace and tgt_vs != rankspace
            ]

            # Apply mapping logic
            # ---------------------
            joined_table = generate_random_table_name()
            drop_joined_table_needed = True

            # Render the startend_join.j2 template
            # This query will join
            sql_template = JINJA_ENV.get_template("startend_join.j2")
            sql_command = sql_template.render(
                src_spaces=subject.spaces,
                src_keyspace=keyspace,
                tgt_keyspace=tgt_keyspace,
                rankspace=rankspace if rankspace in keymap.spaces else None,
                StartDate_colname="StartDate" if "StartDate" in keymap.spaces else None,
                EndDate_colname="EndDate" if "EndDate" in keymap.spaces else None,
                historical_time_space=historical_time_space,
                src_table_name=subject.table_name,
                startend_table=keymap.table_name,
                tgt_table_name=joined_table,
                tgt_keyspaces=tgt_keyspaces,  # <-- For sorting of resultant records
                left_join_flag=exceptions_flag,
                IsPrimary_colname="IsPrimary" if "IsPrimary" in keymap.spaces else None,
                map_direction=map_direction,
            )
            execute(sql_command, format_flag=False)

            # Copy column info from subject's table -> joined_table
            # What if rankspace is in subject.spaces? ==> likely not needed to support this case!
            if len(subject.spaces) > 0:
                copy_custom_col_info(
                    subject.table_name,
                    joined_table,
                    column_names=subject.spaces,
                )

            # Copy (tgt_keyspace & rankspace) column info from keymap's table -> joined_table
            keymap_spaces_to_copy = []
            if (
                tgt_keyspace is not None
                and tgt_keyspace != keyspace
                and tgt_keyspace in keymap.spaces
            ):
                keymap_spaces_to_copy.append(tgt_keyspace)

            if rankspace is not None and rankspace in keymap.spaces:
                keymap_spaces_to_copy.append(rankspace)

            if len(keymap_spaces_to_copy) > 0:
                copy_custom_col_info(
                    keymap.table_name,
                    joined_table,
                    column_names=keymap_spaces_to_copy,
                )
        elif "EndDate" in keymap.spaces:
            raise Exception(
                f"keymap inconsistency: keymap contains 'EndDate' column but no 'StartDate' column"
            )

        # ====================================================
        # END CASE #1: keymap involving StartDate & EndDate
        # ====================================================
        # ==========================================
        # START CASE #2: Traditional keymap Quble
        # ==========================================
        else:
            # Which keyspaces of subject are linkable from keymap
            # [We exclude keyspace,tgt_keyspace & rankspace]
            linkable_keyspaces = []
            for ks in subject.ortho_keyspaces(keymap.keyspaces):
                if ks not in (keyspace, tgt_keyspace, rankspace):
                    # Do not try to link keyspace, tgt_keyspace or rankspace
                    linkable_keyspaces.append(ks)

            if auto_link and len(linkable_keyspaces) > 0:
                keymap = keymap.link_keyspaces(
                    linkable_keyspaces,
                    link_check=link_check,
                    link_dupe_grace=link_dupe_grace,
                    deep_copy=False,
                    grace=True,
                )

            # Aggregate away any ortho keyspaces excluding keyspace, tgt_keyspace & rankspace (if present)
            # ----------------------------------------------------------
            for ks in keymap.ortho_keyspaces(subject.keyspaces):
                if ks not in (keyspace, tgt_keyspace, rankspace, "Rank", "RANK"):
                    keymap = keymap.aggregate1d(keyspace=ks, auto_squeeze=True)

            # distribute cases (unmap)
            # keymap.valuespace = keyspace (being remapped)
            # tgt_keyspace in keymap.keyspaces
            # ---------------------------------
            if map_direction == "reverse":
                # We exclude tgt_keyspace from keyspace expansions...
                #
                #  1) IMPORTANT: WE DO NOT WANT TO INCUR CROSSING THIS KEYSPACE
                #     IN THE EXPANSION NULL KEY (NULL KEY PREVENTION) EXERCISE (see expand_null_key logic)
                #     [IN THIS SCENARIO, tgt_keyspace REPRESENTS AN EXCHANGE FOR THE ORIGINAL keyspace]
                #     [IN OTHER WORDS, tgt_keyspace IS NOT AN INDEPENDENT KEYSPACE FROM THE ORIGINAL keyspace]
                #
                #  2) ALSO, tgt_keyspace IS PRESUMED TO HAVE NO NULLS ANYWAY
                # --------------------------------------------------------------
                expansion_exclusions = [tgt_keyspace]
                keymap = keymap.unvaluespace(
                    drop=False
                )  # <-- will change keymap's primary valuespace to a keyspace (drops any non-primary valuespaces)

                keys_join_op = "leftmost"

                keyspaces_join_op = subject.keyspaces + keymap.ortho_keyspaces(
                    subject.keyspaces
                )
                if (
                    rankspace is not None
                    and rankspace in keymap.keyspaces
                    and rankspace not in keyspaces_join_op
                ):
                    keyspaces_join_op += [rankspace]

            # aggregate (and aggregate_distribute) cases
            # keymap.valuespace = tgt_keyspace
            # keyspace = one of keymap.keyspaces
            # --------------------------------------------
            elif map_direction != "forward":
                raise Exception(
                    f"Invalid map_direction:{map_direction}...'forward' or 'reverse' expected"
                )
            else:
                expansion_exclusions = None
                if exceptions_flag:
                    # Here, we want to preserve left keys for exceptions information
                    keys_join_op = "leftmost"
                else:
                    # Here, we do not need exceptions information,
                    # so we can impose an intersection join
                    keys_join_op = "inter_tunionpostleft"

                keyspaces_join_op = "union"

            # Make sure column_type of keyspace column in subject is consistent with column_type of tgt_keyspace in keymap
            # 1. Conforms keyspaces of keymap to that of subject (collapses dimensions if necessary)
            valuespaces_join_op = {}
            for vs in subject.valuespaces:
                valuespaces_join_op[vs] = (0, vs)

            if applicable_keymap_vs and applicable_keymap_vs not in subject.keyspaces:
                # For (reverse) maps, applicable_keymap_vs may already by in subject.keyspaces
                valuespaces_join_op[applicable_keymap_vs] = (1, applicable_keymap_vs)

            joined = subject.join(
                other=keymap,
                keys_join_op=keys_join_op,
                keyspaces_join_op=keyspaces_join_op,
                valuespaces_join_op=valuespaces_join_op,
                valuespace_prefix=None,
                ignore_missing=ignore_missing,
                auto_fill=auto_fill,
                tfill_method=tfill_method,
                tfill_max=tfill_max,
                tfill_end_mode=tfill_end_mode,
                tfill_honor_nulls=tfill_honor_nulls,
                aggr_method=aggr_method,
                coverage_requirements={1: 0} if link_check else None,
                freq=freq,
                # NOTE: key_ordering will be applied in remap1D.j2 template below against final keyspaces
                key_ordering=None,  # key_ordering=key_ordering,
                view=view,
                tdistribute_mode=tdistribute_mode,
                # NOTE: We have already performed keyspace link (keymap->subject/self) above
                auto_link=False,
                link_check=link_check,
                link_dupe_grace=link_dupe_grace,
                prevent_null_keys=prevent_null_keys,
                expansion_exclusions=expansion_exclusions,
            )

            # =================================================
            #   POST-JOIN, THE JOINED TABLE
            #   WILL HAVE THE FOLLOWING COLUMNS:
            #
            # subject.keyspaces + [tgt_keyspace] + [rankspace (optional)] + subject.valuespaces
            # Final result columns: subject.ortho_keyspaces + [tgt_keyspace]  + subject.valuespaces
            # ==================================================

            # Build list of src_keyspaces, tgt_keyspaces & tgt_valuespaces
            src_keyspaces = []
            tgt_keyspaces = []
            for ks in joined.keyspaces:
                if ks == keyspace:
                    src_keyspaces.append(ks)
                    tgt_keyspaces.append(
                        tgt_keyspace
                    )  # <-- NOTE: For aggregation: q2.valuespace = tgt_keyspace
                # Exclude the rankspace from the output
                elif ks == rankspace:
                    pass
                else:
                    src_keyspaces.append(ks)
                    tgt_keyspaces.append(ks)

            tgt_valuespaces = [
                tgt_vs
                for tgt_vs in joined.valuespaces
                if tgt_vs != tgt_keyspace and tgt_vs != rankspace
            ]

            joined_table = joined.table_name
            drop_joined_table_needed = False

        # ========================================
        # END CASE #2: Traditional keymap Quble
        # ========================================

        # =============================================================
        # Finally, apply remap1d template logic against joined table
        # =============================================================

        # Build build_key_ordering_dict when applicable
        if key_ordering is not None and not isinstance(key_ordering, str):
            key_ordering = build_key_ordering_dict(
                key_ordering, keyspaces=tgt_keyspaces
            )

        # Render the remap1D.j2 template
        # Which will select the requisite columns from the joined table
        sql_template = JINJA_ENV.get_template("remap1D.j2")

        # However, joined.keyspaces may include keymap's rankspace
        # which should be excluded from resultant Quble
        # As such, use (src)keyspaces = subject.keyspaces in remap1D.j2 template
        result_table_name = generate_random_table_name()
        sql_command = sql_template.render(
            keyspaces=src_keyspaces,
            src_keyspace=keyspace,
            tgt_keyspace=tgt_keyspace,
            valuespaces=tgt_valuespaces,
            map_type=map_mode,
            map_basis=map_basis,
            rankspace=rankspace,
            ignore_missing=ignore_missing,
            src_table_name=joined_table,  # <-- q1.table_name should equal q2.table_name
            tgt_table_name=result_table_name,
            key_ordering=key_ordering,
            rank_direction=rank_direction,
            include_endpoints=include_endpoints,
        )
        execute(sql_command, format_flag=False)

        if map_mode == "aggregate_distribute" or map_basis in (
            "rank",
            "pct_rank",
            "uniform_rank",
            "biuniform_rank",
        ):
            copy_custom_col_info(
                joined_table,
                result_table_name,
                column_names=src_keyspaces,
                info_type_exclusions=["fx", "time_basis", "role"],
            )
        else:
            copy_custom_col_info(
                joined_table,
                result_table_name,
                column_names=tgt_keyspaces,
                info_type_exclusions=["fx", "time_basis", "role"],
            )

        # Copy valuespace information
        # ------------------------------
        if time_remap_flag:
            # For time remaps, exclude time_basis & tfill_max
            if map_basis in ("rank", "pct_rank", "uniform_rank", "biuniform_rank"):
                # Do not inherit fx for ranking/pct_ranking
                vs_info_type_exclusions = ["time_basis", "tfill_max", "fx"]
            else:
                vs_info_type_exclusions = ["time_basis", "tfill_max"]
        elif map_basis in ("rank", "pct_rank", "uniform_rank", "biuniform_rank"):
            # Do not inherit fx for ranking/pct_ranking
            vs_info_type_exclusions = ["fx"]
        else:
            vs_info_type_exclusions = None

        copy_custom_col_info(
            joined_table,
            result_table_name,
            column_names=tgt_valuespaces,
            info_type_exclusions=vs_info_type_exclusions,
        )

        result = Quble.from_table(
            result_table_name, valuespace=tgt_valuespaces, remove_duplicate_keys=True
        )

        # For multiple target/result valuespaces, attempt to promote the original primary valuespace (self.valuespace)
        if result.is_multivariate and (self.valuespace in tgt_valuespaces):
            result.valuespace = self.valuespace

        if (
            tfill_method is not None
            and tgt_keyspace in result.keyspaces
            and result.is_time_space(tgt_keyspace)
        ):
            result = result.fill1d(
                keyspace=tgt_keyspace,
                tfill_method=tfill_method,
                tfill_max=tfill_max,
                tfill_end_mode=tfill_end_mode,
                tfill_honor_nulls=tfill_honor_nulls,
            )

        # =========================================
        # START: exceptions Quble (if requested)
        # =========================================
        if exceptions_flag:
            # Render the remap1d_exceptions.j2 template
            # Which will select the requisite columns from the joined table
            sql_template = JINJA_ENV.get_template("remap1d_exceptions.j2")
            # However, joined.keyspaces may include keymap's rankspace which should be excluded from resultant Quble
            # As such, use (src)keyspaces = subject.keyspaces in remap1D.j2 template
            exceptions_table_name = generate_random_table_name()
            if key_ordering is not None and not isinstance(key_ordering, str):
                key_ordering = build_key_ordering_dict(
                    key_ordering, keyspaces=src_keyspaces
                )
            sql_command = sql_template.render(
                src_keyspaces=src_keyspaces,  # <-- These are source keyspaces from the original src_table
                src_keyspace=keyspace,  # <-- This is the src_keypace being remapped
                tgt_keyspace=tgt_keyspace,  # <-- This is desired tgt_keypace (introduced by keymap) [tgt_keyspace WILL NOT appear in exceptions result]
                map_type=map_mode,
                src_table_name=joined_table,  # <-- We infer exceptions by examining the joined_table
                tgt_table_name=exceptions_table_name,
                key_ordering=key_ordering,
            )
            execute(sql_command, format_flag=False)

            # Establish col_info for copy
            col_info = subject.get_space_info(
                info_type=[
                    it1
                    for it1 in CUSTOM_INFO_TYPES
                    if it1 not in ["fx", "time_basis", "role"]
                ],
                space=src_keyspaces,
                omit_unassigned=True,
            )

            # Instantiate Quble from the new table
            exception_qbl = Quble.from_table(
                exceptions_table_name,
                col_info=col_info,
            )

            self._extend_exceptions(exceptions_type, exception_qbl)
        # =========================================
        # END: exceptions Quble (if requested)
        # =========================================

        # Drop the newly created joined table (if needed)
        if drop_joined_table_needed:
            drop_table(joined_table)

        return result

    def calendarize(
        self,
        fiscal_keyspace="Fiscal",
        calendar_keyspace="Dates",
        vantage_keyspace="Vantage",
        freq=None,
        allow_shallow_copy=True,
    ):
        """
        Calendarizes the Fiscal time-keyspace of a Quble
        """
        # Handle trivial cases
        if (
            fiscal_keyspace is None
            or self.is_undefined
            or fiscal_keyspace not in self.keyspaces
        ):
            return self if allow_shallow_copy else self.copy()

        # Ensure fiscal_keyspace is actually a time-keyspace of the Quble
        if fiscal_keyspace not in self.time_keyspaces:
            raise Exception(f"fiscal_keyspace:{fiscal_keyspace} is not a time-keyspace")

        # Ensure calendar_keyspace arg is non-trivial and is NOT present as an existing keyspace of the Quble
        if calendar_keyspace is None:
            raise Exception(f"calendar_keyspace arg required")
        elif calendar_keyspace in self.keyspaces:
            raise Exception(
                f"calendar_keyspace:{calendar_keyspace} already present in self.keyspaces:{self.keyspaces}"
            )

        # Otherwise, perform the remapping: fiscal_keyspace -> calendar_keyspace
        # RootLib().remap() should handle both Non_PIT as well as PIT translations
        controls = None
        if freq is not None and freq != RootLib().get_control("freq"):
            controls = {"freq": freq}

        # NOTE: if controls is None, the ControlContextManager should be innocuous
        with ControlContextManager(controls=controls) as ccm:
            result = RootLib().remap(
                self,
                src_keyspaces=fiscal_keyspace,
                tgt_keyspaces=calendar_keyspace,
                fiscal_keyspace=fiscal_keyspace,
                vantage_keyspace=vantage_keyspace,
            )

        return result

    def num_uncovered_keys(
        self,
        other: Quble,
        column_name=None,
        other_column_name=None,
        grace: bool = False,
    ) -> int:
        """
        Returns the number of keys (for the specified column_name(s)) in other (Quble)
        that are not "covered" (not found) in self's keyspace column_name(s)

        other: The Quble to be covered
        column_name: column name(s) of self to be assessed if None, then keys for all columns will be assessed
        other_column_name: associated column_name in other to be covered (optional...if None then will use the self's column_name)
        grace: handles absence of tables or columns
        """
        # Validate other
        if not isinstance(other, Quble):
            raise Exception("Invalid other...Quble expected")
        elif other.is_undefined:
            raise UndefinedQubleError("other is an undefined Quble")

        # Validate self
        if self.is_undefined:
            raise UndefinedQubleError("self is an undefined Quble")

        # Here, both self & other are non-trivial
        keyspaces = self.keyspaces
        other_keyspaces = other.keyspaces

        # Establish column_name (as list)
        if column_name is None:
            column_name = keyspaces
        elif not isinstance(column_name, (list, tuple)):
            column_name = [column_name]

        for ks in column_name:
            if ks not in keyspaces:
                if grace:
                    return None
                else:
                    raise Exception(f"Absent self.keyspace/column_name:{ks}")

        # Establish other_column_name (as list)
        if other_column_name is None:
            other_column_name = column_name
        elif not isinstance(other_column_name, (list, tuple)):
            other_column_name = [other_column_name]

        for ks in other_column_name:
            if ks not in other_keyspaces:
                if grace:
                    return None
                else:
                    raise Exception(f"Absent other.keyspace/column_name:{ks}")

        sql_template = JINJA_ENV.get_template("uncovered_keys.j2")
        sql_command = sql_template.render(
            self_table=self.table_name,
            self_columns=other_column_name,
            other_table=other.table_name,
            other_columns=other_column_name,
        )
        num_uncovered = execute(sql_command, fetch="one")[0]
        return num_uncovered

    def fully_covers(
        self,
        other: Quble,
        column_name=None,
        other_column_name=None,
        grace: bool = False,
    ) -> bool:
        """
        Indicates whether the keys in the specified column_name(s) of self
        'covers' (includes) all the keys (of the specified column_name(s)) in other (Quble)

        other: The Quble to be covered
        column_name: column name(s) of self to be assessed (if None, then keys for all columns will be assessed)
        other_column_name: associated column_name in other to be covered (optional...if None then will use the self's column_name)
        grace: handles absence of tables or columns

        """
        num_uncovered = self.num_uncovered_keys(
            other=other,
            column_name=column_name,
            other_column_name=other_column_name,
            grace=grace,
        )
        if num_uncovered is None:
            return True if grace else False
        elif num_uncovered == 0:
            return True
        else:
            return False

    # ================================== REINDEXING ===================================

    def reconcile_time(
        self,
        image: Quble,
        time_keyspace: str = None,
        impose_name: bool = True,
        impose_freq: bool = True,
        grace: bool = True,
        require_non_vantage: bool = False,
        allow_shallow_copy: bool = True,
    ):
        """
        Recociles name and/or frequency of
        image's (first or specified) time-keyspace (if present)
        onto self's (first or specified) time-keyspace (if present)

        When time_keyspace is None, this method will seek to identify
        and operate on the first time-keyspace in self and image Qubles

        :param image: comparable Quble
        :type image: Quble

        :param time_keyspace: reconcile specific time-keyspace(s) within self and image
                ==> time_keyspace=None: locate first time-keyspace within self and image
                ==> time_keyspace str: locate this specific time-keyspace within self and image
                ==> time_keyspace two-element list/tuple: locate specific time_keyspace[0/1] within self/image
        :type time_keyspace: str or two-element list/tuple (self,image) or None

        :param impose_name: flag to impose the name of image's time_keyspace
        :type impose_name: bool (True*/False)

        :param impose_freq: flag to impose the frequency of image's time_keyspace
        :type impose_freq: bool (True*/False)

        :param grace: graceful handling for absence of time-keyspaces
        :type grace: bool (True*/False)

        :param require_non_vantage: require non-vantage time-keyspaces
                (rather than a standard time-keyspace)
        :type require_non_vantage: bool (False*/True)

        :param allow_shallow_copy: allows a shallow copy when no changes are needed
        :type allow_shallow_copy: bool (True*/False)
        """
        # --------------------
        # Initialize subject
        # --------------------
        subject = self if allow_shallow_copy else self.copy()

        # --------------------------
        # Handle contingency cases
        # --------------------------
        if subject.is_undefined:
            return subject
        elif image is None:
            return subject
        elif not isinstance(image, Quble):
            raise Exception(
                f"Invalid image arg...expected Quble but type(image):{type(image)}"
            )

        # ----------------------------------------------
        # Identify (first or specified) time-keyspace
        # in the subject and image Qubles (if present)
        # ----------------------------------------------
        if isinstance(time_keyspace, str) or isinstance(time_keyspace, (list, tuple)):
            # Here, a specific time-keyspace(s) (string/list/tuple) specified
            # In this case, we seek out the specified time-keyspace(s)
            # and handle contigencies according to grace directive
            if not isinstance(time_keyspace, (list, tuple)):
                # time_keyspace is a str here
                subject_time_keyspace = time_keyspace
                image_time_keyspace = time_keyspace
            elif len(time_keyspace) != 2:
                # list/tuple does not have two-elements as required
                raise Exception(
                    f"Invalid time_keyspace:{time_keyspace}...str or None or two-element list/tuple expected"
                )
            else:
                # time_keyspace is a two-element list/tuple here
                subject_time_keyspace = time_keyspace[0]
                image_time_keyspace = time_keyspace[1]

            # First, seek/confirm the presence of this specific (time)keyspace in subject Quble
            if subject_time_keyspace in subject.time_keyspaces:
                # specific subject_time_keyspace validated
                pass
            elif subject_time_keyspace in subject.keyspaces:
                # Here, the specified subject_time_keyspace is a keyspace of subject but NOT a time-keyspace...
                # we chose to throw an Exception in this case (regardless of grace arg)
                raise Exception(
                    f"time_keyspace:{time_keyspace} present in subject.keyspaces:{subject.keyspaces} but absent from subject.time_keyspaces:{subject.time_keyspaces}"
                )
            elif grace:
                # The specified subject_time_keyspace is not present, but we have been directed to treat gracefully, so reset subject_time_keyspace to None and continue
                subject_time_keyspace = None
            else:
                raise Exception(
                    f"time_keyspace:{time_keyspace} absent from subject.time_keyspaces:{subject.time_keyspaces} w/grace:{grace}"
                )

            # Next, seek/confirm the presence of this specific (time)keyspace in image Quble
            if image_time_keyspace in image.time_keyspaces:
                # specific image_time_keyspace validated
                pass
            elif image_time_keyspace in image.keyspaces:
                # Here, the specified image_time_keyspace is a keyspace of subject but NOT a time-keyspace...
                # we chose to throw an Exception in this case (regardless of grace arg)
                raise Exception(
                    f"time_keyspace:{time_keyspace} present in image.keyspaces:{image.keyspaces} but absent from image.time_keyspaces:{image.time_keyspaces}"
                )
            elif grace:
                # The specified image_time_keyspace is not present, but we have been directed to treat gracefully, so reset image_time_keyspace to None and continue
                image_time_keyspace = None
            else:
                raise Exception(
                    f"time_keyspace:{time_keyspace} absent from image.time_keyspaces:{image.time_keyspaces} w/grace:{grace}"
                )

        elif time_keyspace is not None:
            raise Exception(
                f"Invalid time_keyspace:{time_keyspace}...str or None or two-element list/tuple expected"
            )

        elif require_non_vantage:
            # Here, no specified keyspace provided, but require_non_vantage...
            # In this case, we seek out the first non-vantage time-keyspace (if present)
            subject_time_keyspace = subject.first_non_vantage_time_keyspace(grace=grace)
            image_time_keyspace = image.first_non_vantage_time_keyspace(grace=grace)

        else:
            # Here, no specified keyspace provided, but not require_non_vantage...
            # In this case, we seek out the first time-keyspace (if present)
            subject_time_keyspace = subject.first_time_keyspace(grace=grace)
            image_time_keyspace = image.first_time_keyspace(grace=grace)

        # ----------------------------------------
        # Exit early if requisite time-keyspace(s) not identified in subject or image
        # [It is likely that grace==True here]
        # ----------------------------------------
        if subject_time_keyspace is None:
            return subject
        elif image_time_keyspace is None:
            return subject

        # ------------------------------------------
        # Establish associated time-frequency for the time-keyspace(s) in subject and image
        # ------------------------------------------
        result_freq = subject.get_space_info(
            info_type="freq", space=subject_time_keyspace
        )
        image_freq = image.get_space_info(info_type="freq", space=image_time_keyspace)

        # ---------------------------------------------------------
        # Impose name of image_time_keyspace (if requested/needed)
        # ---------------------------------------------------------
        if impose_name and subject_time_keyspace != image_time_keyspace:
            # Here, names of time-keyspace DO NOT match
            subject.rename_space(
                space=subject_time_keyspace, tgt_space=image_time_keyspace, inplace=True
            )
            subject_time_keyspace = image_time_keyspace

        # ---------------------------------------------------------
        # Impose freq of image_time_keyspace (if requested/needed)
        # ---------------------------------------------------------
        if (
            impose_freq
            and result_freq is not None
            and image_freq is not None
            and result_freq != image_freq
        ):
            # Here, frequencies of time-keyspace DO NOT match
            subject = subject.asfreq(freq=image_freq, keyspace=subject_time_keyspace)

        return subject

    @RootLib.lazy_kwargs()
    def reindex(
        self,
        index: Quble,
        keyspaces_join_op: str = "right",
        keys_join_op: str = "rightmost",
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        tdistribute_mode="<space_root>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        coverage_requirements=None,
        key_ordering=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        consider_auto_squeeze: bool = False,
        calendar_table_name: str = RootLib.lazy_eval("calendar_table_name"),
        view=RootLib.lazy_eval("view"),
        allow_idx_insertion=True,
        allow_idx_removal=True,
    ) -> Quble:
        """
        Reindexes a Quble to the (keys & keyspaces of the) index provided (will ignore index's valuespace)

        Will allow for insertion of index columns if necessary (if permissioned via allow_idx_insertion)
        Removal of index columns is accomplished using aggregation (if permissioned via allow_idx_removal)

        :param index: Quble of the desired key structure (only keyspaces will be referenced/applicable)
        :type index: Quble or dict (dict keys:keyspaces, dict values:list/numpy array)

        :param tfill_method: The method to be used when filling time/date data against the new keyspace index
        :type tfill_method: {q_fill_method}

        :param tfill_max: The maximum number of consecutive value fill-ins
                         (using the previously supplied fill_method) along a single slice/section of the resulting valuespace.
        :type tfill_max: int

        :param aggr_method: The method that will be used for implicit aggregation (for removal of an axis)
        :type aggr_method: {q_aggr_method}

        :param ignore_missing: Flag that controls the ignore_missing setting for statistical calcs (for implicit aggregation)
        :type ignore_missing: bool

        :param coverage_requirements: (Optional) check for full key coverage in applicable common keyspaces
                                     between pairs of Qubles to be joined.
                                     Expects the following format:

                    ==> dict of ``coverer Quble number in list`` => ``coveree Quble number in list``*
                    ==> Throws an error if *coverer_quble_no* does not fully cover *coveree_quble_no*
                    (as specified by index related to qubles).
        :type coverage_requirements: dict or None

        :param view: Quble indicating conditional elements for which aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :param allow_idx_insertion: Flag to allow/disallow the insertion of a new keyspace/dimension
        :type allow_idx_insertion: bool

        :param allow_idx_removal: Flag to allow/disallow removal of hyper_index/keyspaces
            *False: Each keyspace (index column) in new_order must exist in the original Quble
            *True: Any keyspace from original that is absent in image will be removed (via aggregation & squeeze)
        :type allow_idx_removal: bool

        :returns: The reindexed Quble
        :rtype: qubles.core.quble.Quble

        """
        # Try to coerce a non-Quble index arg
        if not isinstance(index, Quble):
            index = Quble(indices=index)

        # Check keyspace insertions...
        if not allow_idx_insertion:
            for ks in index.keyspaces:
                if ks not in self.keyspaces:
                    raise Exception(
                        "self does not support index.keyspace:{0} yet allow_idx_insertion:{1}",
                        format(ks, allow_idx_insertion),
                    )

        # Check keyspace removals...
        if not allow_idx_removal:
            for ks in self.keyspaces:
                if ks not in index.keyspaces:
                    raise Exception(
                        "index does not support self.keyspace:{0} yet allow_idx_removal:{1}",
                        format(ks, allow_idx_removal),
                    )

        # ---------------------------------------
        # Use subject as a representative for (potentially modified) self
        # ONLY REFER TO subject AFTERWARDS!!!!!
        # ---------------------------------------
        subject = self

        # Perform auto_link on subject (if authorized)
        # Here, we look to link keyspaces as follows: self/subject's keyspaces -> index keyspaces
        # -------------------------------------------------
        # NOTE: we are performing link outside join so that we can control the direction of the link
        # -------------------------------------------------
        if auto_link:
            subject = subject.link_keyspaces(
                index.keyspaces,
                link_check=link_check,
                link_dupe_grace=link_dupe_grace,
                deep_copy=False,
                grace=True,
            )

        joined = self.join(
            other=index,
            keys_join_op=keys_join_op,
            keyspaces_join_op=keyspaces_join_op,
            valuespaces_join_op="left",
            ignore_missing=ignore_missing,
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            tdistribute_mode=tdistribute_mode,
            aggr_method=aggr_method,
            coverage_requirements=None,
            freq=index.context_freq(),
            key_ordering=key_ordering,
            view=view,
            # NOTE: We have already performed keyspace link (index->subject/self) above
            auto_link=False,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
            consider_auto_squeeze=False,
            calendar_table_name=calendar_table_name,
        )
        return joined

    @RootLib.lazy_kwargs()
    def project(
        self,
        index: Quble,
        keyspaces_join_op: str = "union",
        keys_join_op: str = "rightmost",
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        tdistribute_mode="<space_root>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        coverage_requirements: dict = None,
        key_ordering=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        pre_remove_dupe_keys=True,
        consider_auto_squeeze: bool = False,
        calendar_table_name: str = RootLib.lazy_eval("calendar_table_name"),
        view=RootLib.lazy_eval("view"),
        allow_idx_insertion: bool = True,
        index_context_freq_flag: bool = True,
    ) -> Quble:
        """
        Projects the index footprint onto the subject Quble
        against each (distinct) (hyper)key in existing orthogonal keyspace(s) structure
        ==> Imposes (keys & keyspaces & time-freq of the) index onto self
        ==> Similar to Quble.reindex() but allows self to retain 'orthogonal' keyspaces (outside of projection)
        ==> Keyspace removal does not apply
        See :meth:`~qubles.core.quble.Quble.reindex`

        Will allow for insertion of index columns if necessary (if permissioned via allow_idx_insertion)

        :param index: keyspace/key structure to be projected
                      NOTE: index is ideally a non-variate Quble
                      This method will only look at keyspace columns of index arg (will not use valuespaces)
        :type index: Quble or dict (dict keys:keyspaces, dict values:list/numpy array)

        :param tfill_method: The method to be used when filling time/date data against the new keyspace index
        :type tfill_method: {q_fill_method}

        :param tfill_max: The maximum number of consecutive value fill-ins
                         (using the previously supplied fill_method) along a single slice/section of the resulting valuespace.
        :type tfill_max: int

        :param aggr_method: The method that will be used for implicit aggregation (for removal of an axis)
        :type aggr_method: {q_aggr_method}

        :param ignore_missing: Flag that controls the ignore_missing setting for statistical calcs (for implicit aggregation)
        :type ignore_missing: bool

        :param view: Quble indicating conditional elements for which aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :param allow_idx_insertion: Flag to allow/disallow the insertion of a new keyspace/dimension
        :type allow_idx_insertion: bool (True*/False)

        :param index_context_freq_flag: Flag to set context freq using index or subject Quble
                    ==> NOTE: context freq may (or may not) be applicable depending on keys_join_op
                    ==> See :meth:`~qubles.core.quble.Quble.join`
        :type index_context_freq_flag: bool (True*/False)

        :returns: The reindexed Quble
        :rtype: qubles.core.quble.Quble

        """
        # Handle undefined self Quble
        if self.is_undefined:
            # Could consider throwing an Exception here
            return Quble.undefined_instance()

        # Handle case when index is None
        if index is None:
            # Could consider returning an unmodified copy of self here
            raise UndefinedQubleError("The provided index Quble is None")

        # Try to coerce a non-Quble index arg
        if not isinstance(index, Quble):
            index = Quble(indices=index)

        # Handle undefined Quble index arg
        if index.is_undefined:
            # Could consider returning an unmodified copy of self here
            raise UndefinedQubleError("The provided index Quble is undefined")

        # ---------------------------------------
        # Use subject as a representative for (potentially modified) self
        # ONLY REFER TO subject AFTERWARDS!!!!!
        # ---------------------------------------
        subject = self

        # Perform auto_link on subject (if authorized)
        # Here, we look to link keyspaces as follows:
        # self/subject's keyspaces -> index keyspaces
        # -------------------------------------------------
        # NOTE: we are performing link outside join
        # so that we can control the direction of the link
        # -------------------------------------------------
        if auto_link:
            subject = subject.link_keyspaces(
                index.keyspaces,
                link_check=link_check,
                link_dupe_grace=link_dupe_grace,
                deep_copy=False,
                grace=True,
            )

        index_ortho_keyspaces = index.ortho_keyspaces(subject.keyspaces)
        # Does index have ortho keyspaces?
        if index_ortho_keyspaces is None or len(index_ortho_keyspaces) == 0:
            # No index_ortho_keyspaces...keyspaces insertion not applicable
            pass
        # Otherwise, check keyspace insertion permissions...
        elif keyspaces_join_op in ("left", "intersection"):
            # These keyspaces_join_op will NOT introduce new keyspaces into left Quble

            # Limit index's keyspaces to only the dictinct keys from the common_keyspaces
            common_keyspaces = [ks for ks in subject.keyspaces if ks in index.keyspaces]
            if len(common_keyspaces) > 0:
                index = index.distinct_index(keyspaces=common_keyspaces)
            elif keyspaces_join_op == "intersection":
                # No common keyspaces here
                return Quble.undefined_instance()
            else:
                return subject.copy()
        elif not allow_idx_insertion:
            # Here, keyspace insertion is required, but disallowed
            for ks in index.keyspaces:
                if ks not in subject.keyspaces:
                    raise Exception(
                        "self does not support index.keyspace:{0} yet allow_idx_insertion:{1}",
                        format(ks, allow_idx_insertion),
                    )

        # NOTE: keyspace removal does not apply here ['orthogonal' keyspaces are allowed to stay]

        # Determine context_freq as directed
        if index_context_freq_flag:
            # First, call index.context_freq() w/default_freq=None
            context_freq = index.context_freq(default_freq=None)
            if context_freq is None:
                # Next, call subject.context_freq() w/default_freq='<freq>'
                context_freq = subject.context_freq()
        else:
            # First, call subject.context_freq() w/default_freq=None
            context_freq = subject.context_freq(default_freq=None)
            if context_freq is None:
                # Next, call index.context_freq() w/default_freq='<freq>'
                context_freq = index.context_freq()
        # Now, call join method accordingly
        joined = subject.join(
            other=index,
            keys_join_op=keys_join_op,
            keyspaces_join_op=keyspaces_join_op,
            valuespaces_join_op="left",  # <-- Will ignore valuespaces of index arg
            ignore_missing=ignore_missing,
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            tdistribute_mode=tdistribute_mode,
            aggr_method=aggr_method,
            coverage_requirements=None,
            freq=context_freq,
            key_ordering=key_ordering,
            view=view,
            # NOTE: We have already performed keyspace link (index->subject/self) above
            auto_link=False,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
            pre_remove_dupe_keys=pre_remove_dupe_keys,
            consider_auto_squeeze=False,
            calendar_table_name=calendar_table_name,
        )
        return joined

    @RootLib.lazy_kwargs()
    def cross_project(
        self,
        index: Quble,
        keyspaces_join_op: str = "union",
        keys_join_op="rightmost",
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        tdistribute_mode="<space_root>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        coverage_requirements: dict = None,
        key_ordering=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        pre_remove_dupe_keys: bool = True,
        consider_auto_squeeze: bool = False,
        calendar_table_name: str = RootLib.lazy_eval("calendar_table_name"),
        view=RootLib.lazy_eval("view"),
        allow_idx_insertion: bool = True,
        index_context_freq_flag: bool = True,
    ) -> Quble:
        """
        'Cross projection' of the index onto self
        Enforces explicit keys and keyspaces from index onto self
        which is then 'crossed' with 'orthogonal' key-structure of self (if present)

        Will allow for insertion of index keyspaces/columns
        if necessary (if permissioned via allow_idx_insertion)

        See :meth:`~qubles.core.quble.Quble.project`
        """
        # Try to coerce a non-Quble index arg
        if not isinstance(index, Quble):
            index = Quble(indices=index)

        if index.is_undefined:
            # raise Exception('Quble index profile is undefined')
            return self.copy()

        # Does self have any keyspaces outside of index's keyspaces?
        self_ortho_index = self.distinct_ortho_index(keyspace=index.keyspaces)
        if self_ortho_index.is_defined:
            # Here, self has keyspaces outside of index.keyspaces ==> self_ortho_index convert index to a 'crossed' index key structure
            index = (
                self_ortho_index.project(
                    index, index_context_freq_flag=index_context_freq_flag
                ),
            )

        if index.is_undefined:
            raise Exception("Quble index profile is undefined")
        else:
            result = self.project(
                index,
                keyspaces_join_op=keyspaces_join_op,
                keys_join_op=keys_join_op,
                auto_fill=auto_fill,
                tfill_method=tfill_method,
                tfill_max=tfill_max,
                tfill_end_mode=tfill_end_mode,
                tfill_honor_nulls=tfill_honor_nulls,
                tdistribute_mode=tdistribute_mode,
                aggr_method=aggr_method,
                ignore_missing=ignore_missing,
                coverage_requirements=coverage_requirements,
                key_ordering=key_ordering,
                auto_link=auto_link,
                link_check=link_check,
                link_dupe_grace=link_dupe_grace,
                pre_remove_dupe_keys=pre_remove_dupe_keys,
                consider_auto_squeeze=consider_auto_squeeze,
                calendar_table_name=calendar_table_name,
                view=view,
                allow_idx_insertion=allow_idx_insertion,
                index_context_freq_flag=index_context_freq_flag,
            )
            return result

    @RootLib.lazy_kwargs()
    def inner_project(
        self,
        index: Quble,
        keyspaces_join_op: str = "union",
        keys_join_op: str = "intersection",
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        tdistribute_mode="<space_root>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        coverage_requirements: dict = None,
        key_ordering=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        pre_remove_dupe_keys: bool = True,
        consider_auto_squeeze: bool = False,
        calendar_table_name: str = RootLib.lazy_eval("calendar_table_name"),
        view=RootLib.lazy_eval("view"),
        allow_idx_insertion: bool = True,
        index_context_freq_flag: bool = True,
    ) -> Quble:
        """
        'Inner projection' of the index onto self
        (applies intersection of keys for those
        keyspaces shared by both self & index)

        Will allow for insertion of index keyspaces/columns
        if necessary (if permissioned via allow_idx_insertion)

        See :meth:`~qubles.core.quble.Quble.project`
        """
        # Try to coerce a non-Quble index arg
        if not isinstance(index, Quble):
            index = Quble(indices=index)

        if keys_join_op not in VALID_KEYS_JOIN_OP:
            raise Exception(f"Invalid keys_join_op:{keys_join_op}")

        return self.project(
            index=index,
            keyspaces_join_op=keyspaces_join_op,
            keys_join_op=keys_join_op,
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            tdistribute_mode=tdistribute_mode,
            aggr_method=aggr_method,
            ignore_missing=ignore_missing,
            coverage_requirements=coverage_requirements,
            key_ordering=key_ordering,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
            pre_remove_dupe_keys=pre_remove_dupe_keys,
            consider_auto_squeeze=consider_auto_squeeze,
            calendar_table_name=calendar_table_name,
            view=view,
            allow_idx_insertion=allow_idx_insertion,
            index_context_freq_flag=index_context_freq_flag,
        )

    @RootLib.lazy_kwargs()
    def left_inner_project(
        self,
        index: Quble,
        keyspaces_join_op: str = "left",
        keys_join_op: str = "intersection",
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        tdistribute_mode="<space_root>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        coverage_requirements: dict = None,
        key_ordering=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        pre_remove_dupe_keys: bool = True,
        consider_auto_squeeze: bool = False,
        calendar_table_name: str = RootLib.lazy_eval("calendar_table_name"),
        view=RootLib.lazy_eval("view"),
        allow_idx_insertion: bool = True,
        index_context_freq_flag: bool = True,
    ) -> Quble:
        """
        'Left Inner projection' of the index onto self
        Retains all original keyspaces of self,
        but applies intersection of keys for those
        keyspaces shared by both self & index

        Insertion of index keyspaces/columns does not apply

        See :meth:`~qubles.core.quble.Quble.project`
        """
        # Try to coerce a non-Quble index arg
        if not isinstance(index, Quble):
            index = Quble(indices=index)

        if keys_join_op not in VALID_KEYS_JOIN_OP:
            raise Exception(f"Invalid keys_join_op:{keys_join_op}")

        return self.project(
            index=index,
            keyspaces_join_op=keyspaces_join_op,
            keys_join_op=keys_join_op,
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            tdistribute_mode=tdistribute_mode,
            aggr_method=aggr_method,
            ignore_missing=ignore_missing,
            coverage_requirements=coverage_requirements,
            key_ordering=key_ordering,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
            pre_remove_dupe_keys=pre_remove_dupe_keys,
            consider_auto_squeeze=consider_auto_squeeze,
            calendar_table_name=calendar_table_name,
            view=view,
            allow_idx_insertion=allow_idx_insertion,
            index_context_freq_flag=index_context_freq_flag,
        )

    @RootLib.lazy_kwargs()
    def inner_tup_project(
        self,
        index: Quble,
        keyspaces_join_op: str = "union",
        keys_join_op: str = "inter_tunionpostleft",
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        tdistribute_mode="<space_root>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        coverage_requirements: dict = None,
        key_ordering=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        pre_remove_dupe_keys: bool = True,
        consider_auto_squeeze: bool = False,
        calendar_table_name: str = RootLib.lazy_eval("calendar_table_name"),
        view=RootLib.lazy_eval("view"),
        allow_idx_insertion: bool = True,
        index_context_freq_flag: bool = True,
    ) -> Quble:
        """
        'Inner time-union-post (tup) projection' of the index onto self
        (applies inter_tunionpostleft of keys for those keyspaces shared by both self & index)

        Will allow for insertion of index keyspaces/columns if necessary (if permissioned via allow_idx_insertion)

        See :meth:`~qubles.core.quble.Quble.project`
        """
        # Try to coerce a non-Quble index arg
        if not isinstance(index, Quble):
            index = Quble(indices=index)
        return self.project(
            index=index,
            keyspaces_join_op=keyspaces_join_op,
            keys_join_op=keys_join_op,
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            tdistribute_mode=tdistribute_mode,
            aggr_method=aggr_method,
            ignore_missing=ignore_missing,
            coverage_requirements=coverage_requirements,
            key_ordering=key_ordering,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
            pre_remove_dupe_keys=pre_remove_dupe_keys,
            consider_auto_squeeze=consider_auto_squeeze,
            calendar_table_name=calendar_table_name,
            view=view,
            allow_idx_insertion=allow_idx_insertion,
            index_context_freq_flag=index_context_freq_flag,
        )

    @RootLib.lazy_kwargs()
    def outer_project(
        self,
        index: Quble,
        keyspaces_join_op: str = "union",
        keys_join_op: str = "union",
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        tdistribute_mode="<space_root>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        coverage_requirements: dict = None,
        key_ordering=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        pre_remove_dupe_keys: bool = True,
        consider_auto_squeeze: bool = False,
        calendar_table_name: str = RootLib.lazy_eval("calendar_table_name"),
        view=RootLib.lazy_eval("view"),
        allow_idx_insertion: bool = True,
        index_context_freq_flag: bool = True,
    ) -> Quble:
        """
        'Outer projection' of the index onto self
        (applies union of keys for those keyspaces shared by both self & index)

        Will allow for insertion of index columns if necessary (if permissioned via allow_idx_insertion)
        Removal of index columns is accomplished using aggregation (if permissioned via allow_idx_removal)

        See :meth:`~qubles.core.quble.Quble.project`
        """
        # Try to coerce a non-Quble index arg
        if not isinstance(index, Quble):
            index = Quble(indices=index)

        return self.project(
            index=index,
            keyspaces_join_op=keyspaces_join_op,
            keys_join_op=keys_join_op,
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            tdistribute_mode=tdistribute_mode,
            aggr_method=aggr_method,
            ignore_missing=ignore_missing,
            coverage_requirements=coverage_requirements,
            key_ordering=key_ordering,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
            pre_remove_dupe_keys=pre_remove_dupe_keys,
            consider_auto_squeeze=consider_auto_squeeze,
            calendar_table_name=calendar_table_name,
            view=view,
            allow_idx_insertion=allow_idx_insertion,
            index_context_freq_flag=index_context_freq_flag,
        )

    @RootLib.lazy_kwargs()
    def left_outer_project(
        self,
        index: Quble,
        keyspaces_join_op: str = "left",
        keys_join_op: str = "union",
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        tdistribute_mode="<space_root>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        coverage_requirements: dict = None,
        key_ordering=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        pre_remove_dupe_keys: bool = True,
        consider_auto_squeeze: bool = False,
        calendar_table_name: str = RootLib.lazy_eval("calendar_table_name"),
        view=RootLib.lazy_eval("view"),
        allow_idx_insertion: bool = True,
        index_context_freq_flag: bool = True,
    ) -> Quble:
        """
        'Left Outer projection' of the index onto self
        Retains all original keyspaces of self,
        but applies union of keys for those
        keyspaces shared by both self & index

        Insertion of index keyspaces/columns does not apply

        Will allow for insertion of index columns if necessary (if permissioned via allow_idx_insertion)
        Removal of index columns is accomplished using aggregation (if permissioned via allow_idx_removal)

        See :meth:`~qubles.core.quble.Quble.project`
        """
        # Try to coerce a non-Quble index arg
        if not isinstance(index, Quble):
            index = Quble(indices=index)

        return self.project(
            index=index,
            keyspaces_join_op=keyspaces_join_op,
            keys_join_op=keys_join_op,
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            tdistribute_mode=tdistribute_mode,
            aggr_method=aggr_method,
            ignore_missing=ignore_missing,
            coverage_requirements=coverage_requirements,
            key_ordering=key_ordering,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
            pre_remove_dupe_keys=pre_remove_dupe_keys,
            consider_auto_squeeze=consider_auto_squeeze,
            calendar_table_name=calendar_table_name,
            view=view,
            allow_idx_insertion=allow_idx_insertion,
            index_context_freq_flag=index_context_freq_flag,
        )

    @RootLib.lazy_kwargs()
    def insert_index1d(
        self,
        index: Quble,
        keyspace: str,
        keyspaces_join_op="union",
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        tdistribute_mode="<space_root>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        coverage_requirements: dict = None,
        key_ordering=None,
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        consider_auto_squeeze: bool = False,
        calendar_table_name: str = RootLib.lazy_eval("calendar_table_name"),
        view=RootLib.lazy_eval("view"),
    ) -> Quble:
        """
        Inserts specified keyspace/dimension of the Quble
        to that dimension's keys in the index arg Quble

        :meth:`~qubles.core.quble.Quble.reindex`
        """
        if keyspace is None and index is None:
            return self.copy()
        elif keyspace in self.keyspaces:
            raise Exception(f"keyspace:{keyspace} already exists in the Quble")

        if not isinstance(index, Quble):
            raise Exception("Invalid index arg...Quble expected")

        return self.reindex1d(
            self,
            index=index,
            keyspace=keyspace,
            keyspaces_join_op=keyspaces_join_op,
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            tdistribute_mode=tdistribute_mode,
            aggr_method=aggr_method,
            ignore_missing=ignore_missing,
            coverage_requirements=coverage_requirements,
            key_ordering=key_ordering,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
            consider_auto_squeeze=consider_auto_squeeze,
            calendar_table_name=calendar_table_name,
            view=view,
            allow_idx_insertion=True,
            allow_idx_removal=True,
        )

    @RootLib.lazy_kwargs()
    def apply_view(
        self,
        view=RootLib.lazy_eval("view"),
        view_valuespace_as: str = None,
        allow_shallow_copy: bool = True,
    ) -> Quble:
        """
        Returns a new Quble with null data (or no records)
        in elements/keys outside of current view

        :param view: the focal view of interest
        :type view: Quble

        :param view_valuespace_as: optional newly introduced valuespace
                                   providing the view's primary valuespace values
                                   in resultant Quble
        :type view_valuespace_as: str

        :param allow_shallow_copy: permission flag to return a shallow copy
                                   of original self Quble for trivial view case
        :type allow_shallow_copy: bool (True*/False)
        """
        if (
            not self.is_undefined
            and not self.is_empty
            and view is not None
            and not view.is_undefined
        ):
            # return self.reindex(other=view, view=None, allow_idx_removal=False) # <-- This will force view's keys & keyspaces only
            # return self.project(other=view, view=None) # <-- This will force view's keys for shared keyspaces...may allow for resampling across time-keyspaces
            # return self.inner_project(other=view, view=None) # <-- This will force intersection of keys for shared keyspaces

            # ------------------------------------------------------------------
            # Use of inner_tup_project will force:
            #   1) intersection of keys for non-time / non-resampling keyspaces
            #   2) union-postleft keys for shared time w/resampling keyspaces
            # ------------------------------------------------------------------
            if view_valuespace_as is None:
                if view.is_variate:
                    view = view.bool_to_index(coerce_to_bool=True)
                return self.inner_tup_project(index=view, view=None)
            else:
                tgt_valuespaces = []
                tmp_dict = {}
                for vs in self.valuespaces:
                    tmp_dict[vs] = vs
                tgt_valuespaces.append(tmp_dict)

                if view_valuespace_as in tgt_valuespaces:
                    raise Exception(
                        "view_valuespace_as:{0} conflicts with self.valuespace:{1}".format(
                            view_valuespace_as, self.valuespace
                        )
                    )
                elif view.is_index:
                    view = view.index_to_bool(view_valuespace_as)

                tgt_valuespaces.append({view.valuespace: view_valuespace_as})
                # NOTE: These join settings are consistent with
                #       inner_tup_project(valuespaces_join_op='left')
                joined = self.join(
                    view,
                    keyspaces_join_op="union",
                    keys_join_op="inter_tunionpostleft",
                    valuespaces_join_op=tgt_valuespaces,
                    view=None,
                )
                return joined

        else:
            return self if allow_shallow_copy else self.copy()

    def insert_keyspaces(self, hyper_key: dict, hyper_col_types: dict = None) -> Quble:
        """
        Inserts the keyspaces and associated keys
        [If self is empty, a new empty columns will be inserted
        where column types are derived from the keys provided]
        The new keyspaces to be inserted must not be present in the Quble

        :param hyper_key: (dict) new key(s) (per keyspace)

                     The dictionary values may be a consistently
                     EITHER all scalars or conistently all lists/arrays

                ==> For all-scalars case, dictionary values can be either:
                        1a) Python scalar (str, int, float, datetime, date, etc.)
                     or 1b) numpy scalar (including np.datetime64)
                    [NOTE: can use dictionary value='null' so long as associated
                     non-trivial hyper_col_types dict value entry is used]

                ==> For all-list/arrays case, dictionary values can be either:
                        2a) list
                     or 2b) tuple
                     or 2c) numpy array

        :type hyper_key: dict

        :param hyper_col_types: (optional) (dict) of SQL types (per keyspace)
                                for explicit CASTING of resultant columns
        :type hyper_col_types: dict or None
        """
        # Validate self
        if self.is_undefined:
            raise UndefinedQubleError("Undefined Quble")

        # Validate hyper_key
        if hyper_key is None:
            raise Exception("No hyper_key provided")
        elif not isinstance(hyper_key, dict):
            raise Exception("Invalid hyper_key...dict expected")

        # Validate hyper_col_types
        if hyper_col_types is None:
            pass
        elif not isinstance(hyper_col_types, dict):
            raise Exception("Invalid hyper_col_types...dict or None expected")

        # Test for "hyper index" case: dictionary values are lists/tuples/numpy.arrays
        hyper_index_flag = False
        for keyspace in list(hyper_key.keys()):
            if keyspace in self.keyspaces:
                raise Exception(f"keyspace:{keyspace} already present")
            if isinstance(hyper_key[keyspace], (list, tuple, np.ndarray)):
                hyper_index_flag = True
            elif hyper_index_flag:
                raise Exception(
                    f"Inconsistent hyper_key config...elements must be consistently all scalars or all tuples/list/np.ndarray (not mixed)"
                )

        # -------------------------------------
        # CASE #1: HYPER-INDEX CASE
        # [MULTIPLE KEYS FOR EACH NEW KEYSPACE]
        # -------------------------------------
        if hyper_index_flag:
            index_to_insert = Quble(indices=hyper_key)
            result = self.reindex(index=index_to_insert, allow_idx_insertion=True)
            if hyper_col_types is not None:
                result = result.change_types(hyper_col_types)
            return result

        # -------------------------------------
        # CASE #2: STANDARD HYPER-KEY CASE
        # [SINGLE KEY FOR EACH NEW KEYSPACE]
        # -------------------------------------
        # Seed extended_column_names with original keyspaces
        extended_column_names = list(self.keyspaces)
        column_expressions = {}
        for keyspace in list(hyper_key.keys()):
            if keyspace in self.keyspaces:
                raise Exception(f"keyspace:{keyspace} already present")

            key = hyper_key[keyspace]
            if key is None:
                # TODO: Think more about whether this is a hard exception
                raise Exception(f"No key provided for keyspace:{keyspace}")
            elif isinstance(key, str):
                # TODO: Try to parse string to datetime
                try:
                    key = datetime.strptime(key)
                    arr1 = np.array([key])
                    col_type = "timestamp"
                    key = (
                        "null"
                        if isnull(arr1[0])
                        else f"'{key.strftime('%Y-%m-%dT%H:%M:%S.%f')}'"
                    )
                except:
                    if key.lower() == "null":
                        # Here, the user has requested a null record be inserted
                        col_type = (
                            "varchar(4)"  # <-- could probably use varchar(1) here
                        )
                    else:
                        arr1 = np.array([key])
                        col_type = dtype_to_coltype(arr1.dtype)
                        key = "null" if isnull(arr1[0]) else f"'{key}'"
            elif isinstance(key, datetime):
                arr1 = np.array([key])
                col_type = "timestamp"
                key = (
                    "null"
                    if isnull(arr1[0])
                    else f"'{key.strftime('%Y-%m-%dT%H:%M:%S.%f')}'"
                )
            elif isinstance(key, date):
                arr1 = np.array([key])
                col_type = "timestamp"
                key = "null" if isnull(arr1[0]) else f"'{key.strftime('%Y-%m-%d')}'"
            elif not hasattr(key, "dtype"):
                # Assume a simple Python (non-string) type arg was provided
                arr1 = np.array([key])
                col_type = dtype_to_coltype(arr1.dtype)
                key = "null" if isnull(arr1[0]) else key
            elif isinstance(key, np.ndarray):
                raise Exception(
                    "key (dict values) must be either: 1)all scalars, or 2)all numpy arrays/lists/tuples (not mixed"
                )
            elif np.issubdtype(key.dtype, np.datetime64):
                # numpy datetime64 scalar
                arr1 = np.array([key])
                col_type = dtype_to_coltype(arr1.dtype)
                key = "null" if isnull(arr1[0]) else f"'{str(key)}'"
            else:
                arr1 = np.array([key])
                col_type = dtype_to_coltype(arr1.dtype)
                key = "null" if isnull(arr1[0]) else f"'{str(key)}'"

            # As a default, use the raw key as provided
            # TODO: Intercept missing_values / null proxy and handle accordingly

            # If a specific col_type was provided for this keyspace, we employ an explicit casting construct accordingly
            if hyper_col_types is not None and keyspace in list(hyper_col_types.keys()):
                if not isinstance(hyper_col_types[keyspace], str):
                    raise Exception(f"hyper_col_types[{keyspace}] must be str or None")

                col_type = hyper_col_types[keyspace].lower()
                # TODO: Need to strip trailing parenthesis & args
                #       for this type checking to work
                # EXAMPLE: 'varchar(24)' --> 'varchar'
                key = f"CAST({str(key)} AS {col_type})"
            elif isinstance(key, str) and key.lower() == "null":
                key = f"CAST({key} AS {col_type})"

            # Append current keyspace to extended_column_names
            extended_column_names.append(keyspace)
            # We must provide a column expression for each new keyspace
            if isinstance(key, str):
                column_expressions[keyspace] = key
            else:
                column_expressions[keyspace] = str(key)

        # Finally, append original valuespaces to extended_column_names
        # ==> extended_column_names = self.keyspaces + new_keyspaces + self.valuespaces
        extended_column_names = extended_column_names + self.valuespaces

        custom_info_overrides = {}
        if column_expressions is not None:
            for col1 in column_expressions.keys():
                if "role" not in custom_info_overrides:
                    custom_info_overrides["role"] = {}
                custom_info_overrides["role"][col1] = "keyspace"

        return self.select(
            column_names=extended_column_names,
            column_expressions=column_expressions,
            custom_info_overrides=custom_info_overrides,
        )

    def insert_keyspace(self, keyspace: str, key, col_type: str = None) -> Quble:
        """
        Inserts the new keyspace using the specified key
        [If self is empty, a new empty column will be inserted where column type is derived from the key provided]

        For null keys, you may set key to the missing_value for the underlying dtype/Python type
        by assign key='null' and use the desired col_type arg

        Example: self.insert_keyspace(keyspace='Dates', key='null', col_type='timestamp')

        The new keyspace will be placed at end of keyspaces

        :param keyspace: keyspace to add
        :type keyspace: str

        :param key: associated key to add
        [NOTE: can use key='null' so long as an associated, non-trivial col_type is used]
        :type key: Python scalar (str, int, float, datetime, date, etc.) or numpy scalar (including np.datetime64) or list/tuple/numpy array

        :param col_type: (optional) SQL type for explicit CASTING of resultant column
        :type col_type: str or None
        """
        hyper_col_types = None if col_type is None else {keyspace: col_type}
        return self.insert_keyspaces(
            hyper_key={keyspace: key}, hyper_col_types=hyper_col_types
        )

    @RootLib.lazy_kwargs()
    def reindex1d(
        self,
        index: Quble,
        keyspace: str,
        keyspaces_join_op: str = "union",
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        tdistribute_mode="<space_root>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        coverage_requirements: dict = None,
        key_ordering="asc",
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        consider_auto_squeeze: bool = False,
        calendar_table_name: str = RootLib.lazy_eval("calendar_table_name"),
        view=RootLib.lazy_eval("view"),
        allow_idx_insertion: bool = True,
        index_context_freq_flag: bool = True,
    ) -> Quble:
        """
        For the specified keyspace/dimension, projects/reindexes the keys of the index onto self
        [The other keyspaces/dimensions of self are retained]

        :meth:`~qubles.core.quble.Quble.reindex`
        """
        # Try to coerce a non-Quble index arg
        if not isinstance(index, Quble):
            if not isinstance(index, dict):
                index = {keyspace: index}
            index = Quble(indices=index)

        # Isolate the keys from the specified index, then call reindex()

        index1D = index.index(keyspaces=keyspace, distinct=True)
        return self.project(
            index=index1D,
            keyspaces_join_op=keyspaces_join_op,
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            tdistribute_mode=tdistribute_mode,
            aggr_method=aggr_method,
            ignore_missing=ignore_missing,
            coverage_requirements=coverage_requirements,
            key_ordering=key_ordering,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
            consider_auto_squeeze=consider_auto_squeeze,
            calendar_table_name=calendar_table_name,
            view=RootLib.lazy_eval("view"),
            allow_idx_insertion=allow_idx_insertion,
            index_context_freq_flag=index_context_freq_flag,
        )

    @RootLib.lazy_kwargs()
    def intersect1d(
        self,
        index: Quble,
        keyspace: str,
        keyspaces_join_op: str = "union",
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        tdistribute_mode="<space_root>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        coverage_requirements=None,
        key_ordering="asc",
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        consider_auto_squeeze: bool = False,
        calendar_table_name: str = RootLib.lazy_eval("calendar_table_name"),
        view=RootLib.lazy_eval("view"),
        allow_idx_insertion: bool = True,
        index_context_freq_flag: bool = True,
    ) -> Quble:
        """
        Applies an 'inner projection' (intersection) of the index's keys onto self's keys
        for the specified keyspace/dimension of the Quble
        [The other keyspaces/dimensions of self are retained]

        :meth:`~qubles.core.quble.Quble.reindex`
        """
        # Isolate the keys from the specified index, then call reindex()
        index1D = index.index(keyspaces=keyspace, distinct=True)
        return self.inner_project(
            index=index1D,
            keyspaces_join_op=keyspaces_join_op,
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            tdistribute_mode=tdistribute_mode,
            aggr_method=aggr_method,
            ignore_missing=ignore_missing,
            coverage_requirements=coverage_requirements,
            key_ordering=key_ordering,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
            consider_auto_squeeze=consider_auto_squeeze,
            calendar_table_name=calendar_table_name,
            view=RootLib.lazy_eval("view"),
            allow_idx_insertion=allow_idx_insertion,
            index_context_freq_flag=index_context_freq_flag,
        )

    @RootLib.lazy_kwargs()
    def union1d(
        self,
        index: Quble,
        keyspace: str,
        keyspaces_join_op: str = "union",
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        tdistribute_mode="<space_root>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        coverage_requirements: dict = None,
        key_ordering="asc",
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        consider_auto_squeeze: bool = False,
        calendar_table_name: str = RootLib.lazy_eval("calendar_table_name"),
        view=RootLib.lazy_eval("view"),
        allow_idx_insertion: bool = True,
        index_context_freq_flag: bool = True,
    ) -> Quble:
        """
        Applies an 'outer projection' (union) of the index's keys and self's keys
        for the specified keyspace/dimension of the Quble
        [The other keyspaces/dimensions of self are retained]

        :meth:`~qubles.core.quble.Quble.reindex`
        """
        # Isolate the keys from the specified index, then call reindex()
        index1D = index.index(keyspaces=keyspace, distinct=True)
        return self.outer_project(
            index=index1D,
            keyspaces_join_op=keyspaces_join_op,
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            tdistribute_mode=tdistribute_mode,
            aggr_method=aggr_method,
            ignore_missing=ignore_missing,
            coverage_requirements=coverage_requirements,
            key_ordering=key_ordering,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
            consider_auto_squeeze=consider_auto_squeeze,
            calendar_table_name=calendar_table_name,
            view=view,
            allow_idx_insertion=allow_idx_insertion,
            index_context_freq_flag=index_context_freq_flag,
        )

    def are_coindexed(self, other, grace: bool = True) -> bool:
        """
        Indicates whether two (or more) Qubles are 'joined' as defined below:
           1) share same table
           2) have matching keyspaces
           3) share same keyspace columns
              (keyspace columns use same column id)

        :param other: comparable(s)
        :type other: Quble or list/tuple of Qubles

        :param grace: flag to gracefully handle not co-indexed case
                        grace=True (default): simply return False indicating the two Qubles are co-indexed
                        grace=False : raise an error indicating why the two Qubles are not co-indexed
        :type grace: boolean (True*/False)
        """

        others = other if isinstance(other, (list, tuple)) else [other]
        for subject in others:
            if subject is None:
                if grace:
                    return False
                else:
                    raise Exception("other is None")

            elif not isinstance(subject, Quble):
                raise Exception("Non-Quble encountered")

            elif self.table_name != subject.table_name:
                if grace:
                    return False
                else:
                    raise Exception(
                        "Inconsistent table_names...self:{0}, subject:{1}".format(
                            self.table_name, subject.table_name
                        )
                    )
            elif self.keyspaces != subject.keyspaces:
                if grace:
                    return False
                else:
                    raise Exception(
                        "Inconsistent keyspaces...self:{0}, subject:{1}".format(
                            self.keyspaces, subject.keyspaces
                        )
                    )

        return True

    def shares_table_with(self, other) -> bool:
        """
        Indicates whether two (or more) Qubles share a common table

        :param other: comparable(s)
        :type other: Quble or list/tuple of Qubles
        """
        if self.is_undefined:
            # Cannot share a table when undefined
            return False

        others = other if isinstance(other, (list, tuple)) else [other]
        for subject in others:
            if not isinstance(subject, Quble):
                raise Exception("Non-Quble encountered")
            elif subject.is_undefined:
                # Cannot share a table when undefined
                return False
            elif self.table_name != subject.table_name:
                return False

        return True

    def confirm_meta_synchronicity(self, grace=False):
        """
        Confirms "synchronicity" between:
            1) Quble's in-memory column meta data (self._column_info)
        AND 2) associated meta data within table's column comments

        If properly synchronized: returns True
        elif grace: returns False
        else: raises Exception with appropriate error string

        NOTE: Logic treats a meta-data assignment of None
        AS EQUIVALENT TO NO meta-data assignment

        :param grace: flag to handle non-synchronicity gracefully
        :type grace: bool (False*/True)

        :returns: validation status
           ==> True: confirmed match (synchronized)
           ==> False: failed confirmation (NOT synchronized)
        :rtype: bool
        """
        from qubles.io.util.table_utils import (
            get_column_comments_and_types,
            _get_column_comment,
        )

        # For undefined Qubles, simply return True
        # [Here, "synchronicity" is not applicable]
        if self.is_undefined:
            return True

        # Get the column_info from the table's comments
        column_info_from_comments = {}  # <-- Translated
        table_metadata = desc_table(self.table_name)
        table_comments = get_column_comments_and_types(table_metadata)[0]
        if table_comments:
            # --------------------------------------------------------
            # Here, table_comments is a dict of dictionaries where:
            #    ==> outer key: column name, inner key: info_type
            # --------------------------------------------------------
            # But, we need to transpose this format
            # to make compatible with self._column_info so that:
            #    ==> outer key: info_type, inner key: column name
            # --------------------------------------------------------
            for column_name in table_comments:
                comment1 = _get_column_comment(table_comments, column_name)
                if comment1:
                    for info_type in comment1:
                        if info_type:
                            if info_type not in column_info_from_comments:
                                column_info_from_comments[info_type] = {}
                            column_info_from_comments[info_type][column_name] = (
                                comment1[info_type]
                            )

        # Initialize failure_message as None,
        # then re-assign if appropriate below
        failure_message = None

        # Identify info_types (superset)
        if self._column_info is None:
            if column_info_from_comments is None:
                info_types = []
            else:
                info_types = list(self._column_info.keys())
        elif column_info_from_comments is None:
            info_types = list(self._column_info.keys())
        else:
            # Here, info_types will be a super-set of
            # self._column_info.keys() and column_info_from_comments.keys()
            info_types = list(
                set(self._column_info.keys()).union(
                    set(column_info_from_comments.keys())
                )
            )

        # We exclude BUILTIN_INFO_TYPES from info_type comparison
        # [These info types may be present in self._column_info,
        # but will absent from column_info_from_comments]
        info_types = [
            it1 for it1 in info_types if it1 and it1 not in BUILTIN_INFO_TYPES
        ]

        # Initialize dictionary of dictionaries of non-trivial assignments
        non_trivial_column_info = {}
        non_trivial_column_comments = {}

        # ====================== START: info_types LOOP ======================
        for info_type in info_types:
            # Initialize and update non_trivial_column_info[info_type]
            non_trivial_column_info[info_type] = {}
            if self._column_info is None:
                pass
            elif info_type not in self._column_info:
                pass
            elif self._column_info[info_type] is None:
                pass
            else:
                for col_name1 in self._column_info[info_type]:
                    if self._column_info[info_type][col_name1] is not None:
                        # Only place info_type entry here
                        # if the column assignment is not None
                        non_trivial_column_info[info_type][col_name1] = (
                            self._column_info[info_type][col_name1]
                        )

            # Initialize and update non_trivial_column_comments[info_type]
            non_trivial_column_comments[info_type] = {}
            if column_info_from_comments is None:
                pass
            elif info_type not in column_info_from_comments:
                pass
            elif column_info_from_comments[info_type] is None:
                pass
            else:
                for col_name1 in column_info_from_comments[info_type]:
                    if column_info_from_comments[info_type][col_name1] is not None:
                        # Only place info_type entry here
                        # if the column assignment is not None
                        non_trivial_column_comments[info_type][col_name1] = (
                            column_info_from_comments[info_type][col_name1]
                        )

            # -----------------------------------------------------------------
            # Compare: non_trivial_column_info vs. non_trivial_column_comments
            # -----------------------------------------------------------------
            # Check whether both these dictionaries provide non-trivial
            # assignments for the same set of columns (for current info_type)
            # -----------------------------------------------------------------
            column_info_set = set(non_trivial_column_info[info_type].keys())
            column_comments_set = set(non_trivial_column_comments[info_type].keys())
            if column_info_set != column_comments_set:
                # The is not common column coverage here
                # between these two dictionaries
                failure_message = f"column coverage mismatch for info_type:{info_type}, column_info coverage:{column_info_set}, column_comments coverage:{column_comments_set}"
            else:
                # Here, both dictionaries have common column name coverage
                # so we (arbitrarily) loop through the columns (keys)
                # of the non_trivial_column_info[info_type] (dict) and
                # look for agreement of non-trivial assignments for each column
                for col_name1 in list(non_trivial_column_info[info_type].keys()):
                    # Here, col_name1 should be present in both:
                    #     1) non_trivial_column_info[info_type] (dict)
                    # and 2) non_trivial_column_comments[info_type] (dict)
                    if (
                        non_trivial_column_info[info_type][col_name1]
                        != non_trivial_column_comments[info_type][col_name1]
                    ):
                        failure_message = f"Mismatch for info_type:{info_type} and column name:{col_name1}"
                        break

            if failure_message:
                break

        # ====================== END: info_types LOOP ======================

        # if self._column_info is None or len(self._column_info) == 0:
        #     # No in-memory self._column_info here...
        #     # Make sure no table comments are present
        #     if len(column_info_from_comments) > 0:
        #         for column_name in table_comments:
        #             if len(table_comments[column_name]) > 0:
        #                 failure_message = f"No Quble._column_info, yet table_comments:{column_info_from_comments}"

        # elif set(column_info_from_comments.keys()) != set(self._column_info.keys()):

        #     # The (non-ordered) set of outer dict keys (per info_type) differ.
        #     # As such, there is a possible content mis-match here,
        #     # but we need to check for non-trivial content to confirm mismatch
        #     for info_type in self._column_info.keys():
        #         if info_type in column_info_from_comments:
        #             pass
        #         elif self._column_info[info_type] is None \
        #             or len(self._column_info[info_type]) == 0:
        #             pass
        #         else:
        #             # Here, self._column_info[info_type] has non-trivial content,
        #             # but info_type is absent from column_info_from_comments
        #             failure_message = f"{info_type} absent from column_info_from_comments, yet self._column_info[{info_type}]:{self._column_info[info_type]}"
        #             break

        #     if not failure_message:
        #         for info_type in column_info_from_comments.keys():
        #             if info_type in self._column_info:
        #                 pass
        #             elif column_info_from_comments[info_type] is None \
        #                 or len(column_info_from_comments[info_type]) == 0:
        #                 pass
        #             else:
        #                 # Here, column_info_from_comments[info_type] has non-trivial content,
        #                 # but info_type is absent from self._column_info
        #                 failure_message = f"{info_type} absent from self._column_info, yet column_info_from_comments[{info_type}]:{column_info_from_comments[info_type]}"
        #                 break

        # else:
        #     # Here, _column_info and column_info_from_comments have
        #     # common outer dict keys (info_type)
        #     # Now, make sure content matches within each sub-dictionary:
        #     # _column_info[info_type] and column_info_from_comments[info_type]
        #     for info_type in self._column_info.keys():

        #         # See if there is any non-trivial content within self._column_info[info_type]
        #         if self._column_info[info_type] is None or len(self._column_info[info_type]) == 0:
        #             # No content within self._column_info[info_type] here
        #             if info_type in column_info_from_comments \
        #                 and column_info_from_comments[info_type] is not None \
        #                 and len(column_info_from_comments[info_type]) > 0:
        #                 # See if any column_info_from_comments[info_type][col_name1]
        #                 # entries have non-trivial assignments
        #                 for col_name1 in column_info_from_comments[info_type]:
        #                     if column_info_from_comments[info_type][col_name1] is not None:
        #                         # No content within self._column_info[info_type] here
        #                         # but non-trivial content within column_info_from_comments[info_type][col_name1]
        #                         failure_message = f"column_info_from_comments[{info_type}]:{column_info_from_comments[info_type]} should be empty/None"

        #         elif info_type not in column_info_from_comments:
        #             # Non-trivial content in self._column_info[info_type]
        #             # but no content within column_info_from_comments[info_type]
        #             failure_message = f"info_type:{info_type} absent from column_info_from_comments:{column_info_from_comments}"
        #         elif column_info_from_comments[info_type] is None:
        #             # Non-trivial content in self._column_info[info_type]
        #             # but no content within column_info_from_comments[info_type]
        #             failure_message = f"column_info_from_comments[{info_type}] should not be None"
        #         elif len(column_info_from_comments[info_type]) == 0:
        #             # Non-trivial content in self._column_info[info_type]
        #             # but no content within column_info_from_comments[info_type]
        #             failure_message = f"column_info_from_comments[{info_type}] should not be empty"
        #         else:
        #             for col_name1 in self._column_info[info_type]:
        #                 if self._column_info[info_type][col_name1] is None:
        #                     if col_name1 in column_info_from_comments[info_type] \
        #                         and column_info_from_comments[info_type][col_name1] is not None:
        #                         failure_message = f"column_info_from_comments[{info_type}][{col_name1}] should be None"
        #                 elif col_name1 not in column_info_from_comments[info_type]:
        #                     failure_message = f"column name:{col_name1} absent from column_info_from_comments[{info_type}]:{column_info_from_comments[info_type]}"
        #                 elif self._column_info[info_type][col_name1] != column_info_from_comments[info_type][col_name1]:
        #                     failure_message = f"column_info_from_comments[{info_type}][{col_name1}] != self._column_info[{info_type}][{col_name1}]"

        # Return results
        # (depending on failure_messsage)
        if failure_message is None:
            return True
        elif grace:
            return False
        else:
            raise Exception(failure_message)

    @RootLib.lazy_kwargs()
    def equals(
        self,
        other,
        require_coindex: bool = False,
        keyspace_order_sensitive: bool = True,
        key_order_sensitive: bool = False,
        subspace_allowed: bool = False,
        compare_valuespaces: bool = True,
        variate_mode: str = RootLib.lazy_eval("variate_mode"),
        valuespace_order_sensitive: bool = False,
        primary_valuespace_sensitive: bool = False,
        column_info_sensitive: bool = True,
        info_types_to_be_compared: list = list(INFO_TYPES),
        ignore_null_info_values: bool = False,
        epsilon: float = 0.000001,
        grace: bool = True,
        valuespace_flag: bool = False,
    ) -> bool:
        """
        Compares indexes (keyspaces, keys) and valuespaces of Qubles

        :param other: comparable(s)
        :type other: Quble or list/tuple of Qubles

        param require_coindex: require co-indexed state
             (share same underlying table)
        :type require_coindex: boolean (True,False*)

        :param keyspace_order_sensitive: require same keyspaces ordering
        :type keyspace_order_sensitive: boolean (True*,False)

        :param key_order_sensitive: require same key ordering for a given keyspace
        :type key_order_sensitive: boolean (False*,True)

        :param subspace_allowed: allow for other's keyspaces to be a subset of self
        :type subspace_allowed: boolean (False*,True)

        :param compare_valuespaces: Flag for comparison of valuespace values
                                    (and possibly valuespace names) according to variate_mode
        :type compare_valuespaces: boolean (True*,False)

        :param variate_mode: variate_mode for valuespace name and/or value comparison
        :type variate_mode: str ('multi','mixed','uni')

            NOTE: variate_mode ONLY APPLIES if compare_valuespaces == True
              ==> variate_mode is ignored if compare_valuespaces == False

            If variate_mode=='multi':

            valuespace names AND their value records must match

            If variate_mode=='uni':

            value records for primary valuespaces of self & other must match
            (regardless of the primary valuespace names)

        :param valuespace_order_sensitive: Flag to require same valuespaces ordering
                                       ==> Only applicable if variate_mode=='multi' (otherwise ignored)
        :type valuespace_order_sensitive: boolean (False*,True)

        :param column_info_sensitive: Flag to validate column_info agreement
        type column_info_sensitive: boolean (True*,False)

        :param info_types_to_be_compared: List of info types to be considered while column info comparison
        type info_types_to_be_compared: list of info types. For Ex - ['freq','time_basis']

        :param ignore_null_info_values: Flag to ignore comparing info types that have null or None as info values
        type ignore_null_info_values: boolean (True,False*)

        :param epsilon: tolerance for comparing float type columns
        :type epsilon: float

        :param grace: flag to gracfully handle not equal case
                        grace=True (default): simply return False indicating the two Qubles are not equal
                        grace=False : raise an error indicating why the two Qubles are not equal
        :type grace: boolean (True*/False)

        : param valuespace_flag : especially made to handle edge case where keyspace will be converted to valuespace(Dates)
        : type valuespace_flag : boolean  (True*/False)

        #:returns: result of comparison
        #:rtype: boolean
        """

        # TO CONSIDER: Adding equality tests for column info_types?
        if key_order_sensitive:
            raise Exception("key_order_sensitive is not supported!")
        # Validate other
        if other is None:
            if grace:
                return False
            else:
                raise Exception("other is None")
        elif isinstance(other, Quble):
            other = [other]
        elif not isinstance(other, (list, tuple)):
            raise Exception(
                "Invalid other arg...Quble or list/tuple of Qubles required"
            )
        elif len(other) == 0:
            if grace:
                return False
            else:
                raise Exception("other is an empty list")
        else:
            for quble1 in other:
                if not isinstance(quble1, Quble):
                    raise Exception(
                        "Invalid other arg...Quble or list/tuple of Qubles required"
                    )
        # Validate info_types_to_be_compared arg
        if isinstance(info_types_to_be_compared, str):
            info_types_to_be_compared = [info_types_to_be_compared]

        if not isinstance(info_types_to_be_compared, list):
            raise Exception(
                f"info_types_to_be_compared argument should be either a string or list os strings, But not {type(info_types_to_be_compared)}"
            )

        if info_types_to_be_compared != INFO_TYPES:
            for info_type in info_types_to_be_compared:
                if info_type not in INFO_TYPES:
                    raise Exception(
                        f"Invalid info type : {info_type} provided in info_types_to_be_compared argument"
                    )

        # NOTE: at this point, other is confirmed to be a list/index

        # Are the indexes equal?
        # --------------------------
        # NOTE: are_eqindexed() method will handle index
        #       comparison properly for dual scalar case
        if not require_coindex:
            pass
        elif self.are_coindexed(other, grace=grace):
            pass
        elif grace:
            return False
        else:
            raise Exception("Not equal indexed")

        # =========================== START: OTHER LOOP =========================
        # Checking if self has duplicate keys
        subject_has_duplicate_keys = self.has_duplicate_keys()
        # Check if self has numeric columns
        subject_has_numeric_cols = any(
            self.is_numeric(space="<spaces>", summarize=None)
        )

        # Otherwise, loop through each Quble in other and test valuespaces against self
        for other1 in other:
            # =====================================================
            # PART 0: MAKE A SHALLOW COPY OF self -> subject
            # [ONLY REFER TO subject FOR THE REST OF THIS LOOP]
            # =====================================================
            subject = self

            # ===========================================
            # PART 1: VALUESPACE VALIDATION / PREP
            # ===========================================
            # Perform some initial rudimentary checks

            # If self is a uni/multi-scalar, then we require other1 to also be a uni/multi-scalar
            if (
                subject.is_scalar
                or subject.is_multiscalar
                or len(subject.keyspaces) == 0
            ):
                if (
                    other1.is_scalar
                    or other1.is_multiscalar
                    or len(other1.keyspaces) == 0
                ):
                    # No further testing of other1 needed here
                    pass
                elif grace:
                    return False
                else:
                    raise Exception(
                        "self is scalar Quble and other(s) are non-scalar(s)"
                    )
            elif (
                other1.is_scalar or other1.is_multiscalar or len(other1.keyspaces) == 0
            ):
                if grace:
                    return False
                else:
                    raise Exception(
                        "self is non-scalar Quble and other(s) are scalar(s)"
                    )

            # Are length's of other1 & self different?
            if other1.ndim != subject.ndim:
                # Disallow other1 higher dimensionality than self
                if other1.ndim > subject.ndim:
                    if grace:
                        return False
                    else:
                        raise Exception(
                            f"other1:ndim:{other1.ndim} > self.ndim:{subject.ndim}"
                        )
                # Disallow other1 with lesser dimensionality than self unless subspace_allowed
                elif not subspace_allowed:
                    if grace:
                        return False
                    else:
                        raise Exception(
                            "subspace not allowed yet other1:ndim:{0} < self.ndim:{1}".format(
                                other1.ndim, subject.ndim
                            )
                        )
                elif key_order_sensitive:
                    if grace:
                        return False
                    else:
                        raise Exception(
                            "key_order_sensitive:{0} not allowed when comparing a subset of keyspaces".format(
                                key_order_sensitive
                            )
                        )
                # Does other1 have any keyspaces not in self.keyspaces?
                elif any([ks not in subject.keyspaces for ks in other1.keyspaces]):
                    if grace:
                        return False
                    else:
                        raise Exception("Unsupported keyspaces provided")
                else:
                    if keyspace_order_sensitive:
                        # Make sure (subsetted) ordering of other1.keyspaces is consistent with self.keyspaces
                        prev_locn = None
                        for keyspace_locn_of_other_in_self in [
                            subject.keyspaces.index(ks) for ks in other1.keyspaces
                        ]:
                            if prev_locn is None:
                                prev_locn = keyspace_locn_of_other_in_self
                            # Misordered
                            elif keyspace_locn_of_other_in_self <= prev_locn:
                                if grace:
                                    return False
                                else:
                                    raise Exception("Inconsistent keyspace order")

                    # Limit subject's keyspaces to the subset inside other1.keyspaces
                    if not compare_valuespaces or len(subject.valuespaces) == 0:
                        # Here, we do not need to retain subject's valuespaces
                        subject = subject.distinct_index(keyspaces=other1.keyspaces)
                    else:
                        # Aggregate away all orthogonal keyspaces (not in other1.keyspaces)
                        # Here, we are seeking to retain subject's valuespace
                        ortho_keyspaces = subject.ortho_keyspaces(other1.keyspaces)
                        if ortho_keyspaces is not None and len(ortho_keyspaces) > 0:
                            subject = subject.aggregate(
                                aggr_keyspaces=ortho_keyspaces, auto_squeeze=True
                            )
            # Here, self & other1 have same number of keyspaces: Do we care about keyspace ordering?
            # If not, check membership of other1.keyspaces in self.keyspaces regardless of order
            elif not keyspace_order_sensitive:
                # Check membership regardless of order
                if set(subject.keyspaces) == set(other1.keyspaces):
                    pass
                elif grace:
                    return False
                else:
                    raise Exception(
                        "Non-matching (order-insensitive) keyspaces...self:{0}  other1:{1}".format(
                            subject.keyspaces, other1.keyspaces
                        )
                    )
            # Otherwise, keyspace ordering is required. In this case, we require the two keyspace lists to match in noth length & ordering
            elif other1.keyspaces != subject.keyspaces:
                if grace:
                    return False
                else:
                    raise Exception("Inconsistent keyspace order")

            # ===========================================
            # PART 2: VALUESPACE VALIDATION / PREP
            # ===========================================
            valuespaces_map_1to2 = {}
            if not compare_valuespaces:
                # We leave valuespaces_map_1to2 empty so that no values will be compared
                pass
            # Validate variate_mode
            elif variate_mode not in ("uni", "mixed", "multi"):
                raise Exception(
                    "Invalid variate_mode:{0}...valid options: 'uni','mixed','multi'".format(
                        variate_mode
                    )
                )
            elif variate_mode == "mixed":
                raise Exception(f"Unsupported variate_mode:{variate_mode}")
            elif variate_mode == "multi":
                # Here, we compare both valuespace names & values
                if set(subject.valuespaces) != set(other1.valuespaces):
                    # sets of valuespaces do not match
                    if grace:
                        return False
                    else:
                        raise Exception(
                            "sets of valuespaces do not match...subject.valuespaces:{0} vs other.valuespaces:{1}".format(
                                subject.valuespaces, other1.valuespaces
                            )
                        )
                # Are we valuespace order-sensitive? If so, does the ordering match?
                elif valuespace_order_sensitive and (
                    subject.valuespaces != other1.valuespaces
                ):
                    # valuespaces and/or their orderings do not match
                    if grace:
                        return False
                    else:
                        raise Exception(
                            "Inconsistent valuespaces ordering...subject.valuespaces:{0} vs other.valuespaces:{1}".format(
                                subject.valuespaces, other1.valuespaces
                            )
                        )
                else:
                    # Otherwise, build the valuespace map (subject valuespace -> other1 valuespace)
                    # so we can compare values of the two associated columns
                    for vs in subject.valuespaces:
                        if vs not in other1.valuespaces:
                            return False
                        elif vs not in valuespaces_map_1to2:
                            valuespaces_map_1to2[vs] = vs

                if (
                    primary_valuespace_sensitive
                    and subject.valuespace != other1.valuespace
                ):
                    if grace:
                        return False
                    else:
                        raise Exception(
                            f"Primary valuespace assignment for subject ({subject.valuespace}) does not match that of other ({other1.valuespace})"
                        )
            else:
                # Here, we only compare the primary valuespaces regardless of whether the associated names match
                if subject.valuespace is None:
                    if other1.valuespace is None:
                        # Both subject & other1 are non-variate
                        pass
                    else:
                        # Mixed state: non-variate subject & variate other1
                        if grace:
                            return False
                        else:
                            raise Exception(
                                "Mixed state: non-variate subject & variate other1"
                            )
                elif other1.valuespace is None:
                    # Mixed state: variate subject & non-variate other1
                    if grace:
                        return False
                    else:
                        raise Exception(
                            "Mixed state: variate subject & non-variate other1"
                        )
                else:
                    # Here, both subject & other1 are variate
                    # For if variate_mode == 'uni', we compare the values in associated primary valuespace columns
                    valuespaces_map_1to2[subject.valuespace] = other1.valuespace

            # =============================== #
            # PART 3: Column info validation  #
            # =============================== #
            if column_info_sensitive:
                # infer/assign freqs for subject's time-spaces (if applicable)
                for space1 in subject.time_spaces:
                    if (
                        "freq" not in subject._column_info
                        or space1 not in subject._column_info["freq"]
                        or subject._column_info["freq"][space1] is None
                    ):
                        freq1 = subject.get_space_info(
                            info_type="freq",
                            space=space1,
                            grace=True,
                            allow_infer=True,
                            assign_inferred=True,
                        )
                # infer/assign freqs for other1's time-spaces (if applicable)
                for space1 in other1.time_spaces:
                    if (
                        "freq" not in other1._column_info
                        or space1 not in other1._column_info["freq"]
                        or other1._column_info["freq"][space1] is None
                    ):
                        freq1 = other1.get_space_info(
                            info_type="freq",
                            space=space1,
                            grace=True,
                            allow_infer=True,
                            assign_inferred=True,
                        )
                # checking if all info_type and sub_dict's of subject are present in other
                for info_type, sub_dict in subject._column_info.items():
                    if info_type in info_types_to_be_compared:
                        if info_type not in other1._column_info:
                            if all(value is None for value in sub_dict.values()):
                                # Skip if all values in sub_dict are None
                                if ignore_null_info_values:
                                    continue
                                else:
                                    if grace:
                                        return False
                                    else:
                                        raise ValueError(
                                            f"Column info for info_type '{info_type}' is missing in the other quble."
                                        )
                            else:
                                # At this point, info type and its sub_dict are missing in other quble
                                # We need to make sure if the missing info type is not for the
                                # subset of keyspaces present in the other quble
                                if subspace_allowed:
                                    # Logic to make sure col info for subset of keyspaces in other quble
                                    # is present in subject quble. If col info is missing, exception is thrown
                                    for k1 in sub_dict:
                                        if k1 in other1.keyspaces:
                                            if grace:
                                                return False
                                            else:
                                                raise Exception(
                                                    f"Column info for info_type '{info_type}' is missing in the other quble."
                                                )

                                else:
                                    if grace:
                                        return False
                                    else:
                                        raise ValueError(
                                            f"Column info for info_type '{info_type}' is missing in the other quble."
                                        )
                        elif isinstance(sub_dict, dict) and isinstance(
                            other1._column_info[info_type], dict
                        ):
                            # Recursive call to compare nested dictionaries
                            for column_name, info_value in sub_dict.items():
                                # Honoring compare_valuespaces parameter
                                # When compare_valuespaces is False, we don't want to compare
                                # column info for valuespaces
                                if (
                                    column_name in subject.valuespaces
                                    and not compare_valuespaces
                                ):
                                    continue
                                elif (
                                    column_name in subject.keyspaces
                                    and column_name not in other1.keyspaces
                                    and subspace_allowed
                                ):
                                    continue
                                else:
                                    if (
                                        column_name
                                        not in other1._column_info[info_type]
                                    ):
                                        if (
                                            variate_mode.lower() == "uni"
                                            and column_name == subject.valuespace
                                            and other1.valuespace
                                            and other1._column_info[info_type][
                                                other1.valuespace
                                            ]
                                            == info_value
                                        ) or (
                                            variate_mode.lower() == "uni"
                                            and info_type.lower() == "type"
                                            and compare_snowflake_sql_types(
                                                info_value,
                                                other1._column_info[info_type][
                                                    other1.valuespace
                                                ],
                                            )
                                        ):
                                            continue
                                        else:
                                            if grace:
                                                return False
                                            else:
                                                raise ValueError(
                                                    f"Column info for column name '{column_name}' is missing for info_type '{info_type}' in the other quble."
                                                )
                                    if (
                                        other1._column_info[info_type][column_name]
                                        != info_value
                                    ):
                                        if (
                                            info_type.lower() == "type"
                                            and compare_snowflake_sql_types(
                                                info_value,
                                                other1._column_info[info_type][
                                                    column_name
                                                ],
                                            )
                                        ):
                                            continue
                                        else:
                                            if grace:
                                                return False
                                            else:
                                                raise ValueError(
                                                    f"Value mismatch for column_name '{column_name}' for info_type '{info_type}'."
                                                )
                # checking if all info_types and sub_dict's of other are present in self
                # There might be a case where the sub_dict of other quble might have more
                # key value pairs than that of subject quble
                # ---------------------------------------------------------- #
                #                   Example                                  #
                # self  -> fx:{'Opening_Value':'USD'}                        #
                # other -> fx:{'Opening_Value':'USD', 'Closing_Value':'USD'} #
                # ---------------------------------------------------------- #
                for info_type, sub_dict in other1._column_info.items():
                    if info_type in info_types_to_be_compared:
                        if info_type not in subject._column_info:
                            if all(value is None for value in sub_dict.values()):
                                # Skip if all values in sub_dict are None
                                if ignore_null_info_values:
                                    continue
                                else:
                                    if grace:
                                        return False
                                    else:
                                        raise ValueError(
                                            f"Column info for info_type '{info_type}' is missing in the other quble."
                                        )
                            else:
                                if grace:
                                    return False
                                else:
                                    raise ValueError(
                                        f"Column info for info_type '{info_type}' is missing in the other quble."
                                    )
                        elif isinstance(sub_dict, dict) and isinstance(
                            subject._column_info[info_type], dict
                        ):
                            # Recursive call to compare nested dictionaries
                            for column_name, info_value in sub_dict.items():
                                # Honoring compare_valuespaces parameter
                                # When compare_valuespaces is False, we don't want to compare
                                # column info for valuespaces
                                if (
                                    column_name in other1.valuespaces
                                    and not compare_valuespaces
                                ):
                                    continue
                                else:
                                    if (
                                        column_name
                                        not in subject._column_info[info_type]
                                    ):
                                        if (
                                            variate_mode.lower() == "uni"
                                            and column_name == other1.valuespace
                                            and subject._column_info[info_type][
                                                subject.valuespace
                                            ]
                                            == info_value
                                        ) or (
                                            variate_mode.lower() == "uni"
                                            and info_type.lower() == "type"
                                            and compare_snowflake_sql_types(
                                                info_value,
                                                subject._column_info[info_type][
                                                    subject.valuespace
                                                ],
                                            )
                                        ):
                                            continue
                                        else:
                                            if grace:
                                                return False
                                            else:
                                                raise ValueError(
                                                    f"Column info for column name '{column_name}' is missing for info_type '{info_type}' in the other quble."
                                                )
                                    if (
                                        subject._column_info[info_type][column_name]
                                        != info_value
                                    ):
                                        if (
                                            info_type.lower() == "type"
                                            and compare_snowflake_sql_types(
                                                info_value,
                                                subject._column_info[info_type][
                                                    column_name
                                                ],
                                            )
                                        ):
                                            continue
                                        else:
                                            if grace:
                                                return False
                                            else:
                                                raise ValueError(
                                                    f"Value mismatch for column_name '{column_name}' for info_type '{info_type}'."
                                                )

            # Once we have validated column info, we want to check if both the qubles are empty and bail out
            if subject.is_empty and other1.is_empty:
                return True

            # --------------------------------------------------
            # Now for each valuespace's values of other1,
            # against associated valuespace's values in self
            # --------------------------------------------------
            is_float_map1 = {}
            is_float_map2 = {}
            for vs1, vs2 in valuespaces_map_1to2.items():
                if subject.is_float(space=vs1):
                    is_float_map1[vs1] = True

                if other1.is_float(space=vs2):
                    is_float_map2[vs2] = True

            # Check if the Other Quble has duplicate keys
            other_has_duplicate_keys = other1.has_duplicate_keys()
            both_have_duplicates = False

            if (subject_has_duplicate_keys and not other_has_duplicate_keys) or (
                other_has_duplicate_keys and not subject_has_duplicate_keys
            ):
                if grace:
                    return False
                else:
                    raise Exception(
                        "Either Subject or Other Quble have duplicate keys, but in inconsistent patterns"
                    )
            elif subject_has_duplicate_keys and other_has_duplicate_keys:
                both_have_duplicates = True

            # Check if Other Quble has numeric columns
            other_has_numeric_cols = any(
                other1.is_numeric(space="<spaces>", summarize=None)
            )

            # If there are no numeric columns in subject and other1,
            # We can simply do a minus operation between both tables
            if (
                (not subject_has_numeric_cols)
                and (not other_has_numeric_cols)
                and (subject.spaces == other1.spaces)
            ):
                if subject.num_records == other1.num_records:
                    sql_command = f"SELECT * FROM {dquote_dot(subject.table_name)} MINUS SELECT * FROM {dquote_dot(other1.table_name)}"
                else:
                    if grace:
                        return False
                    else:
                        raise Exception(
                            f"Record mismatch!! subject has {subject.num_records} records but Other has {other1.num_records} records"
                        )
                num_value_mismatches = len(execute(sql_command, fetch="all"))
            else:
                # ============================================================
                # PART 3: RENDER & EXECUTE QUERY TO IDENTIFY ANY MISMATCHES
                # ============================================================
                sql_template = JINJA_ENV.get_template("key_mismatches.j2")
                sql_command = sql_template.render(
                    table_name1=subject.table_name,
                    table_name2=other1.table_name,
                    keyspaces=subject.keyspaces,  # <-- Verified to be common to both subject & other1
                    valuespaces_map_1to2=valuespaces_map_1to2,
                    is_float_map1=is_float_map1,
                    is_float_map2=is_float_map2,
                    epsilon=str(epsilon) if epsilon else None,
                    key_order_sensitive=key_order_sensitive,
                    valuespace_flag=valuespace_flag,
                    subject_spaces=subject.spaces,
                    other_spaces=other1.spaces,
                    duplicate_key_presence=both_have_duplicates,
                )
                num_value_mismatches = execute(sql_command, fetch="one")[0]
            if num_value_mismatches > 0:
                if grace:
                    return False
                else:
                    raise Exception(f"# key mis-matches:{num_value_mismatches}")

        # =========================== END: OTHER LOOP =========================

        # Return True by default if none of the tests above encountered any violations
        return True

    def are_eqindexed(
        self,
        other,
        require_coindex: bool = False,
        keyspace_order_sensitive: bool = True,
        key_order_sensitive: bool = True,
        subspace_allowed: bool = False,
        grace: bool = True,
    ) -> bool:
        """
        Indicates whether two (or more) Qubles have equal indexes:
           1) keys in a given index must match and be in same order
           2) same keyspaces
           3) same keyspace ordering

        :param other: comparables
        :type other: Quble or list/tuple of Qubles

        :param require_coindex: require "co-indexed" state (share same underlying table)
        :type require_coindex: boolean (True,False*)

        :param keyspace_order_sensitive: require same keyspace ordering
        :type keyspace_order_sensitive: boolean (True*,False)

        :param key_order_sensitive: require same key ordering for a given keyspace
        :type key_order_sensitive: boolean (True*,False)

        :param subspace_allowed: allow for other's keyspaces to be a subset of self
        :type subspace_allowed: boolean (True*,False)

        :param grace: flag to gracfully handle not equal-indexed case
                        grace=True (default): simply return False indicating the two Qubles are not equal-indexed
                        grace=False : raise an error indicating why the two Qubles are not equal-indexed
        :type grace: boolean (True*/False)

        See :meth:`~qubles.core.quble.Quble.equals`
        """
        # Simply calls Quble.equals()
        # without any valuespace testing params
        # ----------------------------------------
        return self.equals(
            other,
            require_coindex=require_coindex,
            keyspace_order_sensitive=keyspace_order_sensitive,
            key_order_sensitive=key_order_sensitive,
            subspace_allowed=subspace_allowed,
            compare_valuespaces=False,
            valuespace_order_sensitive=False,
        )

    @classmethod
    def estimate_join(
        cls,
        qubles: list,
        key_indep_ratio: float = 0.5,
        density: float = 0.75,
        reverse_iteration: bool = False,
        keyspaces_join_op: str = "union",
        keys_join_op: str = "union",
        single_complex_group_passthru: bool = True,
        grace: bool = True,
    ):
        """
        Estimates record_cnt of a proposed join operation
        [NOTE: Estimation of possible_record_cnt is approximate!!]

        :param qubles: list/tuple/dict of Qubles to be joined
        :type qubles: list/tuple/dict of Qubles
           ==> NOTE: Some elements may actually be Python scalars

        :param keyspaces_join_op: keyspaces join op
        :type keyspaces_join_op: str
        [See: :meth:`~qubles.core.quble.Quble.join`]

        :param keymap_join_op: keyspaces join op
        :type keys_join_op: str
        [See: :meth:`~qubles.core.quble.Quble.join`]

        :param key_indep_ratio: Assumed ratio of independence of keys when unioning within common keyspaces across disparate Qubles (tables)
        1.0: All keys are completely independent [num records across participating tables are additive wjen unioning for common keyspaces]
           ==> combined num records = (# table1) + (# table2) + ...
        0.0: All keys from disparate Qubles are completely duplicated [Generates max keys/records when unioning across participating tables for common keyspaces]
           ==> combined num records = max((# table1), (# table2),...)
        :type key_indep_ratio: float (between [0.0, 1.0]) or None
            ==> NOTE: None will be treated as key_indep_ratio=0.5

        :param density: Assumed density (when joining multi-dimensional Qubles)
                density [0.0, 1.0] inclusive
                The density assumption will affect impact of 'keyspace introductions'
                by a given Quble on the estimated record count
        :type density: float (between [0.0, 1.0]) or None
            ==> NOTE: None will be treated as density=0.75

        :param reverse_iteration: Flag to iterate thorugh the Qubles in reverse order
        :type reverse_iteration: True/False*

        :param single_complex_group_passthru: Flag to pass-through (green light) single complex join group cases
        :type grace: True*/False

        :param exclude_scalar_join_groups: Flag to exclude scalars as a join-group for analysis in this algo
        :type grace: True*/False

        :param grace: Flag raise/not raise and Exception
        :type grace: True*/False

        :rtype: bool
        :returns: flag indicating join state
           ==> True: problematic state
           ==> False: acceptable state
        """
        raise Exception(f"NOT IMPLEMENTED!")
        start = time.time()
        if qubles is None:
            return False
        elif not isinstance(qubles, (list, tuple, dict)):
            raise Exception(
                f"Invalid type(qubles):{type(qubles)}...list/tuple/dict expected"
            )

        # Sort the Quble with the highest dimensionality first
        if reverse_iteration:
            qubles4iteration = (
                reversed(list(qubles.values()))
                if isinstance(qubles, dict)
                else reversed(qubles)
            )
        else:
            qubles4iteration = (
                list(qubles.values()) if isinstance(qubles, dict) else qubles
            )

        ks_to_quble_indices = establish_target_keyspaces(qubles, keyspaces_join_op)

        # Validate key_indep_ratio assumption
        if key_indep_ratio is None:
            key_indep_ratio = 0.5
        elif (key_indep_ratio < 0.0) or (key_indep_ratio > 1.0):
            raise Exception(
                f"key_indep_ratio arg should be between [0.0, 1.0] inclusive"
            )

        # Validate density assumption
        if density is None:
            density = 0.75
        elif (density < 0.0) or (density > 1.0):
            raise Exception(f"density arg should be between [0.0, 1.0] inclusive")

        max_table_size = None  # <-- Initialization
        join_group_ctr = 0
        join_groups_record_cnts = []  # list providing num_records for each join group
        join_groups_q_nos = []  # list of lists of q_nos within h join group
        keyspaces_join_groups = []  # list of lists of keyspaces within each join group
        keyspaces2group_no = {}
        q_nos2group_no = (
            {}
        )  # <-- keys: q_no1, values: join group number (not all Qubles will be represented)

        q_nos2record_cnts = (
            {}
        )  # <-- keys: q_no1, values: num records (not all Qubles will be represented)

        # =============== START: QUBLE INTRODUCTION (q_no1) LOOP ===============
        for q_no1 in range(len(qubles4iteration)):
            # make sure qubles[q_no1] is a defined Quble
            if qubles[q_no1] is None:
                # Not actually Quble
                continue
            elif not isinstance(qubles[q_no1], Quble):
                # Sometimes Python scalars are sent to joins?
                # pass
                raise Exception(
                    f"Expected Quble but encountered type:{type(qubles[q_no1])}"
                )
                # raise Exception(f"Invalid element...expected Quble but encountered type: {type(qubles[q_no])}")
            elif qubles[q_no1].is_undefined:
                # No table to join
                continue

            # Update max_table_size
            if qubles[q_no1].num_records is not None:
                q_nos2record_cnts[q_no1] = qubles[q_no1].num_records
                if max_table_size is None:
                    max_table_size = qubles[q_no1].num_records
                else:
                    max_table_size = max(max_table_size, qubles[q_no1].num_records)

            # Assess validity (after max_table_size update)
            if q_no1 in q_nos2group_no:
                # This Quble is already in a prior join group
                continue
            # Make sure the current table actually has keyspaces for joining
            elif qubles[q_no1].num_keyspaces > 0:
                pass
            elif qubles[q_no1].num_keyspaces is None:
                # This should probably not happen if Quble is not undefined
                continue
            elif (
                exclude_scalar_join_groups
                and (qubles[q_no1].num_keyspaces == 0)
                and (qubles[q_no1].num_records == 1)
            ):
                # Scalar Quble with directive to EXCLUDE from join groups
                continue
            else:
                # Scalar Quble with directive to INCLUDE from join groups
                pass

            # Update the num_records_this_join_group
            keyspaces_this_join_group = []
            q_nos_this_join_group = [
                q_no1
            ]  # if (len(qubles[q_no1].keyspaces) == 0) else []

            # Loop through the keyspaces of this Quble
            # ============ START: CO-JOIN INVESTIGATION (ks1) LOOP =============
            for ks1 in qubles[q_no1].keyspaces:
                if ks1 in keyspaces2group_no:
                    # Is this keyspace (ks1) already in a prior join group?
                    continue
                elif ks1 in keyspaces_this_join_group:
                    # Is this keyspace (ks1) is already slated
                    # for inclusion in the pending join group
                    continue

                # qubles[q_no1] has some un-analyzed keyspaces
                # So it will participate/initiate in the upcoming join group
                if q_no1 not in q_nos_this_join_group:
                    q_nos_this_join_group.append(q_no1)

                keyspaces_this_join_group.append(ks1)

                if ks1 in ks_to_quble_indices:
                    # Is ks1 in any OTHER Quble?
                    participating_qnos_to_analyze = [
                        q_no2
                        for q_no2 in ks_to_quble_indices[ks1]
                        if ((q_no2 != q_no1) and (q_no2 not in q_nos2group_no))
                    ]
                    # ============== START: CO-JOIN (q_no2) LOOP ===============
                    for q_no2 in participating_qnos_to_analyze:
                        if q_no2 == q_no1:
                            # Already pending
                            continue
                        elif q_no2 in q_nos2group_no:
                            # Is qubles[q_no2] is already in a different join group (?)
                            # [Logically, this should not happen here
                            # as the current Quble (qubles[q_no2]) would also
                            # have been included in the same group]
                            continue
                        elif q_no2 in q_nos_this_join_group:
                            # Has this Quble already been slated
                            # for inclusion in the pending join group?
                            continue

                        q_nos_this_join_group.append(q_no2)
                        for ks2 in qubles[q_no2].keyspaces:
                            if ks2 in keyspaces2group_no:
                                # Is this keyspace (ks2) already in a prior join group?
                                continue
                            elif ks2 in keyspaces_this_join_group:
                                # Is this keyspace (ks2) is already slated
                                # for inclusion in the pending join group
                                continue

                            keyspaces_this_join_group.append(ks2)

                    # =============== END: CO-JOIN (q_no2) LOOP ================
            # ============= END: CO-JOIN INVESTIGATION (ks1) LOOP ==============

            # -------------------------------------------------------
            # Now, process the proposed join group (if non-trivial)
            # -------------------------------------------------------
            if (
                len(q_nos_this_join_group) > 0
            ):  # and (len(keyspaces_this_join_group) > 0):
                num_records_this_join_group = None
                keyspaces_this_join_group3 = []  # <-- Initailization
                for q_no3 in q_nos_this_join_group:
                    # NOTE: We can probably safely assume that
                    # qubles[q_no3] is a Quble here
                    # (thanks to the prior Quble validation logic above)

                    # Is qubles[q_no3] introducing new/orthogonal keyspaces into this join group?
                    keyspace_introductions = [
                        ks3
                        for ks3 in qubles[q_no3].keyspaces
                        if ks3 not in keyspaces_this_join_group3
                    ]

                    if qubles[q_no3].num_records is None:
                        # No record info available for this Quble (?)
                        continue

                    elif num_records_this_join_group is None:
                        # First non-trivial Quble encountered within this join group
                        num_records_this_join_group = qubles[q_no3].num_records

                    elif keys_join_op in (
                        "leftmost",
                        "rightmost",
                    ):  # ,'leftmost_tunion','rightmost_tunion','leftmost_tunionpostleft'):
                        if len(keyspace_introductions) > 0:
                            # Assume table with keyspace introductions will drive new size
                            # via the introduction of additional/orthogonal keyspaces
                            # [Note, this is an over-simplification]
                            num_records_this_join_group = max(
                                qubles[q_no3].num_records, num_records_this_join_group
                            )
                        else:
                            # maintain num_records_this_join_group
                            pass

                    elif keys_join_op in (
                        "intersection",
                        "inter_lfreq",
                        "inter_rfreq",
                    ):  # ,'inter_tunion','inter_tunionpostleft','inter_tunionpostright','inter_tunionpostall','rightmost_tunionpostright','lintersection','rintersection'):
                        if len(keyspace_introductions) > 0:
                            # Assume table with keyspace introductions will drive new size
                            # via the introduction of additional/orthogonal keyspaces
                            # [Note, this is an over-simplification]
                            num_records_this_join_group = max(
                                qubles[q_no3].num_records, num_records_this_join_group
                            )
                        else:
                            num_records_this_join_group = min(
                                qubles[q_no3].num_records, num_records_this_join_group
                            )

                    else:  # if keys_join_op in ('union','union_lfreq','union_rfreq','lunion','runion'):
                        num_records_low = max(
                            qubles[q_no3].num_records, num_records_this_join_group
                        )
                        num_records_high = (
                            qubles[q_no3].num_records + num_records_this_join_group
                        )
                        num_records_this_join_group = int(
                            num_records_low
                            + (key_indep_ratio * (num_records_high - num_records_low))
                        )

                    keyspaces_this_join_group3 += keyspace_introductions

                if num_records_this_join_group is not None:
                    # NOTE: We do not formally recognize/log
                    # the current join group until here
                    # Meaning that a join group requires:
                    #   1) atleast one Quble
                    #   3) availability of info on num_records for group
                    for q_no4 in q_nos_this_join_group:
                        q_nos2group_no[q_no4] = join_group_ctr
                    join_groups_record_cnts.append(num_records_this_join_group)
                    join_groups_q_nos.append(q_nos_this_join_group)
                    keyspaces_join_groups.append(keyspaces_this_join_group)
                    for ks3 in keyspaces_this_join_group:
                        keyspaces2group_no[ks3] = join_group_ctr
                    join_group_ctr += 1

                if len(q_nos2group_no) >= len(qubles):
                    # Have all qubles been included in a join group?
                    break

        # ================ END: QUBLE INTRODUCTION (q_no1) LOOP ================

        estimated_record_cnt = None
        complex_join_group_ctr = 0  # <-- Number of join groups with atleast one keyspace (excludes join groups with a scalar Quble)
        for group_no in range(len(join_groups_record_cnts)):
            if join_groups_record_cnts[group_no] is None:
                continue
            elif estimated_record_cnt is None:
                estimated_record_cnt = join_groups_record_cnts[group_no]
            else:
                # Joins across join groups constitute cross-joins
                # which increase the number of records multiplicatively
                estimated_record_cnt *= join_groups_record_cnts[group_no]

            if len(keyspaces_join_groups[group_no]) > 0:
                complex_join_group_ctr += 1

        # Make sure estimated_record_cnt is non-trivial
        if estimated_record_cnt is None:
            estimated_record_cnt = 0

        return estimated_record_cnt

    def run_check_remove_duplicate_keys(self, quble):
        if quble is None or not isinstance(quble, Quble) or quble.is_undefined:
            pass
        else:
            quble.check_remove_duplicate_keys()

    def run_expand_null_keys(self, quble):
        if len(quble.keyspaces_with_nulls) > 0:
            quble = quble.expand_null_keys()
            return quble

    @classmethod
    def join_check(
        cls,
        qubles: list,
        key_indep_ratio: float = 0.5,
        density: float = 0.75,
        reverse_iteration: bool = False,
        keyspaces_join_op: str = "union",
        keys_join_op: str = "union",
        single_complex_group_passthru: bool = True,
        grace: bool = True,
    ):
        """
        Temporary placeholder for method in progress
        """
        return False

    @RootLib.lazy_kwargs()
    def join(
        self,
        other,
        keys_join_op: str = RootLib.lazy_eval("keys_join_op"),
        keyspaces_join_op: str = "union",
        valuespaces_join_op: str = "all",
        valuespace_prefix: str = None,
        valuespace_num_suffix_delimiter: str = None,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        tdistribute_mode="<space_root>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        coverage_requirements: dict = None,
        freq: str = RootLib.lazy_eval("freq"),
        key_ordering="asc",
        view=RootLib.lazy_eval("view"),
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
        pre_remove_dupe_keys=True,
        prevent_null_keys: bool = True,
        expansion_exclusions=None,
        pre_expand: bool = False,
        consider_auto_squeeze: bool = False,
        calendar_table_name: str = RootLib.lazy_eval("calendar_table_name"),
        perform_join_check: bool = False,
    ) -> Quble:
        """Conforms two (or more) Qubles.

        Use this operation when two Qubles need to be conformed on their keyspaces.
        This works by finding joining respective keys to create a common/shared table.
        The Qubles will share keyspaces from the common table, but will have different valuespace columns

        **========== Input Reconciliation**

        The input Qubles do not need to have a common structure.

        - If they are of different frequencies, they will be automatically converted
          to a common frequency.
        - If they use different identifiers, they will be automatically converted to
          the same identifier.

        **========== Output Keyspaces ==========**

        The resultant keyspaces can be controlled with the following args:

        ``keyspaces_join_op``
        Controls which keyspaces end up in the result.
        Supports the following options:

        - ``left``: keep keyspaces from the furthest left Quble
        - ``right``: keep keyspaces from the furthest right Quble
        - ``union``: keep all keyspaces from all Qubles
        - ``intersection``: keep keyspaces that are shared by all Qubles
        - ``xlunion``: keep all keyspaces from all Qubles except the first
        - ``xlintersection``: keep keyspaces shared by all Qubles except the first/left
        - a specific list of keyspaces

        ``keys_join_op``
        Control how the keys within a given keyspace are joined.
        Supports the following options:

        - ``leftmost``: only keep keys (and impose time-freq) from the left-most Quble for each keyspace
                        [Here, 'leftmost' means keys from the left-most supporting Quble/table for a given keyspace]
                        [NOTE: For a given keyspace, the keys may not necessarily
                        be sourced from the first/leftest Quble,
                        but the the left-most Quble that supports that keyspace]
        - ``rightmost``: only keep keys (and impose time-freq) from the right-most Quble for each keyspace
                        [Here, 'rightmost' means keys from the right-most supporting Quble/table for a given keyspace]
                        [NOTE: For a given keyspace, the keys may not necessarily
                        be sourced from the last/rightest Quble,
                        but the the right-most Quble that supports that keyspace]
        - ``union``: keep all keys from all keyspaces [frequency conflicts determined by freq arg]
        - ``union_lfreq``: keep all keys from all keyspaces [frequency conflicts determined by leftmost freq]
        - ``union_rfreq``: keep all keys from all keyspaces [frequency conflicts determined by rightmost freq]
        - ``intersection``: keep only keys that are shared by all Qubles/tables for a given keyspace
                            [frequency conflicts will be determined by freq arg]
        - ``inter_lfreq``: keep only keys that are shared by all Qubles/tables for a given keyspace,
                           but resolve frequency conflicts for time-keyspaces using leftmost freq
        - ``inter_rfreq``: keep only keys that are shared by all Qubles/tables for a given keyspace,
                           but resolve frequency conflicts for time-keyspaces using rightmost freq
        - ``inter_tunion``: union keys for time keyspaces involving 'resampling',
                            otherwise impose intersection of keys for other keyspaces
                            [Here, frequency conflicts will be determined by freq arg]
        - ``inter_tunionpostleft``: qualified unioning of keys for time keyspaces involving 'resampling'
                               with stipulation that timestamps for unioning >= minimum timestamp in left table
                               (iff the time keyspace is present in left table),
                               otherwise 'intersection' of keys for other keyspaces
                               [resolve frequency conflicts for time-keyspaces using leftmost freq]
        - ``inter_tunionpostright``: qualified unioning of keys for time keyspaces involving 'resampling',
                                with a stipulation that timestamps for unioning >= minimum timestamp in right table
                               (iff the time keyspace is present in right table),
                                otherwise 'intersection' of keys for other keyspaces
                                [resolve frequency conflicts for time-keyspaces using rightmost freq]
        - ``inter_tunionpostall``: qualified unioning of keys for time keyspaces involving 'resampling',
                                with a stipulation that timestamps for unioning >= minimum timestamp across all tables
                               (for those tables where time keyspace is present),
                                otherwise 'intersection' of keys for other keyspaces
                                [frequency conflicts will be determined by freq arg]
        - ``leftmost_tunion``: union keys for time keyspaces involving 'resampling',
                               otherwise 'leftmost' keys for other keyspaces
                               [resolve frequency conflicts for time-keyspaces using leftmost freq]
        - ``rightmost_tunion``: union keys for time keyspaces involving 'resampling',
                                otherwise 'rightmost' keys for other keyspaces
                                [resolve frequency conflicts for time-keyspaces using rightmost freq]
        - ``leftmost_tunionpostleft``: qualified unioning of keys for time keyspaces involving 'resampling'
                               with stipulation that timestamps for unioning >= minimum timestamp in left table
                               (iff the time keyspace is present in left table),
                               otherwise 'leftmost' keys for other keyspaces
                               [resolve frequency conflicts for time-keyspaces using leftmost freq]
        - ``rightmost_tunionpostright``: qualified unioning of keys for time keyspaces involving 'resampling',
                                with a stipulation that timestamps for unioning >= minimum timestamp in right table
                               (iff the time keyspace is present in right table),
                                otherwise 'rightmost' keys for other keyspaces
                                [resolve frequency conflicts for time-keyspaces using rightmost freq]
        - ``lunion``: For keyspaces in left Quble: only keep left Quble's keys and impose left's freq,
                      for keyspaces not in left Quble:
                           keep union of all keys from all Qubles and resolve freq conflict w/freq arg
                      (only practical for keyspaces_join_op='union')
               ==> Will implicitly create a dictionary by keyspaces: { '<keyspaces in left Quble>: 'left', '<keyspaces not in left Quble>: 'union'  }

        - ``runion``: For keyspaces in right Quble: only keep right Quble's keys and impose right's freq,
                      for keyspaces not in right Quble:
                           keep union of all keys from all Qubles and resolve freq conflict w/freq arg
                      (only practical for keyspaces_join_op='union')
               ==> Will implicitly create a dictionary by keyspaces: { '<keyspaces in right Quble>: 'right', '<keyspaces not in right Quble>: 'union'  }

        - ``lintersection``: For keyspaces in left Quble: only keep left Quble's keys and impose left's freq,
                             for keyspaces not in left Quble:
                                keep intersection of all keys from all Qubles and resolve freq conflict w/freq arg
                             (only practical for keyspaces_join_op='union')
               ==> Will implicitly create a dictionary by keyspaces: { '<keyspaces in left Quble>: 'left', '<keyspaces not in left Quble>: 'intersection'  }

        - ``rintersection``: For keyspaces in right Quble: only keep right Quble's keys and impose right's freq,
                             for keyspaces not in right Quble:
                                keep intersection of all keys from all Qubles and resolve freq conflict w/freq arg
                             (only practical for keyspaces_join_op='union')
               ==> Will implicitly create a dictionary by keyspaces: { '<keyspaces in right Quble>: 'right', '<keyspaces not in right Quble>: 'intersection'  }

          NOTE: keys_join_op arg will also drive the handling of frequency conflicts...

          When keys_join_op='leftmost': the left-most keyspace
          will be used to resolve freq conflicts across qubles for a specific time-series keyspace

          When keys_join_op='rightmost': the right-most keyspace
          will be used to resolve freq conflicts across qubles for a specific time-series keyspace

          When keyspaces_join_op='union', 'intersection', 'xlunion' or 'xlintersection':
          the freq arg will be used to resolve any freq conflicts

          When keyspaces_join_op is a list/tuple of keyspaces, the left-most keyspace
          will be used to resolve freq conflicts across qubles for a specific time-series keyspace

        - dictionary by keyspaces where values are one of 'left','right','union','intersection'

        **========== Output Valuespaces ==========**

        The resultant valuespaces can be controlled with the following args:

        ``valuespaces_join_op``
        Controls which / how valuespaces appear in joined Quble...

          ``left`` or ``left_all`` - keep all valuespace(s) from first/left Quble only (conflicts are not expected)
          ``right`` or ``right_all`` - keep all valuespace(s) from last/right Quble only (conflicts are not expected)
          ``left_primary`` - keep primary valuespace from first/left Quble only (conflicts are not expected)
          ``right_primary`` - keep primary valuespace from last/right Quble only (conflicts are not expected)
          ``primaries`` - keep primary valuespaces only (order of primaries will be as per order of Qubles beiung joined)
          ``all`` - keep all (primaries & auxillaries) valuespaces across all Qubles (uses this option unless 'primaries' is provided)
          ``xleft_primaries`` - keep primary valuespaces from all Qubles EXCEPT left/first Quble (ordered as per Qubles)
          ``xleft_all`` - keep all valuespaces from all Qubles EXCEPT left/first Quble (ordered as per Qubles)
          ``xright_primaries`` - keep primary valuespace from all Qubles EXCEPT right/last Quble (ordered as per Qubles)
          ``xright_all`` - keep all valuespaces from all Qubles EXCEPT right/last Quble (ordered as per Qubles)
          ``left_all_right_primaries' - keep all valuespace(s) from first/left Quble and primaries from right Qubles (ordered as per Qubles)
          ``left_primary_right_all' - keep all valuespace(s) from first/left Quble and primaries from right Qubles (ordered as per Qubles)


          list of dictionaries (outer list length matches number of Qubles, per Quble):
                 map from each Quble's source valuespaces to (distinct) target valuespaces
                 [only specified source valuespaces will be kept]
                 [valuespace_prefix arg is ignored here]
                 (valuespaces will be ordered as per Qubles)

          list of lists (outer list length matches number of Qubles, per Quble)
                 (distinct) target valuespaces (must match length of related Quble's source valuespaces)
                 [valuespace_prefix arg is ignored here]

          dict: valuespace mapping information...
          dict key: target valuespace
          dict values: two-element tupe/list: (quble_no, src_vs)
          aka (quble number from list to joined, source valuespace from this source quble)
          Example: valuespaces_join_op = {'Values0': (0,'Values_'), 'Values1': (0,'Values_') }
          NOTE: This option allows for control of ordering of target valuespaces in result

        ``valuespace_prefix``

        Optional string to avoid target valuespace conficts
        by imposing this prefix across all target valuespaces
        followed by suffix: '_<quble_number>' (`valuespaces_join_op = 'primaries' OR 'left_primary' OR 'right_primary') or '_<quble_number>_<valuespace_number>'  (`valuespaces_join_op = 'all' OR 'left' OR left_all' OR 'right' OR right_all')
        ==> If valuespace_prefix is None, then no prefixing is performed and original valuespaces (as requested) are honored (subject to raising Exceptions on conflicts)

        ``valuespace_num_suffix_delimiter``

        Delimiter string used append a Quble number suffix
        for resultant valuespaces to avoid valuespace conflicts
        If None, no suffixing with be applied.
        Example: valuespace_num_suffix_delimiter='_'
        ==> source valuespaces: Quble #0: Closes, Quble #1: Prices, Closes, ...
        ==> target valuespaces: Prices_0, Closes_0, Prices_1, Closes_1, ...
        [CANNOT be used simultaneously with valuespace_prefix arg]

        **========== Validation ==========**

        The join can be validated with the following arg:

        ``coverage_requirements``

        Check for full key coverage in applicable common keyspaces between pairs of
        Qubles to be joined. Expects the following format:

        *dict of ``coverer Quble number in list`` => ``coveree Quble number in list``*

        Throws an error if *coverer_quble_no* does not fully cover *coveree_quble_no*
        (as specified by index related to qubles).

        :type tfill_end_mode: str
        :param tfill_end_mode:
            Controls extension/limits beyond original dates.
            Can be 'unconstrained' or 'no_future' or 'in_progress' or 'no_extension' or 'full_extension'
            'unconstrained': Fill (for each orthogonal key) until fill_max is reached
            'no_future': Fill (for each orthogonal key) until fill_max or current date is reached
            'in_progress': Fill (for each orthogonal key) until fill_max or 'in-progress' period is reached [Here, 'in-progress' period means period/interval containing current date]
            'no_extension': Fill (for each orthogonal key) until fill_max or last original, orthogonal date is reached
            'full_extension': Fill (for each orthogonal key) until fill_max or maximum original date (across all orthos) is reached

        :type tfill_honor_nulls: bool
        :param tfill_honor_nulls:
            Flag to honor any existing null values

        :param key_ordering: controls row ordering by key
        :type key_ordering: None, str or dictionary
           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace
           dictionary: dict keys (str): keyspaces, dict values (str): 'asc' or 'desc'
           ==> allows for assigning key ordering (ascending/descending)
           ==> (and relative priority) for each keyspace individually

        :param prevent_null_keys: prevents introduction of null keys via expansion
        :type prevent_null_keys: bool (True/False/'drop')
               ==> True: EXPAND NULLS WITHIN KEYSPACES (EXCLUDING expansion_exclusions if provided)
               ==> False: NO EXPANSION / NO NULL KEY PREVENTION

        :param expansion_exclusions: Any keyspace(s) to exclude from expansion when preventing null keys
                                     [Will be augmented with those keyspaces where no null keys are present across all Qubles]
        :type expansion_exclusions: list,tuple or None

        :param pre_expand: removes null keys in source tables through null key expansion (before joining)
        :type pre_expand: bool (True/False)
               ==> True: PRE-EXPAND NULLS WITHIN KEYSPACES
               ==> False: NO PRE-EXPANSION OF NULL KEYS

        pre_remove_dupe_keys: removes duplicate keys in source tables using default duplicate key removal method
        :type pre_remove_dupe_keys: bool (True/False)
        ==> True: PRE-REMOVE DUPLICATE KEYS ACROSS KEYSPACES
        ==> False: NO PRE-REMOVAL DUPLICATE KEYS ACROSS KEYSPACES
        """
        # ----------------
        # Arg validation
        # ----------------

        if (
            not isinstance(keyspaces_join_op, (list, tuple))
            and keyspaces_join_op not in VALID_KEYSPACES_JOIN_OP
        ):
            raise ValueError(
                "'keyspaces_join_op' must be one of: {}".format(
                    ", ".join(VALID_KEYSPACES_JOIN_OP)
                )
            )

        # =====================================
        # Validate keys_join_op and
        # establish table iteration direction
        # =====================================
        if keys_join_op not in VALID_KEYS_JOIN_OP:
            raise ValueError(
                f"'keys_join_op' must be one of: {', '.join(VALID_KEYS_JOIN_OP)}"
            )

        # Process qubles in reverse order for certain arg configurations
        # In this manner, we can prioriritize the tables & keyspaces
        # appearing in last qubles to be linked/joined with destination/targets
        keys_join_op_for_reverse_iteration = (
            "rightmost",
            "runion",
            "rintersection",
            "rightmost_tunion",
            "inter_tunionpostright",
            "rightmost_tunionpostright",
        )

        # -------------
        # Basic cases
        # -------------
        if isinstance(other, (list, tuple)) and len(other) == 0:
            return self.copy()

        # ---------------------------------------
        # Consolidate Qubles into a single list
        # ---------------------------------------
        if isinstance(other, list):
            qubles = [self] + other
        elif isinstance(other, tuple):
            qubles = [self] + list(other)
        else:
            qubles = [self, other]

        # Remove duplicate keys
        if pre_remove_dupe_keys:
            for i in range(len(qubles)):
                if (
                    qubles[i] is None
                    or not isinstance(qubles[i], Quble)
                    or qubles[i].is_undefined
                ):
                    continue
                else:
                    qubles[i].check_remove_duplicate_keys()

        # ---------------------------------------
        # Attempt auto_link (if applicable)
        # ---------------------------------------
        # The following code will try to link
        # keyspaces of latter qubles (in list)
        # to those of former qubles (in list)
        # ---------------------------------------
        # Process qubles in reverse order for certain arg configurations
        # In this manner, we can prioriritize the tables & keyspaces
        # appearing in last qubles to be linked/joined with destination/targets
        if (
            keyspaces_join_op == "right"
            or keys_join_op in keys_join_op_for_reverse_iteration
        ):
            reverse_link_iteration = True
        else:
            reverse_link_iteration = False

        if auto_link:
            qubles = RootLib().apply_reflib_multilink(
                qubles,
                link_check=link_check,
                link_dupe_grace=link_dupe_grace,
                impose_tgt_keyspace=False,
                reverse_iteration=reverse_link_iteration,
            )

        # Perform join_check (if directed)
        # ----------------------------------
        if perform_join_check:
            if Quble.join_check(
                qubles,
                keyspaces_join_op=keyspaces_join_op,
                reverse_iteration=reverse_link_iteration,
            ):
                raise Exception(f"Problematic join request for qubles:{qubles}")

        # Initialize tgt_valuespaces_order to None
        tgt_valuespaces_order = None

        # ---------------------------------------------------------
        # BUILD MAP FROM KEYPACES TO PARTICIPATING QUBLE INDICES
        # ---------------------------------------------------------
        ks_to_quble_indices = establish_target_keyspaces(qubles, keyspaces_join_op)

        # -----------------------
        # SPECIAL LOGIC FOR EMPTY QUBLES WHEN SOME NON-EMPTY QUBLES ARE PROVIDED.
        # WE DROP THOSE KEYSPACES OF THE EMPTY QUBLES THAT ONLY APPEAR IN EMPTY QUBLES
        # -----------------------
        non_empties = [
            (not quble.is_undefined and not quble.is_empty) for quble in qubles
        ]
        rebuild_ks_to_quble_indices = False
        if any(non_empties):
            # Here, some empty Qubles have been provided
            # Investigate keyspace droppage from empty Qubles
            # Create a map from quble_index to the keyspaces to be dropped from this quble
            quble_index_to_ks_drops = {}
            for ks, quble_indices in ks_to_quble_indices.items():
                if len(quble_indices) == 0:
                    # No qubles participate in this keyspace (?)
                    continue
                elif all([qubles[i].is_empty for i in quble_indices]):
                    # Here, all qubles with this keyspace are empty
                    for i in quble_indices:
                        # Is this keyspace subject to unioning of keys?
                        if (
                            (keys_join_op[0:5] == "union")
                            or (keys_join_op == "lunion" and (i != 0))
                            or (
                                keys_join_op == "runion"
                                and (i != (len(quble_indices) - 1))
                            )
                        ):
                            # ------------------------------------------------------------------
                            # HERE THE FOLLOWING CONDITIONS HOLD:
                            #   1) SOME (OTHER) NON-EMPTY QUBLES ARE TO BE JOINED
                            #   2) THIS KEYSPACE ONLY OCCURS IN EMPTY QUBLES
                            #      [ALTERNATIVELY, KEYSPACE DOES NOT OCCUR IN NON-EMPTY QUBLES]
                            #   2) THIS QUBLE (qubles[i]) IS EMPTY
                            #   4) WE LOOK TO APPLY UNION OF KEYS ACROSS THIS KEYSPACE
                            # ------------------------------------------------------------------
                            # THIS KEYSPACE IS SUBJECT TO (BY DIRECTIVE) UNIONING OF KEYS,
                            # SO WE SEEK TO DROP THIS KEYSPACE FROM THESE EMPTY QUBLES...
                            # ------------------------------------------------------------------
                            # LOGIC: THROUGH OMISSION OF THIS KEYSPACE, THE RESULT
                            # WILL EFFECTIVELY TRANSMIT/SUPPORT ANY KEY FOR THIS KEYSPACE
                            # [AVOIDING CREATION OF A NULL KEY IN RESULT FOR THIS KEYSPACE]
                            # ------------------------------------------------------------------
                            if i not in quble_index_to_ks_drops:
                                quble_index_to_ks_drops[i] = [ks]
                            else:
                                quble_index_to_ks_drops[i] = quble_index_to_ks_drops[
                                    i
                                ] + [ks]

            # Apply keyspace droppages from empties accordingly
            # [so long as some non-empties are present]
            for i, keyspaces_to_drop in quble_index_to_ks_drops.items():
                if keyspaces_to_drop is None:
                    continue
                elif len(keyspaces_to_drop) == 0:
                    # Nothing to drop
                    continue
                elif qubles[i] is None:
                    continue
                elif not isinstance(qubles[i], Quble):
                    raise Exception(f"Non-Quble quble[{i}]:{qubles[i]}")
                elif qubles[i].is_undefined:
                    continue
                else:
                    rebuild_ks_to_quble_indices = True
                    spaces_to_keep = [
                        space
                        for space in qubles[i].spaces
                        if space not in keyspaces_to_drop
                    ]
                    if len(spaces_to_keep) == 0:
                        # Cannot drop all spaces...need to drop this quble from the join list
                        qubles[i] = Quble.undefined_instance()
                    else:
                        qubles[i] = qubles[i].select(column_names=spaces_to_keep)
                        for ks in keyspaces_to_drop:
                            if i in ks_to_quble_indices[ks]:
                                ks_to_quble_indices[ks].remove(
                                    i
                                )  # <-- Removed i from the index list: ks_to_quble_indices[ks]

        # =============================================================
        # Remove any undefined/None qubles (if possible)
        # -------------------------------------------------------------
        # This will include qubles that were originally undefined
        # as well as those make undefined in empty Quble logic above
        # =============================================================
        new_qubles_list = []
        for i in range(len(qubles)):
            if qubles[i] is None:
                continue
            elif not qubles[i].is_undefined:
                new_qubles_list.append(qubles[i])
            elif keys_join_op in ("lunion", "lintersection") and i == 0:
                raise Exception(
                    f"keys_join_op:{keys_join_op}...cannot drop qubles[{i}] w/len(qubles):{len(qubles)}]"
                )
            elif keys_join_op in ("runion", "rintersection") and i == (len(qubles) - 1):
                raise Exception(
                    f"keys_join_op:{keys_join_op}...cannot drop qubles[{i}] w/len(qubles):{len(qubles)}"
                )
            else:
                pass

        # Reconfigure based on new_qubles_list
        if len(new_qubles_list) == 0:
            # raise Exception('join not possible for undefined Qubles')
            # Here, there are no qubles left in the join operation
            return Quble.undefined_instance()
        elif len(new_qubles_list) < len(qubles):
            # Here, we have removed some qubles from the join operation
            qubles = new_qubles_list
            rebuild_ks_to_quble_indices = True
        else:
            qubles = new_qubles_list

        if rebuild_ks_to_quble_indices:
            ks_to_quble_indices = establish_target_keyspaces(qubles, keyspaces_join_op)

        # -------------------------------------------------
        # Apply pre-expansion of null keys when directed
        # -------------------------------------------------
        result_list = []
        if pre_expand:
            for i in range(qubles):
                if len(qubles[i].keyspaces_with_nulls) > 0:
                    qubles[i] = qubles[i].expand_null_keys()

        # ----------------------------------
        # Aggregate away missing keyspaces
        # ----------------------------------
        for i in range(len(qubles)):
            for ks in qubles[i].keyspaces:
                if ks not in ks_to_quble_indices:
                    qubles[i] = qubles[i].aggregate1d(
                        keyspace=ks,
                        aggr_method=aggr_method,
                        ignore_missing=ignore_missing,
                        pct_required=0.0,
                        view=view,
                        key_ordering=key_ordering,
                        auto_squeeze=True,
                    )

        # ---------------------------------------------------------------------------
        #                           Reconcile frequencies
        # ---------------------------------------------------------------------------
        # NOTE: This step may replace some elements of quble array
        #       with modified Qubles that possess different/new table names
        #       As such, usage of table_names (e.g., src_tables_dict below)
        #       should be created after the frequencies are reconciled
        # ---------------------------------------------------------------------------
        for ks, quble_indices in ks_to_quble_indices.items():
            if quble_indices is None or len(quble_indices) == 0:
                # This state should ideally not occur
                continue

            quble_idx2freq = {}
            # NOTE: recon_freq will be resolved below
            # based on keys_join_op and freq args
            recon_freq = None

            # For this ks, loop through the associated/participating quble_indices in a sorted manner
            sorted_quble_indices = np.sort(quble_indices)

            # When imposing rightmost frequency resolution,
            # iterate thorugh Qubles in reverse order
            # ----------------------------------------------
            if keys_join_op in (
                "rightmost",
                "inter_tunionpostright",
                "rightmost_tunionpostright",
                "union_rfreq",
                "inter_rfreq",
                "rightmost_tunion",
            ):
                sorted_quble_indices = sorted_quble_indices[::-1]

            time_spaces_encountered = False
            for quble_idx in sorted_quble_indices:
                if qubles[quble_idx].is_time_space(ks):
                    time_spaces_encountered = True
                    freq1 = qubles[quble_idx].get_freq(
                        ks,
                        freq_hint=freq,
                        allow_infer=True,
                        assign_inferred=True,
                    )
                    quble_idx2freq[quble_idx] = freq1
                    # Assign recon_freq for this keyspace
                    if freq1 is None:
                        # No time-frequency is acceptable/appropriate for empty Qubles
                        # In this case, we exclude this Quble from
                        # freq checks/reconciliation logic
                        if qubles[quble_idx].is_empty:
                            pass
                        else:
                            raise FrequencyReconError(
                                f"Non-empty qubles[{qubles[quble_idx].table_name}] has no frequency for time-space:{ks}"
                            )
                    elif recon_freq is None:
                        # For leftmost or rightmost frequency resolution
                        if keys_join_op in (
                            "rightmost",
                            "leftmost",
                            "inter_tunionpostleft",
                            "leftmost_tunionpostleft",
                            "union_lfreq",
                            "inter_lfreq",
                            "leftmost_tunion",
                        ):
                            recon_freq = freq1
                        # If imposing left frequency and processing first Quble
                        elif keys_join_op in ("lunion", "lintersection") and (
                            quble_idx == 0
                        ):
                            recon_freq = freq1
                        # If imposing right frequency and processing last Quble
                        elif keys_join_op in ("runion", "rintersection") and (
                            quble_idx == len(qubles) - 1
                        ):
                            recon_freq = freq1
                elif time_spaces_encountered:
                    raise FrequencyReconError(
                        f"Keyspace:'{ks}' is not time-related in all provided Qubles"
                    )

            if not time_spaces_encountered:
                # No time-spaces across qubles for this keyspace (ks)
                # continue to next keyspace (ks)
                continue

            # Backstop recon_freq for this keyspace
            # with the default freq if necessary
            if recon_freq is None:
                recon_freq = freq

            quble_idx2freq_values = list(quble_idx2freq.values())
            has_conflict = (
                any(f != quble_idx2freq_values[0] for f in quble_idx2freq_values)
                if len(quble_idx2freq_values) > 0
                else False
            )
            if has_conflict:
                for quble_idx in sorted_quble_indices:
                    if quble_idx2freq[quble_idx] != recon_freq:
                        qubles[quble_idx] = qubles[quble_idx].asfreq(
                            recon_freq,
                            keyspace=ks,
                            tdistribute_mode=tdistribute_mode,
                            auto_link=auto_link,
                            key_ordering=key_ordering,
                        )

        # -------------------------------
        # Check coverage requirements
        # -------------------------------
        if coverage_requirements:
            for coverer_index, coveree_index in coverage_requirements.items():
                noop = (
                    coverer_index is None
                    or coveree_index is None
                    or coverer_index == coveree_index
                )

                if noop:
                    continue
                if coverer_index > len(qubles) or coveree_index > len(qubles):
                    raise ValueError(
                        "'coverage_requirements' includes invalid Quble index {} for list "
                        "of Qubles with length {}".format(coverer_index, len(qubles))
                    )

                # Check coverer -> coveree for all common coverage keyspaces
                # -----------------------------------------------------------
                coverage_keyspaces = []
                for ks, quble_indices in ks_to_quble_indices.items():
                    if (
                        coverer_index in quble_indices
                        and coveree_index in quble_indices
                    ):
                        coverage_keyspaces.append(ks)

                if len(coverage_keyspaces) == 0:
                    continue

                fully_covers = qubles[coverer_index].fully_covers(
                    other=qubles[coveree_index],
                    column_name=coverage_keyspaces,
                )

                if not fully_covers:
                    raise CoverageError(
                        "Coverage failure: qubles[{}] does not fully cover qubles[{}] for "
                        "keyspaces: {}".format(
                            coverer_index, coveree_index, coverage_keyspaces
                        )
                    )

        # -----------------------------
        # Get keyspace frequencies
        # -----------------------------
        keyspace_freqs = {}
        for ks, quble_indices in ks_to_quble_indices.items():
            # Frequencies were already reconciled,
            # so just look at the first Quble affiliated with this keyspace (ks)
            i = quble_indices[
                0
            ]  # <-- i is index of first quble associated with this ks
            if qubles[i].is_time_space(ks):
                keyspace_freqs[ks] = qubles[i].get_freq(
                    ks,
                    freq_hint=recon_freq,
                    allow_infer=True,
                    assign_inferred=True,
                )

        # ----------------------------------------------------------
        # Establish src_tables_dict from src_table_name -> join information
        # ----------------------------------------------------------
        # ORDERING IN src_tables_dict IS IMPORTANT!!!
        # ==> src_tables_dict
        #     will drive iteration ordering through source tables
        #     within the various joining templates invoked below.
        # ----------------------------------------------------------
        src_tables_dict = {}
        if keys_join_op in keys_join_op_for_reverse_iteration:
            # Need to iterate through tables/Qubles
            # in REVERSE order in these cases
            # when we build the SQL query to join keys
            quble_iterator4dict_build = reversed(qubles)
        else:
            # Need to iterate through tables/Qubles
            # in ORIGINAL order in these cases
            quble_iterator4dict_build = qubles

        for quble in quble_iterator4dict_build:
            src_table_name = quble.table_name
            if src_table_name is None:
                continue
            elif src_table_name not in src_tables_dict:
                src_tables_dict[src_table_name] = {}

            if "ks_list" not in src_tables_dict[src_table_name]:
                # 'ks_list' already have been added to this src_table_name
                # due to encounter through co-indexed Quble earlier in list
                src_tables_dict[src_table_name][
                    "ks_list"
                ] = quble.keyspaces  # <-- shallow copy OK here?

        else:
            for quble in qubles:
                src_table_name = quble.table_name
                if src_table_name is None:
                    continue
                elif src_table_name not in src_tables_dict:
                    src_tables_dict[src_table_name] = {}

                if "ks_list" not in src_tables_dict[src_table_name]:
                    # 'ks_list' already have been added to this src_table_name
                    # due to encounter through co-indexed Quble earlier in list
                    src_tables_dict[src_table_name][
                        "ks_list"
                    ] = quble.keyspaces  # <-- shallow copy OK here?

        # Populate src_tables_dict[src_table_name]['earliest_quble']
        # This will be the EARLIEST quble in the ORIGINAL qubles list
        # affiliated with this src_table_name
        # [Recall, multiple qubles may reference same src_table_name]
        for quble in qubles:
            src_table_name = quble.table_name
            if src_table_name is None:
                continue
            elif src_table_name not in src_tables_dict:
                src_tables_dict[src_table_name] = {}

            if "earliest_quble" not in src_tables_dict[src_table_name]:
                src_tables_dict[src_table_name]["earliest_quble"] = quble

        # =============================================================
        # Process valuespaces_join_op arg
        # Establish src_tables_dict[src_table_name]['src_vs2tgt_vs']
        # =============================================================
        primary_tgt_vs = None  # <-- Initialization

        if valuespaces_join_op is None:
            valuespaces_join_op = "all"

        # ---------------------------------------------------
        # Case #1: valuespaces_join_op is a list
        #          of dictionaries/lists (per input quble)
        #      ==> Only specified src valuespaces retained
        # ---------------------------------------------------
        #          inner dict keys: source valuespace
        #          inner dict values: target valuespace
        # ---------------------------------------------------
        if isinstance(valuespaces_join_op, list):
            if len(valuespaces_join_op) != len(qubles):
                raise Exception(
                    "len(valuespaces_join_op):{0} != len(qubles):{1}".format(
                        len(valuespaces_join_op), len(qubles)
                    )
                )

            distinct_tgt_valuespaces = []
            for i, valuespaces_join_op1 in enumerate(valuespaces_join_op):
                src_table_name = qubles[i].table_name
                if src_table_name is None:
                    continue
                src_tables_dict[src_table_name]["src_vs2tgt_vs"] = {}
                if isinstance(valuespaces_join_op1, dict):
                    for src_vs, tgt_vs in valuespaces_join_op1.items():
                        if src_vs not in qubles[i].valuespaces:
                            raise Exception(
                                "src_vs:{0} is absent from qubles[{1}].valuespaces:{2}".format(
                                    src_vs, i, qubles[i].valuespaces
                                )
                            )
                        elif tgt_vs in distinct_tgt_valuespaces:
                            raise Exception(f"Encountered duplicate tgt_vs:{tgt_vs}")
                        else:
                            distinct_tgt_valuespaces.append(tgt_vs)
                            if (
                                src_vs
                                not in src_tables_dict[src_table_name]["src_vs2tgt_vs"]
                            ):
                                src_tables_dict[src_table_name]["src_vs2tgt_vs"][
                                    src_vs
                                ] = tgt_vs
                elif isinstance(valuespaces_join_op1, list):
                    if len(valuespaces_join_op1) != len(qubles[i].valuespaces):
                        raise Exception(
                            "len(valuespaces_join_op1):{0} != len(qubles.valuespaces):{1}".format(
                                len(valuespaces_join_op1), len(qubles.valuespaces)
                            )
                        )
                    for vs_no, tgt_vs in enumerate(valuespaces_join_op1):
                        src_vs = qubles[i].valuespaces[vs_no]
                        if tgt_vs in distinct_tgt_valuespaces:
                            raise Exception(f"Encountered duplicate tgt_vs:{tgt_vs}")
                        else:
                            distinct_tgt_valuespaces.append(tgt_vs)
                            if (
                                src_vs
                                not in src_tables_dict[src_table_name]["src_vs2tgt_vs"]
                            ):
                                src_tables_dict[src_table_name]["src_vs2tgt_vs"][
                                    src_vs
                                ] = tgt_vs
                elif valuespaces_join_op1 is None:
                    pass
                else:
                    raise Exception(
                        "When valuespaces_join_op arg is a list, elements should be either lists or dictionaries"
                    )
        # ---------------------------------------------------
        # Case #2: valuespaces_join_op is a dictionary
        # ---------------------------------------------------
        #          dict keys: target valuespace
        #          dict values: two-element tuple/list: (quble number, source valuespace)
        #          ==> This option allows for control of tgt_valuespaces_order
        # ---------------------------------------------------
        elif isinstance(valuespaces_join_op, dict):
            tgt_valuespaces_order = list(valuespaces_join_op.keys())
            for tgt_vs in valuespaces_join_op:
                if tgt_vs is None:
                    continue
                elif valuespaces_join_op[tgt_vs] is None:
                    continue
                elif not isinstance(valuespaces_join_op[tgt_vs], (list, tuple)):
                    raise Exception(
                        "Invalid valuespaces_join_op[{0}]...expected two-element tuple/list: (quble_number, src_valuespace) but received:{1}".format(
                            tgt_vs, valuespaces_join_op[tgt_vs]
                        )
                    )
                elif len(valuespaces_join_op[tgt_vs]) == 0:
                    continue
                elif len(valuespaces_join_op[tgt_vs]) != 2:
                    raise Exception(
                        "Invalid valuespaces_join_op[{0}]...expected two-element tuple/list: (quble_number, src_valuespace) but received:{1}".format(
                            tgt_vs, valuespaces_join_op[tgt_vs]
                        )
                    )

                # Here we now know that valuespaces_join_op[tgt_vs] is a two-element tuple/list
                quble_number = valuespaces_join_op[tgt_vs][0]
                src_vs = valuespaces_join_op[tgt_vs][1]
                src_table_name = qubles[quble_number].table_name
                if src_table_name is None:
                    # Undefined Quble
                    continue
                elif src_table_name not in src_tables_dict:
                    raise Exception(
                        "Processing valuespaces_join_op[{0}] dict case...src_table_name:{1} absent from src_tables_dict".format(
                            tgt_vs, src_table_name
                        )
                    )
                elif "src_vs2tgt_vs" not in src_tables_dict[src_table_name]:
                    src_tables_dict[src_table_name]["src_vs2tgt_vs"] = {}

                if src_vs not in qubles[quble_number].spaces:
                    raise Exception(
                        "Processing valuespaces_join_op[{0}] dict case...src_vs:{1} absent from qubles[{2}]".format(
                            tgt_vs, src_vs, quble_number
                        )
                    )

                src_tables_dict[src_table_name]["src_vs2tgt_vs"][src_vs] = tgt_vs
        # -------------------------------------
        # Othewise throw an Exception
        # if valuespaces_join_op is NOT str
        # -------------------------------------
        elif not isinstance(valuespaces_join_op, str):
            raise Exception(
                "Invalid valuespaces_join_op:{0}...None,string,list,dict expected"
            )

        # ---------------------------------------------------
        # Case #3: valuespaces_join_op is string
        # ---------------------------------------------------
        else:
            # Validate valuespaces_join_op
            if valuespaces_join_op not in (
                "left",
                "left_all",
                "left_primary",
                "right",
                "right_all",
                "right_primary",
                "primaries",
                "all",
                "xleft_primaries",
                "xleft_all",
                "xright_primaries",
                "xright_all",
                "left_all_right_primaries",
                "left_primary_right_all",
            ):
                raise Exception(
                    f"Unsupported: valuespaces_join_op{valuespaces_join_op}"
                )

            # Validate if valuespace_prefix
            if valuespace_prefix is None:
                if valuespace_num_suffix_delimiter is None:
                    pass
                elif not isinstance(valuespace_num_suffix_delimiter, str):
                    raise Exception(
                        "Invalid valuespace_num_suffix_delimiter:{0}...str expected".format(
                            valuespace_num_suffix_delimiter
                        )
                    )
            elif not isinstance(valuespace_prefix, str):
                raise Exception(
                    f"Invalid valuespace_prefix:{valuespace_prefix}...str expected"
                )
            else:
                if valuespace_num_suffix_delimiter is not None:
                    raise Exception(
                        "Cannot simultaneously apply valuespace_prefix & valuespace_num_suffix_delimiter"
                    )
                valuespace_prefix = valuespace_prefix.strip()
                if len(valuespace_prefix.strip()) == 0:
                    raise Exception(
                        f"Trivial (invalid) valuespace_prefix:{valuespace_prefix}"
                    )

            # Case 3A: Handle left/right valuespaces
            # -----------------------------------------
            if valuespaces_join_op in (
                "left",
                "left_all",
                "left_primary",
                "right",
                "right_all",
                "right_primary",
            ):
                if len(src_tables_dict) == 0:
                    raise Exception("No source tables to join")
                if len(qubles) == 0:
                    raise Exception("No qubles to join")

                if valuespaces_join_op in ("right", "right_all", "right_primary"):
                    quble = qubles[-1]
                    quble_no = len(qubles) - 1
                else:
                    quble = qubles[0]
                    quble_no = 0

                src_table_name = quble.table_name
                src_tables_dict[src_table_name]["src_vs2tgt_vs"] = {}
                if valuespaces_join_op not in ("left_primary", "right_primary"):
                    # Keep all left/right valuespaces as original column_name
                    for vs_no, src_vs in enumerate(quble.valuespaces):
                        if valuespace_prefix:
                            tgt_vs = f"{valuespace_prefix}_{str(quble_no)}_{str(vs_no)}"
                        elif valuespace_num_suffix_delimiter:
                            tgt_vs = (
                                src_vs + valuespace_num_suffix_delimiter + str(quble_no)
                            )
                        else:
                            # valuespace conflicts should not arise here,
                            # as we are sourcing from a single Quble/table
                            tgt_vs = src_vs

                        src_tables_dict[src_table_name]["src_vs2tgt_vs"][
                            src_vs
                        ] = tgt_vs
                elif quble.valuespace is not None:
                    # Here, valuespaces_join_op in ('left_primary','right_primary')
                    # Keep only primary valuespace as original column_name
                    src_vs = quble.valuespace
                    # valuespace conflicts should not arise here,
                    # as we are sourcing from a single Quble/table
                    if valuespace_prefix:
                        tgt_vs = f"{valuespace_prefix}_{str(quble_no)}"
                    elif valuespace_num_suffix_delimiter:
                        tgt_vs = (
                            src_vs + valuespace_num_suffix_delimiter + str(quble_no)
                        )
                    else:
                        tgt_vs = src_vs

                    src_tables_dict[src_table_name]["src_vs2tgt_vs"][src_vs] = tgt_vs

            # Case 3B: Handle multi-Quble valuespaces
            # -----------------------------------------
            elif valuespaces_join_op in (
                "primaries",
                "all",
                "xleft_primaries",
                "xleft_all",
                "xright_primaries",
                "xright_all",
                "left_all_right_primaries",
                "left_primary_right_all",
            ):
                # valuespace prefixing
                if valuespace_prefix:
                    for quble_no, quble in enumerate(qubles):
                        src_table_name = quble.table_name
                        if src_table_name is None:
                            continue
                        elif (
                            valuespaces_join_op in ("xleft_primaries", "xleft_all")
                            and quble_no == 0
                        ):
                            # Exclude valuespaces from the first/left quble
                            continue
                        elif valuespaces_join_op in (
                            "xright_primaries",
                            "xright_all",
                        ) and (quble_no == (len(qubles) - 1)):
                            # Exclude valuespaces from the last/right quble
                            continue

                        if "src_vs2tgt_vs" not in src_tables_dict[src_table_name]:
                            src_tables_dict[src_table_name]["src_vs2tgt_vs"] = {}

                        if valuespaces_join_op in (
                            "left_all_right_primaries",
                            "left_primary_right_all",
                        ):
                            if (
                                (valuespaces_join_op == "left_all_right_primaries")
                                and (quble_no == 0)
                            ) or (
                                (valuespaces_join_op == "left_primary_right_all")
                                and (quble_no != 0)
                            ):
                                for src_vs_no, src_vs in enumerate(quble.valuespaces):
                                    if (
                                        src_vs
                                        not in src_tables_dict[src_table_name][
                                            "src_vs2tgt_vs"
                                        ]
                                    ):
                                        tgt_vs = (
                                            valuespace_prefix
                                            + "_"
                                            + str(quble_no)
                                            + "_"
                                            + str(src_vs_no)
                                        )
                                        src_tables_dict[src_table_name][
                                            "src_vs2tgt_vs"
                                        ][src_vs] = tgt_vs
                            elif quble.valuespace is not None:
                                src_tables_dict[src_table_name]["src_vs2tgt_vs"][
                                    quble.valuespace
                                ] = f"{valuespace_prefix}_{str(quble_no)}"
                        elif valuespaces_join_op not in (
                            "primaries",
                            "primaries_xleft",
                            "primaries_xright",
                        ):
                            for src_vs_no, src_vs in enumerate(quble.valuespaces):
                                if (
                                    src_vs
                                    not in src_tables_dict[src_table_name][
                                        "src_vs2tgt_vs"
                                    ]
                                ):
                                    tgt_vs = (
                                        valuespace_prefix
                                        + "_"
                                        + str(quble_no)
                                        + "_"
                                        + str(src_vs_no)
                                    )
                                    src_tables_dict[src_table_name]["src_vs2tgt_vs"][
                                        src_vs
                                    ] = tgt_vs
                        elif (
                            quble.valuespace is not None
                            and quble.valuespace
                            not in src_tables_dict[src_table_name]["src_vs2tgt_vs"]
                        ):
                            src_tables_dict[src_table_name]["src_vs2tgt_vs"][
                                quble.valuespace
                            ] = f"{valuespace_prefix}_{str(quble_no)}"

                # valuespace suffixing
                elif valuespace_num_suffix_delimiter:
                    for quble_no, quble in enumerate(qubles):
                        src_table_name = quble.table_name
                        if src_table_name is None:
                            continue
                        elif (
                            valuespaces_join_op in ("xleft_primaries", "xleft_all")
                            and quble_no == 0
                        ):
                            # Exclude valuespaces from the first/left quble
                            continue
                        elif valuespaces_join_op in (
                            "xright_primaries",
                            "xright_all",
                        ) and (quble_no == (len(qubles) - 1)):
                            # Exclude valuespaces from the last/right quble
                            continue

                        if "src_vs2tgt_vs" not in src_tables_dict[src_table_name]:
                            src_tables_dict[src_table_name]["src_vs2tgt_vs"] = {}

                        if valuespaces_join_op in (
                            "left_all_right_primaries",
                            "left_primary_right_all",
                        ):
                            if (
                                (valuespaces_join_op == "left_all_right_primaries")
                                and (quble_no == 0)
                            ) or (
                                (valuespaces_join_op == "left_primary_right_all")
                                and (quble_no != 0)
                            ):
                                for src_vs_no, src_vs in enumerate(quble.valuespaces):
                                    if (
                                        src_vs
                                        not in src_tables_dict[src_table_name][
                                            "src_vs2tgt_vs"
                                        ]
                                    ):
                                        tgt_vs = (
                                            src_vs
                                            + valuespace_num_suffix_delimiter
                                            + str(quble_no)
                                        )
                                        src_tables_dict[src_table_name][
                                            "src_vs2tgt_vs"
                                        ][src_vs] = tgt_vs
                            elif quble.valuespace is not None:
                                src_tables_dict[src_table_name]["src_vs2tgt_vs"][
                                    quble.valuespace
                                ] = (
                                    quble.valuespace
                                    + valuespace_num_suffix_delimiter
                                    + str(quble_no)
                                )
                        elif valuespaces_join_op not in (
                            "primaries",
                            "primaries_xleft",
                            "primaries_xright",
                        ):
                            for src_vs_no, src_vs in enumerate(quble.valuespaces):
                                if (
                                    src_vs
                                    not in src_tables_dict[src_table_name][
                                        "src_vs2tgt_vs"
                                    ]
                                ):
                                    tgt_vs = (
                                        src_vs
                                        + valuespace_num_suffix_delimiter
                                        + str(quble_no)
                                    )
                                    src_tables_dict[src_table_name]["src_vs2tgt_vs"][
                                        src_vs
                                    ] = tgt_vs
                        elif (
                            quble.valuespace is not None
                            and quble.valuespace
                            not in src_tables_dict[src_table_name]["src_vs2tgt_vs"]
                        ):
                            src_tables_dict[src_table_name]["src_vs2tgt_vs"][
                                quble.valuespace
                            ] = (
                                quble.valuespace
                                + valuespace_num_suffix_delimiter
                                + str(quble_no)
                            )
                else:
                    # No valuespace_prefix specified...honor original source valuespaces
                    # but requires that no conflicts exist across source valuespaces
                    distinct_tgt_valuespaces = []
                    for quble_no, quble in enumerate(qubles):
                        src_table_name = quble.table_name
                        if src_table_name is None:
                            continue
                        elif (
                            valuespaces_join_op in ("xleft_primaries", "xleft_all")
                            and quble_no == 0
                        ):
                            # Exclude valuespaces from the first/left quble
                            continue
                        elif valuespaces_join_op in (
                            "xright_primaries",
                            "xright_all",
                        ) and (quble_no == (len(qubles) - 1)):
                            # Exclude valuespaces from the last/right quble
                            continue

                        if "src_vs2tgt_vs" not in src_tables_dict[src_table_name]:
                            src_tables_dict[src_table_name]["src_vs2tgt_vs"] = {}

                        if valuespaces_join_op in (
                            "left_all_right_primaries",
                            "left_primary_right_all",
                        ):
                            if (
                                (valuespaces_join_op == "left_all_right_primaries")
                                and (quble_no == 0)
                            ) or (
                                (valuespaces_join_op == "left_primary_right_all")
                                and (quble_no != 0)
                            ):
                                for src_vs in quble.valuespaces:
                                    if src_vs in distinct_tgt_valuespaces:
                                        raise Exception(
                                            f"Encountered duplicate tgt_vs:{src_vs}"
                                        )
                                    if (
                                        src_vs
                                        not in src_tables_dict[src_table_name][
                                            "src_vs2tgt_vs"
                                        ]
                                    ):
                                        src_tables_dict[src_table_name][
                                            "src_vs2tgt_vs"
                                        ][src_vs] = src_vs
                                        distinct_tgt_valuespaces.append(src_vs)
                            elif quble.valuespace is not None:
                                src_vs = quble.valuespace
                                if src_vs in distinct_tgt_valuespaces:
                                    raise Exception(
                                        f"Encountered duplicate tgt_vs:{src_vs}"
                                    )
                                src_tables_dict[src_table_name]["src_vs2tgt_vs"][
                                    quble.valuespace
                                ] = src_vs
                                distinct_tgt_valuespaces.append(src_vs)
                        elif valuespaces_join_op not in (
                            "primaries",
                            "primaries_xleft",
                            "primaries_xright",
                        ):
                            for src_vs in quble.valuespaces:
                                if src_vs in distinct_tgt_valuespaces:
                                    raise Exception(
                                        f"Encountered duplicate tgt_vs:{src_vs}"
                                    )
                                if (
                                    src_vs
                                    not in src_tables_dict[src_table_name][
                                        "src_vs2tgt_vs"
                                    ]
                                ):
                                    src_tables_dict[src_table_name]["src_vs2tgt_vs"][
                                        src_vs
                                    ] = src_vs
                                    distinct_tgt_valuespaces.append(src_vs)
                        elif quble.valuespace is not None:
                            src_vs = quble.valuespace
                            if src_vs in distinct_tgt_valuespaces:
                                raise Exception(
                                    f"Encountered duplicate tgt_vs:{src_vs}"
                                )
                            if (
                                src_vs
                                not in src_tables_dict[src_table_name]["src_vs2tgt_vs"]
                            ):
                                src_tables_dict[src_table_name]["src_vs2tgt_vs"][
                                    src_vs
                                ] = src_vs
                                distinct_tgt_valuespaces.append(src_vs)
            # Case 3C: Invalid valuespaces_join_op
            # -----------------------------------------
            else:
                raise Exception(
                    f"Unsupported: valuespaces_join_op{valuespaces_join_op}"
                )

        # Loop through the src_tables and build
        # primary_tgt_vs and tgt_valuespaces
        # and validate nosrc_vs nor tgt_vs are None
        # and verify there are no tgt_valuespaces duplicates
        # ---------------------------------------------------
        primary_tgt_vs = None
        tgt_valuespaces = []
        resampled_tgt_valuespaces = {}  # <-- May be appended to below
        for src_table_name in src_tables_dict:
            if src_table_name is None:
                continue
            elif "src_vs2tgt_vs" not in src_tables_dict[src_table_name]:
                # This src_table_name does not contribute any valuespaces to the join
                continue
            elif len(src_tables_dict[src_table_name]["src_vs2tgt_vs"]) == 0:
                # This src_table_name does not contribute any valuespaces to the join
                continue

            earliest_quble = src_tables_dict[src_table_name]["earliest_quble"]
            for src_vs, tgt_vs in src_tables_dict[src_table_name][
                "src_vs2tgt_vs"
            ].items():
                # primary_tgt_vs should be first participating primary valuespace encountered
                # as we traverse across all qubles being joined
                if src_vs is None:
                    raise Exception(
                        "Encountered src_vs=None (dict key) for src_tables_dict["
                        + src_table_name
                        + "]['src_vs2tgt_vs']:{1}".format(
                            src_table_name,
                            src_tables_dict[src_table_name]["src_vs2tgt_vs"],
                        )
                    )
                elif tgt_vs is None:
                    raise Exception(
                        "Encountered tgt_vs=None (dict value) for src_tables_dict["
                        + src_table_name
                        + "]['src_vs2tgt_vs']:{1}".format(
                            src_table_name,
                            src_tables_dict[src_table_name]["src_vs2tgt_vs"],
                        )
                    )
                elif primary_tgt_vs is None and src_vs == earliest_quble.valuespace:
                    primary_tgt_vs = tgt_vs

                if tgt_vs in tgt_valuespaces:
                    raise Exception(
                        f"Internal inconsistency...duplicate tgt_vs:{tgt_vs}"
                    )
                else:
                    tgt_valuespaces.append(tgt_vs)

        # If no primary_tgt_vs, try to inherit first element of tgt_valuespaces
        if primary_tgt_vs is None and len(tgt_valuespaces) > 0:
            primary_tgt_vs = tgt_valuespaces[0]

        # ---------------------------------------------------------
        # Handle trivial case when only one src_table is present
        # [i.e., The Qubles are already pre-joined]
        # by selectively renaming the valuespaces as directed
        # ---------------------------------------------------------
        if len(src_tables_dict) == 1:
            column_map = {}
            for src_table_name in src_tables_dict:
                for ks in src_tables_dict[src_table_name]["ks_list"]:
                    column_map[ks] = ks
                for src_vs, tgt_vs in src_tables_dict[src_table_name][
                    "src_vs2tgt_vs"
                ].items():
                    column_map[src_vs] = tgt_vs

            return self.select(column_names=column_map, preferred_vs=primary_tgt_vs)

        # ------------------------------------------------------
        # Populate resampling & null_placeholder information
        # ------------------------------------------------------
        resampled_keyspaces = []  # <-- Initialization
        for ks, quble_indices in ks_to_quble_indices.items():
            ks_is_time = ks in keyspace_freqs
            # Resampling of a particular keyspaces requires following...
            #
            #     1) Time index/dimension
            #     2a) More than one participating qubles
            #         for this time dimension
            # or 2b) other tables/qubles being joined do not have this time dimension
            #        [but may have additional "ortho" (non-time) keys not in the time-based quble]
            #        AND non-intersection keys join operation for "ortho" (non-time) keys
            #        Logic: The non-intersection joining of "ortho" (non-time) keys from OTHER qubles (WITHOUT the time dimension)
            #               may introduce new dates/ortho pair (combo) keys into the quble(s) WITH the time dimension
            #               and these new dates/ortho pair combo keys will (inturn) invoke/require resampling in time-based quble
            #
            #     3) One or more valuespaces present [Rethink this one...for index Qubles, resampling be if interest]
            #
            #   4a) (ks == 'Vantage') or
            #   4b) tfill_method is not None and ((tfill_max is None) or (tfill_max > 0))
            # ---------------------------------------------------------------

            keys_join_ops_for_non_time_intersection = (
                "intersection",
                "inter_lfreq",
                "inter_rfreq",
                "inter_tunion",
                "inter_tunionpostleft",
                "inter_tunionpostright",
                "inter_tunionpostall",
            )
            if (
                ks_is_time
                and auto_fill
                and (
                    len(quble_indices) > 1
                    or (ks == "Vantage")
                    or (
                        (keys_join_op not in keys_join_ops_for_non_time_intersection)
                        and len(quble_indices) < len(qubles)
                    )
                )
                and len(tgt_valuespaces) > 0
            ):
                # We only resample those qubles that have a non-trivial tgt_valuespace
                # [cannot use src_valuespace here as valuespace conflicts may exist across source qubles]
                # [tgt_valuespaces will have addressed possible source valuespace conflicts]
                for i in quble_indices:
                    src_table_name = qubles[i].table_name
                    if src_table_name is None:
                        continue
                    elif (
                        "src_vs2tgt_vs" not in src_tables_dict[src_table_name]
                        or len(src_tables_dict[src_table_name]["src_vs2tgt_vs"]) == 0
                    ):
                        # This Quble is not contributing a valuespace to the output
                        continue

                    # Establish src_tables_dict[src_table_name]['resampling_dict'] where applicable
                    if "resampling_dict" not in src_tables_dict[src_table_name]:
                        src_tables_dict[src_table_name]["resampling_dict"] = {}
                    if ks not in src_tables_dict[src_table_name]["resampling_dict"]:
                        src_tables_dict[src_table_name]["resampling_dict"][ks] = {}

                    src_tables_dict[src_table_name]["resampling_dict"][ks]["freq"] = (
                        keyspace_freqs[ks]
                    )

                    # Establish src_tables_dict[src_table_name]['src_vs2null_placeholders'] where applicable
                    for src_vs, tgt_vs in src_tables_dict[src_table_name][
                        "src_vs2tgt_vs"
                    ].items():
                        # tfill_max1 for this quble for this src_vs
                        if ks == "Vantage":
                            tfill_max1 = -1
                        else:
                            tfill_max1 = qubles[i]._space_info_indirection(
                                info_type="tfill_max",
                                space=src_vs,
                                info_assignment=tfill_max,
                                grace=True,
                            )

                        # Continue to next loop iteration when tfill_max1 in (None,0)
                        if not tfill_max1:
                            # No filling
                            continue
                        else:
                            # The valuespaces of this Quble need to be resampled across this keyspace...
                            if ks not in resampled_keyspaces:
                                # Add this keyspace (ks) to the list of resampled_keyspaces
                                resampled_keyspaces.append(ks)

                        if qubles[i]._space_info_indirection(
                            info_type="tfill_honor_nulls",
                            space=src_vs,
                            info_assignment=tfill_honor_nulls,
                            grace=True,
                        ):
                            if (
                                "src_vs2null_placeholders"
                                not in src_tables_dict[src_table_name]
                            ):
                                src_tables_dict[src_table_name][
                                    "src_vs2null_placeholders"
                                ] = {}

                            src_tables_dict[src_table_name]["src_vs2null_placeholders"][
                                src_vs
                            ] = null_placeholder_as_str(
                                qubles[i].get_space_info(info_type="type", space=src_vs)
                            )

                        if (
                            "tfill_max"
                            not in src_tables_dict[src_table_name]["resampling_dict"][
                                ks
                            ]
                        ):
                            src_tables_dict[src_table_name]["resampling_dict"][ks][
                                "tfill_max"
                            ] = {}

                        if (
                            "tfill_method"
                            not in src_tables_dict[src_table_name]["resampling_dict"][
                                ks
                            ]
                        ):
                            src_tables_dict[src_table_name]["resampling_dict"][ks][
                                "tfill_method"
                            ] = {}

                        # For ks=='Vantange', hardcode: tfill_max=-1 & tfill_method='pad', and tfill_end_mode=None
                        if ks == "Vantage":
                            # 'tfill_max' & 'tfill_method' is assigned per src_vs
                            src_tables_dict[src_table_name]["resampling_dict"][ks][
                                "tfill_max"
                            ][src_vs] = -1
                            src_tables_dict[src_table_name]["resampling_dict"][ks][
                                "tfill_method"
                            ][src_vs] = "pad"
                            if (
                                "tfill_end_mode"
                                not in src_tables_dict[src_table_name][
                                    "resampling_dict"
                                ][ks]
                            ):
                                # 'tfill_end_mode' is assigned once (scalar) using first src_vs
                                src_tables_dict[src_table_name]["resampling_dict"][ks][
                                    "tfill_end_mode"
                                ] = None
                        else:
                            # 'tfill_max' & 'tfill_method' is assigned per src_vs
                            src_tables_dict[src_table_name]["resampling_dict"][ks][
                                "tfill_max"
                            ][src_vs] = tfill_max1
                            src_tables_dict[src_table_name]["resampling_dict"][ks][
                                "tfill_method"
                            ][src_vs] = qubles[i]._space_info_indirection(
                                info_type="tfill_method",
                                space=src_vs,
                                info_assignment=tfill_method,
                                grace=True,
                            )

                            if (
                                "tfill_end_mode"
                                not in src_tables_dict[src_table_name][
                                    "resampling_dict"
                                ][ks]
                            ):
                                # 'tfill_end_mode' is assigned once (scalar) using first src_vs
                                src_tables_dict[src_table_name]["resampling_dict"][ks][
                                    "tfill_end_mode"
                                ] = qubles[i]._space_info_indirection(
                                    info_type="tfill_end_mode",
                                    space=src_vs,
                                    info_assignment=tfill_end_mode,
                                    grace=True,
                                )

                        # If src_tables_dict[src_table_name]['resampling_dict'][ks]['tfill_max'][src_vs] is not None and not Zero
                        # Log this tgt_vs as having been 'resampled' so that we can eventually set tfill_max=0 in result to prevent subsequent resampling
                        if src_tables_dict[src_table_name]["resampling_dict"][ks][
                            "tfill_max"
                        ][src_vs]:
                            resampled_tgt_valuespaces[tgt_vs] = src_tables_dict[
                                src_table_name
                            ]["resampling_dict"][ks]["tfill_max"][src_vs]

        # --------------------------
        # Perform join operation
        # --------------------------
        tgt_table_name = generate_random_table_name()

        keyspaces = list(ks_to_quble_indices.keys())
        num_keyspaces = len(keyspaces)

        # Identify appropriate join sql_template
        sql_template = JINJA_ENV.get_template("join.j2")

        # ==============================================================
        # MODIFY keys_join_op ACCORDINGLY IF NO RESAMPING IS PRESENT
        # ==============================================================

        # ---------------------------------------------------
        # KEYSPACES WILL BE EITHER 'joined', 'unioned'
        # ---------------------------------------------------
        joined_keyspace_introducers = {}  # <-- look at keys for joined_keyspaces (list)
        unioned_keyspaces = []
        unioning_min_threshold_tbl = None

        # -------------------------------------------------------------------------------
        # For a given src_table_name,
        # some union_keyspaces will be INSIDE a given src_table_name's keyspaces
        # and some union_keyspaces will be OUTSIDE a given src_table_name's keyspaces...
        #   1) unioned keyspaces INSIDE a table: "nonortho_and_unioned"
        #   2) unioned keyspaces OUTSIDE a table: "ortho_and_unioned"
        #      ==> The latter group ("ortho_and_unioned") will be used to create
        #          src_tables_dict[src_table]['ortho_and_unioned_crosser_info'] for a given table
        # -------------------------------------------------------------------------------
        # a subset of these unioned keyspaces for this table will be list the keyspaces for which distinct crosser tables will be needed
        ortho_and_unioned_crossers_needed = []

        if all([(quble1.is_scalar or quble1.is_multiscalar) for quble1 in qubles]):
            # Ignore keys_join_op here (parameter does not apply to this case)
            sql_template = JINJA_ENV.get_template("join_scalars.j2")
        elif keys_join_op not in VALID_KEYS_JOIN_OP:  # valid_keys_join_op:
            raise Exception(f"Unsupported keys_join_op:{keys_join_op}")
        else:
            if src_tables_dict is None or len(src_tables_dict) == 0:
                raise Exception("Empty src_tables_dict")

            # Depending on keys_join_op, classify each keyspace as one of following:
            #   'direct': meaning this keyspace only occurs in one table
            #   'nonunioned': occurs in multiple tables and non-introducer tables are included via left join
            #   'unioned': keyspaces to be unioned
            #
            # Also need join_type (scalar): None or 'left'
            # Also need joined_keyspace_introducers list mapping all nonunioned keyspaces to respective introducing table
            if keys_join_op in (
                "leftmost",
                "rightmost",
                "intersection",
                "lintersection",
                "rintersection",
            ):
                # all keyspaces are directs and all keyspaces have leftmost (rightmost) introducers

                # Secondly, assign joined_keyspaces
                first_src_table = (
                    list(src_tables_dict.keys())[0]
                    if len(src_tables_dict) > 0
                    else None
                )
                for table_ctr, src_table_name in enumerate(src_tables_dict.keys()):
                    ks_list = src_tables_dict[src_table_name]["ks_list"]
                    src_tables_dict[src_table_name]["joined_keyspaces"] = []
                    src_tables_dict[src_table_name]["unioned_keyspaces"] = []
                    for ks in ks_list:
                        if ks in unioned_keyspaces:
                            if (
                                ks
                                not in src_tables_dict[src_table_name][
                                    "unioned_keyspaces"
                                ]
                            ):
                                src_tables_dict[src_table_name][
                                    "unioned_keyspaces"
                                ].append(ks)
                            continue

                        if (
                            ks
                            not in src_tables_dict[src_table_name]["joined_keyspaces"]
                        ):
                            src_tables_dict[src_table_name]["joined_keyspaces"].append(
                                ks
                            )

                        if ks not in joined_keyspace_introducers:
                            joined_keyspace_introducers[ks] = src_table_name

                    if len(src_tables_dict[src_table_name]["joined_keyspaces"]) > 0:
                        # Does this table have joined_keyspaces not introduced by itself?
                        # If no, then this table does not interact with other tables in the join exercise (aka: cross join)
                        src_table_has_join_interactions = any(
                            src_table_name != joined_keyspace_introducers[ks1]
                            for ks1 in src_tables_dict[src_table_name][
                                "joined_keyspaces"
                            ]
                        )
                        src_table_joined_against_firstly_introduced = any(
                            joined_keyspace_introducers[ks1] == first_src_table
                            for ks1 in src_tables_dict[src_table_name][
                                "joined_keyspaces"
                            ]
                        )

                        # Now, assign join_type for this src_table_name
                        if not src_table_has_join_interactions:
                            src_tables_dict[src_table_name]["join_type"] = "cross"
                        elif keys_join_op in ("leftmost", "rightmost"):
                            src_tables_dict[src_table_name]["join_type"] = "left"
                        elif (
                            keys_join_op in ("lintersection", "rintersection")
                            and src_table_joined_against_firstly_introduced
                        ):
                            src_tables_dict[src_table_name]["join_type"] = "left"
                        else:
                            src_tables_dict[src_table_name]["join_type"] = None
                    else:
                        src_tables_dict[src_table_name]["join_type"] = None
            elif keys_join_op in ("lunion", "runion"):
                # only keyspaces from first (last) table are directs and have introducers
                for table_ctr, src_table_name in enumerate(src_tables_dict.keys()):
                    src_tables_dict[src_table_name]["joined_keyspaces"] = []
                    src_tables_dict[src_table_name]["unioned_keyspaces"] = []
                    ks_list = src_tables_dict[src_table_name]["ks_list"]
                    # NOTE: anchoring only applies to intersection cases
                    if table_ctr == 0:
                        for ks in ks_list:
                            if ks not in joined_keyspace_introducers:
                                joined_keyspace_introducers[ks] = src_table_name

                            if (
                                ks
                                not in src_tables_dict[src_table_name][
                                    "joined_keyspaces"
                                ]
                            ):
                                src_tables_dict[src_table_name][
                                    "joined_keyspaces"
                                ].append(ks)

                    # Union all keyspaces not in first table
                    # and not already joined against a keyspace from the first table
                    else:
                        for ks in ks_list:
                            if (
                                ks not in joined_keyspace_introducers
                                and ks not in unioned_keyspaces
                            ):
                                unioned_keyspaces.append(ks)

                            if (
                                ks
                                not in src_tables_dict[src_table_name][
                                    "unioned_keyspaces"
                                ]
                            ):
                                src_tables_dict[src_table_name][
                                    "unioned_keyspaces"
                                ].append(ks)

                    if len(src_tables_dict[src_table_name]["joined_keyspaces"]) > 0:
                        # Does this table have joined_keyspaces not introduced by itself?
                        # If no, then this table does not interact with other tables in the join exercise (aka: cross join)
                        src_table_has_join_interactions = any(
                            src_table_name != joined_keyspace_introducers[ks1]
                            for ks1 in src_tables_dict[src_table_name][
                                "joined_keyspaces"
                            ]
                        )
                        # Now, assign join_type for this src_table_name
                        if not src_table_has_join_interactions:
                            src_tables_dict[src_table_name]["join_type"] = "cross"
                        else:
                            src_tables_dict[src_table_name]["join_type"] = "left"
                    else:
                        src_tables_dict[src_table_name]["join_type"] = None
            elif keys_join_op in (
                "leftmost_tunion",
                "rightmost_tunion",
                "inter_tunion",
                "inter_tunionpostleft",
                "inter_tunionpostright",
                "leftmost_tunionpostleft",
                "rightmost_tunionpostright",
                "inter_tunionpostall",
            ):
                unioning_min_threshold_tbl = {}
                for table_ctr, src_table_name in enumerate(src_tables_dict.keys()):
                    src_tables_dict[src_table_name]["joined_keyspaces"] = []
                    src_tables_dict[src_table_name]["unioned_keyspaces"] = []
                    ks_list = src_tables_dict[src_table_name]["ks_list"]
                    # resampling keyspaces (to be unioned) are not direct nor have introducers
                    # [see logic above for construction of resampled_keyspaces]
                    for ks in resampled_keyspaces:
                        if ks not in unioned_keyspaces:
                            unioned_keyspaces.append(ks)
                            if (
                                keys_join_op
                                in (
                                    "inter_tunionpostleft",
                                    "inter_tunionpostright",
                                    "leftmost_tunionpostleft",
                                    "rightmost_tunionpostright",
                                )
                                and table_ctr == 0
                                and ks in ks_list
                            ):
                                if ks not in unioning_min_threshold_tbl:
                                    unioning_min_threshold_tbl[ks] = [src_table_name]
                                elif (
                                    src_table_name not in unioning_min_threshold_tbl[ks]
                                ):
                                    unioning_min_threshold_tbl[ks] += [src_table_name]

                            elif (
                                keys_join_op == "inter_tunionpostall" and ks in ks_list
                            ):
                                if ks not in unioning_min_threshold_tbl:
                                    unioning_min_threshold_tbl[ks] = [src_table_name]
                                elif (
                                    src_table_name not in unioning_min_threshold_tbl[ks]
                                ):
                                    unioning_min_threshold_tbl[ks] += [src_table_name]

                    for ks in ks_list:
                        if ks in unioned_keyspaces:
                            if (
                                ks
                                not in src_tables_dict[src_table_name][
                                    "unioned_keyspaces"
                                ]
                            ):
                                src_tables_dict[src_table_name][
                                    "unioned_keyspaces"
                                ].append(ks)
                            continue

                        if (
                            ks
                            not in src_tables_dict[src_table_name]["joined_keyspaces"]
                        ):
                            src_tables_dict[src_table_name]["joined_keyspaces"].append(
                                ks
                            )

                        # non-resampling keyspaces (to be intersectioned)
                        # are not direct, but are intersectioned and also have introducers
                        if (
                            ks not in joined_keyspace_introducers
                            and ks not in unioned_keyspaces
                        ):
                            joined_keyspace_introducers[ks] = src_table_name

                    if len(src_tables_dict[src_table_name]["joined_keyspaces"]) > 0:
                        # Does this table have joined_keyspaces not introduced bny iteslf?
                        # If no, then this table does not interact with other tabels in the join exercise (aka: cross join)
                        src_table_has_join_interactions = any(
                            src_table_name != joined_keyspace_introducers[ks1]
                            for ks1 in src_tables_dict[src_table_name][
                                "joined_keyspaces"
                            ]
                        )
                        # Now, assign join_type for this src_table_name
                        if not src_table_has_join_interactions:
                            src_tables_dict[src_table_name]["join_type"] = "cross"
                        elif keys_join_op in (
                            "leftmost_tunion",
                            "rightmost_tunion",
                            "leftmost_tunionpostleft",
                            "rightmost_tunionpostright",
                        ):
                            src_tables_dict[src_table_name]["join_type"] = "left"
                        else:
                            src_tables_dict[src_table_name]["join_type"] = None
                    else:
                        src_tables_dict[src_table_name]["join_type"] = None
            elif keys_join_op in ("union", "union_rfreq", "union_lfreq"):
                # No keyspaces are directs, no keyspaces have introducers
                # NOTE: anchoring only applies to intersection cases
                for table_ctr, src_table_name in enumerate(src_tables_dict.keys()):
                    src_tables_dict[src_table_name]["joined_keyspaces"] = []
                    src_tables_dict[src_table_name]["unioned_keyspaces"] = []
                    src_tables_dict[src_table_name]["join_type"] = None
                    ks_list = src_tables_dict[src_table_name]["ks_list"]
                    for ks in ks_list:
                        if ks not in unioned_keyspaces:
                            unioned_keyspaces.append(ks)

                        if (
                            ks
                            not in src_tables_dict[src_table_name]["unioned_keyspaces"]
                        ):
                            src_tables_dict[src_table_name]["unioned_keyspaces"].append(
                                ks
                            )
            else:
                raise Exception(f"Invalid keys_join_op:{keys_join_op}")

            # ====================================================
            # Do any unioned_keyspaces exist?
            # If so, populate ortho_and_unioned_crossers_needed and src_tables_dict[src_table]['ortho_and_unioned_crosser_info'] accordingly for a given table
            # ====================================================
            for src_table_name in src_tables_dict:
                src_tables_dict[src_table_name]["nonortho_and_unioned_keyspaces"] = []
                src_tables_dict[src_table_name]["ortho_and_unioned_keyspaces"] = []
                if len(unioned_keyspaces) > 0:
                    ks_list = src_tables_dict[src_table_name]["ks_list"]
                    # Is this table a 'union participant'? If not, continue
                    is_union_participant_table = any(
                        ks1 in unioned_keyspaces for ks1 in ks_list
                    )
                    if not is_union_participant_table:
                        continue

                    # For the current src_table_name (a verified union_participant), assign each unioned keyspace to either the 'non-ortho' or 'ortho' list
                    # --------------------------------------------------------------------------
                    # For each table, record following information:
                    #   ==> src_tables_dict[src_table_name]['nonortho_and_unioned_keyspaces']: unioned keyspaces WITHIN current src_table_name
                    #   ==> src_tables_dict[src_table_name]['ortho_and_unioned_keyspaces']: unioned keyspaces OUTSIDE current src_table_name
                    for ks in unioned_keyspaces:
                        if ks in ks_list:
                            src_tables_dict[src_table_name][
                                "nonortho_and_unioned_keyspaces"
                            ].append(ks)
                        else:
                            src_tables_dict[src_table_name][
                                "ortho_and_unioned_keyspaces"
                            ].append(ks)
            # Now we have documented
            #     src_tables_dict[src_table_name]['nonortho_and_unioned_keyspaces'] and src_tables_dict[src_table_name]['ortho_and_unioned_keyspaces']
            # We do a second pass over union participants to identify "crossing information" against each's complementary union co-participant
            # ----------------------------------------------------------------------
            for union_participant_table in src_tables_dict:
                src_tables_dict[union_participant_table][
                    "ortho_and_unioned_crosser_info"
                ] = {}
                # Does this table have any non-ortho unioned keyspaces?
                # If not, we don't need to include in unioning nor crossing exercise
                # --------------------------------------------------------------------
                if (
                    len(
                        src_tables_dict[union_participant_table][
                            "nonortho_and_unioned_keyspaces"
                        ]
                    )
                    == 0
                ):
                    continue
                # Given that this table has non-ortho unioned keyspaces (aka there are unioned keyspaces INSIDE this table)...
                # Does this (union participant) table need "crossing"? Are there unioned keyspaces OUTSIDE (not present) in this table?
                # [aka, are there any "unioned_and_ortho" keyspaces for this table?]
                # -------------------------------------------------
                # If so, record the "crosser information" as it related to each complementary table
                # Crosser info
                # -------------------------------------------------
                elif (
                    len(
                        src_tables_dict[union_participant_table][
                            "ortho_and_unioned_keyspaces"
                        ]
                    )
                    > 0
                ):
                    for union_participant_table1 in src_tables_dict:
                        # Exclude non-participants from crossing exercise
                        if (
                            len(
                                src_tables_dict[union_participant_table1][
                                    "nonortho_and_unioned_keyspaces"
                                ]
                            )
                            == 0
                        ):
                            continue
                        # Look to complementary, union participant tables for crossing info
                        elif union_participant_table1 != union_participant_table:
                            distinct_columns1 = []
                            unioned_crossers1 = []
                            # NOTE: each ortho_ks (of src_table_name) when crossed against a complementary union_participant_table1
                            #       will show up in either the distinct_columns1 list OR the unioned_crossers1 list
                            for ortho_ks in src_tables_dict[union_participant_table][
                                "ortho_and_unioned_keyspaces"
                            ]:
                                if (
                                    ortho_ks
                                    in src_tables_dict[union_participant_table1][
                                        "ks_list"
                                    ]
                                ):
                                    distinct_columns1.append(ortho_ks)
                                else:
                                    unioned_crossers1.append(ortho_ks)
                                    if (
                                        ortho_ks
                                        not in ortho_and_unioned_crossers_needed
                                    ):
                                        ortho_and_unioned_crossers_needed.append(
                                            ortho_ks
                                        )

                            # We need at least one distinct_columns for union_participant_table1 here
                            # [Interpretation: otherwise, union_participant_table1 does not support any ortho_and_unioned_keyspaces of
                            # current src_table_name, and therefore does not contribute to the table_crosser for src_table_name]
                            if len(distinct_columns1) > 0:
                                src_tables_dict[union_participant_table][
                                    "ortho_and_unioned_crosser_info"
                                ][union_participant_table1] = (
                                    distinct_columns1,
                                    unioned_crossers1,
                                )
            sql_template = JINJA_ENV.get_template("join.j2")

        # -------------------------------------------------------------
        # Establish expansion_keyspaces based on prevent_null_keys & expansion_exclusions arg
        # (expansion_keyspaces are keyspaces requiring expansion to prevent null keys)
        # Recall: keyspaces is a (unique) list of all applicable keyspaces across all qubles to be joined
        # -------------------------------------------------------------
        nulls_present = {}
        keyspaces_without_nulls = []
        keyspaces_with_nulls = []
        # Loop through the applicable keyspaces
        for ks in ks_to_quble_indices:
            nulls_present[ks] = False  # <-- Initialization
            # For this keyspace, loop through the applicable qubles
            for i in ks_to_quble_indices[ks]:
                # Log and exit when encountering any quble with null keys for this keyspace
                if ks in qubles[i].keyspaces and qubles[i].has_nulls(ks):
                    nulls_present[ks] = True
                    break
            # Log keyspaces_without_nulls if no quble has any null keys for this keyspace
            if not nulls_present[ks]:
                keyspaces_without_nulls.append(ks)
            else:
                keyspaces_with_nulls.append(ks)

        # Invoke the join template
        sql_command = sql_template.render(
            calendar_table_name=calendar_table_name,
            keys_join_op=keys_join_op,
            keyspaces=keyspaces,
            src_tables_dict=src_tables_dict,
            tgt_table_name=tgt_table_name,
            key_ordering=key_ordering,
            joined_keyspace_introducers=joined_keyspace_introducers,
            unioned_keyspaces=unioned_keyspaces,
            ortho_and_unioned_crossers_needed=ortho_and_unioned_crossers_needed,
            expansion_keyspaces=[],
            keyspaces_with_nulls=keyspaces_with_nulls,
            unioning_min_threshold_tbl=unioning_min_threshold_tbl,
            tgt_valuespaces_order=tgt_valuespaces_order,
            drop_null_keys=True if prevent_null_keys == "drop" else False,
        )
        execute(sql_command, format_flag=False)

        # ========================================
        # Copy custom info for source keyspaces from respective src_table to keyspace within (new) tgt_table_name
        # ========================================
        # Keep a list as to which keyspaces have been introduced
        introduced_keyspaces = []

        # Recall that src_tables_dict is a dictionary as such, we are iterating through src_tables_dict in the order
        # for which each src_table_name was presented to this method
        col_info = {}
        for src_table_name in src_tables_dict:
            ks_list = src_tables_dict[src_table_name]["ks_list"]
            if ks_list is None:
                continue

            # Track keyspaces_to be introduced from this src_table_name
            keyspaces_to_be_introduced = []
            for ks in ks_list:
                if ks is None:
                    continue  # <-- Try to be safe for below calls
                elif ks not in introduced_keyspaces:
                    # Here, src_table_name has "introduced" the keyspace (ks) to the tgt_table_name
                    keyspaces_to_be_introduced.append(ks)

            # Process & add keyspaces_to_be_introduced
            if len(keyspaces_to_be_introduced) > 0:
                src_quble = src_tables_dict[src_table_name]["earliest_quble"]
                if src_quble is not None:
                    col_info_to_add = src_quble.get_space_info(
                        info_type=CUSTOM_INFO_TYPES,
                        space=keyspaces_to_be_introduced,
                        omit_unassigned=True,
                    )
                    if col_info_to_add is not None:
                        col_info = combine_column_info(col_info, col_info_to_add)
                introduced_keyspaces = introduced_keyspaces + keyspaces_to_be_introduced

            # Exit the src_table_name loop once all (unique) keyspaces have been introduced (and keyspaces info has been copied)
            if len(introduced_keyspaces) == num_keyspaces:
                break

        # Next, copy custom info for source valuespaces from respective src_table_name to target valuespace within (new) tgt_table_name
        for src_table_name in src_tables_dict:
            if (
                "src_vs2tgt_vs" in src_tables_dict[src_table_name]
                and src_tables_dict[src_table_name]["src_vs2tgt_vs"] is not None
            ):
                src_qbl = src_tables_dict[src_table_name]["earliest_quble"]
                if src_qbl is not None:
                    col_info_to_add = src_qbl.get_space_info(
                        info_type=CUSTOM_INFO_TYPES,
                        space=src_tables_dict[src_table_name]["src_vs2tgt_vs"],
                        omit_unassigned=True,
                    )
                    if col_info_to_add is not None:
                        col_info = combine_column_info(col_info, col_info_to_add)

        # Were any target valuespaces 'resampled' during join?
        col_info_to_add = {}
        for resampled_tgt_vs, orig_tfill_max in resampled_tgt_valuespaces.items():
            # Here, we set 'tfill_max'=0 that have been 'resampled' herein to prevent latter additional filling of result Quble
            if orig_tfill_max > 0:
                if "tfill_max" not in col_info_to_add:
                    col_info_to_add["tfill_max"] = {}
                col_info_to_add["tfill_max"][resampled_tgt_vs] = 0

        if col_info_to_add is not None:
            col_info = combine_column_info(col_info, col_info_to_add)

        # -----------------
        # Build tgt_quble
        # -----------------
        tgt_quble = Quble.from_table(
            tgt_table_name,
            valuespace=tgt_valuespaces,
            col_info=col_info,
            remove_duplicate_keys=True,
        )

        # Promote the appropriate valuespace (if needed)
        if (
            primary_tgt_vs is not None
            and tgt_quble.valuespace is not None
            and tgt_quble.valuespace != primary_tgt_vs
        ):
            tgt_quble.valuespace = primary_tgt_vs

        if not prevent_null_keys:
            pass
        elif isinstance(prevent_null_keys, str) and prevent_null_keys == "drop":
            pass
        else:
            # -------------------------------------------------
            # Expand keyspaces with newly introduced null keys (to prevent_null_keys)
            # -------------------------------------------------
            keyspaces_where_null_keys_introduced = []
            for ks in tgt_quble.keyspaces_with_null_keys:
                if ks in keyspaces_without_nulls:
                    keyspaces_where_null_keys_introduced.append(ks)
            if len(keyspaces_where_null_keys_introduced) > 0:
                tgt_quble = tgt_quble.expand_null_keys(
                    expansion_keyspaces=keyspaces_where_null_keys_introduced,
                    key_ordering=key_ordering,
                )
        return tgt_quble

    @RootLib.lazy_kwargs()
    def pivot(
        self,
        pivot_keyspace: str = "<last_keyspace>",
        valuespace: str = "<valuespace>",
        key_ordering="asc",
    ) -> Quble:
        """
        Pivots the specified 'pivot_keyspace'
        for the specified valuespace of a 2+D Quble
        and yields multi-variate (n-1)dimensional Quble
        where each valuespace corresponds to the
        number of unique/distinct keys in the pivot_keyspace

        NOTE: The original valuespace (column name) specified will be lost
              and will be replaced by multiple new valuespaces
              that correpond to the distinct keys in the pivot_keyspace

        Example:

        Y ==> (3D Quble)
        <----------- keyspaces --------------><- valuespaces ->
        +---------+-------------+-------------+---------------+
        | Tickers |    Dates    |   Account   |     Values    |
        +=========+=============+=============+===============+
        |   IBM   | 2017-12-31  |     EPS     |      15.56    |
        |   IBM   | 2018-12-31  |     EPS     |       NULL    |
        |   AAPL  | 2016-12-31  |     EPS     |      83.89    |
        |   AAPL  | 2017-12-31  |     EPS     |      88.18    |
        |   AAPL  | 2018-12-31  |     EPS     |      67.73    |
        |   GOOG  | 2017-12-31  |     EPS     |     146.19    |
        |   IBM   | 2017-12-31  |  Cash Flow  |       8.26    |
        |   IBM   | 2018-12-31  |  Cash Flow  |       6.18    |
        |   AAPL  | 2016-12-31  |  Cash Flow  |      77.08    |
        |   AAPL  | 2017-12-31  |  Cash Flow  |      82.24    |
        |   AAPL  | 2018-12-31  |  Cash Flow  |       NULL    |
        |   GOOG  | 2017-12-31  |  Cash Flow  |     128.83    |
        |   IBM   | 2017-12-31  |     Debt    |      18.25    |
        |   IBM   | 2018-12-31  |     Debt    |      12.16    |
        |   AAPL  | 2016-12-31  |     Debt    |      62.55    |
        |   AAPL  | 2017-12-31  |     Debt    |      92.22    |
        |   AAPL  | 2018-12-31  |     Debt    |      73.37    |
        |   GOOG  | 2017-12-31  |     Debt    |     207.42    |
        +---------+-------------+-------------+---------------+

        X = Y.pivot(pivot_keyspace='Account')
        X ==> (2D Quble w/3 Valuespaces)
        X.valuespaces = ['EPS', 'Cash Flow', 'Debt']

        <------ keyspaces ------><--------- valuespaces --------->
        +---------+-------------+---------+-----------+----------+
        | Tickers |    Dates    |   EPS   | Cash Flow |   Debt   |
        +=========+=============+=========+===========+==========+
        |   IBM   | 2017-12-31  |  15.56  |    8.26   |  18.25   |
        |   IBM   | 2018-12-31  |   NULL  |    6.18   |  12.16   |
        |   AAPL  | 2016-12-31  |  83.89  |   77.08   |  62.55   |
        |   AAPL  | 2017-12-31  |  88.18  |   82.24   |  92.22   |
        |   AAPL  | 2018-12-31  |  67.73  |    NULL   |  73.37   |
        |   GOOG  | 2017-12-31  | 146.19  |  128.83   | 207.42   |
        +---------+-------------+---------+-----------+----------+

        The pivot operation can be undone using the Quble.unpivot() method...
        Y = X.unpivot(new_keyspace='Account', valuespaces_to_unpivot=['EPS','Cash Flow','Debt'], new_valuespace='Values')
        Y ==> (3D Quble w/1 Valuespace)

        """
        # Handle trivial/invalid cases
        # -----------------------------
        if self.is_undefined or self.is_scalar or self.ndim is None:
            return self.copy()

        # Validate the valuespace arg
        valuespace = self.validate_valuespace(
            valuespace, grace=False, solo_required=True
        )

        # Validate pivot_keyspace
        keyspaces = self.keyspaces
        pivot_keyspace = self.validate_keyspace(
            pivot_keyspace,
            auto_link=RootLib.lazy_eval("auto_link"),
            grace=False,
            coerce_to_list=False,
        )

        if pivot_keyspace not in keyspaces:
            raise Exception(
                "pivot keyspace:{0} not present within keyspaces:{1}".format(
                    pivot_keyspace, keyspaces
                )
            )

        # Build list of remaining keyspaces
        remaining_keyspaces = []
        for ks in keyspaces:
            if ks != pivot_keyspace:
                remaining_keyspaces.append(ks)

        # NOTE there should be no NULL records here due to .get_columns() options above
        # unique_pivot_keys = np.unique(pivot_keys_dict[pivot_keyspace])
        unique_pivot_keys = self.distinct_index_array1d(keyspace=pivot_keyspace)
        if len(unique_pivot_keys) == 0:
            # Not sure of the best approach here.
            # In theory, there are no records in the table
            # aso arguable, we should return a non-variate Quble result if possible
            ortho_keyspaces = [ks for ks in self.keyspaces if ks != pivot_keyspace]
            if len(pivot_keyspace) > 0:
                return self.index(keyspaces=ortho_keyspaces, distinct=True)
            else:
                return Quble()

        # Generate the target table name
        table_name = generate_random_table_name()

        # Build key_ordering dictionary when applicable
        if key_ordering is not None and not isinstance(key_ordering, str):
            key_ordering = build_key_ordering_dict(
                key_ordering, keyspaces=self.ortho_keyspaces(pivot_keyspace)
            )

        # NOTE: pivot.j2 will extend query_base.j2 (does not need a multivariate wrapper)
        sql_template = JINJA_ENV.get_template("pivot.j2")
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            tgt_table_name=table_name,
            keyspaces=keyspaces,
            pivot_keyspace=pivot_keyspace,
            unique_pivot_keys=unique_pivot_keys,
            valuespace=valuespace,
            key_ordering=key_ordering,
        )
        execute(sql_command)

        col_info = self.get_space_info(
            info_type=CUSTOM_INFO_TYPES,
            space=remaining_keyspaces,
            omit_unassigned=True,
        )

        if valuespace is not None:
            valuespace_info = self.get_space_info(
                info_type=CUSTOM_INFO_TYPES,
                space=[valuespace],
                omit_unassigned=True,
            )
            if valuespace_info is not None:
                for info_type, info_assignments in valuespace_info.items():
                    for vs, info_value in info_assignments.items():
                        if vs != valuespace:
                            raise Exception(
                                "Internal inconsistency...vs:{0} != valuespace:{1}".format(
                                    vs, valuespace
                                )
                            )
                        # Assign the valuespace_info to each new unqique secondary key column
                        for pivot_key in unique_pivot_keys:
                            # Ignore trivial unique secondary key
                            if pivot_key and len(pivot_key) > 0:
                                if col_info is None:
                                    col_info = {}
                                if info_type not in col_info:
                                    col_info[info_type] = {}
                                col_info[info_type][pivot_key] = info_value

        new_column_names = get_column_names(table_name)

        # Identify new primary valuespace as first valuespace
        primary_valuespace = None
        if new_column_names is not None:
            for column_name in new_column_names:
                # If this the first valuespace?
                if (
                    remaining_keyspaces is None
                    or column_name not in remaining_keyspaces
                ):
                    primary_valuespace = column_name
                    break

        return Quble.from_table(
            table_name,
            valuespace=primary_valuespace,
            col_info=col_info,
        )

    def null_placeholder_as_str(self, space="<valuespace>"):
        """
        Yields conventional NULL value placeholder
        expressed as a string
        depending on space's column (sql) type

        :type space: str or list of str
        :param space: space(s) to be placeheld.
        """
        space = self.validate_space(space)
        if isinstance(space, (list, tuple)):
            null_placeholders = []
            for space1 in space:
                coltype = self.get_column_type(space1)
                null_placeholders.append(null_placeholder_as_str(coltype))
            return null_placeholders
        else:
            coltype = self.get_column_type(space)
            return null_placeholder_as_str(coltype)

    def placehold(self, space="<valuespace>") -> Quble:
        """
        Replaces NULL values within the specified space(s) of the Quble
        with null placeholder convention depending on space's column (sql) type
        [See: :meth:`~qubles.core.quble.Quble.null_placeholder_as_str`]

        :type space: str or list of str
        :param space: space(s) to be placeheld.
        """
        spaces = self.validate_space(space, coerce_to_list=True, grace=False)
        null_placeholders = self.null_placeholder_as_str(
            space=spaces
        )  # <-- list w/len = len(spaces)
        placehold_expressions = {}
        for i, space1 in enumerate(spaces):
            placehold_expressions[space1] = (
                '(CASE WHEN "'
                + space1
                + '" IS NULL THEN '
                + null_placeholders[i]
                + ' ELSE "'
                + space1
                + '" END)'
            )

        placeheld_self = self.select(column_expressions=placehold_expressions)
        return placeheld_self

    def unplacehold(self, space="<valuespace>") -> Quble:
        """
        (Un)replaces null placeholder with NULLs in specified space(s) of Quble
        the expected null placeholder is derived from convention
        based on the space's column (sql) type
        [See: :meth:`~qubles.core.quble.Quble.null_placeholder_as_str`]

        :type space: str or list of str
        :param space: space(s) to be unplaceheld.
        """
        spaces = self.validate_space(space, coerce_to_list=True, grace=False)
        null_placeholders = self.null_placeholder_as_str(
            space=spaces
        )  # <-- list w/len = len(spaces)
        unplacehold_expressions = {}
        for i, space1 in enumerate(spaces):
            coltype = self.get_column_type(space1)
            unplacehold_expressions[space1] = (
                'CAST((CASE WHEN "'
                + space1
                + '" = '
                + null_placeholders[i]
                + ' THEN NULL ELSE "'
                + space1
                + '" END) AS '
                + coltype
                + ")"
            )

        unplaceheld_self = self.select(column_expressions=unplacehold_expressions)
        return unplaceheld_self

    @RootLib.lazy_kwargs()
    def unpivot(
        self,
        new_keyspace: str,
        valuespaces_to_unpivot="<valuespaces>",
        new_valuespace: str = DEFAULT_VALUESPACE,
        compress: bool = RootLib.lazy_eval("auto_compress"),
        treat_false_as_null: bool = False,
    ) -> Quble:
        """
        Unpivots the specified valuespace(s) and creates
        a new_keyspace & new_valuespace column
        The resultant Quble will be an
        (n+1)D (dimensional) UNIVARIATE Quble (single valuespace)

        where: n=# original keyspaces,
               m=# original valuespaces
           and p=# valuespaces_to_unpivot

        Not all valuespaces need to participate in the unpivot operation.
        [The non-participating valuespaces will be dropped from the result]

        The valuespaces_to_unpivot are replaced with a single new_valuespace

        The original keyspaces are augmented with the additional new_keypace

        The resultant keys within the new_keyspace column
        correpond to respective valuespaces from where each record was sourced

        IMPORTANT: ALL valuespaces_to_unpivot MUST HAVE CONSISTENT DATA TYPES

        NOTE: The column info of the resultant new_valuespace
              will be inherited from the first valuespace to be unpivoted

        compress: controls whether to remove records with null values within new_valuespace column
        new_keyspace_pole: controls whether to place new_keyspace first (True) or last (False)

        :param treat_false_as_null: For boolean valuespaces, controls how to
                                    treat/remove False values for compression
        :type treat_false_as_null: boolean

        Example:

        X ==> (2D Quble w/5 Valuespaces)
        <------ keyspaces ------><----------------- valuespaces ---------------------->
        +---------+-------------+---------+---------+-----------+----------+----------+
        | Tickers |    Dates    |  Sales  |   EPS   | Cash Flow |  Assets  |   Debt   |
        +=========+=============+=========+=========+===========+==========+==========+
        |   IBM   | 2017-12-31  |   6.27  |  15.56  |    8.26   |   9.56   |  18.25   |
        |   IBM   | 2018-12-31  |   9.43  |   NULL  |    6.18   |   3.81   |  12.16   |
        |   AAPL  | 2016-12-31  |  72.31  |  83.89  |   77.08   |  42.12   |  62.55   |
        |   AAPL  | 2017-12-31  |  68.75  |  88.18  |   82.24   |  96.80   |  92.22   |
        |   AAPL  | 2018-12-31  |  84.49  |  67.73  |    NULL   |  47.32   |  73.37   |
        |   GOOG  | 2017-12-31  | 126.48  | 146.19  |  128.83   | 156.77   | 207.42   |
        +---------+-------------+---------+---------+-----------+----------+----------+

        Y = X.unpivot(new_keyspace='Account', valuespaces_to_unpivot=['EPS','Cash Flow','Debt'], new_valuespace='Values')
        Y ==> (3D Quble w/1 Valuespace)

        <-------------- keyspaces ------------><- valuespaces ->
        +---------+-------------+-------------+----------------+
        | Tickers |    Dates    |   Account   |     Values     |
        +=========+=============+=============+================+
        |   IBM   | 2017-12-31  |     EPS     |      15.56     |
        |   IBM   | 2018-12-31  |     EPS     |       NULL     |
        |   AAPL  | 2016-12-31  |     EPS     |      83.89     |
        |   AAPL  | 2017-12-31  |     EPS     |      88.18     |
        |   AAPL  | 2018-12-31  |     EPS     |      67.73     |
        |   GOOG  | 2017-12-31  |     EPS     |     146.19     |
        |   IBM   | 2017-12-31  |  Cash Flow  |       8.26     |
        |   IBM   | 2018-12-31  |  Cash Flow  |       6.18     |
        |   AAPL  | 2016-12-31  |  Cash Flow  |      77.08     |
        |   AAPL  | 2017-12-31  |  Cash Flow  |      82.24     |
        |   AAPL  | 2018-12-31  |  Cash Flow  |       NULL     |
        |   GOOG  | 2017-12-31  |  Cash Flow  |     128.83     |
        |   IBM   | 2017-12-31  |     Debt    |      18.25     |
        |   IBM   | 2018-12-31  |     Debt    |      12.16     |
        |   AAPL  | 2016-12-31  |     Debt    |      62.55     |
        |   AAPL  | 2017-12-31  |     Debt    |      92.22     |
        |   AAPL  | 2018-12-31  |     Debt    |      73.37     |
        |   GOOG  | 2017-12-31  |     Debt    |     207.42     |
        +---------+-------------+-------------+----------------+

        """
        # Handle trivial/invalid cases
        # -----------------------------
        if self.is_undefined or self.ndim is None:
            return self.copy()

        if new_keyspace is None:
            raise Exception("Non-trivial new_keyspace arg required")

        # Validate valuespaces_to_unpivot
        valuespaces_to_unpivot = self.validate_valuespace(
            valuespace=valuespaces_to_unpivot, grace=False, coerce_to_list=True
        )
        if valuespaces_to_unpivot is None:
            return Quble()
        elif not isinstance(valuespaces_to_unpivot, (tuple, list)):
            raise Exception(
                "Internal inconsistency...valuespaces_to_unpivot is not a list/tuple"
            )
        elif len(valuespaces_to_unpivot) == 0:
            # Could consider return self.index() or return self.as_index()
            return Quble()

        if new_valuespace is None:
            raise Exception("Non-trivial new_valuespace arg required")
        elif new_valuespace == new_keyspace:
            raise Exception(
                "new_keyspace:{0} CANNOT MATCH new_valuespace:{1}".format(
                    new_keyspace, new_valuespace
                )
            )

        # Validate new_keyspaces
        old_keyspaces = self.keyspaces
        if old_keyspaces is None or not isinstance(old_keyspaces, (tuple, list)):
            raise Exception(
                "Internal inconsistency...keyspaces is None or not a list/tuple"
            )
        elif new_keyspace in old_keyspaces:
            raise Exception(
                "new_keyspace:{0} CANNOT EXIST IN keyspaces:{1}".format(
                    new_keyspace, new_valuespace
                )
            )

        # Build list of new_valuespaces
        new_valuespace_info = None
        vs_types = self.get_column_type(valuespaces_to_unpivot)
        if vs_types is None:
            pass
        elif not isinstance(vs_types, dict):
            # Here, vs_types should be a simple dictionary keyed on each valuespace
            raise Exception(
                f"In unpivot: dict expected for vs_types but type(vs_types):{type(vs_types)}"
            )
        elif len(vs_types) == 0:
            # No type info?
            pass
        else:
            if len(set(vs_types.values())) > 1:
                # More than one column type present
                # in type dictionary across valuespaces_to_unpivot
                raise Exception(
                    "All valuespaces to be unpivoted must be of compatible data types"
                )
            old_vs_ref = list(vs_types.keys())[0]
            if old_vs_ref not in self.spaces:
                # Sanity check...
                # otherwise some logic must have gone wrong here
                raise Exception(
                    f"old_vs_ref:{old_vs_ref} absent from self.spaces:{self.spaces}"
                )
            new_valuespace_info = self.get_space_info(
                info_type=CUSTOM_INFO_TYPES_FOR_VALUESPACES,
                space={old_vs_ref: new_valuespace},
                omit_unassigned=True,
            )

        # Generate the target table name
        table_name = generate_random_table_name()

        # NOTE: unpivot.j2 will extend query_base.j2 (does not need a multivariate wrapper)
        sql_template = JINJA_ENV.get_template("unpivot.j2")
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            tgt_table_name=table_name,
            new_keyspace=new_keyspace,
            keyspaces=old_keyspaces + [new_keyspace],
            valuespaces=[new_valuespace],
            valuespaces_to_unpivot=valuespaces_to_unpivot,
            # Try to avoid self.bool_valuespaces (when not applicable) for better performance?
            bool_valuespaces=(
                self.bool_valuespaces if (compress and treat_false_as_null) else []
            ),
            treat_false_as_null=treat_false_as_null,
            new_valuespace=new_valuespace,
            compress=compress,
        )

        execute(sql_command)

        col_info = self.get_space_info(
            info_type=CUSTOM_INFO_TYPES,
            space=old_keyspaces,
            omit_unassigned=True,
        )
        # COPY/ASSIGN new_valuespace_info FOR new_valuespace
        if new_valuespace_info is not None:
            update_column_info(col_info, new_valuespace_info)

        return Quble.from_table(
            table_name,
            col_info=col_info,
        )

    def replace_missings(
        self, new_value, space: str = "<valuespace>", compress=None
    ) -> Quble:
        """
        [See: :meth:`~qubles.core.quble.Quble.replace`]
        """
        return self.replace(
            old_value="<null>", new_value=new_value, space=space, compress=compress
        )

    def replace_with_null(
        self, old_value, space: str = "<valuespace>", compress=None
    ) -> Quble:
        """
        [See: :meth:`~qubles.core.quble.Quble.replace`]
        """
        return self.replace(
            old_value=old_value, new_value=None, space=space, compress=compress
        )

    def replace(
        self, old_value, new_value, space: str = "<valuespace>", compress=None
    ) -> Quble:
        """
        Replaces the specified old/source value (old_value)
        with the new/target value (new_value) for the specified Quble's space

        All original spaces will be retained.
        Only the specified single space will be modified.

        :type old_value: varies (depending on associated column type)
        :param old_value: list of values or value to be replaced (use: None, '<null>' or '<NULL>' to replace null records)

        :type new_value: varies (depending on associated column type)
        :param new_value: list of replacement values or replacement value (use: None, '<null>' or '<NULL>' to replace with null records)

        :type space: str or list of str
        :param space: space(s) to be placeheld.

        :param compress: compression controls
        :type compress: True or False or None or string
                [See: :meth:`~qubles.core.quble.Quble.compress`]
                ==> If string contains word 'any': Quble.compress(summarize='any',...)
                ==> If string contains word 'all': Quble.compress(summarize='all',...)
                ==> If string contains word 'drop': Quble.compress(drop=True,...)
        """
        # Handle trivial case
        # ---------------------
        if isinstance(space, list):
            # if spaces is a list, it should have same length as old_value and new_value list
            if not (
                isinstance(old_value, list)
                and isinstance(new_value, list)
                and len(old_value) == len(new_value)
                and len(old_value) == len(space)
            ):
                raise ValueError("In-correct values passed for a multivariate quble.")
            spaces = space
        else:
            # We still need to handle the case when space is passed as "<valuespaces>"
            spaces = self.validate_space(
                space, grace=False, solo_required=False, coerce_to_list=True
            )
            new_value = [new_value]
            old_value = [old_value]
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_empty:
            return self.copy()
        elif old_value == new_value:
            if not compress:
                return self.copy()
            elif isinstance(compress, str):
                return self.compress(summarize=compress)
            else:
                return self.compress(summarize="any")
        replacement_info = {}
        for index in range(0, len(spaces)):
            # Establish/validate space
            space = self.validate_space(spaces[index], grace=False, solo_required=True)

            # -------------------------------------------------------------------------------------
            # At this point: column_name, old_value, new_value are compatible lists (or tuples)
            # -------------------------------------------------------------------------------------
            # Now build replacement_info dictionary map: column_name1 -> (old_value1,new_value1)
            # -------------------------------------------------------------------------------------
            input_values = [old_value[index], new_value[index]]
            output_values = []
            is_string_variant = False

            # --------------------------------------
            # String (variant) (or binary) column
            # --------------------------------------
            if self.is_string(space=space, grace=True) or self.is_binary(
                space=space, grace=True
            ):
                is_string_variant = True
                for input_val1 in input_values:
                    # '<null>' input_val1

                    if input_val1 in (None, "<null>", "<NULL>"):
                        output_val1 = None
                    # string input_val1
                    elif isinstance(input_val1, str):
                        output_val1 = f"'{input_val1}'"
                    # datetime input_val1
                    elif isinstance(input_val1, (datetime, np.datetime64)):
                        output_val1 = f"'{str(input_val1)}'"
                    # other (bool/int/float/etc) input_val1
                    else:
                        output_val1 = f"'{str(input_val1)}'"

                    # Append output_val1 to output_values
                    output_values.append(output_val1)
            # -------------------------
            # Date/Timestamp column
            # ------------------------
            elif self.is_time_space(space=space, grace=True):
                for input_val1 in input_values:
                    # '<null>' input_val1
                    if input_val1 in (None, "<null>", "<NULL>"):
                        output_val1 = None
                    # string input_val1
                    # [Hopefully string provide can be
                    # interpretted by sql as a date/timestamp]
                    elif isinstance(input_val1, str):
                        output_val1 = f"'{input_val1}'"
                    # datetime input_val1
                    # [Hopefully Python's datetime->string conversion will yield a string
                    # that can be interpretted by sql as a date/timestamp]
                    elif isinstance(input_val1, (datetime, np.datetime64)):
                        output_val1 = f"'{str(input_val1)}'"
                    # other (bool/int/float/etc) input_val1
                    # [This case would likey not work]
                    else:
                        output_val1 = f"'{str(input_val1)}'"

                    # Append output_val1 to output_values
                    output_values.append(output_val1)
            # -------------------------
            # Date/Timestamp column
            # ------------------------
            elif self.is_time_space(space=space, grace=True):
                for input_val1 in input_values:
                    # '<null>' input_val1
                    if input_val1 in (None, "<null>", "<NULL>"):
                        output_val1 = None
                    # string input_val1
                    # [Hopefully string provide can be
                    # interpretted by sql as a date/timestamp]
                    elif isinstance(input_val1, str):
                        output_val1 = f"'{input_val1}'"
                    # datetime input_val1
                    # [Hopefully Python's datetime->string conversion will yield a string
                    # that can be interpretted by sql as a date/timestamp]
                    elif isinstance(input_val1, (datetime, np.datetime64)):
                        output_val1 = f"'{str(input_val1)}'"
                    # other (bool/int/float/etc) input_val1
                    # [This case would likey not work]
                    else:
                        output_val1 = f"'{str(input_val1)}'"

                    # Append output_val1 to output_values
                    output_values.append(output_val1)

            # -------------------------------------
            # Other columns (bool/int/float/etc)
            # -------------------------------------
            else:
                for input_val1 in input_values:
                    # '<null>' input_val1
                    if input_val1 in (None, "<null>", "<NULL>"):
                        output_val1 = None
                    # string input_val1
                    # [Hopefully string provided will be interpretted by sql accorindgly]
                    # [For example: input_val1='TRUE' -> output_val1='TRUE']
                    # [For example: input_val1='6' -> output_val1='6]
                    elif isinstance(input_val1, str):
                        output_val1 = input_val1
                    # datetime input_val1
                    # [This case would likey not work]
                    elif isinstance(input_val1, (datetime, np.datetime64)):
                        output_val1 = str(input_val1)
                    # other (bool/int/float/etc) input_val1
                    # [Hopefully string provided will be interpretted by sql accorindgly]
                    # [For example: input_val1=True -> output_val1='True']
                    # [For example: input_val1=6 -> output_val1='6]
                    else:
                        output_val1 = str(input_val1)

                    # Append output_val1 to output_values
                    output_values.append(output_val1)

            replacement_info[space] = (
                output_values[0],
                output_values[1],
                is_string_variant,
            )

        table_name = generate_random_table_name()

        sql_template = JINJA_ENV.get_template("replace.j2")

        sql_command = sql_template.render(
            all_column_names=self.column_names,
            replacement_info=replacement_info,
            src_table_name=self.table_name,
            tgt_table_name=table_name,
        )
        execute(sql_command)

        # Instantiate Quble from the new table
        result = Quble.from_table(
            table_name,
            col_info=self.get_space_info(
                info_type=CUSTOM_INFO_TYPES,
                space="<all>",
                omit_unassigned=True,
            ),
        )

        if compress:
            summarize = (
                "all"
                if isinstance(compress, str) and (compress.find("all") >= 0)
                else "any"
            )
            drop = (
                True
                if isinstance(compress, str) and (compress.find("drop") >= 0)
                else False
            )
            result.compress(summarize=summarize, drop=drop, inplace=True)

        return result

    def clear(self, deep_copy: bool = True) -> Quble:
        """Remove all records, but keep the definition (columns).

        :type deep_copy: bool
        :param deep_copy:
          When ``True``, creates a Quble in the image of self with no records.
          When ``False``, removes all records from self.

        """
        if self.is_empty:
            return self.copy(deep_copy=deep_copy)
        else:
            return self.select(data_exclusion="WITH NO DATA", deep_copy=deep_copy)

    # ================================== TIME-OPS: FILLING ===================================

    @RootLib.lazy_kwargs()
    def make_contiguous(
        self,
        keyspace="<time_keyspaces>",
        valuespace="<valuespaces>",
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        key_ordering="asc",
        deep_copy: bool = True,
    ) -> Quble:
        """
        Rekeys (reindexed) the datetime keys
        of the specified time_keyspace
        to be 'contiguous' (no gaps)
        (at the related freq)
        """
        # Create validated time_keyspaces list
        # ----------------------------------------
        time_keyspaces = self.validate_keyspace(
            keyspace, grace=False, coerce_to_list=True, time_space_required=True
        )

        # Perform fills for each time_space
        # using contiguous_flag=True & compress=None
        # -------------------------------------------------
        if len(time_keyspaces) > 0 and (valuespace is not None):
            # For performance, initialize result with a shallow copy
            result = self
            for ks in time_keyspaces:
                result = result.fill1d(
                    keyspace=keyspace,
                    valuespace=valuespace,
                    tfill_method=tfill_method,
                    tfill_max=tfill_max,
                    tfill_end_mode=tfill_end_mode,
                    tfill_honor_nulls=tfill_honor_nulls,
                    contiguous_flag=True,
                    key_ordering=key_ordering,
                    compress=None,
                    deep_copy=deep_copy,
                )
        else:
            result = self.copy() if deep_copy else self

        return result

    @RootLib.lazy_kwargs()
    def cross_fill1d(
        self,
        keyspace: str,
        crosser_keyspace: str,
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        remove_dupes: bool = False,
        deep_copy: bool = True,
    ) -> Quble:
        """
        'Crosses' a specified crossee time-keyspace (typically 'Vantage')
        with a crosser_keyspace (typically 'Fiscal') for ALL valuespaces of Quble

        ==> ALL valuespaces will be cross-filled AND retained

        This operation introduces additional keys from the keyspace
        Drawn from the dictinct keys across the non_crosser_keyspaces 'crossee' time keys

        remove_dupes: flag (True*/False) or str ('first','last') to invoke
                      the removal of any duplicate keys from the original Quble

                      False: Do not remove duplicate keys
                              (operate on original Quble regardless of possible duplicate keys)
                      True or 'last': retain only the last duplicate key record in the Quble's table
                      'first': retain only the first duplicate key record in the Quble's table
                      [See: :meth:`~qubles.core.quble.Quble.remove_duplicate_keys`]

        **Procedure:**
        Create a temporary 'crossing_table' of distinct records
        drawn for non-keyspace_crosser columns of the orginal table
        (i.e., distinct records across columns excluding crosser_keyspace column).

        NOTE: Within this 'crossing_table', the key combinations across dually orthogonal columns
        (i.e., exluding BOTH keyspace & crosser_keyspace columns)
        will appear in multiple records that collectively represent
        the 'localized union' of the distinct keys (from keyspace column)
        that appear in the original table for each dually orthogonal key combination

        Also, create a temporary 'min_keys_table' which provides the minimum keyspace key
        grouped by (across the) orthogonal (non-keyspace) columns of the original table

        Now create an 'crossed_table' by JOINING this 'crossing_table'
        with the original table across the non_crosser columns/keyspaces
        [thereby forcing the localized union of the distinct keys]

        Then create an 'unfilled_table' by JOINING the 'min_keys_table' with the 'crossed_table'
        across the orthogonal (non-keyspace) columns/keyspaces
        ALSO IMPOSE THE CONDITION: keyspace keys >= "min_key" column from the 'min_keys_table'

        Create the final table/Quble by applying a time-filling operation
        to the keyspace column of the 'unfilled_table'

        Example: Quble X:

        Ticker     Fiscal        Vantage    Sales
        ------     ------        -------    -----
        A      2016-12-31    2017-02-08   110.5 # <-- Original of FY2016 @ Vantage:2017-02-08
        A      2017-12-31    2018-02-11   136.2 # <-- Original of FY2017 @ Vantage:2018-02-11
        A      2017-12-31    2019-02-09   139.4 # <-- First Restatement of FY2017 @ Vantage:2019-02-09
        A      2018-12-31    2019-02-09   141.2 # <-- Original of FY2018 @ Vantage:2019-02-09
        A      2016-12-31    2019-04-14   111.2 # <-- First Restatement of FY2016 @ Vantage:2019-04-14

        Quble Y = X.cross_fill1d(keyspace='Vantage', crosser_keyspace='Fiscal', tfill_max=-1)

        Quble Y ordered by 'Vantage', 'Fiscal'...

        Ticker     Fiscal        Vantage    Sales
        ------     ------        -------    -----
        A      2016-12-31    2017-02-08   110.5 # <-- Original of FY2016 @ Vantage:2017-02-08

        A      2016-12-31    2018-02-11   110.5 # <-- Newly crossed record for FY2016 @ Vantage:2018-02-11 (Filled from Original Vantage:2017-02-08)
        A      2017-12-31    2018-02-11   136.2 # <-- Original of FY2017 @ Vantage:2018-02-11

        A      2016-12-31    2019-02-09   110.5 # <-- Newly crossed record for FY2016 @ Vantage:2019-02-09 (Filled from Original Vantage:2017-02-08)
        A      2017-12-31    2019-02-09   139.4 # <-- First Restatement of FY2017 @ Vantage:2019-02-09
        A      2018-12-31    2019-02-09   141.2 # <-- Original of FY2018 @ Vantage:2019-02-09

        A      2016-12-31    2019-04-14   111.2 # <-- First Restatement of FY2016 @ Vantage:2019-04-14
        A      2017-12-31    2019-04-14   139.4 # <-- Newly crossed record for FY2017 @ Vantage:2019-04-14 (Filled from Restated Vantage:2019-02-09)
        A      2018-12-31    2019-04-14   141.2 # <-- Newly crossed record for FY2018 @ Vantage:2019-04-14 (Filled from Original Vantage:2019-02-09)

          In this example, the 'cross-filled' result (Quble Y)
          provides a prevailing filled time-history
          across 'Fiscal' keys at each ortho key-pair ('Vantage' & 'Ticker')
          so that subsequent time-operation across the 'Fiscal' keyspace
          for each ortho-key pair ('Ticker' & 'Vantage')
          will reflect the proper/filled 'Fiscal' history
        """
        if self.is_undefined or self.is_empty:
            return self.copy(deep_copy=deep_copy)

        # Handle non-variate Quble
        # [NOTE: Can simply return a copy or alternatively throw an Exception]
        if self.is_nonvariate:
            return self.copy(deep_copy=deep_copy)

        # Remove dupes and assign modified self to subject
        # Only refer to subject subsequently
        if not remove_dupes:
            # Make shallow copy
            subject = self
        elif isinstance(remove_dupes, str) and remove_dupes.lower() == "first":
            # Keep first duplicate record
            subject = self.check_remove_duplicate_keys(
                rankspace=None, inplace=False, rank_direction="asc"
            )
        else:
            # Keep last duplicate record
            subject = self.check_remove_duplicate_keys(
                rankspace=None, inplace=False, rank_direction="desc"
            )

        crosser_keyspace = subject.validate_space(
            space=crosser_keyspace,
            grace=False,
            solo_required=True,
            time_space_required=True,
        )

        # Make sure cross_keyspace is distinct from keyspace
        if crosser_keyspace == keyspace:
            raise ValueError(
                "crosser_keyspace: {} MUST NOT MATCH keyspace:{1}".format(
                    crosser_keyspace, keyspace
                )
            )

        # Handle non-fill case...
        if keyspace == "Vantage":
            tfill_max = -1
            tfill_method = "pad"
        else:
            # NOTE: Procure valuespace's filling info: tfill_max, tfill_method, tfill_honor_nulls & tfill_end_mode
            # NOTE: For logical reasons, filling info IS NOT associated with the time-keyspace, rather the valuespace!!
            tfill_max = subject._space_info_indirection(
                info_type="tfill_max",
                space=subject.valuespace,
                info_assignment=tfill_max,
                grace=True,
            )
            tfill_method = subject._space_info_indirection(
                info_type="tfill_method",
                space=subject.valuespace,
                info_assignment=tfill_method,
                grace=True,
            )

        # Handle non-fill case based on tfill_max
        if tfill_max is None or (tfill_max == 0):  # or not tfill_method or
            return subject.copy(deep_copy=deep_copy)

        tfill_honor_nulls = subject._space_info_indirection(
            info_type="tfill_honor_nulls",
            space=subject.valuespace,
            info_assignment=tfill_honor_nulls,
            grace=True,
        )
        tfill_end_mode = subject._space_info_indirection(
            info_type="tfill_end_mode",
            space=subject.valuespace,
            info_assignment=tfill_end_mode,
            grace=True,
        )

        if tfill_end_mode not in (
            "no_future",
            "in_progress",
            "no_extension",
            "full_extension",
            "unconstrained",
        ):
            raise ValueError(f"Invalid tfill_end_mode: {tfill_end_mode}")

        freq = subject.get_freq(keyspace, allow_infer=True, assign_inferred=True)

        if freq is None:
            raise ValueError("Unable to establish existing frequency")

        if freq not in PPY:
            raise ValueError(f"Invalid frequency: {freq}")

        table_name = generate_random_table_name()
        sql_template = JINJA_ENV.get_template("cross_fill.j2")

        # Build key_ordering dictionary when applicable
        if key_ordering is not None and not isinstance(key_ordering, str):
            key_ordering = build_key_ordering_dict(
                key_ordering, keyspaces=subject.keyspaces
            )

        sql_command = sql_template.render(
            keyspaces=subject.keyspaces,
            keyspace=keyspace,
            crosser_keyspace=crosser_keyspace,
            freq=freq,
            fill_end_mode=tfill_end_mode,
            fill_max=tfill_max if tfill_max is not None else -1,
            fill_method=tfill_method,
            key_ordering=key_ordering,
            # NOTE: We intentionally designed fill.j2 & fill_body.j2 templates
            #       to use ks_list, table_to_be_filled & null_placeholder_for_fill args
            #       (NOT keyspaces, src_table_name & null_placeholder args as in other templates)
            #       because the fill.j2 & fill_body.j2 templates may be called
            #       from other (wrapper) templates that may already be using the
            #       keyspaces, src_table_name arg & null_placeholder
            #       variable names in an inconsistent manner
            src_table_name=subject.table_name,
            tgt_table_name=table_name,
            calendar_table_name=RootLib().get_control("calendar_table_name"),
            valuespaces=subject.valuespaces,
            fill_honor_nulls=tfill_honor_nulls,
        )
        execute(sql_command, format_flag=False)

        # Establish col_info for copy
        if table_name == subject.table_name:
            col_info = None
        else:
            col_info = subject.get_space_info(
                info_type=CUSTOM_INFO_TYPES,
                space="<all>",
                omit_unassigned=True,
            )
            if subject.valuespace is not None:
                orig_tfill_max = subject.get_space_info(
                    info_type="tfill_max", space=subject.valuespace, grace=True
                )
                if orig_tfill_max is not None and orig_tfill_max != 0:
                    # Here, we set 'tfill_max'=0 for (time) keyspace in (target) table to prevent additional filling later
                    add_col_info = {"tfill_max": {subject.valuespace: 0}}
                    update_column_info(col_info, add_col_info)

        # Instantiate Quble from the new table
        result = Quble.from_table(
            table_name,
            col_info=col_info,
        )

        if compress:
            summarize = (
                "all"
                if isinstance(compress, str) and (compress.find("all") >= 0)
                else "any"
            )
            drop = (
                True
                if isinstance(compress, str) and (compress.find("drop") >= 0)
                else False
            )
            result.compress(summarize=summarize, drop=drop, inplace=True)

        return result

    @RootLib.lazy_kwargs()
    def fill1d(
        self,
        keyspace: str = "<first_time_keyspace>",
        valuespace="<valuespaces>",
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        original_dates_only: bool = False,
        contiguous_flag: bool = False,
        key_ordering="asc",
        compress: bool = RootLib.lazy_eval("auto_compress"),
        pre_cross_fill: bool = True,
        deep_copy: bool = True,
    ) -> Quble:
        """
        Fill missing values within specified valuespace(s)
        Retains all original valuespaces, but only fills specified valuespace(s)

        ==> Any 'orthogonal' (extra) valuespaces will be retained but not filled
        ==> For multiple filling valuespaces cases,the ordering of the resultant valuespaces may change such that the valuespace to be filled may be placed as the first valuespace
        Use this method to fill missing data forward in time. For example, if there
        exists a non-missing data point on 2018-01-31 and a missing data point on
        2018-02-28, the value for February will be filled in based on January's value.
        This method requires the Quble to have a time-based keyspace, otherwise an exception will be raised.

        :type keyspace: str
        :param keyspace:
           Fill data along this keyspace. Must be time-based.
        :type valuespace: str or list/tuple of strings
        :param valuespace:
            The valuespace(s) to be filled
            [Any 'orthogonal' (extra) valuespaces will be kept but not filled]
            Following templated arg values supported via Quble.validate_valuespace() method...
            ``<valuespace>``:fill only the primary valuespace
            ``<valuespaces>`` or ``<all>``:fill all valuespaces
            ``<first_valuespace>`` or ``<first>``:fill only the first valuespace
            ``<last_valuespace>`` or ``<last>``:fill only the last valuespace
            ``<auxvalspaces>``:fill only the auxillary valuespaces
            ``<numeric_valuespaces>``:fill only the numeric valuespaces
            ``<float_valuespaces>``:fill only the float valuespaces
            ``<time_valuespaces>``:fill only the time valuespaces
            [see method validate_valuespace for all supported options]
        :type tfill_method: str
        :param tfill_method:
            The method to be used when filling data against the new keyspace index.
            Can be None, 'pad' or 'backfill'.
        :type tfill_max: int
        :param tfill_max:
            Maximum number of consecutive value fill-ins (using supplied
            fill_method) along a single slice/section of resulting valuespace.
            Treat tfill_max > 0: finite filling
            Treat tfill_max < 0: Infinite tfill_max
            Treat tfill_max = None: NO filling
            Treat tfill_max = 0: NO filling
        :param key_ordering: controls row ordering by key
        :type key_ordering: None, str or dictionary
           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace
           dictionary: dict keys (str): keyspaces, dict values (str): 'asc' or 'desc'
           ==> allows for assigning key ordering (ascending/descending)
           ==> (and relative priority) for each keyspace individually
        :type tfill_end_mode: str
        :param tfill_end_mode:
            Controls extension/limits beyond original dates.
            Can be 'unconstrained' or 'no_future' or 'in_progress' or 'no_extension' or 'full_extension'
            'unconstrained': Fill (for each orthogonal key) until fill_max is reached
            'no_future': Fill (for each orthogonal key) until fill_max or current date is reached
            'in_progress': Fill (for each orthogonal key) until fill_max or 'in-progress' period is reached [Here, 'in-progress' period means period/interval containing current date]
            'no_extension': Fill (for each orthogonal key) minimum of (fill_max or last original, orthogonal date) is reached
            'full_extension': Fill (for each orthogonal key) until minimum of (fill_max or maximum original date ACROSS ALL ORTHO KEYSPACES) is reached
        :type tfill_honor_nulls: bool
        :param tfill_honor_nulls:
            Flag to honor any existing null values
        :type original_dates_only: bool
        :param original_dates_only:
            Controls whether restrict the result
            to only those dates originally present
        :type contiguous_flag: bool
        :param contiguous_flag: controls whether contiguous dates (at prevailing freq) are required
        :type compress: bool
        :param compress:
            Flag to compress the result.
        :param pre_cross_fill: flag to control whether to cross-fill
                           when the keyspace to be filled is a time keyspace
                           AND ortho_resampling_keyspaces also exist
        :type pre_cross_fill: boolean (True*/False)
        :type deep_copy: bool
        :param deep_copy:
            Flag to indicate whether the existing Quble should be copied
            (and thus left unchanged) or changed in-place.
        :rtype: qubles.core.quble.Quble
        :returns:
            The current Quble (or a copy of it) with the fill operation completed.
        """
        if self.is_undefined or self.is_empty:
            return self.copy(deep_copy=deep_copy)

        # Make a shallow copy of self as subject Only refer to subject (not self) afterwards
        subject = self

        # Validate valuespace
        index_was_provided = False
        if not subject.is_index:
            valuespaces_to_fill = subject.validate_valuespace(
                valuespace=valuespace, grace=False, coerce_to_list=True
            )
        elif valuespace not in ("<valuespace>", "<valuespaces>"):
            raise Exception(
                "Absent non-trivial valuespace:{0}...subject is an index-only (valueless) Quble".format(
                    valuespace
                )
            )
        else:
            # Proceed to convert to bool
            index_was_provided = True
            subject = subject.index_to_bool()
            valuespaces_to_fill = [subject.valuespace]

        # Remove any null valuespaces
        if valuespaces_to_fill is not None:
            for i in range(len(valuespaces_to_fill)):
                if valuespaces_to_fill[i] is None:
                    valuespaces_to_fill.pop(i)

        # Handle case where no valuespaces_to_fill [NOTE: Can simply return a copy or alternatively throw an Exception]
        if valuespaces_to_fill is None or len(valuespaces_to_fill) == 0:
            return subject.copy(deep_copy=deep_copy)

        # Validate keyspace
        keyspace = subject.validate_keyspace(
            keyspace, grace=False, solo_required=True, time_space_required=True
        )

        if pre_cross_fill:
            subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)

        # NOTE: filling info (e.g., tfill_method, etc.) is sourced / associated with each valuespace (NOT the space/keyspace being filled)
        valuespace_type = {}
        tfill_method_dict = {}
        tfill_max_dict = {}
        tfill_honor_nulls_dict = {}
        null_placeholder_dict = {}
        # tfill_end_mode_scalar below not implemented as valuespace-specific (for practical reasons)
        tfill_end_mode_scalar = None
        for vs in valuespaces_to_fill:
            if vs is None:
                continue
            valuespace_type[vs] = subject.get_space_info(info_type="type", space=vs)
            if not isinstance(tfill_method, dict):
                tfill_method_dict[vs] = subject._space_info_indirection(
                    info_type="tfill_method",
                    space=vs,
                    info_assignment=tfill_method,
                    grace=True,
                )
            elif vs in tfill_method:
                tfill_method_dict[vs] = tfill_method[vs]
            else:
                tfill_method_dict[vs] = subject._space_info_indirection(
                    info_type="tfill_method",
                    space=vs,
                    info_assignment="<space_root>",
                    grace=True,
                )
            if not isinstance(tfill_max, dict):
                tfill_max_dict[vs] = subject._space_info_indirection(
                    info_type="tfill_max",
                    space=vs,
                    info_assignment=tfill_max,
                    grace=True,
                )
            elif vs in tfill_max:
                tfill_max_dict[vs] = tfill_max[vs]
            else:
                tfill_max_dict[vs] = subject._space_info_indirection(
                    info_type="tfill_max",
                    space=vs,
                    info_assignment="<space_root>",
                    grace=True,
                )
            if not isinstance(tfill_honor_nulls, dict):
                tfill_honor_nulls_dict[vs] = subject._space_info_indirection(
                    info_type="tfill_honor_nulls",
                    space=vs,
                    info_assignment=tfill_honor_nulls,
                    grace=True,
                )
            elif vs in tfill_honor_nulls:
                tfill_honor_nulls_dict[vs] = tfill_honor_nulls[vs]
            else:
                tfill_honor_nulls_dict[vs] = subject._space_info_indirection(
                    info_type="tfill_honor_nulls",
                    space=vs,
                    info_assignment="<space_root>",
                    grace=True,
                )
            if tfill_honor_nulls_dict[vs]:
                null_placeholder_dict[vs] = null_placeholder_as_str(valuespace_type[vs])
                # Evaluate tfill_end_mode_scalar until it is assigned a non-trivial value
                tfill_end_mode_scalar = subject._space_info_indirection(
                    info_type="tfill_end_mode",
                    space=vs,
                    info_assignment=tfill_end_mode,
                    grace=True,
                )
        # Is any filling required?
        filling_required = False  # <-- Initialization
        for vs1, tfill_max1 in tfill_max_dict.items():
            if tfill_max1 is not None and tfill_max1 != 0:
                # Filling is required when atleast one valuespace's tfill_max1 is not trivial (0 or None)
                filling_required = True
        # Exist now if not filling_required
        if filling_required:
            pass
        elif index_was_provided:
            return subject.bool_to_index()
        else:
            return subject.copy(deep_copy=deep_copy)
        # Validate tfill_end_mode_scalar
        if tfill_end_mode_scalar is None:
            tfill_end_mode_scalar = "no_future"
        elif tfill_end_mode_scalar not in (
            "no_future",
            "in_progress",
            "no_extension",
            "full_extension",
            "unconstrained",
        ):
            raise ValueError(f"Invalid tfill_end_mode: {tfill_end_mode_scalar}")
        # Access & validate freq
        freq = subject.get_freq(keyspace, allow_infer=True, assign_inferred=True)
        if freq is None:
            raise ValueError("Unable to establish existing frequency")
        elif freq not in PPY:
            raise ValueError(f"Invalid frequency: {freq}")

        table_name = generate_random_table_name()
        sql_template = JINJA_ENV.get_template("fill.j2")
        # Build key_ordering dictionary when applicable
        if key_ordering is not None and not isinstance(key_ordering, str):
            key_ordering = build_key_ordering_dict(
                key_ordering, keyspaces=subject.keyspaces
            )
        sql_command = sql_template.render(
            calendar_table_name=RootLib().get_control("calendar_table_name"),
            fill_end_mode=tfill_end_mode_scalar,
            fill_max=tfill_max_dict,
            fill_method=tfill_method_dict,
            freq=freq,
            key_ordering=key_ordering,
            keyspace=keyspace,
            # NOTE: We intentionally designed fill.j2 & fill_body.j2 templates to use ks_list, table_to_be_filled & null_placeholder_for_fill args
            # (NOT keyspaces, src_table_name & null_placeholder args as in other templates) because the fill.j2 & fill_body.j2 templates may be called
            # from other (wrapper) templates that may already be using the keyspaces, src_table_name arg & null_placeholder variable names in an inconsistent manner
            ks_list=subject.keyspaces,
            table_to_be_filled=subject.table_name,
            tgt_table_name=table_name,
            valuespaces=subject.valuespaces,  # All valuespaces (not just those being filled)
            null_placeholder_for_fill=null_placeholder_dict,
            original_dates_only=original_dates_only,
            contiguous_flag=contiguous_flag,
        )
        execute(sql_command, format_flag=False)

        col_info = self.get_space_info(
            info_type=CUSTOM_INFO_TYPES,
            space="<all>",
            omit_unassigned=True,
        )
        # Assign col_info['tfill_max'][vs]=0 for this vs in valuespaces_to_fill
        if (
            col_info is not None
            and "tfill_max" in col_info
            and col_info["tfill_max"] is not None
        ):
            for vs in valuespaces_to_fill:
                # Is this a non-rolled, but (finitely) filled valuespace?
                if (
                    vs in col_info["tfill_max"]
                    and col_info["tfill_max"][vs] is not None
                    and col_info["tfill_max"][vs] > 0
                ):
                    # Here, we set 'tfill_max'=0 for finite filling vs in (target) table to prevent additional filling later
                    col_info["tfill_max"][vs] = 0

        # Assign new primary valuespace
        if subject.valuespace in valuespaces_to_fill:
            # If the original primary valuespace is valuespaces_to_fill, keep subject's same designated primary valuespace
            new_primary_valuespace = subject.valuespace
        elif len(valuespaces_to_fill) > 0:
            new_primary_valuespace = valuespaces_to_fill[0]
        else:
            new_primary_valuespace = None

        result = Quble.from_table(
            table_name,
            valuespace=new_primary_valuespace,
            col_info=col_info,
        )

        if index_was_provided:
            result = result.bool_to_index()
        elif compress:
            summarize = (
                "all"
                if isinstance(compress, str) and (compress.find("all") >= 0)
                else "any"
            )
            drop = (
                True
                if isinstance(compress, str) and (compress.find("drop") >= 0)
                else False
            )
            result.compress(summarize=summarize, drop=drop, inplace=True)

        return result

    @RootLib.lazy_kwargs()
    def aggr_fill1d(
        self,
        keyspace: str = "<first_keyspace>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        pct_required: float = None,
        num_required: int = 0,
        fill_max: int = None,
        pct_required_glb: float = None,
        num_required_glb: int = 0,
        fill_max_glb: int = None,
        key_ordering="asc",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        deep_copy: bool = True,
        clob_export_mode: str = RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode: str = RootLib.lazy_eval("blob_export_mode"),
        keymap_lib="SECINFO",
    ) -> Quble:
        """
        Fills the null values with the aggregate value
        as computed across the specified keyspace
        for each set of 'orthonal' keys
        See: :meth:`~qubles.core.quble.Quble.aggr_fill`
        """
        return self.aggr_fill(
            aggr_keyspaces=keyspace,
            aggr_method=aggr_method,
            valuespace=valuespace,
            view=view,
            pct_required=pct_required,
            num_required=num_required,
            fill_max=fill_max,
            pct_required_glb=pct_required_glb,
            num_required_glb=num_required_glb,
            fill_max_glb=fill_max_glb,
            key_ordering=key_ordering,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            deep_copy=deep_copy,
            clob_export_mode=clob_export_mode,
            blob_export_mode=blob_export_mode,
            keymap_lib=keymap_lib,
        )

    @RootLib.lazy_kwargs()
    def aggr_fill(
        self,
        aggr_keyspaces: str = "<keyspaces>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        pct_required: float = 0.0,
        num_required: int = 0,
        fill_max: int = None,
        pct_required_glb: float = 0.0,
        num_required_glb: int = 0,
        fill_max_glb: int = None,
        key_ordering="asc",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        deep_copy: bool = True,
        clob_export_mode: str = RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode: str = RootLib.lazy_eval("blob_export_mode"),
        keymap_lib="SECINFO",
    ) -> Quble:
        """
        Fills the null values with the aggregate value
        as computed across the aggr_keyspaces
        for each set of 'orthonal' keys

        :param aggr_keyspaces: keyspaces for the aggregation computation
        :type aggr_keyspaces: str or list of strings

        :param aggr_method: The method that will be used for aggregation.
        :type aggr_method: {q_aggr_method}

        :param valuespace: valuespace(s) to be filled
            ==> Other valuespaces will be retained but not filled
        :type valuespace: str or list of strings
                      (keywords may be used such as '<valuespaces>', '<valuespace>', etc.
                      [See: :meth:`~qubles.core.quble.Quble.validate_valuespace`]

        :param view: Quble indicating conditional elements
                     for which aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :param pre_cross_fill: flag to control whether to cross-fill
                           when the keyspace to be filled is a time keyspace
                           AND ortho_resampling_keyspaces also exist
        :type pre_cross_fill: boolean (True*/False)

        :param pre_fill: flag to control whether to pre-fill
                         when some being aggregated are resampling keyspaces
        :type pre_fill: boolean (True/False*)

        :type deep_copy: bool
        :param deep_copy:
            Flag to indicate whether the existing Quble should be copied
            (and thus left unchanged) or changed in-place.

        :type pct_required: None or float
        :param pct_required:
            Percentage of non-null values required to
            authorize filling across specified filling/aggregation keyspace(s)
            for each set of orthogonal keysets
            Value must be: 0.0 <= pct_required <= 1.0

        :type num_required: None or int
        :param num_required:
            Control for necessary to authorize filling
            across the specified filling/aggregation keyspace(s)
            for each set of orthogonal keysets
            Value must be either None or an int >= 0

        :type fill_max: None or int
        :param fill_max:
            Control for maximum allowable number of data points to fill
            across the specified filling/aggregation keyspace(s)
            for each set of orthogonal keysets
            Value must be either None or an int > 0
            IMPORTANT: fill_max == 0 yields NO UNFILLING (simply return a copy)
            IMPORTANT: fill_max == None represents unconstrained condition
            IMPORTANT: fill_max < 0 represents unconstrained condition

        :type pct_required_glb: None or float
        :param pct_required_glb:
            Percentage of non-null values required to
            authorize filling across ALL keyspaces
            Value must be: 0.0 <= pct_required <= 1.0

        :type num_required_glb: None or int
        :param num_required_glb:
            Control for necessary to authorize filling across ALL keyspaces
            Value must be either None or an int >= 0

        :type fill_max_glb: None or int
        :param fill_max_glb:
            Control for maximum allowable number of data points to fill
            across ALL keyspaces
            IMPORTANT: fill_max_glb == 0 yields NO UNFILLING (simply return a copy)
            IMPORTANT: fill_max_glb == None represents unconstrained condition
            IMPORTANT: fill_max_glb < 0 represents unconstrained condition

        :param key_ordering: controls row ordering by key
        :type key_ordering: None, str or dictionary
           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace
           dictionary: dict keys (str): keyspaces, dict values (str): 'asc' or 'desc'
           ==> allows for assigning key ordering (ascending/descending)
           ==> (and relative priority) for each keyspace individually

        :param clob_export_mode: treament for column type: 'clob'/'CLOB'
                                 in Python-based aggregation functions
        :type clob_export_mode: 'unicode','object','string','str',None

        :param blob_export_mode: treament for column type: 'blob'/'BLOB'
                                 in Python-based aggregation functions
        :type blob_export_mode: 'object','string','str','unicode',None

        :param keymap_lib: Lib for locating keymap (when applicable)
        :type keymap_lib: str (LibAddress) or DataLib or None

        :rtype: Quble
        :returns: filled Quble

        :returns: Modified Quble with null values replaced with aggregate values
        :rtype: qubles.core.quble.Quble

        """
        return self.sub_aggr_fill(
            keymap=None,  # <-- Will perform non-grouped aggregation
            aggr_keyspaces=aggr_keyspaces,
            aggr_method=aggr_method,
            valuespace=valuespace,
            view=view,
            pct_required=pct_required,
            num_required=num_required,
            fill_max=fill_max,
            pct_required_glb=pct_required_glb,
            num_required_glb=num_required_glb,
            fill_max_glb=fill_max_glb,
            key_ordering=key_ordering,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            deep_copy=deep_copy,
            clob_export_mode=clob_export_mode,
            blob_export_mode=blob_export_mode,
        )

    @RootLib.lazy_kwargs()
    def sub_aggr_fill1d(
        self,
        keymap: Quble,
        keyspace: str = "<first_keyspace>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        pct_required: float = None,
        num_required: int = 0,
        fill_max: int = None,
        pct_required_glb: float = 0.0,
        num_required_glb: int = 0,
        fill_max_glb: int = 0,
        key_ordering="asc",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        deep_copy: bool = True,
        clob_export_mode: str = RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode: str = RootLib.lazy_eval("blob_export_mode"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        tdistribute_mode="<space_root>",
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        prevent_null_keys: bool = False,
        link_dupe_grace: bool = True,
    ) -> Quble:
        """
        Fills the null values with the sub-aggregate value
        as computed across the specified keyspace
        for each set of 'orthonal' keys
        See: :meth:`~qubles.core.quble.Quble.sub_aggr_fill`
        """
        return self.sub_aggr_fill(
            keymap=keymap,
            aggr_keyspaces=keyspace,
            aggr_method=aggr_method,
            valuespace=valuespace,
            view=view,
            pct_required=pct_required,
            num_required=num_required,
            fill_max=fill_max,
            pct_required_glb=pct_required_glb,
            num_required_glb=num_required_glb,
            fill_max_glb=fill_max_glb,
            key_ordering=key_ordering,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            deep_copy=deep_copy,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            tdistribute_mode=tdistribute_mode,
            auto_fill=auto_fill,
            auto_link=auto_link,
            link_check=link_check,
            prevent_null_keys=prevent_null_keys,
            link_dupe_grace=link_dupe_grace,
            clob_export_mode=clob_export_mode,
            blob_export_mode=blob_export_mode,
        )

    @RootLib.lazy_kwargs()
    def sub_aggr_fill(
        self,
        keymap: Quble,
        aggr_keyspaces: str = "<keyspaces>",
        aggr_method: str = RootLib.lazy_eval("aggr_method"),
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
        pct_required: float = 0.0,
        num_required: int = 0,
        fill_max: int = 0,
        pct_required_glb: float = 0.0,
        num_required_glb: int = 0,
        fill_max_glb: int = 0,
        key_ordering="asc",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        deep_copy: bool = True,
        clob_export_mode: str = RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode: str = RootLib.lazy_eval("blob_export_mode"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        tdistribute_mode="<space_root>",
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        prevent_null_keys: bool = False,
        link_dupe_grace: bool = True,
        keymap_lib="SECINFO",
    ) -> Quble:
        """
        Fills the null values with the sub-aggregate value
        as computed across the aggr_keyspaces
        for each set of 'orthonal' keys.

        :param keymap: mapping where values provide target keys for the specified keyspace
                        The primary valuespace of the keymap will be applied
        :type keymap: Quble or str or None
        ==> Set keymap=None for no sub-grouping
        ==> Set keymap=str to group using an existing valuespace
        ==> Set keymap=Quble to group using an external Quble

        :param aggr_keyspaces: keyspaces for the aggregation computation
        :type aggr_keyspaces: str or list of strings

        :param aggr_method: The method that will be used for aggregation.
        :type aggr_method: {q_aggr_method}

        :param valuespace: valuespace(s) to be filled
            ==> Other valuespaces will be retained but not filled
        :type valuespace: str or list of strings
                      (keywords may be used such as '<valuespaces>', '<valuespace>', etc.
                      [See: :meth:`~qubles.core.quble.Quble.validate_valuespace`]

        :param view: Quble indicating conditional elements
                     for which aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :param pre_cross_fill: flag to control whether to cross-fill
                           when the keyspace to be filled is a time keyspace
                           AND ortho_resampling_keyspaces also exist
        :type pre_cross_fill: boolean (True*/False)

        :param pre_fill: flag to control whether to pre-fill
                         when some being aggregated are resampling keyspaces
        :type pre_fill: boolean (True/False*)

        :type deep_copy: bool
        :param deep_copy:
            Flag to indicate whether the existing Quble should be copied
            (and thus left unchanged) or changed in-place.

        :type pct_required: None or float
        :param pct_required:
            Percentage of non-null values required to
            authorize filling across specified filling/aggregation keyspace(s)
            for each set of orthogonal keysets AND groups (if present)
            Value must be: 0.0 <= pct_required <= 1.0

        :type num_required: None or int
        :param num_required:
            Control for necessary to authorize filling
            across the specified filling/aggregation keyspace(s)
            for each set of orthogonal keysets AND groups (if present)
            Value must be either None or an int >= 0

        :type fill_max: None or int
        :param fill_max:
            Control for maximum allowable number of data points to fill
            across the specified filling/aggregation keyspace(s)
            for each set of orthogonal keysets AND groups (if present)
            Value must be either None or an int > 0
            IMPORTANT: fill_max == 0 yields NO UNFILLING (simply return a copy)
            IMPORTANT: fill_max == None represents unconstrained condition
            IMPORTANT: fill_max < 0 represents unconstrained condition

        :type pct_required_glb: None or float
        :param pct_required_glb:
            Percentage of non-null values required to
            authorize filling across ALL keyspaces
            Value must be: 0.0 <= pct_required <= 1.0

        :type num_required_glb: None or int
        :param num_required_glb:
            Control for necessary to authorize filling across ALL keyspaces
            Value must be either None or an int >= 0

        :type fill_max_glb: None or int
        :param fill_max_glb:
            Control for maximum allowable number of data points to fill
            across ALL keyspaces
            IMPORTANT: fill_max_glb == 0 yields NO UNFILLING (simply return a copy)
            IMPORTANT: fill_max_glb == None represents unconstrained condition
            IMPORTANT: fill_max_glb < 0 represents unconstrained condition

        :param key_ordering: controls row ordering by key
        :type key_ordering: None, str or dictionary
           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace
           dictionary: dict keys (str): keyspaces, dict values (str): 'asc' or 'desc'
           ==> allows for assigning key ordering (ascending/descending)
           ==> (and relative priority) for each keyspace individually

        :param clob_export_mode: treament for column type: 'clob'/'CLOB'
                                 in Python-based aggregation functions
        :type clob_export_mode: 'unicode','object','string','str',None

        :param blob_export_mode: treament for column type: 'blob'/'BLOB'
                                 in Python-based aggregation functions
        :type blob_export_mode: 'object','string','str','unicode',None

        :type auto_link: bool
        :param auto_link: Control for auto-linking (keyspace affiliation)
            ==> Relates to keymap application only

        :param link_check: flag to check the linking keymap
        :type link_check: bool (False*/True)
            ==> Relates to keymap application only

        :param link_dupe_grace: flag allow for duplicates in the linking keymap
        :type link_dupe_grace: bool (True*/False)
            ==> Relates to keymap application only

        :param keymap_lib: Lib for locating keymap (when applicable)
        :type keymap_lib: str (LibAddress) or DataLib or None

        :rtype: Quble
        :returns: filled Quble

        :returns: Modified Quble with null values replaced with aggregate values
        :rtype: qubles.core.quble.Quble

        """
        if self.is_undefined or self.is_empty or self.is_scalar or self.is_multiscalar:
            return self.copy(deep_copy=deep_copy)

        # Parse aggr_method arg...
        # Format of aggr_method: <aggr_fn_name>:<sub_keyspace>
        # Here, the usage of colon and suffix is optional
        # --------------------------------------------------
        if keymap is None:
            (aggr_method, keymap) = self._parse_func_name(
                func_name=aggr_method, keymap_lib=keymap_lib
            )
            # When the keymap is inferred,
            # then a security keyspace is required
            security_keyspace_required = False  # <-- Initialization
            if (
                keymap is not None
                and isinstance(keymap, Quble)
                and keymap.is_defined
                and not keymap.is_empty
                and keymap.has_security_keyspace()
            ):
                security_keyspace_required = True

            if security_keyspace_required and not self.has_security_keyspace():
                raise Exception(
                    f"keymap found yet no security_keyspace in keyspaces:{self.keyspaces}"
                )

        # Make a shallow copy of self as subject
        # Only refer to subject (not self) afterwards
        subject = self

        # Validate aggr_keyspaces
        # May perform auto-linking implicitly here
        aggr_keyspaces = subject.validate_keyspace(
            aggr_keyspaces,
            grace=False,
            coerce_to_list=True,
        )

        # Validate aggr_method arg
        if aggr_method in INCOMPATIBLE_SPACE_AGGRS:
            raise Exception(
                f"Invalid aggr_method:{aggr_method} must not appear in INCOMPATIBLE_SPACE_AGGRS:{INCOMPATIBLE_SPACE_AGGRS}"
            )

        # Does this aggr_method require numeric valuespaces?
        numeric_required = aggr_method in NUMERIC_ONLY_AGGR_METHODS

        # Validate fill_max arg
        if fill_max is None:
            pass
        elif fill_max < 0:
            # Treat negative fill_max as infinite/unconstrained filling
            fill_max = None
            # raise Exception(f"Invalid fill_max:{fill_max}...Non-negative integer required")
        elif fill_max == 0:
            _logger.debug(f"Warning...fill_max:{fill_max} will yield no filling")
            return subject.copy(deep_copy=deep_copy)

        # Validate num_required arg
        if num_required is None:
            pass
        elif num_required < 0:
            raise Exception(
                f"Invalid num_required:{num_required}...Non-negative integer required"
            )

        # Validate pct_required arg
        if pct_required is None:
            pass
        elif pct_required < -0.0001 or pct_required > 1.0001:
            raise Exception(
                f"Invalid pct_required:{pct_required}...0 <= pct_required <= 1.0"
            )

        # Validate valuespace arg
        # and populate valuespaces_to_fill
        # NOTE: This method will yield an empty list for a
        # non-variate Quble when no explicit valuespace(s) requested
        valuespaces_to_fill = self.validate_valuespace(
            valuespace,
            grace=False,
            coerce_to_list=True,
            numeric_required=numeric_required,
        )

        # Process valuespaces_to_fill
        if valuespaces_to_fill is None or len(valuespaces_to_fill) == 0:
            # Return a copy when there are no valuespaces to be filled
            return subject.copy(deep_copy=deep_copy)
        elif None in valuespaces_to_fill:
            # Remove any null valuespaces from the list
            popped_ctr = 0
            for i in range(len(valuespaces_to_fill)):
                j = i - popped_ctr
                if valuespaces_to_fill[j] is None:
                    valuespaces_to_fill.pop(j)
                    popped_ctr += 1

        # Update num_required_glb to consider
        # possibly more constraining pct_required_glb
        if pct_required_glb is None or pct_required_glb == 0:
            pass
        elif pct_required_glb < -0.0001 or pct_required_glb > 1.0001:
            raise Exception(
                f"Invalid pct_required_glb:{pct_required_glb}...required: 0 <= pct_required_glb <= 1.0"
            )
        else:
            num_required_glb_tmp = min(
                int(np.ceil(pct_required_glb * subject.num_records)),
                subject.num_records,
            )
            if num_required_glb_tmp is None or num_required_glb_tmp < 0:
                pass
            elif num_required_glb is None:
                num_required_glb = num_required_glb_tmp
            else:
                num_required_glb = max(num_required_glb, num_required_glb_tmp)

        # Update num_required_glb to consider
        # possibly more constraining fill_max_glb
        if fill_max_glb is None:
            pass
        elif fill_max_glb < 0:
            # Treat negative fill_max_glb as infinite/unconstrained filling
            # pass
            # raise Exception(f"Invalid fill_max_glb:{fill_max_glb}...required: fill_max_glb > 0")
            fill_max_glb = None
        elif fill_max_glb == 0:
            _logger.debug(
                f"Warning...fill_max_glb:{fill_max_glb} will yield no filling"
            )
            return subject.copy(deep_copy=deep_copy)
        else:
            num_required_glb_tmp = subject.num_records - fill_max_glb
            if num_required_glb_tmp is None or num_required_glb_tmp < 0:
                pass
            elif num_required_glb is None:
                num_required_glb = num_required_glb_tmp
            else:
                num_required_glb = max(num_required_glb, num_required_glb_tmp)

        # Remove any valuespaces that do not meet
        # the num_required_glb "global" fill requirements
        # [which now has been encapsulated in the num_required_glb variable]
        num_non_nulls_dict = subject.num_non_nulls_all_spaces

        if valuespaces_to_fill is None or len(valuespaces_to_fill) == 0:
            pass
        elif num_required_glb is None or num_required_glb <= 0:
            pass
        elif subject.num_records is None:
            pass
        elif subject.num_records < num_required_glb:
            # Cannot possibly meet the number of non-nulls required,
            # regardless of content within each valuespace
            # So, in this case, we cannot / do not fill any valuespaces
            valuespaces_to_fill = []
        elif num_non_nulls_dict is None:
            pass
        else:
            popped_ctr = 0
            for i in range(len(valuespaces_to_fill)):
                j = i - popped_ctr
                vs = valuespaces_to_fill[j]
                if vs not in num_non_nulls_dict:
                    continue
                elif num_non_nulls_dict[vs] is None:
                    continue
                elif num_non_nulls_dict[vs] < num_required_glb:
                    # Not enough non-null records in this valuespace
                    # to satisfy the global filling requirement(s)
                    valuespaces_to_fill.pop(j)
                    popped_ctr += 1

        # Remove any valuespaces with no null records?
        popped_ctr = 0
        for i in range(len(valuespaces_to_fill)):
            j = i - popped_ctr
            vs = valuespaces_to_fill[j]
            if (
                vs in num_non_nulls_dict
                and num_non_nulls_dict[vs] is not None
                and num_non_nulls_dict[vs] == subject.num_records
            ):
                # No null records in this valuespace
                # to satisfy the global filling requirement(s)
                valuespaces_to_fill.pop(j)
                popped_ctr += 1

        # Handle case where there are no remaining valuespaces_to_fill
        # [NOTE: We simply return a copy or alternatively throw an Exception]
        if valuespaces_to_fill is None or len(valuespaces_to_fill) == 0:
            return subject.copy(deep_copy=deep_copy)

        # List valuespaces_to_not_fill
        # valuespaces_to_not_fill = [vs for vs in subject.valuespaces if vs not in valuespaces_to_fill]

        # Apply view to subject
        # using view's primary valuespace
        # Also, infer weightspace if present
        # -----------------------------------
        weightspace = None
        if view is None:
            pass
        elif isinstance(view, str):
            # Here, view (str) identifies a weightspace column of the Quble
            if view not in subject.valuespaces:
                raise Exception(
                    f"view:{view} absent from subject.valuespaces:{subject.valuespaces}"
                )
            weightspace = view
            weightspace_type = self.get_column_type(weightspace)
            weightspace_is_numeric = coltype_is_numeric(weightspace_type)
            weightspace_is_bool = coltype_is_bool(weightspace_type)
            if aggr_method not in WTD_TO_UNWTD_AGGR_DICT or weightspace_is_bool:
                # Non-weighted aggregation OR boolean weightspace
                # Implementation: Restrict to records where weightspace = True
                if weightspace_is_bool:
                    where_clause = (
                        'WHERE "'
                        + weightspace
                        + '" IS NOT NULL AND "'
                        + weightspace
                        + '" <> False'
                    )
                elif weightspace_is_numeric:
                    where_clause = (
                        'WHERE "'
                        + weightspace
                        + '" IS NOT NULL AND "'
                        + weightspace
                        + '" <> 0'
                    )
                else:
                    raise Exception(
                        f"Invalid coltype:{weightspace_type} for weightspace:{weightspace} with aggr_method:{aggr_method}"
                    )

                spacesxweightspace = [
                    space1 for space1 in subject.spaces if space1 != weightspace
                ]
                subject = subject.select(
                    column_names=spacesxweightspace, where_clause=where_clause
                )
                # No need to continue to recognize weightspace now
                weightspace = None
            elif not weightspace_is_numeric:
                raise Exception(
                    f"weightspace:{weightspace} has invalid column type:{weightspace_type}...numeric or bool type required"
                )
            # else:
            # Here, we are performing a weighted aggregation,
            # and the weightspace is a numeric column
            # pass

        elif not isinstance(view, Quble):
            raise Exception("Invalid view...Quble, str or None expected")
        elif view.is_undefined:
            pass
        elif (
            aggr_method not in WTD_TO_UNWTD_AGGR_DICT
            or view.is_scalar
            or view.is_multiscalar
            or view.is_index
            or view.is_bool()
        ):
            # Determine if this is a weighted aggregation method by looking at:
            # aggr_method not in WTD_TO_UNWTD_AGGR_DICT
            subject = subject.apply_view(view, allow_shallow_copy=True)
        elif not view.is_numeric():
            raise Exception(
                "For weight aggregation:{0}, view must be index, bool or numeric Quble"
            )
        elif subject.are_coindexed(view):
            if view.valuespace is None:
                # Highly unlikely case, but check to be sure
                raise Exception(
                    "self & view are coindexed, yet view.valuespace is None"
                )
            weightspace = view.valuespace
        else:
            # Here, we are performing a weighted aggregation
            # with a numeric non-scalar view (weighting Quble)
            if subject.valuespace is None or subject.valuespace != "weighting":
                weightspace = "weighting"
            else:
                weightspace = "wgt"
            # NOTE: weightspace will be imposed column,
            # but must be distinct from subject.valuespace
            subject = subject.apply_view(
                view, view_valuespace_as=weightspace, allow_shallow_copy=True
            )

            # Perform some checks
            if weightspace not in subject.valuespaces:
                raise Exception(
                    "weightspace:{0} was not created during the join operation"
                )

        # Perform weightspace checks
        # ---------------------------
        if weightspace is None:
            # subject = subject.sub_variate(valuespace=valuespaces_to_fill, allow_shallow_copy=True)
            pass
        elif weightspace not in subject.valuespaces:
            raise Exception(
                "weightspace:{0} absent from valuespaces:{subject.valuespaces}"
            )
        elif weightspace not in valuespaces_to_fill:
            # subject = subject.sub_variate(valuespace=valuespaces_to_fill + [weightspace], allow_shallow_copy=True)
            pass
        elif valuespaces_to_fill == [weightspace]:
            # Are we about to remove the only valuespace?
            # In this case, valuespaces_to_fill only has weightspace
            # And there is nothing to fill here, so we exit early
            # NOTE: we could also throw an Exception here
            return subject.copy(deep_copy=deep_copy)
        else:
            #  subject = subject.sub_variate(valuespace=valuespaces_to_fill, allow_shallow_copy=True)
            # Remove weightspace from valuespaces_to_fill (if applicable)
            valuespaces_to_fill.pop(valuespaces_to_fill.index(weightspace))

        # NOTE: Apply pre_cross_fill BEFORE pre_fill
        if pre_cross_fill:
            subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)

        if pre_fill:
            subject = subject._apply_pre_fill(allow_shallow_copy=True)

        # ================ START: KEYMAP (IF APPLICABLE) ===================
        if keymap is None:
            groupspace = None
        elif isinstance(keymap, str):
            # In this case, assume user has specified keymap arg
            # as an existing space/column of original Quble
            # [No need for joining tables operation here]
            if keymap in subject.valuespaces:
                # Nominal case
                groupspace = keymap
            elif keymap not in subject.keyspaces:
                raise Exception(
                    f"keymap str:{keymap} is absent from subject.spaces:{subject.spaces}"
                )
            elif aggr_keyspaces is None or keymap not in aggr_keyspaces:
                # This keyspace will already be an ortho (grouping) keyspace
                pass
            else:
                # Remove keymap (str) from aggr_keyspaces?
                # as now we will be grouping on this keyspace
                # Could also throw an Exception here
                aggr_keyspaces = [ks1 for ks1 in aggr_keyspaces if ks1 != keymap]

        elif not isinstance(keymap, Quble):
            raise Exception(
                f"Invalid keymap...expected Quble but type(keymap):{type(keymap)}"
            )
        elif keymap.is_undefined:
            # Could also throw an exception here
            groupspace = None
        elif keymap.is_nonvariate:
            raise Exception(f"Invalid keymap...variate Quble expected")
        else:
            # Set freq reconciliation based on subject's context
            freq = subject.context_freq()

            # Which keyspaces of subject are linkable from keymap
            # [We exclude keyspace,tgt_keyspace & rankspace]
            linkable_keyspaces = subject.ortho_keyspaces(keymap.keyspaces)

            if auto_link and len(linkable_keyspaces) > 0:
                keymap = keymap.link_keyspaces(
                    linkable_keyspaces,
                    link_check=link_check,
                    link_dupe_grace=link_dupe_grace,
                    deep_copy=False,
                    grace=True,
                )

            # Aggregate away any ortho keyspaces
            # excluding keyspace, tgt_keyspace & rankspace (if present)
            # ----------------------------------------------------------
            for ks in keymap.ortho_keyspaces(subject.keyspaces):
                keymap = keymap.aggregate1d(keyspace=ks, auto_squeeze=True)

            expansion_exclusions = None
            # We impose an intersection join here
            keys_join_op = "inter_tunionpostleft"
            keyspaces_join_op = "union"

            groupspace = "_group_"  # <-- Arbitrary...will not be retained
            if groupspace in subject.spaces:
                raise Exception(
                    f"groupspace:{groupspace} present in subject.spaces:{subject.spaces}"
                )
                valuespaces_join_op[groupspace] = (1, keymap.valuespace)

            # Populate valuespaces_join_op dict
            valuespaces_join_op = {}

            # First, add subject's valuespaces
            # to valuespaces_join_op dictionary
            # to be sourced from subject (Quble #0 in join list)
            for vs in subject.valuespaces:
                valuespaces_join_op[vs] = (0, vs)

            # Next, add groupspace to valuespaces_join_op dictionary
            # to be sourced from keymap (Quble #1 in join list)
            if keymap.valuespace is None:
                raise Exception(f"keymap.valuespace is None...keymap is nonvariate?")
            valuespaces_join_op[groupspace] = (1, keymap.valuespace)

            subject = subject.join(
                other=keymap,
                keys_join_op=keys_join_op,
                keyspaces_join_op=keyspaces_join_op,
                valuespaces_join_op=valuespaces_join_op,
                valuespace_prefix=None,
                ignore_missing=True,
                auto_fill=auto_fill,
                tfill_method=tfill_method,
                tfill_max=tfill_max,
                tfill_end_mode=tfill_end_mode,
                tfill_honor_nulls=tfill_honor_nulls,
                aggr_method=aggr_method,
                coverage_requirements={1: 0} if link_check else None,
                freq=freq,
                # NOTE: key_ordering will be applied in remap1D.j2 template below against final keyspaces
                # key_ordering=key_ordering,
                key_ordering=None,
                view=view,
                tdistribute_mode=tdistribute_mode,
                # NOTE: We have already performed keyspace link (keymap->subject/self) above
                auto_link=False,
                link_check=link_check,
                link_dupe_grace=link_dupe_grace,
                prevent_null_keys=prevent_null_keys,
                expansion_exclusions=expansion_exclusions,
            )

            # =================================================
            #   POST-JOIN, THE JOINED TABLE
            #   WILL HAVE THE FOLLOWING COLUMNS:
            #
            # subject.keyspaces + [groupspace] + [weightspace (optional)] + subject.valuespaces
            # Final result columns: subject.keyspaces + subject.valuespaces
            # ==================================================

        # ================ END: KEYMAP (IF APPLICABLE) ===================

        # =========================== START: VALUESPACES LOOP ===========================
        sql_aggr_fn_per_vs = {}
        extra_fn_args_per_vs = {}
        include_null_values_per_vs = {}
        # aggr_keyspaces_presort_needed_per_vs = {}

        # for vs in subject.valuespaces:
        for vs in valuespaces_to_fill:
            # Validate/convert aggr_method
            # (will convert to SQL compatible upper-case FUNCTION NAME)
            (
                sql_aggr_fn,
                extra_fn_args,
                is_custom,
                is_weighted,
                aggr_keyspaces_presort_needed,
            ) = subject._validate_and_convert_aggr_method(
                aggr_method,
                column_name=vs,
                ignore_missing=True,
                num_required=num_required,
                percentile=50.0,  # <-- Not applicable...use placeholder
                epsilon=1e-6,  # <-- Not applicable...use placeholder
                weightspace=weightspace,
                clob_export_mode=clob_export_mode,
                blob_export_mode=blob_export_mode,
            )
            sql_aggr_fn_per_vs[vs] = sql_aggr_fn
            if isinstance(extra_fn_args, (list, tuple)):
                # Convert to string for easier use within query template
                extra_fn_args = [
                    str(extra_fn_args1) for extra_fn_args1 in extra_fn_args
                ]
            extra_fn_args_per_vs[vs] = extra_fn_args

            # if aggr_keyspaces_presort_needed:
            # TODO: Supporting this case...
            # Will likely require supporting a new query template
            # [this template may require that all columns use same setting]
            # raise Exception(f"Invalid aggr_method:{aggr_method} (?) yeilded aggr_keyspaces_presort_needed:{aggr_keyspaces_presort_needed}")
            # aggr_keyspaces_presort_needed_per_vs[vs] = aggr_keyspaces_presort_needed

        # =========================== END: VALUESPACES LOOP ===========================

        # Build build_key_ordering_dict when applicable
        if key_ordering is not None and not isinstance(key_ordering, str):
            key_ordering = build_key_ordering_dict(
                key_ordering, keyspaces=subject.keyspaces
            )

        # Currently, aggr_fill.j2 does not support
        # (non-wtd nor wtd) first/last aggregation
        tgt_table_name = generate_random_table_name()
        sql_template = JINJA_ENV.get_template("aggr_fill.j2")
        if "wtd" in aggr_method:
            wtd_aggr_quble = self.aggregate(
                aggr_keyspaces=aggr_keyspaces,
                aggr_method=aggr_method,  # <- aggr_method would go here,
                pct_required=pct_required,
                num_required=num_required,
                valuespace=valuespace,
                view=view,
                key_ordering=key_ordering,
                pre_cross_fill=pre_cross_fill,
                pre_fill=pre_fill,
                auto_squeeze=True,
            )

            wtd_aggr_table = wtd_aggr_quble.table_name
        else:
            wtd_aggr_table = None
        sql_command = sql_template.render(
            aggr_keyspaces=aggr_keyspaces,
            sql_aggr_fn_per_vs=sql_aggr_fn_per_vs,
            key_ordering=key_ordering,
            keyspaces=subject.keyspaces,
            src_table_name=subject.table_name,
            tgt_keyspaces=subject.keyspaces,
            tgt_table_name=tgt_table_name,
            valuespaces_to_fill=valuespaces_to_fill,
            valuespaces=self.valuespaces,
            groupspace=groupspace,
            weightspace=weightspace,
            # col_types_dict=col_types_dict,
            extra_fn_args_per_vs=extra_fn_args_per_vs,
            pct_required=pct_required,
            num_required=num_required,
            fill_max=None if fill_max is None or fill_max <= 0 else fill_max,
            # aggr_keyspaces_presort_needed_per_vs=aggr_keyspaces_presort_needed_per_vs,
            wtd_aggr_table=wtd_aggr_table,
        )
        execute(sql_command)

        # Determine spaces_to_keep based on weightspace & groupspace
        if weightspace is None:
            if groupspace is None:
                # weightspace and groupspace are both None
                spaces_to_keep = self.spaces
            else:
                # weightspace is None, groupspace is not None
                spaces_to_keep = [
                    space1 for space1 in self.spaces if space1 != groupspace
                ]
        elif groupspace is None:
            # weightspace is not None, groupspace is None
            spaces_to_keep = [space1 for space1 in self.spaces if space1 != weightspace]
        else:
            # weightspace and groupspace are both not None
            spaces_to_keep = [
                space1
                for space1 in self.spaces
                if space1 not in (weightspace, groupspace)
            ]

        # Establish col_info for copy
        # We retain all original info types here
        info_types_to_copy = CUSTOM_INFO_TYPES
        col_info = self.get_space_info(
            info_type=info_types_to_copy,
            space=spaces_to_keep,
            omit_unassigned=True,
        )
        # Instantiate Quble from the new table
        result = Quble.from_table(
            tgt_table_name,
            col_info=col_info,
        )

        return result

    @RootLib.lazy_kwargs()
    def unfill1d(
        self,
        keyspace: str = "<first_keyspace>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfill_pct_max: float = None,
        unfill_max: int = None,
        key_ordering="asc",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        deep_copy: bool = True,
        compress: bool = False,
        clob_export_mode: str = RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode: str = RootLib.lazy_eval("blob_export_mode"),
    ) -> Quble:
        """
        "Unfills" non-null values (replaces with nulls) conditionally
        provided satisfaction of certain "unfill criteria" (requirements)
        evaluated across the specified keyspace
        for each set of 'orthogonal' keys
        See: :meth:`~qubles.core.quble.Quble.unfill`
        """
        return self.unfill(
            aggr_keyspaces=keyspace,
            valuespace=valuespace,
            view=view,
            unfill_pct_max=unfill_pct_max,
            unfill_max=unfill_max,
            key_ordering=key_ordering,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            deep_copy=deep_copy,
            compress=compress,
            clob_export_mode=clob_export_mode,
            blob_export_mode=blob_export_mode,
        )

    @RootLib.lazy_kwargs()
    def unfill(
        self,
        aggr_keyspaces: str = "<keyspaces>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfill_pct_max: float = None,
        unfill_max: int = None,
        key_ordering="asc",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        deep_copy: bool = True,
        compress: bool = False,
        clob_export_mode: str = RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode: str = RootLib.lazy_eval("blob_export_mode"),
    ) -> Quble:
        """
        "Unfills" non-null values (replaces with nulls) conditionally
        providing the satisfaction of "unfill criteria" (requirements)
        evaluated across the specified aggr_keyspaces
        for each set of 'orthogonal' keys

        :param aggr_keyspaces: keyspaces for the aggregation computation
        :type aggr_keyspaces: str or list of strings

        :param aggr_method: The method that will be used for aggregation.
        :type aggr_method: {q_aggr_method}

        :param valuespace: valuespace(s) to be filled
            ==> Other valuespaces will be retained but not filled
        :type valuespace: str or list of strings
                      (keywords may be used such as '<valuespaces>', '<valuespace>', etc.
                      [See: :meth:`~qubles.core.quble.Quble.validate_valuespace`]

        :param view: Quble indicating conditional elements
                     for which aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :type unfill_pct_max: None or float
        :param unfill_pct_max:
            Maximum percentage of non-null data points
            required to authorize unfilling
            across the specified aggregation/filling keyspace(s)
            for each set of orthogonal keys and group keys.
            Value must be: 0.0 <= unfill_pct_max <= 1.0
            IMPORTANT: unfill_pct_max == 0 yields NO UNFILLING (simply return a copy)
            IMPORTANT: unfill_pct_max == None represents unconstrained condition
            IMPORTANT: unfill_pct_max == 1.0 represents unconstrained condition

        :type unfill_max: None or int
        :param unfill_max:
            Maximum allowable number of non-null data points
            required to authorize unfilling
            across the specified aggregation/filling keyspace(s)
            for each set of orthogonal keys and group keys.
            Value must be either None or an int
            IMPORTANT: fill_max == 0 yields NO UNFILLING (simply return a copy)
            IMPORTANT: fill_max == None represents unconstrained condition
            IMPORTANT: fill_max < 0 represents unconstrained condition

        :param pre_cross_fill: flag to control whether to cross-fill
                           when the keyspace to be filled is a time keyspace
                           AND ortho_resampling_keyspaces also exist
        :type pre_cross_fill: boolean (True*/False)

        :param pre_fill: flag to control whether to pre-fill
                         when some being aggregated are resampling keyspaces
        :type pre_fill: boolean (True/False*)

        :type deep_copy: bool
        :param deep_copy:
            Flag to indicate whether the existing Quble should be copied
            (and thus left unchanged) or changed in-place.

        :param key_ordering: controls row ordering by key
        :type key_ordering: None, str or dictionary
           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace
           dictionary: dict keys (str): keyspaces, dict values (str): 'asc' or 'desc'
           ==> allows for assigning key ordering (ascending/descending)
           ==> (and relative priority) for each keyspace individually

        :param compress: flag for compressing resultant Quble
        :type compress: bool (True/False)

        :param clob_export_mode: treament for column type: 'clob'/'CLOB'
                                 in Python-based aggregation functions
        :type clob_export_mode: 'unicode','object','string','str',None

        :param blob_export_mode: treament for column type: 'blob'/'BLOB'
                                 in Python-based aggregation functions
        :type blob_export_mode: 'object','string','str','unicode',None

        :rtype: Quble
        :returns: filled Quble

        :returns: Modified Quble with null values replaced with aggregate values
        :rtype: qubles.core.quble.Quble

        """
        return self.sub_unfill(
            keymap=None,  # <-- Will perform non-grouped aggregation
            aggr_keyspaces=aggr_keyspaces,
            valuespace=valuespace,
            view=view,
            unfill_pct_max=unfill_pct_max,
            unfill_max=unfill_max,
            key_ordering=key_ordering,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            deep_copy=deep_copy,
            compress=compress,
            clob_export_mode=clob_export_mode,
            blob_export_mode=blob_export_mode,
        )

    @RootLib.lazy_kwargs()
    def sub_unfill1d(
        self,
        keymap: Quble,
        keyspace: str = "<first_keyspace>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfill_pct_max: float = None,
        unfill_max: int = None,
        key_ordering="asc",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        deep_copy: bool = True,
        compress: bool = False,
        clob_export_mode: str = RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode: str = RootLib.lazy_eval("blob_export_mode"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        tdistribute_mode="<space_root>",
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        prevent_null_keys: bool = False,
        link_dupe_grace: bool = True,
    ) -> Quble:
        """
        Un-fills the non-null values with the sub-aggregate value
        as computed across the specified keyspace
        for each set of 'orthonal' keys
        See: :meth:`~qubles.core.quble.Quble.sub_unfill`
        """
        return self.sub_unfill(
            keymap=keymap,
            aggr_keyspaces=keyspace,
            valuespace=valuespace,
            view=view,
            unfill_pct_max=unfill_pct_max,
            unfill_max=unfill_max,
            key_ordering=key_ordering,
            pre_cross_fill=pre_cross_fill,
            pre_fill=pre_fill,
            deep_copy=deep_copy,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            tdistribute_mode=tdistribute_mode,
            auto_fill=auto_fill,
            auto_link=auto_link,
            link_check=link_check,
            prevent_null_keys=prevent_null_keys,
            link_dupe_grace=link_dupe_grace,
            compress=compress,
            clob_export_mode=clob_export_mode,
            blob_export_mode=blob_export_mode,
        )

    @RootLib.lazy_kwargs()
    def sub_unfill(
        self,
        keymap: Quble,
        aggr_keyspaces: str = "<keyspaces>",
        valuespace="<valuespaces>",
        view=RootLib.lazy_eval("view"),
        unfill_pct_max: float = None,
        unfill_max: int = None,
        key_ordering="asc",
        pre_cross_fill: bool = True,
        pre_fill: bool = False,
        deep_copy: bool = True,
        compress: bool = False,
        clob_export_mode: str = RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode: str = RootLib.lazy_eval("blob_export_mode"),
        aggr_method: bool = RootLib.lazy_eval("aggr_method"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        tdistribute_mode="<space_root>",
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        prevent_null_keys: bool = False,
        link_dupe_grace: bool = True,
    ) -> Quble:
        """
        Fills the null values with the sub-aggregate value
        as computed across the specified aggr_keyspaces
        for each set of 'orthonal' keys

        :param keymap: mapping where values provide target keys for the specified keyspace
                        The primary valuespace of the keymap will be applied
        :type keymap: Quble or str or None
        ==> Set keymap=None for no sub-grouping
        ==> Set keymap=str to group using an existing valuespace
        ==> Set keymap=Quble to group using an external Quble

        :param aggr_keyspaces: keyspaces for the aggregation computation
        :type aggr_keyspaces: str or list of strings

        :param valuespace: valuespace(s) to be filled
            ==> Other valuespaces will be retained but not filled
        :type valuespace: str or list of strings
                      (keywords may be used such as '<valuespaces>', '<valuespace>', etc.
                      [See: :meth:`~qubles.core.quble.Quble.validate_valuespace`]

        :param view: Quble indicating conditional elements
                     for which aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :type unfill_pct_max: None or float
        :param unfill_pct_max:
            Maximum percentage of non-null data points
            required to authorize unfilling
            across the specified aggregation/filling keyspace(s)
            for each set of orthogonal keys and group keys.
            Value must be: 0.0 <= unfill_pct_max <= 1.0
            IMPORTANT: unfill_pct_max == 0 yields NO UNFILLING (simply return a copy)
            IMPORTANT: unfill_pct_max == None represents unconstrained condition
            IMPORTANT: unfill_pct_max == 1.0 represents unconstrained condition

        :type unfill_max: None or int
        :param unfill_max:
        Maximum allowable number of non-null data points required to authorize unfilling across the specified aggregation/filling keyspace(s)
        for each set of orthogonal keys and group keys.
        Value must be either None or an int
        IMPORTANT: fill_max == 0 yields NO UNFILLING (simply return a copy)
        IMPORTANT: fill_max == None represents unconstrained condition
        IMPORTANT: fill_max < 0 represents unconstrained condition

        :param pre_cross_fill: flag to control whether to cross-fill
                           when the keyspace to be filled is a time keyspace
                           AND ortho_resampling_keyspaces also exist
        :type pre_cross_fill: boolean (True*/False)

        :param pre_fill: flag to control whether to pre-fill
                         when some being aggregated are resampling keyspaces
        :type pre_fill: boolean (True/False*)

        :type deep_copy: bool
        :param deep_copy:
            Flag to indicate whether the existing Quble should be copied
            (and thus left unchanged) or changed in-place.

        :param key_ordering: controls row ordering by key
        :type key_ordering: None, str or dictionary
           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace
           dictionary: dict keys (str): keyspaces, dict values (str): 'asc' or 'desc'
           ==> allows for assigning key ordering (ascending/descending)
           ==> (and relative priority) for each keyspace individually

        :param compress: flag for compressing resultant Quble
        :type compress: bool (True/False)

        :param clob_export_mode: treament for column type: 'clob'/'CLOB'
                                 in Python-based aggregation functions
        :type clob_export_mode: 'unicode','object','string','str',None

        :param blob_export_mode: treament for column type: 'blob'/'BLOB'
                                 in Python-based aggregation functions
        :type blob_export_mode: 'object','string','str','unicode',None

        :type auto_link: bool
        :param auto_link: Control for auto-linking (keyspace affiliation)
            ==> Relates to keymap application only

        :param link_check: flag to check the linking keymap
        :type link_check: bool (False*/True)
            ==> Relates to keymap application only

        :param link_dupe_grace: flag allow for duplicates in the linking keymap
        :type link_dupe_grace: bool (True*/False)
            ==> Relates to keymap application only

        :rtype: Quble
        :returns: filled Quble

        :returns: Modified Quble with null values replaced with aggregate values
        :rtype: qubles.core.quble.Quble

        """
        if self.is_undefined or self.is_empty or self.is_scalar or self.is_multiscalar:
            return self.copy(deep_copy=deep_copy)

        # Make a shallow copy of self as subject
        # Only refer to subject (not self) afterwards
        subject = self

        # Validate aggr_keyspaces
        # May perform auto-linking implicitly here
        aggr_keyspaces = subject.validate_keyspace(
            aggr_keyspaces,
            grace=False,
            coerce_to_list=True,
        )

        # Validate unfill_max arg
        if unfill_max is None:
            pass
        elif unfill_max < 0:
            # Treat negative unfill_max as infinite/unconstrained unfilling
            # raise Exception(f"Invalid unfill_max:{unfill_max}...Non-negative integer required")
            unfill_max = None
        elif unfill_max == 0:
            _logger.debug(f"Warning...unfill_max:{unfill_max} will yield no unfilling")
            return subject.copy(deep_copy=deep_copy)

        # Validate unfill_pct_max arg
        if unfill_pct_max is None:
            pass
        elif unfill_pct_max < 0 or unfill_pct_max > 1.0001:
            raise Exception(
                f"Invalid unfill_pct_max:{unfill_pct_max}...0 <= unfill_pct_max <= 1.0"
            )
        elif unfill_pct_max == 0:
            _logger.debug(
                f"Warning...unfill_pct_max:{unfill_pct_max} will yield no unfilling"
            )
            return subject.copy(deep_copy=deep_copy)

        # Validate valuespace arg
        # and populate valuespaces_to_unfill
        # NOTE: This method will yield an empty list for a
        # non-variate Quble when no explicit valuespace(s) requested
        valuespaces_to_unfill = self.validate_valuespace(
            valuespace,
            grace=False,
            coerce_to_list=True,
            # numeric_required=False,
        )

        # Process valuespaces_to_unfill
        if valuespaces_to_unfill is None or len(valuespaces_to_unfill) == 0:
            # Return a copy when there are no valuespaces to be filled
            return subject.copy(deep_copy=deep_copy)
        elif None in valuespaces_to_unfill:
            # Remove any null valuespaces from the list
            popped_ctr = 0
            for i in range(len(valuespaces_to_unfill)):
                j = i - popped_ctr
                if valuespaces_to_unfill[j] is None:
                    valuespaces_to_unfill.pop(j)
                    popped_ctr += 1

        # Remove any valuespaces with no non-null records?
        num_non_nulls_dict = subject.num_non_nulls_all_spaces
        popped_ctr = 0
        for i in range(len(valuespaces_to_unfill)):
            j = i - popped_ctr
            vs = valuespaces_to_unfill[j]
            if (
                vs in num_non_nulls_dict
                and num_non_nulls_dict[vs] is not None
                and num_non_nulls_dict[vs] == 0
            ):
                # No non-null records in this valuespace
                # to satisfy the global unfilling requirement(s)
                valuespaces_to_unfill.pop(j)
                popped_ctr += 1

        # Handle case where there are no remaining valuespaces_to_unfill
        # [NOTE: We simply return a copy or alternatively throw an Exception]
        if valuespaces_to_unfill is None or len(valuespaces_to_unfill) == 0:
            return subject.copy(deep_copy=deep_copy)

        # List valuespaces_to_not_fill
        # valuespaces_to_not_fill = [vs for vs in subject.valuespaces if vs not in valuespaces_to_unfill]

        # Apply view to subject
        # using view's primary valuespace
        # Also, infer weightspace if present
        # -----------------------------------
        weightspace = None
        if view is None:
            pass
        elif isinstance(view, str):
            # Here, view (str) identifies a weightspace column of the Quble
            if view not in subject.valuespaces:
                raise Exception(
                    f"view:{view} absent from subject.valuespaces:{subject.valuespaces}"
                )

            weightspace = view
            weightspace_type = self.get_column_type(weightspace)
            weightspace_is_numeric = coltype_is_numeric(weightspace_type)
            weightspace_is_bool = coltype_is_bool(weightspace_type)
            # Non-weighted aggregation OR boolean weightspace
            # Implementation: Restrict to records where weightspace = True
            if weightspace_is_bool:
                where_clause = (
                    'WHERE "'
                    + weightspace
                    + '" IS NOT NULL AND "'
                    + weightspace
                    + '" <> False'
                )
            elif weightspace_is_numeric:
                where_clause = (
                    'WHERE "'
                    + weightspace
                    + '" IS NOT NULL AND "'
                    + weightspace
                    + '" <> 0'
                )
            else:
                raise Exception(
                    f"Invalid coltype:{weightspace_type} for weightspace:{weightspace} with aggr_method:{aggr_method}"
                )

            spacesxweightspace = [
                space1 for space1 in subject.spaces if space1 != weightspace
            ]
            subject = subject.select(
                column_names=spacesxweightspace, where_clause=where_clause
            )
            weightspace = None
        elif not isinstance(view, Quble):
            raise Exception("Invalid view...Quble, str or None expected")
        elif view.is_undefined:
            pass
        else:
            subject = subject.apply_view(view, allow_shallow_copy=True)

        # NOTE: Apply pre_cross_fill BEFORE pre_fill
        if pre_cross_fill:
            subject = subject._apply_pre_cross_fill(allow_shallow_copy=True)

        if pre_fill:
            subject = subject._apply_pre_fill(allow_shallow_copy=True)

        # ================ START: KEYMAP (IF APPLICABLE) ===================
        if keymap is None:
            groupspace = None
        elif isinstance(keymap, str):
            # In this case, assume user has specified keymap arg
            # as an existing space/column of original Quble
            # [No need for joining tables operation here]
            if keymap in subject.valuespaces:
                # Nominal case
                groupspace = keymap
            elif keymap not in subject.keyspaces:
                raise Exception(
                    f"keymap str:{keymap} is absent from subject.spaces:{subject.spaces}"
                )
            elif aggr_keyspaces is None or keymap not in aggr_keyspaces:
                # This keyspace will already be an ortho (grouping) keyspace
                pass
            else:
                # Remove keymap (str) from aggr_keyspaces?
                # as now we will be grouping on this keyspace
                # Could also throw an Exception here
                aggr_keyspaces = [ks1 for ks1 in aggr_keyspaces if ks1 != keymap]

        elif not isinstance(keymap, Quble):
            raise Exception(
                f"Invalid keymap...expected Quble but type(keymap):{type(keymap)}"
            )
        elif keymap.is_undefined:
            # Could also throw an exception here
            groupspace = None
        elif keymap.is_nonvariate:
            raise Exception(f"Invalid keymap...variate Quble expected")
        else:
            # Set freq reconciliation based on subject's context
            freq = subject.context_freq()

            # Which keyspaces of subject are linkable from keymap
            # [We exclude keyspace,tgt_keyspace & rankspace]
            linkable_keyspaces = subject.ortho_keyspaces(keymap.keyspaces)

            if auto_link and len(linkable_keyspaces) > 0:
                keymap = keymap.link_keyspaces(
                    linkable_keyspaces,
                    link_check=link_check,
                    link_dupe_grace=link_dupe_grace,
                    deep_copy=False,
                    grace=True,
                )

            # Aggregate away any ortho keyspaces
            # excluding keyspace, tgt_keyspace & rankspace (if present)
            # ----------------------------------------------------------
            for ks in keymap.ortho_keyspaces(subject.keyspaces):
                keymap = keymap.aggregate1d(keyspace=ks, auto_squeeze=True)

            expansion_exclusions = None
            # We impose an intersection join here
            keys_join_op = "inter_tunionpostleft"
            keyspaces_join_op = "union"

            groupspace = "_group_"  # <-- Arbitrary...will not be retained
            if groupspace in subject.spaces:
                raise Exception(
                    f"groupspace:{groupspace} present in subject.spaces:{subject.spaces}"
                )
                valuespaces_join_op[groupspace] = (1, keymap.valuespace)

            # Populate valuespaces_join_op dict
            valuespaces_join_op = {}

            # First, add subject's valuespaces
            # to valuespaces_join_op dictionary
            # to be sourced from subject (Quble #0 in join list)
            for vs in subject.valuespaces:
                valuespaces_join_op[vs] = (0, vs)

            # Next, add groupspace to valuespaces_join_op dictionary
            # to be sourced from keymap (Quble #1 in join list)
            if keymap.valuespace is None:
                raise Exception(f"keymap.valuespace is None...keymap is nonvariate?")
            valuespaces_join_op[groupspace] = (1, keymap.valuespace)

            subject = subject.join(
                other=keymap,
                keys_join_op=keys_join_op,
                keyspaces_join_op=keyspaces_join_op,
                valuespaces_join_op=valuespaces_join_op,
                valuespace_prefix=None,
                ignore_missing=True,
                auto_fill=auto_fill,
                tfill_method=tfill_method,
                tfill_max=tfill_max,
                tfill_end_mode=tfill_end_mode,
                tfill_honor_nulls=tfill_honor_nulls,
                aggr_method=aggr_method,
                coverage_requirements={1: 0} if link_check else None,
                freq=freq,
                # NOTE: key_ordering will be applied in remap1D.j2 template below against final keyspaces
                # key_ordering=key_ordering,
                key_ordering=None,
                view=view,
                tdistribute_mode=tdistribute_mode,
                # NOTE: We have already performed keyspace link (keymap->subject/self) above
                auto_link=False,
                link_check=link_check,
                link_dupe_grace=link_dupe_grace,
                prevent_null_keys=prevent_null_keys,
                expansion_exclusions=expansion_exclusions,
            )

            # =================================================
            #   POST-JOIN, THE JOINED TABLE
            #   WILL HAVE THE FOLLOWING COLUMNS:
            #
            # subject.keyspaces + [groupspace] + [weightspace (optional)] + subject.valuespaces
            # Final result columns: subject.keyspaces + subject.valuespaces
            # ==================================================

        # ================ END: KEYMAP (IF APPLICABLE) ===================

        # Build build_key_ordering_dict when applicable
        if key_ordering is not None and not isinstance(key_ordering, str):
            key_ordering = build_key_ordering_dict(
                key_ordering, keyspaces=subject.keyspaces
            )

        # Currently, aggr_fill.j2 does not support
        # (non-wtd nor wtd) first/last aggregation
        tgt_table_name = generate_random_table_name()
        sql_template = JINJA_ENV.get_template("unfill.j2")

        sql_command = sql_template.render(
            aggr_keyspaces=aggr_keyspaces,
            key_ordering=key_ordering,
            keyspaces=subject.keyspaces,
            src_table_name=subject.table_name,
            tgt_keyspaces=subject.keyspaces,
            tgt_table_name=tgt_table_name,
            valuespaces_to_unfill=valuespaces_to_unfill,
            valuespaces=self.valuespaces,
            groupspace=groupspace,
            unfill_pct_max=unfill_pct_max,
            unfill_max=unfill_max,
        )
        execute(sql_command)

        # Establish col_info for copy
        # We retain all original info types here
        info_types_to_copy = CUSTOM_INFO_TYPES

        # Determine spaces_to_keep based on weightspace & groupspace
        if weightspace is None:
            if groupspace is None:
                # weightspace and groupspace are both None
                spaces_to_keep = self.spaces
            else:
                # weightspace is None, groupspace is not None
                spaces_to_keep = [
                    space1 for space1 in self.spaces if space1 != groupspace
                ]
        elif groupspace is None:
            # weightspace is not None, groupspace is None
            spaces_to_keep = [space1 for space1 in self.spaces if space1 != weightspace]
        else:
            # weightspace and groupspace are both not None
            spaces_to_keep = [
                space1
                for space1 in self.spaces
                if space1 not in (weightspace, groupspace)
            ]

        # Establish col_info to copy to resultant Quble
        col_info = self.get_space_info(
            info_type=info_types_to_copy,
            space=spaces_to_keep,
            omit_unassigned=True,
        )
        # Instantiate Quble from the new table
        result = Quble.from_table(
            tgt_table_name,
            col_info=col_info,
        )

        # Return the resultant Quble
        if compress:
            result.compress(inplace=True)

        return result

    def get_freq(
        self,
        space: str = "<first_time_keyspace>",
        freq_hint: str = "default_freq",
        allow_infer: bool = True,
        assign_inferred: bool = True,
        time_space_required: bool = True,
        grace: bool = True,
    ) -> str:
        """
        Gets the frequency for a time/timer column (by referencing the column information table)
        If unavailable via column information table, frequency may be inferred and assigned (based on arguments)

        space: the (key)space (index column) for which the frequency is requested

        freq_hint: the initial frequency hint for inference
                    (if necessaery, method will continue on to investigate all other frequencies)

        allow_infer: Flag for inferring frequency when not pre-assigned (only applicable for time/date columns)

        assign_inferred: Flag for assigning the inferred frequency (only applicable for time/date columns)

        time_space_required: Flag for requiring that the space (column) by SQL type: datetime (timestamp)
                ==> Typically, the 'freq' column info ONLY applies to datetime (timestamp) columns
                ==> However, we may sometimes use the 'freq' into type with an integer column
                ==> along with a given frequency profile as a proxy for the associated datetimes.

        grace: Flag for graceful handling of invalid column name
        """
        if self.is_undefined:
            return None

        # Validate space arg
        space = self.validate_space(
            space,
            grace=grace,
            solo_required=True,
            time_space_required=time_space_required,
        )

        if space in self.spaces:
            pass
        elif grace:
            return None
        else:
            raise Exception(f"Absent space:{space}")

        return self.get_space_info(
            info_type="freq",
            space=space,
            grace=grace,
            allow_infer=allow_infer,
            assign_inferred=assign_inferred,
        )

    def _infer_freqs(
        self,
        time_spaces="<time_keyspaces>",
        freq_hint: str = "default_freq",
        assign_inferred: bool = True,
        force_reinfer: bool = True,
        grace: bool = True,
    ) -> dict:
        """
        Infers frequencies for the specified time-spaces in the Quble

            ==> NOTE: When freq_hint is dict (keys:time-space, value:freq_hint)
            ==> method ALSO infers freqs for keys(spaces) of freq_hint dict
            ==> (when these dict keys correspond to a valid time-space)

        :param time_spaces: time-spaces for frequencies to be inferred
        :type time_spaces: str or list of strings
                      (keywords may be used such as '<time_spaces>', '<time_keyspaces>', etc.
                      [See: :meth:`~qubles.core.quble.Quble.validate_valuespace`]

        :param freq_hint: (optional) frequency hint for frequency inference of time-keyspace(s)
        :type freq_hint: str, dictionary, None
            ==> None*: No hint
            ==> 'default_freq': use prevailing default frequency control from the RootLib()
            ==> str: will use the specified freq_hint for frequency inference against all time-keyspaces
            ==> dictionary: dictionary keys=(time) keyspaces, dictionary values=freq hint for a given keyspace
                            NOTE: when dictionary value=None, frequency inference is still performed but with no freq_hint

        :param assign_inferred: (optional) Flag to direct for info_type assignment
                                 of the inferred frequency for each time-keyspace
        :type assign_inferred: boolean (True*/False)

        :param force_reinfer: (optional) Flag to force reinference of frequency
                              (even if already present in column info)
                              [Otherwise, the frequency from the column info will be returned]
                              [NOTE: There is overhead in determining if already present]
        :type force_reinfer: boolean (True*/False)

        :param grace: (optional) flag for graceful handling of invalid or non-time space arg
        :type grace: bool (True*/False)

        :returns: dictionary of inferred frequencies for each time-keyspace in the Quble
        :rtype: dictionary
        """
        # Optional inference for all time-spaces (not just time-keyspaces)

        # Initialize the inferred_freqs
        inferred_freqs = {}

        # Handle trivial cases
        if self.is_undefined or time_spaces is None:
            return inferred_freqs

        # Validate time_spaces arg
        time_spaces = self.validate_space(
            time_spaces, grace=grace, coerce_to_list=True, time_space_required=True
        )

        # Return early if no time_spaces were specified
        if time_spaces is None:
            return inferred_freqs

        # Augment time_spaces with any content from freq_hint (dict)
        if isinstance(freq_hint, dict):
            # Here a dictionary has been provided with
            # specific frequency hints for each time-keyspace
            # Augment time_spaces (list) to ALSO include any
            # keys from freq_hint (dict) iff valid time-spaces
            if time_spaces is None:
                time_spaces = []
            elif isinstance(time_spaces, tuple):
                # Coerce tuple to a list to support appending below
                time_spaces = list(time_spaces)

            for space1 in freq_hint:
                if space1 is None or space1 in time_spaces:
                    # Already included in time_spaces
                    continue
                elif space1 not in self.time_spaces:
                    # space1 is NOT A VALID time-space
                    continue
                else:
                    time_spaces.append(space1)

        # Return empty dict if o time_spaces to infer
        if len(time_spaces) == 0:
            return inferred_freqs

        # Infer frequencies according to freq_hint arg
        if freq_hint is None or isinstance(freq_hint, str):
            for space1 in time_spaces:
                inferred_freqs[space1] = self._infer_freq(
                    space=space1,
                    freq_hint=freq_hint,
                    assign_inferred=assign_inferred,
                    force_reinfer=force_reinfer,
                )
        elif isinstance(freq_hint, dict):
            # Here a freq_hint dictionary has been provided with
            # specific frequency hints for each time-space

            for space1 in time_spaces:
                freq_hint1 = freq_hint[space1] if space1 in freq_hint else None
                # NOTE: it is OK if freq1 is None...frequency will still be inferred (but with no freq_hint)
                #   ==> User may intentionally use freq dictionary with a None value
                #   ==> to force an immediate frequency inference
                inferred_freqs[space1] = self._infer_freq(
                    space=space1,
                    freq_hint=freq_hint1,
                    assign_inferred=assign_inferred,
                    force_reinfer=force_reinfer,
                )
        else:
            raise Exception(
                f"Invalid freq_hint:{freq_hint}...dict,str or None expected"
            )

        # Return the inferred frequencies
        return inferred_freqs

    def _infer_all_freqs(
        self,
        freq_hint: str = "default_freq",
        assign_inferred: bool = True,
        force_reinfer: bool = True,
        include_valuespaces: bool = False,
    ) -> dict:
        """
        Infers frequencies for all time-(key)spaces of the Quble

        If include_valuespaces==True: infers all time-spaces (regardless of key or value role)
        If include_valuespaces==False: infers only time-keyspaces (excludes time-valuespaces)

        ~see qubles.core.quble.Quble._infer_freqs
        """
        if not isinstance(freq_hint, dict):
            time_spaces_to_infer = (
                self.time_spaces if include_valuespaces else self.time_keyspaces
            )
        elif include_valuespaces:
            # Infer all-time-spaces in this case
            time_spaces_to_infer = self.time_spaces
        else:
            # Added logic to include any time-valuespaces
            # provided as keys of the frequency hint dict
            # (even when include_valuespaces==False)
            # [Allows constructor for force inference for specific time-valuespaces]
            time_spaces_to_infer = [ks for ks in self.time_keyspaces]
            for time_space1 in freq_hint.keys():
                if (
                    time_space1 not in time_spaces_to_infer
                    and time_space1 in self.time_spaces
                ):
                    time_spaces_to_infer.append(time_space1)

        return self._infer_freqs(
            time_spaces=time_spaces_to_infer,
            freq_hint=freq_hint,
            assign_inferred=assign_inferred,
            force_reinfer=force_reinfer,
        )

    def _infer_freq(
        self,
        space: str = "<first_time_keyspace>",
        freq_hint: str = "default_freq",
        assign_inferred: bool = True,
        force_reinfer: bool = True,
        verbose: bool = False,
        grace: bool = True,
    ) -> str:
        """
        Infers and returns the frequency of the specified (time) space/column_name
        Also will assign the inferred frequency if directed

        :param space: the time-keyspace for which the frequency is to be inferred
        :type space: str

        :param freq_hint: (optional) hint for frequency inference of time-space(s)
        :type freq_hint: str
            ==> None: No hint
            ==> 'default_freq': use prevailing default frequency control from the RootLib()
            ==> str: a specific freq_hint for frequency inference

        :param assign_inferred: (optional) Flag to direct for info_type assignment
                                 of the inferred frequency for each time-keyspace
        :type assign_inferred: boolean (True*/False)

        :param force_reinfer: (optional) Flag to force reinference of frequency
                              (even if already present in column info)
                              [Otherwise, the frequency from the column info will be returned]
                              [NOTE: There is overhead in determining if already present]
        :type force_reinfer: boolean (True*/False)

        :param verbose: (optional) Flag to direct for inferred frequency display
        :type verbose: boolean (True/False*)

        :param grace: (optional) flag for graceful handling of invalid or non-time space arg
        :type grace: bool (True*/False)

        :returns: associated time-frequency
        :rtype: str
        """
        if self.is_undefined:
            return None

        # Validate space arg
        space = self.validate_space(
            space, grace=grace, solo_required=True, time_space_required=True
        )

        if space in self.spaces:
            pass
        elif grace:
            return None
        else:
            raise Exception(f"Absent space:{space}")

        # Ensure the specified keyspace is a time-keyspace
        # --------------------------------------------------
        if not self.is_time_space(space=space, grace=True):
            if grace:
                return None
            else:
                raise Exception(f"Cannot infer frequency for non-time space:{space}")

        # See if a frequency is already present in Quble's info_type
        # -----------------------------------------------------------
        if not force_reinfer and self.has_space_info(info_type="freq", space=space):
            return self.get_space_info(info_type="freq", space=space)

        # Establish candidate_freqs (order is important here)
        # ------------------------------------------------------
        if freq_hint == "default_freq":
            freq_hint = RootLib().get_control("freq")

        calendar_table = RootLib().get_control("calendar_table_name")
        freq_info_table = "FreqInfo"  # <-- can eventually make this a control and/or place in QUBLE_CONSTS

        # If the table has no records, we will accept the frequency hint
        # TODO: should freq_hint be None in the first case?
        if self.num_records is None:
            freq = freq_hint
        elif self.num_records == 0:
            freq = freq_hint
        else:
            freq_command = f'WITH dd AS (SELECT DISTINCT "{space}" FROM "{self.table_name}"), x AS (SELECT dd."{space}", c."Freq", c."Freq_idx" from dd left join "{calendar_table}" c on c."Dates"=DATE(dd."{space}") where c."Freq" IS NOT NULL and dd."{space}" IS NOT NULL), y AS (SELECT "Freq", COUNT(*) AS freq_hits FROM x GROUP BY "Freq") SELECT y."Freq", fi."PPY", fi."Infer_order" from y LEFT JOIN "{freq_info_table}" fi on fi."Freq"=y."Freq" WHERE y.freq_hits = (SELECT COUNT(*) FROM dd WHERE dd."{space}" IS NOT NULL) ORDER BY fi."Infer_order" ASC'

            freq_candidates = execute(freq_command, fetch="all")

            # Identify the best freq candidate
            if freq_candidates is None or not isinstance(
                freq_candidates, (list, tuple)
            ):
                raise Exception(
                    f"Invalid type(freq_candidates):{type(freq_candidates)}"
                )
            elif len(freq_candidates) == 0:
                freq = None
            else:
                # --------------------------------------------------------------------
                # At this point, freq_candidates should be a list of tuples
                # where each element in the list represents a row of the result set
                # and each inner tuple should have one element
                # (representing the contents of the one-and-only column for a given row)
                # --------------------------------------------------------------------
                # First, convert the result set (list of tuples)
                # into a simple list of candidates (strings)
                # drawn from the first/only column for each row
                # --------------------------------------------------------------------
                freq_candidate_list = [row1[0] for row1 in freq_candidates]
                if freq_hint is not None and freq_hint in freq_candidate_list:
                    freq = freq_hint
                else:
                    freq = freq_candidate_list[0]

        # Record the inferred freq (if authorized)
        if assign_inferred and freq:
            self.set_space_info(space=space, info_type="freq", info_value=freq)
        return freq

    @RootLib.lazy_kwargs()
    def asfreq(
        self,
        freq: str,
        keyspace: str = "<first_time_keyspace>",
        time_basis_override="<no override>",
        tdistribute_mode="<space_root>",
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        key_ordering="asc",
        exceptions_flag: bool = False,
        inplace: bool = False,
    ) -> Quble:
        """
        Changes the frequency of the specified time-keyspace

        :param freq: the desired new time-frequency
        :type freq: str (correspodning to a supported time freq)
        Examples:
        freq='CEOM': calendar month-end,
        freq='WEEKDAY': weekday/business days

        :param keyspace: the time-keyspace to be converted
        :type keyspace: typically str

        :param time_basis_override: override to space or global-settings
        :type time_basis_override: str (or None) or dictionary keyed per valuespace
                ==> '<no override>': for no override...in this case, will consult space info gracefully
                ==> '<None>' or 'None': to force time_basis=None

        :param tdistribute_mode: 'distribution' mode for converting from low-freq to high-freq
        :type tdistribute_mode: str (or None)

            'forward': distribute forward in time INCLUDING original end-point (no look-ahead bias)
                        [CEOM->DAILY Example: Apply the end-of-month values
                        TO original end-of-month point AND all intra-month days
                        in the NEXT-MONTH except the last day of next month]

            'xforward': distribute forward in time EXCLUDING original end-point (no look-ahead bias)
                        [CEOM->DAILY Example: Apply the end-of-month values
                        to all days in the NEXT-MONTH including the last day of next month
                        but do not apply to the original month-end date]

            'coincident': back-distribute (CAUTION: possible look ahead bias)
                          [CEOM->DAILY Example: Apply the end-of-month value
                          to all intra-month days DURING THE CURRENT month]

            'disallow': Do not allow converting from low-freq to high-freq (raises Exception)

        :param auto_link: Control for auto-linking (keyspace affiliation)
        :type auto_link: bool

        :param key_ordering: controls row ordering by key
        :type key_ordering: None, str or dictionary
           None: do not re-sort records in result
           str ('asc' or 'desc'): sort keys in ascending/descending order per each keyspace
           dictionary: dict keys (str): keyspaces, dict values (str): 'asc' or 'desc'
           ==> allows for assigning key ordering (ascending/descending)
           ==> (and relative priority) for each keyspace individually

        NOTE: tfill_method, tfill_max, aggr_method, link_check & link_dupe_grace are current not used,
              but supported here for legacy purposes

        :param exceptions_flag: flag whether to generate exceptions Quble
        :type exceptions_flag: (boolean) False*/True

        :returns: updated (resampled) Quble
        :rtype: Quble
        """
        # Validate table
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate keyspace
        # NOTE: grace=False so should fail here is keyspace is not in self
        keyspace = self.validate_keyspace(
            keyspace,
            auto_link=auto_link,
            grace=False,
            solo_required=True,
            time_space_required=True,
        )

        # Validate freq
        if freq is None:
            # Alternatively, could throw an error here
            return self if inplace else self.copy()
        elif freq not in PPY:
            raise Exception(f"Invalid (tgt) freq:{freq}")
        elif self.is_empty:
            # For empty Quble, we can simply assign the target freq
            # as there are no values to convert
            result = self if inplace else self.copy()
            result.set_space_info(space=keyspace, info_type="freq", info_value=freq)
            return result

        # Establish & validate existing src_freq
        src_freq = self.get_freq(keyspace, allow_infer=True, assign_inferred=True)

        if src_freq is None:
            pass
        elif src_freq == freq:
            return self if inplace else self.copy()
        elif src_freq not in PPY:
            raise Exception(f"Invalid src_freq:{src_freq}")

        # --------------------------------------------------
        # Establish subject & variate_provided flag
        # NOTE: Only refer to subject (not self) hereafter
        # --------------------------------------------------
        if self.is_nonvariate:
            # Build an (intermediate) boolean-univariate Quble
            variate_provided = False
            subject = self.index_to_bool()
        else:
            variate_provided = True
            subject = self

        # Ensure keyspace is (still) present in subject.keyspaces
        # This step is likly redundant and uneceesary
        if keyspace not in subject.keyspaces:
            raise Exception(
                f"keyspace:{keyspace} absent from subject.keyspaces:{subject.keyspaces}"
            )

        # ----------------------------------------------
        #        DISTRIBUTION VS AGGREGATION
        # ----------------------------------------------
        # Are we increasing the time frequency?
        #
        # Determine if we are 'distributing'
        # from a (coarse) lower-frequency
        # to a (finer, more granular) higher-frequency
        # Otherwise we are 'aggregating' from
        # a (fine, more granular) higher-freq
        # to a (coarser) lower-frequency
        # ----------------------------------------------
        # NOTE: (src_freq is None) is assumed to be
        # inherently high-frequency (ppy >> 1)
        # ----------------------------------------------
        if (src_freq is not None) and PPY[freq] > PPY[src_freq]:
            distribute_flag = True
        else:
            distribute_flag = False

        # ========================== START: VALUESPACES LOOP ========================
        tdistribute_modes = {}
        asfreq_techniques = {}
        time_bases = {}
        converting_vantage_flag = keyspace == "Vantage"
        for vs in subject.valuespaces:
            tdistribute_mode = subject._space_info_indirection(
                info_type="tdistribute_mode",
                space=vs,
                info_assignment=tdistribute_mode,
                grace=True,
            )
            if tdistribute_mode is None:
                tdistribute_mode = "forward"

            # Validate tdistribute_mode
            if not distribute_flag:
                # tdistribute_mode does not apply in this case
                pass
            elif tdistribute_mode in (
                "coincident",
                "forward",
                "xforward",
            ):  # <-- Possible look-ahead bias here for 'coincident' option
                pass
            elif tdistribute_mode == "disallow":
                raise Exception(
                    f"distribution disallowed...tdistribute_mode:{tdistribute_mode}"
                )
            else:
                raise Exception(
                    f"Invalid tdistribute_mode:{tdistribute_mode} for valuespace:{vs}"
                )

            # Establish time_basis for this valuespace
            # by considering the time_basis_override arg
            if time_basis_override is None or time_basis_override == "<no override>":
                # No override...consult space info gracfully
                # OK if time_basis = None here (aka no time-basis)
                time_basis = subject.get_space_info(
                    info_type="time_basis", space=vs, grace=True
                )
            elif time_basis_override in ("<None>", "None"):
                time_basis = None
            elif not isinstance(time_basis_override, dict):
                # time_basis_override presumed (required?) to be a scalar here
                time_basis = (
                    None if time_basis_override == "<None>" else time_basis_override
                )
            elif vs in time_basis_override:
                # Use the valuespace-specific override here
                # as provided in the time_basis_override dict
                time_basis = time_basis_override[vs]
            elif converting_vantage_flag:
                # Eventually, we will get more sophisticated on how we define a Vantage space
                time_basis = None
            else:
                # No valuespace-specific override provided,
                # so consult space info gracfully
                time_basis = subject.get_space_info(
                    info_type="time_basis", space=vs, grace=True
                )

            # Establish asfreq_techniques list & validate time_basis
            if distribute_flag:
                asfreq_technique = "freq_dist"
            elif time_basis in (None, "None", "first", "last"):
                asfreq_technique = "freq_aggr_via_endpt"
            elif time_basis in (
                "mean",
                "ave",
                "median",
                "sum",
                "high",
                "max",
                "low",
                "min",
                "cume",
                "prod",
                "geo_cume",
                "geo_mean",
                "geo_prod",
                "geo100_cume",
                "geo100_mean",
                "geo100_prod",
            ):
                asfreq_technique = "freq_aggr_via_stat"
            else:
                raise Exception(f"Invalid time_basis[{vs}]:{time_basis}")

            # Copy settings to dictionaries keyed by valuespace
            tdistribute_modes[vs] = tdistribute_mode
            asfreq_techniques[vs] = asfreq_technique
            time_bases[vs] = time_basis

        # ========================== END: VALUESPACES LOOP ========================
        calendar_table_name = RootLib().get_control("calendar_table_name")
        # ------------------------------------
        # Generate exceptions (if requested)
        # ------------------------------------
        exceptions = None
        if exceptions_flag:
            exceptions_table_name = generate_random_table_name()
            # Establish date_rank_direction
            if (
                subject.is_univariate
                and subject.valuespace is not None
                and subject.get_space_info(
                    info_type="time_basis", space=subject.valuespace, grace=True
                )
                == "first"
            ):
                # Here, we take FIRST record in each tgt_freq time-bin
                # and all other records are deemed exceptions
                date_rank_direction = "asc"
            else:
                # Here, we take LAST record in each tgt_freq time-bin
                # and all other records are deemed exceptions
                date_rank_direction = "desc"

            # Perform frequency conversion
            sql_template = JINJA_ENV.get_template("asfreq_exceptions.j2")
            sql_command = sql_template.render(
                src_table_name=subject.table_name,
                tgt_table_name=exceptions_table_name,
                tgt_freq=freq,
                calendar_table_name=calendar_table_name,
                keyspace=keyspace,
                keyspaces=subject.keyspaces,
                valuespaces=subject.valuespaces,
                distribute_flag=distribute_flag,
                date_rank_direction=date_rank_direction,
                key_ordering=key_ordering,
            )

            execute(sql_command)

            # Instantiate Quble from the new table
            exceptions = Quble.from_table(
                exceptions_table_name,
                col_info=self._column_info,
                freq_hint=src_freq if src_freq is not None else None,
                exceptions_flag=exceptions_flag,
            )

        # --------------------------
        # Generate main result...
        # --------------------------
        if inplace:
            table_name = self.table_name
        else:
            table_name = generate_random_table_name()

        # Build key_ordering dictionary when applicable
        if key_ordering is not None and not isinstance(key_ordering, str):
            key_ordering = build_key_ordering_dict(
                key_ordering, keyspaces=subject.keyspaces
            )
        # Perform frequency conversion
        # TODO: Consider adding ignore_missing arg to method signature and template signature below
        # to ignore (not ignore) null values in frequency aggregation operation
        sql_template = JINJA_ENV.get_template("asfreq.j2")
        sql_command = sql_template.render(
            src_table_name=subject.table_name,
            tgt_table_name=table_name,
            src_freq=src_freq,
            tgt_freq=freq,
            calendar_table_name=calendar_table_name,
            keyspace=keyspace,
            keyspaces=subject.keyspaces,
            valuespaces=subject.valuespaces,
            time_bases=time_bases,
            asfreq_techniques=asfreq_techniques,
            tdistribute_modes=tdistribute_modes,
            key_ordering=key_ordering,
        )
        execute(sql_command, format_flag=False)

        # Establish col_info for copy
        if table_name == subject.table_name:
            update_column_info(self._column_info, {"freq": {keyspace: freq}})
        else:
            col_info = subject.get_space_info(
                info_type=CUSTOM_INFO_TYPES,
                space="<all>",
                omit_unassigned=True,
            )

            # Institute freq info for the specific keyspace accordingly
            # [Assumes freq conversion command was successful]
            add_col_info = {"freq": {keyspace: freq}}

            # Adjust tfill_max for new freq accordingly (if applicable)
            # if subject.has_space_info(info_type='tfill_max', space=valuespace):
            for vs in subject.valuespaces:
                src_tfill_max = subject.get_space_info(
                    info_type="tfill_max", space=vs, grace=True
                )
                if src_tfill_max is not None and src_tfill_max > 0 and freq is not None:
                    # We do not adjust if src_tfill_max <= 0
                    tgt_tfill_max = int(
                        round((PPY[freq] / PPY[src_freq]) * src_tfill_max)
                    )
                    if "tfill_max" not in add_col_info:
                        add_col_info["tfill_max"] = {}
                    # Institute updated tgt_tfill_max for each valuespace (vs)
                    add_col_info["tfill_max"][vs] = tgt_tfill_max

            # Update the col_info with the 'freq' & 'tfill_max' assignments
            update_column_info(col_info, add_col_info)

        if inplace:
            self._clear_num_records_caches()
            result = self
        else:
            # Instantiate Quble from the new table
            result = Quble.from_table(
                table_name,
                col_info=col_info,
                valuespace=self.valuespace,
                exceptions_flag=exceptions_flag,
            )

        # ------------------------------------
        # Generate exceptions (if requested)
        # ------------------------------------
        if exceptions:
            self._extend_exceptions("Frequency", exceptions)

        # if variate was NOT provided, then convert back to index
        if not variate_provided:
            exceptions = result.exceptions
            result = result.bool_to_index()
            result.exceptions = exceptions

        return result

    @classmethod
    def build_dateranges(
        cls,
        daterange_mode,
        daterange_keyspace: str,
        dates_keyspace: str,
        date_index: Quble,
    ) -> Quble:
        """
        Generates a 2D index Quble for conditional analysis

        :param daterange_mode: conditional daterange modes to be analyzed
        :type daterange_mode: comma delimited string or a list of strings
                 ==> entries should correponds to valid daterange_mode options
                 [e.g., 'Mondays', 'Jans', DoW', 'DoM', etc.]

        :param daterange_keyspace: daterange keyspace name
        :type daterange_keyspace: str

        :param dates_keyspace: dates keyspace for date_index
        :type dates_keyspace: str
                 ==> Only applies when date_index is an numpy array of datetime64/datetime
                 ==> Otherwise, the dates keyspace from the date_index will be used

        :param date_index: candidate datetime
        :type date_index: 1D index Quble or 1D boolean Quble

        Returns a 2D index Quble (dates_keyspace x daterange_keyspace)

        """
        # Validate/massage date_index
        if date_index is None:
            return None

        if not isinstance(date_index, Quble):
            raise Exception("Invalid date_index: Quble expected")
        elif date_index.is_index:
            pass
        elif date_index.is_bool():
            # Force bool to index
            date_index = date_index.bool_to_index(key_ordering=None)
        else:
            raise Exception("Invalid date_index: index or bool Quble expected")

        # Ensure single-dimension time-indexed Quble
        if date_index.ndim != 1:
            raise Exception(
                "Invalid date_index: single dimension time-indexed Quble required"
            )
        elif not date_index.has_time_keyspaces:
            raise Exception(
                "Invalid date_index: single dimension time-indexed Quble required"
            )

        orig_dates_keyspace = date_index.first_time_keyspace(grace=False)

        # Impose dates_keyspace (if necessary)
        if dates_keyspace is None:
            dates_keyspace = orig_dates_keyspace
        elif dates_keyspace != orig_dates_keyspace:
            date_index = date_index.rekeyspace(
                keyspace=orig_dates_keyspace, tgt_keyspace=dates_keyspace
            )

        if dates_keyspace is None:
            raise Exception("Not able to infer dates_keyspace")
        elif dates_keyspace not in date_index.keyspaces:
            raise Exception(
                f"date_index does not support dates_keyspace:{dates_keyspace}"
            )

        # Should we check/handle empty date_index here??
        if isinstance(daterange_mode, str):
            daterange_mode = split(",", daterange_mode)

        if not isinstance(daterange_mode, list) and not isinstance(
            daterange_mode, tuple
        ):
            raise Exception(
                "Invalid daterange_mode arg: str, list or tuple (of strings) expected"
            )

        # Expand daterange_mode (tuple or list)
        # into date_range_keys where applicable
        # -------------------------------------------
        date_range_keys = []
        for drm in daterange_mode:
            if drm == "DoW":  # <-- Days of the Week
                date_range_keys += ["Mons", "Tues", "Weds", "Thus", "Fris"]
            elif drm == "DoM":  # <-- Days of the Month
                # for dom_no in range(21):
                # date_range_keys.append(f"DoM.{str(dom_no + 1)}")
                for dom_no in range(10, 0, -1):
                    date_range_keys.append(f"DoM.-{str(dom_no)}")
                for dom_no in range(10):
                    date_range_keys.append(f"DoM.{str(dom_no + 1)}")
            elif drm == "WoM":  # <-- Weeks of the Month
                # for wom_no in range(4):
                # date_range_keys.append(f"WoM.{str(wom_no + 1)}")
                for dom_no in range(2, 0, -1):
                    date_range_keys.append(f"WoM.-{str(dom_no)}")
                for dom_no in range(2):
                    date_range_keys.append(f"WoM.{str(dom_no + 1)}")
            elif drm == "MoQ":  # <-- Months of the Quarter
                date_range_keys += ["MoQ.1", "MoQ.2", "MoQ.3"]
            elif drm == "MoY":  # <-- Months of the Year
                date_range_keys += [
                    "Jans",
                    "Febs",
                    "Mars",
                    "Aprs",
                    "Mays",
                    "Juns",
                    "Juls",
                    "Augs",
                    "Seps",
                    "Octs",
                    "Novs",
                    "Decs",
                ]
            elif drm == "QoY":  # <-- Months of the Quarter
                date_range_keys += ["QoY.1", "QoY.2", "QoY.3", "QoY.4"]
            elif drm == "SoY":  # <-- Seasons of the Year
                date_range_keys += ["Springs", "Summers", "Falls", "Winters"]
            elif drm == "Years":  # <-- All (Applicable) Years
                dates_array = date_index.distinct_index_array1d(
                    keyspace=dates_keyspace, contiguous_flag=False, key_ordering="asc"
                )
                if dates_array is not None and len(dates_array) > 0:
                    # To save time, we only need first (earliest) & last (latest) dates
                    # (NOTE: It is OK if there is only one element)
                    dates_array_first_last = dates_array[[0, -1]]
                    first_year = (
                        dates_array_first_last[0].astype("datetime64[Y]").astype(int)
                        + 1970
                    )  # Earliest year
                    last_year = (
                        dates_array_first_last[-1].astype("datetime64[Y]").astype(int)
                        + 1970
                    )  # Latest year
                    years = range(first_year, last_year + 1)
                    for year in years:
                        date_range_keys.append(str(year))
            elif drm == "All":  # <-- All Dates
                date_range_keys.append(drm)
            # Unexpected Case...
            # ---------------------
            else:
                # Hope for the best here, if it is not covered
                # then it will be trapped below
                date_range_keys.append(drm)

        date_ranges = None
        # Load the Standard Date Ranges (if needed)
        # --------------------------------------------
        if len(date_range_keys) == 0:
            # No date ranges requested here
            if daterange_keyspace is None:
                daterange_keyspace = "Date Ranges"
            # Here, the key='All' will not actually appear as there will be no records
            date_ranges = date_index.clear().insert_keyspace(
                keyspace=daterange_keyspace, key="All"
            )
        elif date_range_keys == ["All"]:
            # Only 'All' date range requested here
            if daterange_keyspace is None:
                daterange_keyspace = "Date Ranges"
            date_ranges = date_index.insert_keyspace(
                keyspace=daterange_keyspace, key="All"
            )
        else:
            # Non-trivial date ranges requested...need to consult STANDARD_DATE_RANGES
            sdr_str_address = (
                f"UTILS{RootLib().get_control('index_delimiter')}STANDARD_DATE_RANGES"
            )
            standard_date_ranges = RootLib()[sdr_str_address]
            # Validate & reindex standard_date_ranges
            if standard_date_ranges is None:
                # STANDARD_DATE_RANGES not available
                date_ranges = None
            elif not isinstance(standard_date_ranges, (Quble)):
                raise Exception(
                    f"sdr_str_address resolved to type:{standard_date_ranges}"
                )
            else:
                if standard_date_ranges.ndim != 2:
                    raise Exception("Invalid standard_date_ranges:2D index Quble")

                sdr_dates_keyspace = standard_date_ranges.first_time_keyspace(
                    grace=False
                )
                # Here, locate sdr_daterange_keyspace as the
                # keyspace of standard_date_ranges that is NOT sdr_dates_keyspace
                sdr_daterange_keyspace = None
                for ks in standard_date_ranges.keyspaces:
                    if ks != sdr_dates_keyspace:
                        sdr_daterange_keyspace = ks
                        break

                # Make sure standard_date_ranges has been converted to 2D time-indexed bool Quble
                if standard_date_ranges.is_index:
                    standard_date_ranges = standard_date_ranges.index_to_bool()
                elif not standard_date_ranges.is_bool():
                    raise Exception(
                        "Invalid standard_date_ranges:bool or Index Quble expected"
                    )

                if sdr_dates_keyspace is None:
                    raise Exception("Unable to infer sdr_dates_keyspace")
                elif sdr_daterange_keyspace is None:
                    raise Exception("Unable to infer sdr_daterange_keyspace")

                # Limit standard_date_ranges to only date_ranges of interest
                standard_date_key_index = Quble(
                    data={sdr_daterange_keyspace: date_range_keys}, valuespace=None
                )

                # Initialize date_ranges
                # by projecting standard_date_key_index onto standard_date_ranges
                date_ranges = standard_date_ranges.inner_project(
                    index=standard_date_key_index
                )

                if date_ranges.is_index:
                    date_ranges = date_ranges.index_to_bool()

                if daterange_keyspace is None:
                    daterange_keyspace = sdr_dates_keyspace

                # Rekeyspace standard_date_ranges if needed
                if (sdr_dates_keyspace != dates_keyspace) or (
                    sdr_daterange_keyspace != daterange_keyspace
                ):
                    column_name_dict = {
                        sdr_dates_keyspace: dates_keyspace,
                        sdr_daterange_keyspace: daterange_keyspace,
                    }
                    if date_ranges.valuespace is not None:
                        column_name_dict[date_ranges.valuespace] = (
                            date_ranges.valuespace
                        )

                    date_ranges = date_ranges.select(column_names=column_name_dict)

                # Project the date_index onto the standard_date_ranges
                # This step may involve an implicit frequency change
                # Which is why we needed to (temporarily) make date_ranges a boolean-valued Quble
                date_ranges = date_ranges.inner_project(index=date_index)

                # (Re)convert date_ranges boolean values Quble to an index Quble
                date_ranges = date_ranges.bool_to_index(key_ordering=None)

            # Add 'All' dates (when requested)
            if ("All" in daterange_mode) and (date_index is not None):
                all_dates = date_index.insert_keyspace(
                    keyspace=daterange_keyspace, key="All"
                )
                if date_ranges is None:
                    date_ranges = all_dates
                else:
                    date_ranges.merge_inplace(all_dates, self_precedence=True)

        return date_ranges

    @RootLib.temp_frame()
    def convert_fx(
        self, fx, valuespace="<currency_valuespaces>", fxlib="FX", grace: bool = False
    ) -> Quble:
        """
        Applies fx conversion to specified valuespace(s) of the Quble
        All original valuespaces will be retained in result
        (but only the specified valuespace(s) will be converted/altered)

        :param fx: target fx
        :type fx: str or dictionary per valuespace
        ==> Assignments can be traditional (three-character ISO) fx (e.g., 'USD','EUR', ...)
        or an security-specific fx "scheme" (e.g., 'PRC','REP','EST','HRP')

        :param valuespace: valuespace(s) to convert
        :type valuespace: str or list of strings
                    (keywords may be used such as '<valuespaces>', '<valuespace>', etc.
                    [See: :meth:`~qubles.core.quble.Quble.validate_valuespace`]

        :param fxlib: fx library for currency conversion data
        :type fxlib: str (address) or list (address) or DataLib
             ==> Library should support fields: 'PER_GBP_C', 'PER_GBP_M', 'PER_GBP_D', etc...
             ==> These fields should support <fx> keyspace for qualification of a specific cross-fx rate

        :param grace: flag for graceful handling
                      of invalid args (e.g., valuespace etc)
        :type fxlib: bool (False*/True)

        :rtype: qubles.core.quble.Quble
        :returns: Quble with currencies converted accordingly
        """
        # Validate table
        if self.is_undefined:
            if fx is not None and not grace:
                raise UndefinedQubleError("Undefined Quble (no table)")
            else:
                return self.copy()

        # Handle (non-variate) index case
        # with trivial valuespace & fx assignment
        if (
            self.is_nonvariate
            and fx is None
            and valuespace in ("<valuespace>", "<valuespaces>", None)
        ):
            return self.copy()

        # Validate valuespace arg
        valuespace = self.validate_valuespace(
            valuespace, grace=False, coerce_to_list=True
        )  # <- Could is grace=False here?
        # Trap for trivial case of no valuespaces to be converted
        # Can happen when no numeric valuespaces are present
        # or the specified valuespace is non-numeric
        if len(valuespace) == 0:
            return self.copy()

        # ---------------------------------
        # Make a copy of self and
        # only refer to subject hereafter
        # ---------------------------------
        subject = self.copy()

        # Infer dates_keyspace (if present) from within subject.keyspaces
        # ----------------------------------------------------------------
        dates_keyspace = subject.first_time_keyspace()

        # -----------------
        # Initialize base_fx
        # (will be reset per valuespace below)
        # -------------------------------------
        base_fx = subject.fx  # <-- Starting fx
        # ====================================
        # SET TEMPORARY FRAME PARAMETERS
        # ====================================

        RootLib().set_control("ignore_mult", False)
        RootLib().set_control("ignore_add", False)
        RootLib().set_control("auto_fx", False)
        RootLib().set_control("variate_mode", "uni")

        converted_quble = Quble(dtype="undefined")
        per_gbp = None  # <-- Will be procured when needed later
        id_keyspace = None  # <-- Will be procured when needed later

        # =============================== START: VALUESPACE LOOP ==================================
        for vs in valuespace:
            if isinstance(fx, dict):
                if vs not in fx:
                    # Here, we asssume user intentaionally
                    # chose not to change this particular valuespace
                    # since it was left out of the dictionary
                    pass
                else:
                    tgt_fx = fx[vs]
            else:
                tgt_fx = fx

            base_fx = subject.get_space_info(info_type="fx", space=vs, grace=True)
            time_basis = subject.get_space_info(
                info_type="time_basis", space=vs, grace=True
            )

            # ===========================
            # Check for trivial cases
            # ===========================
            if tgt_fx == base_fx:
                # No conversion needed
                continue
            elif (
                subject.is_datetime(vs)
                or subject.is_bool(vs)
                or subject.is_str(vs)
                or subject.is_binary(vs)
            ):  # <-- May be safer than not subject.is_numeric(vs)
                # --------------------------------------------------------------
                # Raise Exception for non-numeric valuespaces unless grace=True
                # --------------------------------------------------------------
                if grace:
                    # Ignore the tgt_fx request here
                    continue
                else:
                    raise Exception(
                        f"Cannot convert fx for non-numeric valuespace:{vs}"
                    )

            elif (tgt_fx is None) or (base_fx is None):
                # ----------------------------------------------------------
                # Since, tgt_fx != base_fx, we know that
                # one is None and the other is not None
                # ----------------------------------------------------------
                # In other words, we are trying to assign either:
                #    1) trivial-fx (fx=None) -> non-trivial fx (fx='USD',...)
                # or 2) non-trivial fx (fx='USD',...) -> non-fx (fx=None)
                # ----------------------------------------------------------
                # Only allow such actions when grace=True
                # ----------------------------------------------------------
                if grace:
                    # No explicit conversion needed...gracefully assign/unassign fx for this valuespace
                    subject.set_space_info(space=vs, info_type="fx", info_value=tgt_fx)
                    continue
                else:
                    raise Exception(
                        "grace={0} converting base_fx:{1} -> tgt_fx:{2}...use grace=True".format(
                            grace, base_fx, tgt_fx
                        )
                    )
            elif subject.is_empty:
                # No data to convert...merely assign fx for this valuespace
                subject.set_space_info(space=vs, info_type="fx", info_value=tgt_fx)
                continue
            # ---------------------------------------------
            # Throw an error if no time dimension present
            # and we are try to convert returns data
            # ---------------------------------------------
            elif (dates_keyspace is None) and (time_basis == "geo_cume"):
                raise Exception(
                    "Need time-dimension to convert fx for (returns) valuespace:{0} with time_basis:{1}".format(
                        vs, time_basis
                    )
                )

            # ======================================================
            # PROCURE per_gbp FROM fxlib (if not already done so)
            # ======================================================
            # ====================== START: Procure per_gbp ====================
            if per_gbp is None:
                # Make sure fxlib is available...
                # ------------------------------------
                if fxlib is None:
                    raise Exception("No fxlib provided")
                elif isinstance(fxlib, DataLib):
                    pass
                elif isinstance(fxlib, str):
                    if fxlib not in RootLib().field_index:
                        raise Exception(
                            "No {0} library present in RootLib...needed to access fx information".format(
                                fxlib
                            )
                        )
                    fxlib_orig = fxlib
                    fxlib = RootLib()[fxlib]
                    if not isinstance(fxlib, DataLib):
                        raise Exception(
                            f"RootLib()[{fxlib_orig}] did not yield a DataLib"
                        )

                elif isinstance(fxlib, LibAddress):
                    fxlib_orig = fxlib
                    fxlib = RootLib()[fxlib]
                    if not isinstance(fxlib, DataLib):
                        raise Exception(
                            f"RootLib()[{fxlib_orig}] did not yield a DataLib"
                        )
                else:
                    raise Exception(
                        f"Invalid fxlib:{fxlib}...str/DataLib/LibAddress required"
                    )

                # ================ START: if/else dates_keyspace ===============
                # Access non-time/time version depending on dates_keyspace
                if (
                    dates_keyspace is None
                ):  # <-- Object to be converted does not exhibit a time dimension
                    per_gbp_field = "PER_GBP_C"
                    per_gbp = fxlib.get(per_gbp_field, suppress_recording=True)
                else:
                    # Procure per_gbp (with only needed currencies)
                    # -----------------------------------------------
                    if (
                        subject.get_space_info(info_type="freq", space=dates_keyspace)
                        == "CEOM"
                    ) and ("PER_GBP_M" in fxlib.field_index):
                        per_gbp_field = "PER_GBP_M"
                    else:
                        per_gbp_field = "PER_GBP_D"

                    per_gbp = fxlib.get(per_gbp_field, suppress_recording=True)

                    # Procure dates_keyspace_fx (dates_keyspace used by FX library)
                    # ----------------------------------------------------------------
                    dates_keyspace_fx = per_gbp.first_time_keyspace(grace=True)

                    if dates_keyspace_fx is None:
                        raise Exception("dates_keyspace_fx not specified nor inferred")
                    elif dates_keyspace_fx not in per_gbp.keyspaces:
                        raise Exception(
                            "Absent keyspace:{0} within fxlib['{1}']".format(
                                dates_keyspace_fx, per_gbp_field
                            )
                        )
                    # Reconcile date_keyspace (if required)
                    # ---------------------------------------
                    if dates_keyspace_fx != dates_keyspace:
                        per_gbp = per_gbp.rekeyspace(
                            keyspace=dates_keyspace_fx, tgt_keyspace=dates_keyspace
                        )
                    # Reindex dates_keyspace of per_gbp
                    # Also, fill by additional 5 periods
                    # (for better coverage)
                    # ---------------------------------

                    per_gbp = per_gbp.reindex1d(
                        subject, keyspace=dates_keyspace
                    ).fill1d(
                        dates_keyspace,
                        tfill_method="pad",
                        tfill_max=5,
                        original_dates_only=True,
                        tfill_end_mode="no_extension",
                    )
                # ================= END: if/else dates_keyspace ================

                # Validate the resultant per_gbp
                # ---------------------------------
                if per_gbp.is_empty:
                    raise Exception(f"Empty: fxlib['{per_gbp_field}']")
                elif "FX" not in per_gbp.keyspaces:
                    raise Exception(f"No FX keyspace in: fxlib['{per_gbp_field}']")
                elif not per_gbp.is_univariate:
                    raise Exception("per_gbp is not univariate")

            # ======================= END: Procure per_gbp =====================

            # ====================================================================
            # (SIMPLE) CASE 1: Standard FX conversions (non-company specific)
            # ====================================================================
            if (tgt_fx not in ("REP", "PRC", "EST", "DOM", "LCL", "LOCAL", "HRP")) and (
                base_fx not in ("REP", "PRC", "EST", "DOM", "LCL", "LOCAL", "HRP")
            ):
                if not per_gbp.has_key1d(keyspace="FX", key=tgt_fx):
                    raise Exception(
                        "Unsupported/absent FX tgt_fx_key: fxlib['{0}']['FX:{1}']".format(
                            per_gbp_field, tgt_fx
                        )
                    )
                elif not per_gbp.has_key1d(keyspace="FX", key=base_fx):
                    raise Exception(
                        "Unsupported/absent FX base_fx_key: fxlib['{0}']['FX:{1}']".format(
                            per_gbp_field, base_fx
                        )
                    )

                # Compute cross-rate: tgt_per_base
                # ---------------------------------
                tgt_per_base = per_gbp.get1d(
                    tgt_fx, keyspace="FX", auto_squeeze=True
                ) / per_gbp.get1d(base_fx, keyspace="FX", auto_squeeze=True)

                # Apply FX conversion
                # -----------------------
                if (dates_keyspace in tgt_per_base.keyspaces) and (
                    time_basis == "geo_cume"
                ):
                    cross_ratio = tgt_per_base / tgt_per_base.shift1d(
                        1, dates_keyspace, tfill_end_mode="no_extension"
                    )
                    converted_quble[vs] = ((subject + 1.0) * cross_ratio) - 1.0
                    # Can use below code if we want to allow ignore_mult='right' for no fx information
                    # self_plus_one = (subject + 1.0)
                    # RootLib().set_control('ignore_mult', 'right')
                    # converted_quble_plus_one = (self_plus_one * cross_ratio)
                    # converted_quble = new_quble_plus_one - 1.0
                else:
                    converted_quble[vs] = subject[vs] * tgt_per_base

            # ========================================================================
            # CASE 2: Non-Standard FX conversions (company specific)
            # ------------------------------------------------------------------------
            # tgt_fx or base_fx involves: ('REP','PRC','EST','DOM','LCL','LOCAL','HRP')
            # ========================================================================
            else:
                # ----------------------------------------------
                # Procure id_keyspace (if not yet done so)
                # ----------------------------------------------
                if id_keyspace is None:
                    if "SECMSTR" not in RootLib().field_index:
                        raise Exception(
                            "No SECMSTR present...needed to infer asset_kesypace"
                        )

                    id_keyspace = subject.validate_keyspace(
                        "<SECMSTR>", auto_link=True, grace=True
                    )

                    if id_keyspace is None:
                        # NO IDENTIFIER DIMENSION IDENTIFIED
                        raise Exception(
                            "NO identifier keyspace found...Check for presence of SECMSTR library in RootLib() and/or id_keyspace in Quble"
                        )

                # Create a Surrogate for HRP
                # ----------------------------
                HRP_SURROGATE = (
                    "REP"  # <-- Set this to None when directly handling 'HRP'
                )

                # --------------------------------
                # Establish base_fx structure
                # --------------------------------
                if base_fx in ("REP", "PRC", "EST", "DOM"):
                    base_fx_scheme_name = f"{base_fx}_FX"
                elif base_fx in ("LCL", "LOCAL"):
                    base_fx_scheme_name = "LCL_FX"
                elif base_fx == "HRP":
                    if HRP_SURROGATE is not None:
                        # Temporary solution
                        base_fx_scheme_name = f"{HRP_SURROGATE}_FX"
                    else:
                        base_fx_scheme_name = f"{tgt_fx}_FX"
                else:
                    # base_fx should be a standard fx code here
                    base_fx_scheme_name = None

                # NOTE: fx_scheme will be a 1-D Quble (id_keyspace)
                #       with associated FX assignment per each security
                if base_fx_scheme_name is None:
                    # base_fx should be a standard fx code here
                    base_fx_scheme = None
                    base_fx_per_gbp = per_gbp.get1d(
                        base_fx, keyspace="FX", auto_squeeze=True
                    )
                else:
                    base_fx_scheme = fxlib.get(
                        base_fx_scheme_name, suppress_recording=True
                    )
                    base_fx_scheme = base_fx_scheme.link_keyspaces(
                        id_keyspace,
                        link_check=False,
                        link_dupe_grace=True,
                        deep_copy=False,
                        grace=True,
                    )

                    # Reduce the asset ids in base_fx_scheme to
                    # only those in subject then compress [rest are wasteful / not needed]
                    base_fx_scheme = base_fx_scheme.intersect1d(
                        subject, keyspace=id_keyspace
                    )
                    if (
                        base_fx_scheme.valuespace is not None
                        and base_fx_scheme.valuespace != "FX"
                    ):
                        base_fx_scheme.rename_space(
                            base_fx_scheme.valuespace, "FX", inplace=True
                        )

                    base_fx_per_gbp = per_gbp.remap1d(
                        base_fx_scheme,
                        keyspace="FX",
                        tgt_keyspace=id_keyspace,
                        map_type="aggregate",
                        map_basis=None,
                    )

                # --------------------------------
                # Establish tgt_fx structure
                # --------------------------------
                if tgt_fx in ("REP", "PRC", "EST", "DOM"):
                    tgt_fx_scheme_name = f"{tgt_fx}_FX"
                elif tgt_fx in ("LCL", "LOCAL"):
                    tgt_fx_scheme_name = "LCL_FX"
                elif tgt_fx == "HRP":
                    if HRP_SURROGATE is not None:
                        tgt_fx_scheme_name = (
                            f"{HRP_SURROGATE}_FX"  # <-- Temporary solution
                        )
                    else:
                        tgt_fx_scheme_name = f"{tgt_fx}_FX"
                else:  # <-- fx should be a standard fx code here
                    tgt_fx_scheme_name = None

                # NOTE: fx_scheme will be a 1-D Quble (id_keyspace) with associated FX assignment per each security
                if tgt_fx_scheme_name is None:
                    tgt_fx1 = tgt_fx  # <-- tgt_fx should be a standard fx code here
                    tgt_fx_scheme = None
                    tgt_fx_per_gbp = per_gbp.get1d(
                        tgt_fx1, keyspace="FX", auto_squeeze=True
                    )
                else:
                    tgt_fx_scheme = fxlib.get(
                        tgt_fx_scheme_name, suppress_recording=True
                    )
                    tgt_fx_scheme = tgt_fx_scheme.link_keyspaces(
                        id_keyspace,
                        link_check=False,
                        link_dupe_grace=True,
                        deep_copy=False,
                        grace=True,
                    )
                    # Reduce the asset ids in tgt_fx_scheme to
                    # only those in subject then compress [rest of the ids are wasteful / not needed]
                    tgt_fx_scheme = tgt_fx_scheme.intersect1d(
                        subject, keyspace=id_keyspace
                    )
                    tgt_fx_scheme.compress(inplace=True)
                    if (
                        tgt_fx_scheme.valuespace is not None
                        and tgt_fx_scheme.valuespace != "FX"
                    ):
                        tgt_fx_scheme.rename_space(
                            tgt_fx_scheme.valuespace, "FX", inplace=True
                        )

                    tgt_fx_per_gbp = per_gbp.remap1d(
                        tgt_fx_scheme,
                        keyspace="FX",
                        tgt_keyspace=id_keyspace,
                        map_type="aggregate",
                        map_basis=None,
                    )

                # Compute cross-rate: tgt_per_base
                # ---------------------------------
                tgt_per_base = tgt_fx_per_gbp / base_fx_per_gbp

                # Apply FX conversion
                # -----------------------
                if (dates_keyspace in tgt_per_base.keyspaces) and (
                    time_basis == "geo_cume"
                ):
                    cross_ratio = tgt_per_base / tgt_per_base.shift1d(
                        1, dates_keyspace, tfill_end_mode="no_extension"
                    )
                    converted_quble[vs] = ((subject[vs] + 1.0) * cross_ratio) - 1.0
                else:
                    converted_quble[vs] = subject[vs] * tgt_per_base

            # Finally, record the new fx for this valuespace
            # per the conversion that was performed above
            converted_quble.set_space_info(space=vs, info_type="fx", info_value=tgt_fx)

        # =============================== END: VALUESPACE LOOP ==================================

        # Which subject.valuespaces were converted/unconverted?
        unconverted_valuespaces = []
        converted_valuespaces = []
        for vs in subject.valuespaces:
            if vs not in converted_quble.valuespaces:
                unconverted_valuespaces.append(vs)
            else:
                converted_valuespaces.append(vs)
        # ====================================
        # Return the result according to
        # converted/unconverted valuespaces
        # ====================================
        if len(converted_valuespaces) == 0:
            # No valuespaces were converted
            # [Here, some may have been handled via mere fx property reassignment]
            return subject
        elif len(unconverted_valuespaces) == 0:
            # All the original valuespaces were converted
            # These converted valuespaces are in converted_quble
            result_quble = converted_quble
        else:
            # Some (but not all) of the original
            # valuespaces were converted
            # ==> Rejoin converted_quble to reintroduce unconverted_valuespaces
            valuespaces_join_op = []

            # Create valuespaces_join_op[0] as a dict
            # These valuespaces to be sourced from original (unconverted) subject
            valuespaces_join_op.append({})
            for vs in unconverted_valuespaces:
                valuespaces_join_op[0][vs] = vs

            # Create valuespaces_join_op[1] as a dict
            # These valuespaces to be sourced from the converted_quble
            valuespaces_join_op.append({})
            for vs in converted_valuespaces:
                valuespaces_join_op[1][vs] = vs

            # NOTE: We are imposing the original keys & keyspaces on the result
            #   ==> keys_join_op='left' & keyspaces_join_op='left'
            result_quble = subject.join(
                other=converted_quble,
                keys_join_op="leftmost",
                keyspaces_join_op="left",
                valuespaces_join_op=valuespaces_join_op,
            )
        result_quble.promote_valuespace_inplace(valuespace=subject.valuespace)
        return result_quble

    @property
    def as_index(self) -> Quble:
        return self.drop_valuespaces

    @property
    def drop_valuespaces(self) -> Quble:
        """
        Drops all valuespaces from a Quble
        The result will be an index_only Quble
        """
        if len(self.valuespaces) == 0:
            return self.copy()
        elif len(self.keyspaces) > 0:
            return self.select(column_names=self.keyspaces)
        elif self.is_scalar:
            raise Exception("Cannot drop valuespace from a scalar Quble")
        else:
            raise Exception("Cannot drop valuespace when no keyspaces are present")

    def link_keyspaces(
        self,
        keyspaces,
        keyspace_aliases=None,
        link_check: bool = False,
        link_dupe_grace: bool = True,
        deep_copy: bool = False,
        grace: bool = True,
    ) -> Quble:
        """
        Attempts to "link-in" any of the specified keyspaces
        by first applying simple keyspace_aliases (if provided)
        then invoking applicable "linking keymaps" from
        the available RefLibs currently present in the RootLib

        :param keyspaces: desired keyspaces to be linked to (where applicable)
        :type keyspaces: list of strings (or individual str)

        :param keyspace_aliases: (optional) list/tuple of lists/tuples/sets
                                  OR dictionary of lists/tuples/sets
                                  providing families of keyspace aliases
                            dictionary keys: alias group name
                            dictionary values: list/tuple/set of aliased keyspaces
        :type keyspace_aliases: dict/list/tuple of lists/tuples/sets (or None)

        :param link_check: flag to check the linking keymap
        :type link_check: bool (False*/True)

        :param link_dupe_grace: flag allow for duplicates in the linking keymap
        :type link_dupe_grace: bool (True*/False)

        :param deep_copy: If True, guarantees that a copy (or modified) result is returned
        :type deep_copy: (False*/True)

        :param grace: (boolean) controls for behavior when no keymap linking occurs
        :type grace: (True*/False)

        :rtype: qubles.core.quble.Quble
        :returns: Quble with desired keys linked-in where possible/applicable
        """
        if isinstance(keyspaces, str):
            keyspaces = [keyspaces]

        # Make a copy of self and only
        # refer to adj_self hereafter
        adj_self = self

        # ortho_src_keyspaces are keymap.keyspaces that are NOT INCLUDED in self.keyspaces
        # (and will therefore EXCLUDE keyspace arg as well)
        # ortho_src_keyspaces: source keyspace candidates for possible linking
        ortho_src_keyspaces = adj_self.ortho_keyspaces(keyspaces)

        # absent_tgt_keyspaces WILL ONLY INCLUDE hyper_key.keyspaces NOT PRESENT in self.keyspaces
        # absent_tgt_keyspaces: desired/target keyspace candidates to be linked to
        absent_tgt_keyspaces = adj_self.absent_keyspaces(keyspaces)

        # -----------------------------------------------
        # First, apply keyspace_aliases (when provided)
        # -----------------------------------------------

        # Convert keyspace_aliases from dict of lists/tuples -> list of lists/tuples
        if isinstance(keyspace_aliases, dict):
            aliases_as_list = []
            for alias_group_name, ks_aliases in keyspace_aliases.items():
                if ks_aliases is None:
                    continue
                elif not isinstance(ks_aliases, (list, tuple, set)):
                    raise Exception(
                        f"Invalid dict entry keyspace_aliases:[{alias_group_name}]:{ks_aliases}...list/tuple/set dict values expected"
                    )
                aliases_as_list.append(ks_aliases)
            keyspace_aliases = aliases_as_list

        # At this point, keyspace_aliases should be either:
        #    1) None
        # or 2) a list/tuple of lists/tuples
        if keyspace_aliases is None:
            pass
        elif not isinstance(keyspace_aliases, (list, tuple)):
            raise Exception(
                f"Invalid keyspace_aliases:{keyspace_aliases}...dict/list of lists/tuples/sets (or None) expected"
            )
        elif len(keyspace_aliases) == 0:
            pass
        elif (len(ortho_src_keyspaces) > 0) and (len(absent_tgt_keyspaces) > 0):
            keyspaces_rename_map = {}
            for ks_aliases1 in keyspace_aliases:
                # Validate ks_aliases1
                if ks_aliases1 is None:
                    continue
                elif not isinstance(ks_aliases1, (list, tuple, set)):
                    raise Exception(
                        f"Invalid keyspace_aliases:{keyspace_aliases}...dict/list of lists/tuples/sets (or None) expected"
                    )

                # Remove None elements from current ks_aliases1 (to be safe)
                # Then create a set for comparison (will eliminate duplicates)
                ks_aliases1 = set([ks for ks in ks_aliases1 if ks is not None])

                if len(ks_aliases1) <= 1:
                    # Need more than one alias to be relevant
                    continue

                # Loop through the ortho_src_keyspaces
                for src_ks in ortho_src_keyspaces:
                    if src_ks in keyspaces_rename_map:
                        # Has this src_ks (ortho keyspace) been remapped yet?
                        continue
                    elif src_ks in ks_aliases1:
                        # Does this src_ks (ortho keyspace) of adj_self appear in these ks_aliases1?
                        # AND do any of the absent_tgt_keyspaces ALSO appear in the same ks_aliases1?
                        for tgt_ks in absent_tgt_keyspaces:
                            if tgt_ks == src_ks:
                                # This case should ideally NOT happen
                                # due to non-overlapping lists:
                                # ortho_src_keyspaces & absent_tgt_keyspaces
                                continue
                            elif tgt_ks in keyspaces_rename_map.values():
                                # Has this tgt_ks (absent keyspace) been included in the remap yet?
                                continue
                            elif tgt_ks in ks_aliases1:
                                keyspaces_rename_map[src_ks] = tgt_ks
                                break

            # For non-trivial keyspaces_rename_map, apply renames
            # then recompute ortho_src_keyspaces & absent_tgt_keyspaces
            if len(keyspaces_rename_map) > 0:
                adj_self.rename_spaces(space_map=keyspaces_rename_map, inplace=True)
                ortho_src_keyspaces = adj_self.ortho_keyspaces(keyspaces)
                absent_tgt_keyspaces = adj_self.absent_keyspaces(keyspaces)

        # ------------------------------------
        # Next, apply remapping via resident
        # RefLibs of RootLib where possible
        # ------------------------------------
        if (len(ortho_src_keyspaces) > 0) and (len(absent_tgt_keyspaces) > 0):
            return RootLib().remap(
                adj_self,
                src_keyspaces=ortho_src_keyspaces,
                tgt_keyspaces=absent_tgt_keyspaces,
                deep_copy=deep_copy,
                grace=True,
            )
        elif deep_copy:
            return adj_self.copy()
        else:
            adj_self._clear_num_records_caches()
            return adj_self

    def _value_type_check(self, coltype_func, valuespace="<first_valuespace>"):
        orig_valuespace = valuespace
        valuespace = self.validate_valuespace(
            valuespace="<all>" if valuespace == "<and>" else valuespace,
            grace=False,
        )

        if valuespace is None:
            return False

        column_type = self.get_column_type(valuespace)

        if isinstance(column_type, (list, tuple)):
            result = [coltype_func(t) for t in column_type]
        else:
            result = coltype_func(column_type)

        # Apply 'and' condition if applicable (should yield a scalar boolean)
        if isinstance(result, (list, tuple)) and orig_valuespace == "<and>":
            if len(result) == 0:
                return False

            and_result = result[0]

            for other_result in result[1:]:
                and_result = and_result and other_result

            return and_result

        return result

    # ==================================== ACCESS / GETTERS =====================================

    def __getitem__(self, key) -> Quble:
        """
        Retrieve slice from Quble
        """
        return self.get(key)

    def get_window1d(
        self,
        periods: int,
        key,
        space: str = "<first_time_keyspace>",
        sample_shift: int = 0,
        auto_squeeze: bool = False,
    ) -> Quble:
        """
        Returns a subset of data in a Quble
        yielding all the records within a trailing window of a
        specified number of periods at the underlying frequency
        from the specified (datetime) key
        within the specified time-space (column of dates/timestamps)

        :param periods: trailing window (# periods > 0 at underlying frequency)
        :type periods: int (or None)

        :param key: base date/time for window
        :type key: datetime, np.datetime64,or (datetime-friendly) string,or single-row Quble index that includes the time-space as a keyspace
        NOTE: if key is an Quble index that includes other non-time keyspaces that are present in self,
        these keyspaces will ALSO be applied as addition conditions.In this case, these additional keyspaces may be absent (or present) in result depending on auto_squeeze=True(False)

        :param space: the (time)space for windowing
        :type space: str

        :param sample_shift: (optional) # periods to shift the window
                (ideally non-negative) (=0: no shift, >0:older window)
        :type sample_shift: int (or None)

        :param auto_squeeze: keyspace removal (retention) flag
                             for any extra keyspaces
                             provided in key arg as Quble index case
        :type auto_squeeze: boolean
           ==> NOTE: auto_squeeze ONLY APPLIES TO EXTRA/ORTHOGONAL SPACES
           ==>       when key is a single-record (non-valued) Quble index
        """
        # Validate self
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_empty:
            return self.copy()

        # Validate periods
        if periods is None or periods <= 0:
            raise Exception(f"Invalid window:{periods}...positive integer expected")

        # Validate sample_shift
        if (sample_shift is not None) and (sample_shift < 0):
            _logger.warning("sample_shift < 0")

        # Validate space
        space = self.validate_space(
            space, grace=False, solo_required=True, time_space_required=True
        )

        # Validate key
        timekey_index_table_name = None  # <-- Initialization
        timekey_index_keyspaces = None  # <-- Initialization
        timekey_str = None  # <-- Initialization

        if key is None:
            raise Exception("key arg required")
        elif isinstance(key, str):
            timekey_str = key
        elif isinstance(key, datetime):
            timekey_str = str(key)
        elif hasattr(key, "dtype") and np.issubdtype(key, np.datetime64):
            timekey_str = str(key)
        elif isinstance(key, Quble):
            if key.is_undefined:
                raise Exception("key arg is undefined Quble")
            elif not key.is_index:
                raise Exception(
                    "key arg as Quble MUST be index-only (non-valued) Quble"
                )
            elif key.num_records == 0:
                return self.clear()  # <-- Could also throw an Exception here
            elif key.num_records != 1:
                raise Exception(
                    "key arg as Quble MUST be single-record index-only (non-valued) Quble"
                )
            elif space not in key.keyspaces:
                raise Exception(
                    "space:{0} absent from key arg single-record index-only (non-valued) Quble"
                )
            else:
                timekey_str = None
                timekey_index_table_name = key.table_name
                timekey_index_keyspaces = key.keyspaces
        else:
            raise Exception(
                "Invalid key:{0}...datetime or datetime64 or str or single-record index-only (non-valued) Quble expected".format(
                    key
                )
            )

        # timekey integrity check
        if timekey_index_table_name is None or timekey_index_keyspaces is None:
            if timekey_str is None:
                raise Exception("Could not procure timekey information")
        elif timekey_str is not None:
            raise Exception("Could not procure timekey information")

        # Procure the frequency
        freq = self.get_space_info(
            info_type="freq", space=space, allow_infer=True, assign_inferred=True
        )

        # ---------------------------------
        # Apply get_window1D.j2 template
        # ---------------------------------
        table_name = generate_random_table_name()

        sql_template = JINJA_ENV.get_template("get_window1D.j2")
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            tgt_table_name=table_name,
            calendar_table_name=RootLib().get_control("calendar_table_name"),
            timespace=space,
            timekey_str=timekey_str,
            timekey_index_table_name=timekey_index_table_name,
            timekey_index_keyspaces=timekey_index_keyspaces,
            auto_squeeze=auto_squeeze,
            window=periods,
            freq=freq,
            allspaces=self.spaces,
            sample_shift=0 if sample_shift is None else sample_shift,
        )
        execute(sql_command)

        return Quble.from_table(
            table_name,
            col_info=self.get_space_info(
                info_type=CUSTOM_INFO_TYPES,
                space=self.spaces,
                omit_unassigned=True,
            ),
        )

    @RootLib.lazy_kwargs()
    def get1d(
        self,
        key,
        keyspace: str = "<first_keyspace>",
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        complex_indexing: bool = RootLib.lazy_eval("complex_indexing"),
        ignore_keyerrors: bool = RootLib.lazy_eval("ignore_keyerrors"),
        auto_expand: bool = RootLib.lazy_eval("auto_expand"),
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        tdistribute_mode="<space_root>",
        key_ordering="asc",
        link_dupe_grace: bool = True,
    ):
        # Validate the keyspace arg
        keyspace = self.validate_keyspace(keyspace, grace=False, solo_required=True)

        return self.get(
            {keyspace: [key]},
            auto_squeeze=auto_squeeze,
            auto_fill=auto_fill,
            tfill_method=tfill_method,
            tfill_max=tfill_max,
            tfill_end_mode=tfill_end_mode,
            tfill_honor_nulls=tfill_honor_nulls,
            complex_indexing=complex_indexing,
            ignore_keyerrors=ignore_keyerrors,
            auto_expand=auto_expand,
            auto_link=auto_link,
            link_check=link_check,
            tdistribute_mode=tdistribute_mode,
            key_ordering=key_ordering,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def get_core(
        self,
        hyper_key,
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        complex_indexing: bool = RootLib.lazy_eval("complex_indexing"),
        ignore_keyerrors: bool = RootLib.lazy_eval("ignore_keyerrors"),
        auto_expand: bool = RootLib.lazy_eval("auto_expand"),
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        tdistribute_mode="<space_root>",
        keyspace_delimiter: str = RootLib.lazy_eval("keyspace_delimiter"),
        index_delimiter: str = RootLib.lazy_eval("index_delimiter"),
        key_ordering="asc",
        link_dupe_grace: bool = True,
    ) -> Quble:
        """
        Driver method for the old Join based implementation of get
        NOTE: This currently supports fill operations whereas the SnowPark implementation does not
        """
        # Assign self->adj_self and only refer to adj_self hereafter
        adj_self = self

        # CASE: adj_self is undefined (no table)
        if adj_self.is_undefined:
            return adj_self.copy()
        # CASE: None
        elif hyper_key is None:
            return adj_self.clear()  # <-- could also yield Quble()
        elif isinstance(hyper_key, Quble):
            # Use adj_self's first_keyspace to convert scalar Quble
            # to a one-dimensional index only Quble with one record
            if hyper_key.is_scalar:
                custom_info_overrides = {"role": {adj_self.first_keyspace: "keyspace"}}
                column_name_map = {hyper_key.valuespace: adj_self.first_keyspace}
                # Apply the scalar value as a key to the first keyspace of adj_self
                hyper_key = hyper_key.select(
                    column_names=column_name_map,
                    custom_info_overrides=custom_info_overrides,
                )
            # Use adj_self's keyspaces to convert multi-scalar Quble's values
            # to a multi-dimensional index only Quble with one record
            elif hyper_key.is_multiscalar:
                if hyper_key.num_valuespaces != adj_self.num_keyspaces:
                    raise Exception(
                        "multiscalar hyper_key.num_valuespaces:{0} != self.num_keyspaces:{1}",
                        format(hyper_key.num_valuespaces, adj_self.num_keyspaces),
                    )
                custom_info_overrides = {}
                column_name_map = {}
                for i, hykey_vs in enumerate(hyper_key.valuespaces):
                    column_name_map[hykey_vs] = self.num_keyspaces[i]
                    custom_info_overrides["role"] = {self.num_keyspaces[i]: "keyspace"}
                # Apply the multiscalar's values as keys to the keyspaces of adj_self
                hyper_key = hyper_key.select(
                    column_names=column_name_map,
                    custom_info_overrides=custom_info_overrides,
                )
            else:
                pass
        # CASE: LITERAL NON-STRING SCALARs
        elif np.isscalar(hyper_key) or isinstance(hyper_key, datetime):
            hyper_index = {}
            if adj_self.first_keyspace is None:
                raise Exception(
                    "adj_self.first_keyspace required for Quble.get(<Index>)"
                )
            hyper_index[adj_self.first_keyspace] = [hyper_key]
            hyper_key = Quble(indices=hyper_index)
        elif isinstance(hyper_key, DataLib):
            # Apply get sequentially for each field/Quble in the DataLib provided
            # [typically this will be a multiple remapping operation]
            new_quble = adj_self.copy()
            for ks in hyper_key.fields():
                with ControlContextManager(controls={"default_keyspace": ks}) as ccm:
                    new_quble = new_quble[hyper_key[ks]]

            return new_quble
        # CASE: str or ALL OTHER CASES
        # <-- When all else fails, try to coerce the arg to a Quble object
        elif isinstance(hyper_key, PandasDF):
            # Once we make changes to Quble constructor to honor space_info from PandasDF class
            # we no longer need to do space_info = hyper_key.space_info
            hyper_key = Quble(hyper_key, space_info=hyper_key.space_info)
        elif isinstance(hyper_key, pd.DataFrame):
            hyper_key = Quble(hyper_key)
        else:
            # Was hyper_key = Quble(hyper_key,context=adj_self) earlier
            # Removed context argument as Quble constructor no longer supports it
            hyper_key = Quble(hyper_key)

        # Here we know hyper_key is a defined, non-scalar Quble

        # Make sure hyper_key is a Quble
        # -------------------------------------
        if not isinstance(hyper_key, Quble):
            raise Exception("Unable to convert arg to Quble")
        # Handle undefined hyper_key
        # ----------------------------
        elif hyper_key.is_empty:  # or hyper_key.has_no_values:
            return adj_self.clear()

        # ----------------------------------------------------
        # At this point we have converted hyper_key to a Quble class
        # Invoke auto_link (if applicable)
        # [Will try to make adj_self better conform to hyper_key]
        # ------------------------------------------------------
        if auto_link:  # <-- Intentionally NOT else here
            adj_self = adj_self.link_keyspaces(
                hyper_key.keyspaces,
                link_check=link_check,
                link_dupe_grace=link_dupe_grace,
                deep_copy=False,
                grace=True,
            )
            if adj_self.is_empty:  # or adj_self.has_no_values:
                return adj_self.copy()

        # Suppress time filling when not selecting from time keyspaces
        if not any([ks in hyper_key.keyspaces for ks in adj_self.time_keyspaces]):
            tfill_max = None

        # For index or boolean hyper_key, apply join
        # --------------------------------------------
        if hyper_key.is_index or hyper_key.is_bool():
            # For uni-variate, boolean-valued hyper_key,
            # convert hyper_key to an index
            if hyper_key.is_index:
                pass
            elif hyper_key.is_bool():
                hyper_key = hyper_key.bool_to_index()

            # Check for auto_expand conflicts
            if not auto_expand:
                for ks in hyper_key.keyspaces:
                    if ks not in adj_self.keyspaces:
                        raise Exception(
                            f"keyspace:{ks} absent yet auto_expand:{auto_expand}"
                        )
            joined = adj_self.join(
                other=hyper_key,
                keys_join_op="rightmost",
                keyspaces_join_op="union",
                valuespaces_join_op="left",
                # ignore_missing=ignore_missing, # <-- We are keeping all keyspaces (keyspaces_join_op='union'), therefore we do not need to aggregate away any dimensions inside join method
                auto_fill=auto_fill,
                tfill_method=tfill_method,
                tfill_max=tfill_max,
                tfill_end_mode=tfill_end_mode,
                tfill_honor_nulls=tfill_honor_nulls,
                # aggr_method=aggr_method, # <-- We are keeping all keyspaces (keyspaces_join_op='union'), therefore we do not need to aggregate away any dimensions inside join method
                key_ordering=key_ordering,
                tdistribute_mode=tdistribute_mode,
                auto_link=auto_link,
                link_check=link_check,
                link_dupe_grace=link_dupe_grace,
                consider_auto_squeeze=auto_squeeze,
            )

            # Apply auto_squeeze (if applicable)
            # ----------------------------------
            if auto_squeeze and isinstance(joined, Quble) and len(joined.keyspaces) > 0:
                distinct_key_counts_for_hyper_key = hyper_key.distinct_key_counts
                distinct_key_counts_for_joined = joined.distinct_key_counts
                if (
                    distinct_key_counts_for_hyper_key is not None
                    and distinct_key_counts_for_joined is not None
                ):
                    spaces_to_keep = []
                    spaces_to_squeeze = []
                    for ks in joined.keyspaces:
                        if (
                            ks in distinct_key_counts_for_hyper_key
                            and distinct_key_counts_for_hyper_key[ks] == 1
                            and ks in distinct_key_counts_for_joined
                            and distinct_key_counts_for_joined[ks] == 1
                        ):
                            # This keyspace has a single key
                            # as was directed by the hyper_key (selector Quble)
                            # In this case, we want to 'squeeze away' this keyspace
                            spaces_to_squeeze.append(ks)
                        else:
                            spaces_to_keep.append(ks)

                    # Is squeezing of any keyspaces required?
                    if len(spaces_to_keep) < len(joined.keyspaces):
                        # Add the valuespaces to spaces_to_keep (if present)
                        if joined.valuespaces is not None:
                            spaces_to_keep += joined.valuespaces

                        # We cannot squeeze all spaces
                        # (would yield an undefinable table/Quble)
                        # In this case, we attempt to reintroduce
                        # an arbitrary keyspace from spaces_to_squeeze
                        # [In this case, the Quble does not have a valuespace]
                        if len(spaces_to_keep) == 0 and len(spaces_to_squeeze) > 0:
                            spaces_to_keep.append(spaces_to_squeeze[0])
                        joined = joined.select(
                            column_names=spaces_to_keep,
                            key_ordering=key_ordering,
                            tgt_keyspaces=self.keyspaces,
                        )

            return joined
        # Otherwise, apply remap
        # (using default keyspace)
        # ---------------------------
        else:
            if adj_self.first_keyspace is None:
                raise Exception(
                    "adj_self.first_keyspace required for Quble.get(<variate Quble>)"
                )
            return adj_self.remap1d(hyper_key, keyspace=adj_self.first_keyspace)

    @RootLib.lazy_kwargs()
    def get(
        self,
        hyper_key,
        auto_squeeze: bool = RootLib.lazy_eval("auto_squeeze"),
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        complex_indexing: bool = RootLib.lazy_eval("complex_indexing"),
        ignore_keyerrors: bool = RootLib.lazy_eval("ignore_keyerrors"),
        auto_expand: bool = RootLib.lazy_eval("auto_expand"),
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        tdistribute_mode="<space_root>",
        keyspace_delimiter: str = RootLib.lazy_eval("keyspace_delimiter"),
        index_delimiter: str = RootLib.lazy_eval("index_delimiter"),
        key_ordering="asc",
        link_dupe_grace: bool = True,
    ) -> Quble:
        """
        Returns multidimensional cross-section of the Quble
        with records as dictated by (index or primary valuespace of) hyper_key arg


        The Quble.get() method uses snowpark dataframes to find and return multidimensional cross-section of the Quble.
        The Quble.get_core() method uses Qubles to ind and return multidimensional cross-section of the Quble
        The above methods gets called depending on following scenarios
        1) Quble.get() is executed completely when auto_fill is set to False and tfill_max is 0 / None
        2) Quble.get_core() is called when the Quble.get() method identifies that a fill operation is required or if the
           hyper_key is a Quble or Dataliv object

        The Snowpark implementation was done to improve performance in case of simple get operations that do not involve
        fill logic.

        :param hyper_key: The key defining what subset of the Quble to get
            Different data types specify this key in their own way:
            |  Quble: if Quble is primary boolean or (non-valued) index:
                      keeps keys as instructed by index or primary valuespace
                      otherwise, performs a Quble.remap1d() against the first keyspace of the Quble
            |  DataLib (bool type): performs an iterative Quble.remap1d() for each field/keyspace in DataLib
            |  list of strings without index_delimiters nor keyspace delimiters: retains only the specified valuespaces
            |  str with index_delimiters and/or keyspace delimiters: builds a Quble (with only index columns) from str
                                                                     and re-calls Quble.get()
            |  list/tuple of strings without index_delimiters nor keyspace delimiters: sub-selects specified valuespaces

        :type hyper_key: Quble, str, dict

        :param auto_squeeze: Indicates whether to remove single-element dimensions from result.
                            Defaults to RootLib().get_control('auto_squeeze') if supplied value is None.
        :type auto_squeeze: bool or None

        :type tfill_max: int or str (indirection case)
        :param tfill_max: The tfill_max parameter of the associated space

        :param tfill_method: Method to use for filling time/date data holes using the index.
        :type tfill_method: {q_fill_method} limited to one of -> ['backfill', 'pad'] or None

        :param complex_indexing: { True, False, RootLib.lazy_eval('complex_indexing' }
                       indicates whether allow "complex indexing" (sophisticated parsing of str arg)
        :type complex_indexing: str

        :param auto_expand: Flag for allowing absent/external/orthogonal keyspaces within the hyper_key argument.
        :type auto_expand: bool

        .. note::
            All keyspaces specified within the hyper_key arg MUST be present in self.keyspaces

        :returns: Appropriate subset of self
        :rtype: qubles.core.quble.Quble

        """
        # Init keyspaces_in_result, valuespaces_in_result, subset_flag
        # These variables are used further in the logic
        adj_self = self
        keyspaces_in_result, valuespaces_in_result = (
            adj_self.keyspaces,
            adj_self.valuespaces,
        )
        subset_flag = True

        # Parsing the hyper_key into a pandas dataframe for further processing
        if adj_self.is_undefined:
            return adj_self.copy()
        elif hyper_key is None:
            return adj_self.clear()
        elif isinstance(hyper_key, str):
            # When we encounter Quble['Values'], we need to promote Values column to primary Vs
            initial_split = hyper_key.strip().split(index_delimiter)

            # Handle trivial cases
            if len(initial_split) == 0:
                return adj_self.copy()
            elif "" in initial_split:
                raise Exception("One or more empty keys were provided.")

            for i, element in enumerate(initial_split):
                striped_element = element.strip()
                if len(striped_element) == 0:
                    continue

                split_ks_str = striped_element.split(keyspace_delimiter, 1)
                # If no keyspace prefix present ==> this element is a valuespace qualifier
                if (len(split_ks_str) == 1) or (
                    (len(split_ks_str) == 2) and split_ks_str[0].strip() == "valuespace"
                ):
                    # We assume only one valuespace qualifier will be used
                    tgt_vs = (
                        split_ks_str[0].strip()
                        if len(split_ks_str) == 1
                        else split_ks_str[1].strip()
                    )
                    if tgt_vs not in adj_self.valuespaces:
                        raise ValuespaceRefError(f"Absent valuespace: {tgt_vs}")
                    else:
                        if adj_self.valuespace != tgt_vs:
                            adj_self = adj_self.promote_valuespace(
                                valuespace=tgt_vs, deep_copy=False, retain_address=False
                            )

                        initial_split.pop(i)
                        if len(initial_split) == 0:
                            return adj_self
                        hyper_key = index_delimiter.join(initial_split)
                        if len(hyper_key) == 0:
                            return adj_self
                        else:
                            break
                else:
                    continue

            if not complex_indexing:
                raise Exception(f"complex_indexing prohibited: key={hyper_key}")
            hyper_key = Quble.string_to_index(
                hyper_key,
                default_keyspace=adj_self.first_keyspace,
                keyspace_delimiter=keyspace_delimiter,
                index_delimiter=index_delimiter,
                key_delimiter=RootLib().get_control("key_delimiter"),
                range_delimiter=RootLib().get_control("range_delimiter"),
                complex_indexing_date=RootLib().get_control("complex_indexing_date"),
                datetime64_dtype=RootLib().get_control("datetime64_dtype"),
                context=adj_self,
                return_type="PandasDF",
            )

            # Trap for valuespace filtering
            # Quble['Values:100,200'] scenarios
            for column, value_list in hyper_key.to_dict(orient="list").items():
                if column in adj_self.valuespaces and len(value_list) > 0:
                    raise Exception(f"keyspace:{column} absent")

            keyspaces_to_join = [
                '"' + col + '"'
                for col in adj_self.keyspaces
                if col in hyper_key.columns.tolist()
            ]
            keyspaces_in_result = ['"' + i + '"' for i in keyspaces_in_result]
            valuespaces_in_result = ['"' + col + '"' for col in adj_self.valuespaces]
        elif isinstance(hyper_key, dict):
            keyspaces_to_join = [
                '"' + col + '"' for col in adj_self.keyspaces if col in hyper_key
            ]

            for key in hyper_key:
                if key not in keyspaces_in_result:
                    keyspaces_in_result.append(key)
            keyspaces_in_result = ['"' + i + '"' for i in keyspaces_in_result]
            valuespaces_in_result = ['"' + col + '"' for col in adj_self.valuespaces]

            hyper_key = pd.DataFrame(hyper_key)
        elif isinstance(hyper_key, (list, tuple)):
            for idx, column_name in enumerate(hyper_key):
                if column_name is None:
                    continue
                elif not isinstance(column_name, str):
                    raise Exception(
                        f"hyper_key list/tuple requires str elements, yet hyper_key:[{idx}] = {hyper_key[idx]}"
                    )
                elif column_name not in adj_self.valuespaces:
                    raise Exception(
                        f"list/tuple element hyper_key:[{idx}] = {column_name} is absent from adj_self.valuespaces:{adj_self.valuespaces}"
                    )
            return adj_self.sub_variate(valuespace=hyper_key, allow_shallow_copy=False)
        elif (
            isinstance(hyper_key, (Quble, DataLib))
            or np.isscalar(hyper_key)
            or isinstance(hyper_key, datetime)
        ):
            subset_flag = False

        else:
            subset_flag = False

        # Init to auto setting, augment if a valuespace has tfill_max assigned
        # Checking if fill operation is required
        perform_fill = False
        time_keyspaces = self.time_keyspaces
        if not auto_fill:
            pass
        # The below scenarios will be dealt in get_core
        elif np.isscalar(hyper_key) or isinstance(
            hyper_key, (Quble, DataLib, datetime)
        ):
            perform_fill = True
        elif time_keyspaces is None or len(time_keyspaces) == 0:
            pass
        elif any(
            [
                True if ks in time_keyspaces else False
                for ks in hyper_key.columns.to_list()
            ]
        ):
            if tfill_max is None:
                pass
            elif isinstance(tfill_max, int):
                perform_fill = True if tfill_max != 0 else False
            elif not isinstance(tfill_max, str):
                # Should we raise an exception here ?
                pass
            elif tfill_max in ("<space_root>", "<root_space>", "<space>", "<root>"):
                for vs in adj_self.valuespaces:
                    tfill = adj_self._space_info_indirection(
                        info_type="tfill_max",
                        space=vs,
                        info_assignment=tfill_max,
                        grace=True,
                    )
                    if tfill not in (0, None):
                        perform_fill = True
                        break
            else:
                # Can also consider putting this in each method that handles tfill_max args
                tfill_max = self.validate_periods1d(
                    periods=tfill_max, keyspace=time_keyspaces[0]
                )
                if isinstance(tfill_max, int):
                    perform_fill = True if tfill_max != 0 else False

        if isinstance(hyper_key, (PandasDF, pd.DataFrame)):
            # At this point, hyper_key is a pandas dataframe
            # we still want to continue with snowpark flow even if perform_fill = True
            # But hyper_key should not have any time_keyspaces
            # Here we check if the hyper_key is subset of the main (adj_self) Quble
            # If we are trying to insert new rows via hyper_key, we transfer the control to get_core method
            session = SnowparkSessionManager.get_snowpark_session()
            main_df = session.table(dquote_dot(adj_self.table_name))
            hyper_key_df = session.create_dataframe(hyper_key)
            if not is_subset(main_df, hyper_key_df):
                subset_flag = False

        # If filling is required, we go through the old get logic, otherwise use Snowpark
        if not subset_flag or perform_fill:
            return adj_self.get_core(
                hyper_key=hyper_key,
                auto_squeeze=auto_squeeze,
                auto_fill=auto_fill,
                tfill_method=tfill_method,
                tfill_max=tfill_max,
                tfill_end_mode=tfill_end_mode,
                tfill_honor_nulls=tfill_honor_nulls,
                complex_indexing=complex_indexing,
                ignore_keyerrors=ignore_keyerrors,
                auto_expand=auto_expand,
                auto_link=auto_link,
                link_check=link_check,
                tdistribute_mode=tdistribute_mode,
                keyspace_delimiter=keyspace_delimiter,
                index_delimiter=index_delimiter,
                key_ordering=key_ordering,
                link_dupe_grace=link_dupe_grace,
            )
        else:
            # performing join
            main_df = main_df.join(hyper_key_df, on=keyspaces_to_join)

            if auto_squeeze:
                hyper_key_df_cols = [
                    '"' + col + '"' if '"' not in col else col
                    for col in hyper_key_df.columns
                ]
                for keyspace in keyspaces_in_result.copy():
                    if (
                        keyspace in hyper_key_df_cols
                        and main_df.agg(
                            F.countDistinct(F.col(keyspace)).alias("DISTINCT_COUNT")
                        ).first()["DISTINCT_COUNT"]
                        == 1
                    ):
                        keyspaces_in_result.remove(keyspace)

            # Final selection
            final_spaces = [
                space for space in keyspaces_in_result + valuespaces_in_result
            ]

            # Key ordering
            if len(keyspaces_in_result) > 0:
                if isinstance(key_ordering, str):
                    sort_order = [
                        True if key_ordering.lower() == "asc" else False
                    ] * len(keyspaces_in_result)
                    sort_cols = keyspaces_in_result
                elif isinstance(key_ordering, dict):
                    sort_cols = ['"' + col + '"' for col in key_ordering.keys()]
                    sort_order = [
                        True if order.lower() == "asc" else False
                        for col, order in key_ordering.items()
                    ]
                else:
                    raise Exception(
                        "Incorrect value provided for key ordering parameter"
                    )

                main_df = main_df.select(final_spaces).orderBy(
                    sort_cols, ascending=sort_order
                )
            else:
                main_df = main_df.select(final_spaces)

            # Final col info
            infos_to_drop = ["type"]
            column_info = deepcopy(adj_self._column_info)

            for column_name in adj_self.spaces:
                if f'"{column_name}"' not in final_spaces:
                    for info_type in column_info:
                        if column_name in column_info[info_type]:
                            column_info[info_type].pop(column_name)

            for info_type in column_info:
                if column_info[info_type] is None or len(column_info[info_type]) == 0:
                    infos_to_drop.append(info_type)

            for info_type in infos_to_drop:
                del column_info[info_type]

            table_name = generate_random_table_name()
            main_df.write.mode("overwrite").save_as_table(
                f"TMP_{table_name}", table_type="temporary"
            )
            session.sql(
                f'CREATE OR REPLACE TABLE "{table_name}" as select * from "TMP_{table_name}"'
            ).collect()
            session.sql(f'DROP TABLE "TMP_{table_name}"').collect()
            return Quble.from_table(
                table_name=table_name,
                col_info=column_info,
                valuespace=adj_self.valuespace,
            )

    # ================================== ASSIGNMENT / SETTERS ===================================

    def _swap_table(
        self,
        new_table: str,
        col_info: dict = None,
        touch: bool = True,
        valuespace: str = None,
    ):
        """
        Handles all necessary attribute assignments & clean-ups
        to perform a table switch so that self inherits the table_name provided

        NOTE: new_name may be provided as a string or as a Quble
        ==> When new_name arg is a string, assigns self.table_name = new_table
        ==> When new_name arg is a Quble, assigns self.table_name = new_table.table_name

        :param new_table: table to be swapped
        :type new_table: str or Quble

        :param col_info: dict containing metadata assignments for column roles/fxs/etc.
        :type col_info: (optional) dict or None -> can also be provided via new_table param (only applicable when new_table is provided as a Quble)

        :param touch: updates the timestamp of the Quble
        :type touch: bool (True/False*)

        :param valuespace: valuespace to apply (will infer from Quble if new_table is a Quble and no valuespace param is supplied)
        :type valuespace: str
        """
        if isinstance(new_table, Quble):
            new_table_name = new_table.table_name
        else:
            new_table_name = new_table

        # If table name is not changing, simply return here
        if new_table_name == self.table_name:
            return

        # Update reference tracking
        TableReferences().decrement_table_reference(self.table_name)
        TableReferences().increment_table_reference(new_table_name)

        # Assign self's table_name
        self.table_name = new_table_name
        orig_primary_vs = self.valuespace

        # Clear cached data/metadata
        self._clear_cache()

        if not isinstance(new_table, Quble):
            if col_info is not None:
                update_column_info(self._column_info, col_info)
            else:
                self._column_info = {}
                self._synchronize_space_info()
            if valuespace is not None and valuespace in self.valuespaces:
                self._initialize_space_roles(valuespace)
            elif orig_primary_vs in new_table.valuespaces:
                self._initialize_space_roles(orig_primary_vs)
            else:
                self._initialize_space_roles()
        else:
            update_column_info(self._column_info, new_table._column_info)
            if valuespace is not None and valuespace in self.valuespaces:
                self._initialize_space_roles(valuespace)
            elif new_table.valuespace in new_table.valuespaces:
                self._initialize_space_roles(new_table.valuespace)
            elif orig_primary_vs in new_table.valuespaces:
                self._initialize_space_roles(orig_primary_vs)
            else:
                self._initialize_space_roles()

        if touch:
            self.touch()

    def __setitem__(self, key, value):
        return self.set(key, value)

    @RootLib.lazy_kwargs()
    def set1d(
        self,
        key,
        value,
        keyspace: str = RootLib.lazy_eval("default_keyspace"),
        complex_indexing: bool = RootLib.lazy_eval("complex_indexing"),
        variate_mode: str = RootLib.lazy_eval("variate_mode"),
    ):
        hyper_key = {}
        if isinstance(key, (list, tuple)):
            hyper_key[keyspace] = [key]
        elif not isinstance(key, str):
            hyper_key[keyspace] = [key]
        elif complex_indexing:
            key = f"{keyspace}:{key}"
            hyper_key = Quble.string_to_index(
                key,
                default_keyspace=keyspace,
                keyspace_delimiter=RootLib().get_control("keyspace_delimiter"),
                index_delimiter=RootLib().get_control("index_delimiter"),
                key_delimiter=RootLib().get_control("key_delimiter"),
                range_delimiter=RootLib().get_control("range_delimiter"),
                complex_indexing_date=RootLib().get_control("complex_indexing_date"),
                datetime64_dtype=RootLib().get_control("datetime64_dtype"),
                context=self,
            )
        else:
            hyper_key[keyspace] = [key]

        # Call the set method accordingly
        self.set(
            hyper_key,
            value,
            complex_indexing=complex_indexing,
            variate_mode=variate_mode,
        )

    @RootLib.lazy_kwargs()
    def set(
        self,
        hyper_key,
        value,
        valuespace="<valuespace>",
        variate_mode: str = RootLib.lazy_eval("variate_mode"),
        keys_join_op: str = RootLib.lazy_eval("keys_join_op"),
        keyspaces_join_op: str = "union",
        complex_indexing: bool = RootLib.lazy_eval("complex_indexing"),
        keyspace_delimiter: str = RootLib.lazy_eval("keyspace_delimiter"),
        index_delimiter: str = RootLib.lazy_eval("index_delimiter"),
        key_delimiter: str = RootLib.lazy_eval("key_delimiter"),
        range_delimiter: str = RootLib.lazy_eval("range_delimiter"),
        auto_fill: bool = RootLib.lazy_eval("auto_fill"),
        tfill_method="<space_root>",
        tfill_max="<space_root>",
        tfill_end_mode="<space_root>",
        tfill_honor_nulls="<space_root>",
        tdistribute_mode="<space_root>",
    ):
        """
        Performs a valuespace assignment (update) on self
        May introduce new records.
        May also add new keyspaces from hyper_key or value,
        but should not remove any keyspaces.

        :param hyper_key: where to assign
        :type hyper_key: Quble (either index-only or uni/multi boolean valued)
                         or object coercable to index Quble:
                         [dictionary, str (convertable to Quble index), Index,
                         or an object coercable to an index Quble]

        :param value: what to assign
        :type value: variate Quble, literal scalar, dict, or
                     (non-structured or structured) numpy array

        value:
                1) variate Quble
             or 2) literal scalar (compatible with self's valuespace)
                   [here the (scalar) value will be repeatedly assigned to all applicable elements]
             or 3) (non-structured) numpy array
                   [dtype compatible/coercable with self's valuespace(s) to be assigned]
                   [length must match hyper_key.num_records]
             or 4) (structured) numpy array where names represent valuespaces
                   [dtype compatible/coercable with self's valuespace(s) to be assigned]
                   [length must match hyper_key.num_records]
             or 5) dict keyed by valuespace where dict values are:
                  a) scalars [here the (scalar) value will be assigned to all applicable elements]
                  b) list (length must match hyper_key.num_records)
                  c) tuple (length must match hyper_key.num_records)
                  d) (non-structured) numpy array
                     [length must match hyper_key.num_records]

        Notes:
           value as numpy array w/len(value)=1 or literal scalar:
              the (single) value will be assigned to all applicable elements

           value as numpy array w/len(value)=hyper_key.num_records:
                value array will populate the valuespace of a Quble crafted using hyper_key (index) footprint

           value as numpy array w/len(value)=self[hyper_key].num_records (footprint of self's ortho data):
                value array will be populate the valuespace
                of a Quble crafted using self's ortho data (index) footprint

        :param valuespace: target valuespace to be assigned
                           (only applies when variate_mode=='uni')
                           [If variate_mode != 'uni': valuespace arg is ignored]
        :type valuespace: str

        :param variate_mode: Controls uni-variate / multi-variate assignment
        :type variate_mode: str ('uni','mixed','multi')

        :param keys_join_op: keys join operator
                            [See: :meth:`~qubles.core.quble.Quble.join`]
        :type keys_join_op: str

        :param keyspaces_join_op: keyspace join operator
                                  [See: :meth:`~qubles.core.quble.Quble.join`]
        :type keyspaces_join_op: str

        :param complex_indexing: Flag for allowance/rejection of hyper_key string case
        :type complex_indexing: bool

        :param keyspace_delimiter: Control for parsing hyper_key string case
                                   [See: :meth:`~qubles.core.quble.Quble.string_to_index`]
        :type keyspace_delimiter: str

        :param index_delimiter: Control for parsing hyper_key string case
                                [See: :meth:`~qubles.core.quble.Quble.string_to_index`]
        :type index_delimiter: str

        :param key_delimiter: Control for parsing hyper_key string case
                              [See: :meth:`~qubles.core.quble.Quble.string_to_index`]
        :type key_delimiter: str

        :param range_delimiter: Control for parsing hyper_key string case
                               [See: :meth:`~qubles.core.quble.Quble.string_to_index`]
        :type range_delimiter: str
        """
        # ============================
        # Establish tgt_valuespace
        # ============================
        tgt_valuespace = self.validate_valuespace(
            valuespace, grace=True, solo_required=True
        )

        # If tgt_valuespace returns as None, requested valuespace does not yet exist (or self is undefined)
        if tgt_valuespace is None:
            # If valuespace param is default, take default, else accept param as tgt_valuespace
            if valuespace == "<valuespace>":
                tgt_valuespace = DEFAULT_VALUESPACE
            else:
                tgt_valuespace = valuespace

        # =========================
        # Validate variate_mode
        # =========================
        if variate_mode not in ("uni", "mixed", "multi"):
            raise Exception(
                "Invalid variate_mode:{0}...valid options: 'uni','mixed','multi'".format(
                    variate_mode
                )
            )

        # =======================
        # Handle trivial cases
        # =======================
        if hyper_key is None or value is None:
            # Do nothing here as no assignment applies
            return
        elif isinstance(hyper_key, Quble) and hyper_key.is_undefined:
            # Do nothing here as no assignment applies
            # [Could also raise an Exception here]
            return
        elif isinstance(value, Quble) and value.is_undefined:
            # Do nothing here as no assignment applies
            # [Could also raise an Exception here]
            return
        # ====================================
        # Pass case when hyper_key is Quble
        # ====================================
        elif isinstance(hyper_key, Quble):
            pass
        # ===========================================
        # Otherwise, convert hyper_key arg to Quble
        # [ideally a non-variate/index Quble]
        # ===========================================
        # CASE: dictionary
        elif isinstance(hyper_key, dict):
            # Convert dict to index Quble
            hyper_key = Quble(indices=hyper_key)
            if not hyper_key.is_index:
                raise Exception(
                    "Unable to convert hyper_key arg (dictionary) to an Quble index"
                )
        # CASE: str
        elif isinstance(hyper_key, str):
            tgt_valuespace_via_hyper_key_parse = False  # <-- Initialzation
            hyper_key_strarr = hyper_key.strip().split(index_delimiter)
            for hyper_key_str_no, hyper_key_str1 in enumerate(hyper_key_strarr):
                num_keyspace_delimiters = hyper_key_str1.find(keyspace_delimiter)
                if num_keyspace_delimiters <= 0:
                    # Here, this element is not coercable string -> index Quble component
                    # As such, we treat as a valuespace qualification
                    hyper_key_str2 = hyper_key_str1.strip()
                    if len(hyper_key_str2) > 0:
                        tgt_valuespace = hyper_key_str2
                        tgt_valuespace_via_hyper_key_parse = True
                    hyper_key_strarr.pop(hyper_key_str_no)

            # Handle case: X[<valuespace>] = Z
            if len(hyper_key_strarr) == 0:
                # Convert scalar values to a scalar Quble
                if np.isscalar(value):
                    if tgt_valuespace is None:
                        raise Exception(
                            "Internal inconsistency...tgt_valuespace is None"
                        )
                    # Convert scalar value arg to an appropriate Quble
                    # NOTE: We don't need to support tgt_valuespace column info if/when tgt_valuespace in self.spaces
                    value = Quble(value, valuespace=tgt_valuespace)

                # At this point, value should be a defined, variate Quble
                # Otherwise, raise an Exception
                if not isinstance(value, Quble):
                    raise Exception(
                        f"value arg must be type Quble, np.ndarray or np.scalar, received type: {type(value)}"
                    )
                elif value.is_undefined:
                    raise UndefinedQubleError("value Quble is undefined")
                elif value.valuespace is None:
                    value = value.index_to_bool()

                if self.is_undefined:
                    column_map = {}
                    for ks in value.keyspaces:
                        column_map[ks] = ks
                    if tgt_valuespace is not None:
                        column_map[value.valuespace] = tgt_valuespace

                    value2 = value.select(
                        column_names=column_map, preferred_vs=tgt_valuespace
                    )
                    self._swap_table(value2)
                    return
                elif tgt_valuespace is None:
                    raise Exception("Internal inconsistency...tgt_valuespace is None")
                else:
                    # valuespaces_join_op[new_valuespace] = (quble_number, old_valuespace)
                    # ==> THIS APPROACH PUTS NEWLY INTRODUCED tgt_valuespace AS FIRST VALUESPACE!!!
                    # ----------------------------------------------------------------------
                    valuespaces_join_op = {}
                    valuespaces_join_op[tgt_valuespace] = (1, value.valuespace)
                    for vs in self.valuespaces:
                        if vs != tgt_valuespace:
                            valuespaces_join_op[vs] = (0, vs)

                    value2 = self.join(
                        value,
                        keys_join_op=keys_join_op,
                        keyspaces_join_op=keyspaces_join_op,
                        valuespaces_join_op=valuespaces_join_op,
                        auto_fill=auto_fill,
                        tfill_method=tfill_method,
                        tfill_max=tfill_max,
                        tfill_end_mode=tfill_end_mode,
                        tfill_honor_nulls=tfill_honor_nulls,
                        tdistribute_mode=tdistribute_mode,
                    )

                    self._swap_table(value2, valuespace=tgt_valuespace)
                    return
            elif tgt_valuespace_via_hyper_key_parse:
                raise Exception(
                    f"tgt_valuespace:{tgt_valuespace} via hyper_key_parse yet remaining hyper_key_strarr:{hyper_key_strarr}"
                )
            elif not complex_indexing:
                raise Exception(f"complex_indexing prohibited: hyper_key={hyper_key}")
            else:
                hyper_key = Quble.string_to_index(
                    index_delimiter.join(hyper_key_strarr),
                    context=self,
                    keyspace_delimiter=keyspace_delimiter,
                    index_delimiter=index_delimiter,
                    key_delimiter=key_delimiter,
                    range_delimiter=range_delimiter,
                )
        elif (
            (isinstance(hyper_key, str) and hyper_key == "<valuespaces>")
            or (
                isinstance(hyper_key, (list, tuple))
                and (len(hyper_key) > 0)
                and all([isinstance(hk1, str) for hk1 in hyper_key])
            )
            or (
                isinstance(hyper_key, np.ndarray)
                and (len(hyper_key) > 0)
                and (
                    np.issubdtype(hyper_key.dtype, np.unicode_)
                    or np.issubdtype(hyper_key.dtype, np.string_)
                )
            )
        ):
            # Trap for hyper_key == '<valuespaces>'
            # In this case the intention is to inherit all of value.valuespaces into self
            if isinstance(hyper_key, str) and hyper_key == "<valuespaces>":
                hyper_key = value.valuespaces
            # Validate len(hyper_key)
            # Should match value.num_valuespaces
            if len(hyper_key) == 0:
                # Do nothing here as no/empty assignment qualifier was specified
                return
            elif len(hyper_key) != value.num_valuespaces:
                raise Exception(
                    f"hyper_key is list/tuple/np.array of all strings, yet len(hyper_key):{len(hyper_key)} != value.num_valuespaces:{value.num_valuespaces}"
                )
            elif isinstance(hyper_key, np.ndarray) and hyper_key.ndim > 1:
                raise Exception(
                    f"hyper_key is np.array of all strings, yet hyper_key.ndim:{hyper_key.ndim} > 1"
                )

            if self.is_undefined:
                column_map = {}
                for ks in value.keyspaces:
                    column_map[ks] = ks
                for vs_no, src_vs in enumerate(value.valuespaces):
                    column_map[src_vs] = hyper_key[vs_no]
                value2 = value.select(column_names=column_map)
                self._swap_table(value2)
                return
            elif tgt_valuespace is None:
                raise Exception("Internal inconsistency...tgt_valuespace is None")
            else:
                valuespaces_join_op = (
                    []
                )  # <-- List of dicts (each dict is a valuespace map for self/value respectively)
                # valuespaces_join_op[0]: valuespace dict for self Quble
                valuespaces_join_op.append({})
                for vs in self.valuespaces:
                    if vs != tgt_valuespace:
                        valuespaces_join_op[0][vs] = vs

                # valuespaces_join_op[1]: valuespace dict for value Quble
                valuespaces_join_op.append({})
                for vs_no, vs in enumerate(value.valuespaces):
                    if vs in self.valuespaces:
                        raise Exception(
                            f"value Quble valuespace:{vs} already present in self.valuespaces:{self.valuespaces}"
                        )
                    elif len(hyper_key[vs_no]) == 0:
                        raise Exception(
                            f"Invalid/empty hyper_key[{vs_no}]:{hyper_key[vs_no]}"
                        )
                    valuespaces_join_op[1][vs] = hyper_key[vs_no]

                value2 = self.join(
                    value,
                    keys_join_op=keys_join_op,
                    keyspaces_join_op=keyspaces_join_op,
                    valuespaces_join_op=valuespaces_join_op,
                    auto_fill=auto_fill,
                    tfill_method=tfill_method,
                    tfill_max=tfill_max,
                    tfill_end_mode=tfill_end_mode,
                    tfill_honor_nulls=tfill_honor_nulls,
                    tdistribute_mode=tdistribute_mode,
                )

                self._swap_table(value2)
                return
        # CASE: Index, IndexArray1D or non-structured numpy array
        # ==> Apply as keys against self.first_keyspace
        elif isinstance(hyper_key, (Index, IndexArray1D)) or (
            isinstance(hyper_key, np.ndarray)
            and not is_structured_dtype(hyper_key.dtype)
        ):
            indices_arg = {}
            # !!! CHANGED adj_self TO self BELOW. ASSUMING THIS IS CORRECT (as adj_self was undefined), BUT SHOULD BE VERIFIED !!!
            if self.first_keyspace is None:
                raise Exception("self.first_keyspace required for Quble.set(<Index>)")
            indices_arg[self.first_keyspace] = hyper_key
            hyper_key = Quble(indices=indices_arg)
        # ALL OTHER CASES
        else:  # Last resort, try to convert hyper_key arg to Quble object
            hyper_key = Quble(hyper_key)

        # =================================
        #  VALIDATE hyper_key Quble...
        # =================================
        if not isinstance(hyper_key, Quble):
            # The conversions above must have failed (being extra safe)
            raise Exception("Unable to convert hyper_key to a Quble")

        # ==================================================================
        #            CASE #1: EMPTY / UNDEFINED hyper_key Quble
        # ==================================================================
        if hyper_key.is_empty or hyper_key.is_undefined:
            # Do nothing here as no assignment applies
            return

        # ==================================================================
        #                CASE #2: NON-VARIATE hyper_key Quble
        # ==================================================================
        if hyper_key.is_nonvariate:
            # --------------------------------------------------------------
            # Convert non-Quble value --> Quble value
            # --------------------------------------------------------------
            # Acceptable cases:
            #    1) dict of numpy arrays (keyed by valuespace)
            #    2) Python scalar (to be applied to all relevant valuespaces)
            #    3) numpy array (with length == hyper_key.num_records) (to be applied to all relevant valuespaces)
            #    4) structured numpy array (with length == hyper_key.num_records) (keyed by valuespace)
            # --------------------------------------------------------------

            if not isinstance(value, Quble):
                if hyper_key.is_scalar or hyper_key.is_multiscalar:
                    raise Exception(
                        "hyper_key cannot be a uni/multi-scalar when value arg is not a Quble"
                    )

                value_array_dict = hyper_key.to_array_dict(
                    column_names=hyper_key.keyspaces
                )

                # ------------------------------------------------------
                # CASE 2A: hyper_key: NON-VARIATE Quble, value: dict
                # ------------------------------------------------------
                value_valuespaces = []  # <-- Initialization
                if isinstance(value, dict):
                    # Assume we are given an array_dict (or ateast valuespace components)
                    for vs in value:
                        if vs in hyper_key.keyspaces:
                            # We disallow value dictionary keys that match hyper_key.keyspaces
                            raise Exception(
                                "value dict key: {0} is should not be present in hyper_key.keyspaces:{1}".format(
                                    vs, hyper_key.keyspaces
                                )
                            )
                        elif isinstance(value[vs], (list, tuple)):
                            value_array_dict[vs] = np.array(value[vs])
                        elif not isinstance(value[vs], np.ndarray):
                            value_array_dict[vs] = np.repeat(
                                value[vs], hyper_key.num_records
                            )
                        elif len(value[vs]) != hyper_key.num_records:
                            raise Exception(
                                "dict value[{0}] is np.array, yet len(value[{0}]):{1} != hyper_key.num_records:{2}".format(
                                    vs, len(value), hyper_key.num_records
                                )
                            )
                        else:
                            value_array_dict[vs] = value[vs]
                        value_valuespaces.append(vs)
                else:
                    # ----------------------------------
                    # Here, value is:
                    #   a) list/tuple
                    #   b) (literal) scalar
                    #   c) structured np.ndarray
                    #   d) unstructured np.ndarray
                    # ----------------------------------
                    if isinstance(value, (list, tuple)):
                        value = np.array(value)
                    elif not isinstance(value, np.ndarray):
                        # Assume a Python scalar was provided here
                        # which we first convert to a (non-structured) numpy array
                        value = np.repeat(value, hyper_key.num_records)

                    # numpy array value case
                    if len(value) != hyper_key.num_records:
                        # Raise an Exception when array length does not match hyper_key.num_records
                        raise Exception(
                            "value is np.array, yet len(value):{0} != hyper_key.num_records:{1}".format(
                                len(value), hyper_key.num_records
                            )
                        )
                    # ----------------------------------------------------------------------
                    # CASE 2B: hyper_key: NON-VARIATE Quble, value: structured numpy array
                    # ----------------------------------------------------------------------
                    # Add valuespaces to value_array_dict accordingly...
                    if is_structured_dtype(value.dtype):
                        # structured numpy array...apply based on structured names
                        for vs in value.dtype.names:
                            if vs in hyper_key.keyspaces:
                                # We disallow value dictionary keys that match hyper_key.keyspaces
                                raise Exception(
                                    "value dict key: {0} is should not be present in hyper_key.keyspaces:{1}".format(
                                        vs, hyper_key.keyspaces
                                    )
                                )
                            else:
                                value_array_dict[vs] = value[vs]
                                value_valuespaces.append(vs)
                    # ----------------------------------------------------------------------
                    # CASE 2C: hyper_key: NON-VARIATE Quble, value: non-structured np array
                    # ----------------------------------------------------------------------
                    # Otherwise, non-structured numpy array...
                    # apply to all relevant target valuespaces
                    elif variate_mode == "multi":
                        for vs in self.valuespaces:
                            value_array_dict[vs] = value
                            value_valuespaces.append(vs)

                    elif variate_mode == "mixed":
                        raise Exception(f"Unsupported variate_mode:{variate_mode}")

                    elif tgt_valuespace is None:
                        value_array_dict[DEFAULT_VALUESPACE] = value
                        value_valuespaces.append(DEFAULT_VALUESPACE)
                    else:
                        value_array_dict[tgt_valuespace] = value
                        value_valuespaces.append(tgt_valuespace)

                # Construct value Quble from value_array_dict
                value = Quble.from_array_dict(
                    value_array_dict, valuespace=value_valuespaces
                )

            # Finally, call self.merge_inplace()
            # NOTE: We should probably perform self.merge_inplace
            # even if value.project(hyper_key).is_empty
            # as new valuespace creation may still apply
            # ------------------------------------------------
            self.merge_inplace(
                value.project(hyper_key),
                self_precedence=False,
                variate_mode=variate_mode,
            )

        # ==================================================================
        #                    CASE #3: VARIATE hyper_key Quble
        # ==================================================================
        else:
            if variate_mode == "multi":
                if not hyper_key.is_bool(space="<valuespaces>", summarize="all"):
                    # This test applies to both uni/multi-scalar
                    # as well as non-scalar hyper_key Qubles
                    raise Exception(
                        "When hyper_key is variate Quble and variate_mode=='multi': all boolean valuespaces required"
                    )
                hykey_vs_iterator = hyper_key.valuespaces
            elif variate_mode == "mixed":
                raise Exception(f"Unsupported variate_mode:{variate_mode}")
            elif hyper_key.valuespace is None:
                # Should not happen here due to hyper_key.is_nonvariate check above
                raise Exception(
                    "Internal inconsistency...hyper_key.valuespace is None (unexpectdly)"
                )
            else:  # elif variate_mode == uni':
                if not hyper_key.is_bool(space=hyper_key.valuespace, summarize="all"):
                    # This test applies to both uni/multi-scalar as well as non-scalar hyper_key Qubles
                    raise Exception(
                        "When hyper_key is Quble and variate_mode=='uni': boolean primary valuespace required"
                    )
                hykey_vs_iterator = [hyper_key.valuespace]

            # --------------------------------------------------------------
            # Convert non-Quble value --> Quble value
            # --------------------------------------------------------------
            # Acceptable cases:
            #    1) dict of numpy arrays (keyed by valuespace)
            #    2) Python scalar (to be applied to all relevant valuespaces)
            #    3) numpy array (with length == hyper_key.num_records) (to be applied to all relevant valuespaces)
            #    4) structured numpy array (with length == hyper_key.num_records) (keyed by valuespace)
            # --------------------------------------------------------------
            if not isinstance(value, Quble):
                if hyper_key.is_scalar or hyper_key.is_multiscalar:
                    raise Exception(
                        "hyper_key cannot be a uni/multi-scalar when value arg is not a Quble"
                    )

                value_array_dict = hyper_key.to_array_dict(
                    column_names=hyper_key.keyspaces
                )

                # --------------------------------------------------
                # CASE 3A: hyper_key: VARIATE Quble, value: dict
                # --------------------------------------------------
                value_valuespaces = []  # <-- Initialization
                if isinstance(value, dict):
                    for vs in value:
                        if vs in hykey_vs_iterator:
                            if vs in hyper_key.keyspaces:
                                # We disallow value dictionary keys that match hyper_key.keyspaces
                                raise Exception(
                                    "value dict key: {0} is should not be present in hyper_key.keyspaces:{1}".format(
                                        vs, hyper_key.keyspaces
                                    )
                                )
                            elif isinstance(value[vs], (list, tuple)):
                                value_array_dict[vs] = np.array(value[vs])
                            elif not isinstance(value[vs], np.ndarray):
                                value_array_dict[vs] = np.repeat(
                                    value[vs], hyper_key.num_records
                                )
                            elif len(value[vs]) != hyper_key.num_records:
                                raise Exception(
                                    "dict value[{0}] is np.array, yet len(value[{0}]):{1} != hyper_key.num_records:{2}".format(
                                        vs, len(value), hyper_key.num_records
                                    )
                                )
                            else:
                                value_array_dict[vs] = value[vs]
                            value_valuespaces.append(vs)
                # ----------------------------------
                # Here, value is:
                #   a) list/tuple
                #   b) (literal) scalar
                #   c) structured np.ndarray
                #   d) unstructured np.ndarray
                # ----------------------------------
                else:
                    if isinstance(value, (list, tuple)):
                        value = np.array(value)
                    elif not isinstance(value, np.ndarray):
                        # Assume a Python scalar was provided here
                        # which we first convert to a (non-structured) numpy array
                        value = np.repeat(value, hyper_key.num_records)

                    # numpy array value case
                    if len(value) != hyper_key.num_records:
                        # Raise an Exception when array length does not match hyper_key.num_records
                        raise Exception(
                            "value is np.array, yet len(value):{0} != hyper_key.num_records:{1}".format(
                                len(value), hyper_key.num_records
                            )
                        )
                    # ------------------------------------------------------------------
                    # CASE 3B: hyper_key: VARIATE Quble, value: structured numpy array
                    # ------------------------------------------------------------------
                    # Add valuespaces to value_array_dict accordingly...
                    if is_structured_dtype(value.dtype):
                        # structured numpy array...apply based on structured names
                        for vs in value.dtype.names:
                            if vs in hyper_key.keyspaces:
                                # We disallow value dictionary keys that match hyper_key.keyspaces
                                raise Exception(
                                    "value dict key: {0} is should not be present in hyper_key.keyspaces:{1}".format(
                                        vs, hyper_key.keyspaces
                                    )
                                )
                            elif vs in hykey_vs_iterator:
                                value_array_dict[vs] = value[vs]
                                value_valuespaces.append(vs)
                    # ----------------------------------------------------------------------
                    # CASE 3C: hyper_key: NON-VARIATE Quble, value: non-structured np array
                    # ----------------------------------------------------------------------
                    else:
                        # non-structured numpy array...apply to all relevant target valuespaces
                        for vs in hykey_vs_iterator:
                            value_array_dict[vs] = value
                            value_valuespaces.append(vs)

                # Construct value Quble from value_array_dict
                value = Quble.from_array_dict(
                    value_array_dict, valuespace=value_valuespaces
                )
            # Now, value is a Quble
            # Loop through the applicable valuespace(s) in hyper_key
            for vs in hykey_vs_iterator:
                # ===================================================================
                # tgt_valuespace logic:
                # ---------------------
                #    If (variate_mode == 'multi'): we are assigning hyper_key.valuespaces (see hykey_vs_iterator assignment above)
                #    If (variate_mode == 'uni') and (tgt_valuespace is None): self will inherit hyper_key.valuespace (see hykey_vs_iterator assignment above)
                #    If (variate_mode == 'uni') and (tgt_valuespace is not None): self assignment will be made against self's primary valuespace
                # ===================================================================
                tgt_valuespace1 = (
                    vs
                    if ((variate_mode == "multi") or (tgt_valuespace is None))
                    else tgt_valuespace
                )

                if variate_mode == "multi" and vs not in value.valuespaces:
                    # value Quble does not support this hykey_vs valuespace
                    # No values to assign for this valuespace (when variate_mode == 'multi')
                    continue
                elif not hyper_key.is_scalar and not hyper_key.is_multiscalar:
                    hyper_key_to_assign = hyper_key.bool_to_index(vs)
                    unprojected_value = value[vs] if variate_mode == "multi" else value
                    value_to_assign = unprojected_value.project(hyper_key_to_assign)
                    # Intentionally calling merge_inplace w/variate_mode='uni'
                    self.merge_inplace(
                        value_to_assign,
                        valuespace=tgt_valuespace1,
                        self_precedence=False,
                        variate_mode="uni",
                    )
                elif hyper_key.scalar_values[vs]:
                    value_to_assign = value[vs] if variate_mode == "multi" else value
                    # Intentionally calling merge_inplace w/variate_mode='uni'
                    self.merge_inplace(
                        value_to_assign,
                        valuespace=tgt_valuespace1,
                        self_precedence=False,
                        variate_mode="uni",
                    )

    def touch(self, grace: bool = False):
        """
        Updates the time_stamp of the Quble to current time (only necessarry for env nodes)
        [Modifies self, does not return anything]

        grace: (boolean) Flag for handling of undefined/absent (no table) Quble case
            grace=True: does nothing when Quble is undefined (has no underlying table)
            grace=False: raises and Exception when Quble is undefined (has no underlying table)
        """
        if not self.is_undefined:
            if is_env_table(self.table_name):
                _logger.debug(f"Touching quble: {self.table_name}")
                self.time_stamp = datetime.now()
                snowflake_set_quble_timestamp(self.table_name, self.time_stamp)
        elif grace:
            pass
        elif self.is_undefined:
            raise UndefinedQubleError(
                f"Cannot perform touch an undefined (no table) Quble!"
            )
        else:
            raise AbsentQubleError(f"Cannot perform touch an absent (table) Quble!")

    @RootLib.lazy_kwargs()
    def merge_inplace(
        self,
        other: Quble,
        self_precedence: bool = False,
        variate_mode: str = RootLib.lazy_eval("variate_mode"),
        valuespace="<valuespace>",
        auto_fx: bool = RootLib.lazy_eval("auto_fx"),
        auto_convert: bool = RootLib.lazy_eval("auto_convert"),
        auto_expand: bool = RootLib.lazy_eval("auto_expand"),
        auto_type: str = RootLib.lazy_eval("auto_type"),
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
    ):
        """
        See :meth:`~qubles.core.quble.Quble.merge`
        """
        return self.merge(
            other=other,
            self_precedence=self_precedence,
            inplace=True,
            variate_mode=variate_mode,
            valuespace=valuespace,
            auto_fx=auto_fx,
            auto_convert=auto_convert,
            auto_expand=auto_expand,
            auto_type=auto_type,
            auto_link=auto_link,
            link_check=link_check,
            link_dupe_grace=link_dupe_grace,
        )

    @RootLib.lazy_kwargs()
    def merge(
        self,
        other: Quble,
        self_precedence: bool = False,
        inplace: bool = False,
        variate_mode: str = RootLib.lazy_eval("variate_mode"),
        valuespace="<valuespace>",
        auto_fx: bool = RootLib.lazy_eval("auto_fx"),
        auto_convert: bool = RootLib.lazy_eval("auto_convert"),
        auto_expand: bool = RootLib.lazy_eval("auto_expand"),
        auto_type: str = RootLib.lazy_eval("auto_type"),
        auto_link: bool = RootLib.lazy_eval("auto_link"),
        link_check: bool = RootLib.lazy_eval("link_check"),
        link_dupe_grace: bool = True,
    ):
        """
        Merges the records (and columns) of two Qubles.

        :param other: (Quble) to be merged into self
        :type other: Quble

        :param self_precedence: Flag for self precedence when records of
                                the two tables are matched on keys of keyspaces
        :type self_precedence: boolean (True*/False)
            self_precedence=True: self takes precedence for matching records
            self_precedence=False: other takes precedence for matching records

        :param inplace: Flag for changing self directly inplace
        :type inplace: boolean (True/False*)
            inplace=True: modifies self Quble directly and returns self
            inplace=False: returns a (possibly) modified Quble (leaves self unchanged)

        :param variate_mode: controls variate handling
        :type variate_mode: string ('uni'*/'multi'/'mixed')
        variate_mode='uni': merges primary valuespace of other into the specified valuespace of self but retains all auxillary valuespaces of self in result
        ==> result will have self's valuespaces + the specified valuespace (if new)
        variate_mode='mixed': not supported at this time
        variate_mode='multi': merges all valuespaces of other into all valespaces of self
        ==> result valuespaces will be a union of
        ==> self's valuespaces & other's valuespaces

        :param valuespace: indicates target valuespace in self when using variate_mode='uni'
                           [valuespace arg is ignored if variate_mode != 'uni']
        :type valuespace: str (must be a valid existing valuespace of self)

        :param auto_fx: Flag for automated fx (currency) reconciliation
        :type auto_fx: bool (True*/False)
            auto_fx=True: automatically reconciles fx conflicts between valuespaces of self & other
            auto_fx=False: fx conflicts between valuespaces of self & other yield an Exception

        :param auto_convert: Flag for automated frequency reconciliation
        :type auto_convert: boolean (True*/False)
            auto_convert=True: automatically reconciles frequency conflicts between valuespaces pairs of self & other
            auto_convert=False: frequency conflicts between valuespaces pairs of self & other yield an Exception

        :param auto_expand: flag to allow dimensional/column expansion in self
        :type auto_expand: bool (True*/False)

        :param auto_type: Flag for automated column type reconciliation
        :type auto_type: bool (True*/False)
        auto_type=True: automatically reconciles column type conflicts between valuespaces pairs of self & other
        auto_type=False: column type conflicts between valuespaces pairs of self & other yield an Exception

        :param auto_link: Control for auto-linking (keyspace affiliation)
        :type auto_link: bool

        :param key_ordering: (optional) controls row ordering by key
        :type key_ordering: None (no keyspace sorting), 'asc' or 'desc', dict
                 [See: :meth:`~qubles.core.quble.Quble.key_sort`]

        """
        # Validate other arg
        # --------------------
        if other is None:
            return self if inplace else self.copy()
        elif not isinstance(other, Quble):
            raise Exception("Invalid other arg...Quble required")

        # Remove duplicate keys from qubles
        self.check_remove_duplicate_keys()
        other.check_remove_duplicate_keys()

        # Validate variate_mode
        # -----------------------
        if variate_mode not in ("uni", "mixed", "multi"):
            raise Exception(
                "Invalid variate_mode:{0}...valid options: 'uni','mixed','multi'".format(
                    variate_mode
                )
            )

        # -------------------------------
        # Handle other list/tuple case
        # -------------------------------
        if isinstance(other, (list, tuple)):
            result = self.copy()
            for other1 in other:
                result = result.merge(
                    other1,
                    self_precedence=self_precedence,
                    inplace=inplace,
                    variate_mode=variate_mode,
                    valuespace=valuespace,
                    auto_fx=auto_fx,
                    auto_convert=auto_convert,
                    auto_expand=auto_expand,
                    auto_type=auto_type,
                    auto_link=auto_link,
                    link_check=link_check,
                    link_dupe_grace=link_dupe_grace,
                )
            return result

        # -------------------------------
        # Handle undefined Quble cases
        # -------------------------------
        elif self.is_undefined:
            if other.is_undefined:
                return self if inplace else self.copy()
            elif inplace:
                self._swap_table(other)
                return self
            else:
                return other.copy()
        elif other.is_undefined:
            return self if inplace else self.copy()

        # ---------------------------------------
        # Attempt auto_link (if applicable)
        # ---------------------------------------
        # The following code will try to link
        # keyspaces of latter qubles (in list)
        # to those of former qubles (in list)
        # ---------------------------------------
        if auto_link:
            (adj_self, adj_other) = RootLib().apply_reflib_multilink(
                [self, other],
                link_check=link_check,
                link_dupe_grace=link_dupe_grace,
                impose_tgt_keyspace=False,
            )
        else:
            adj_self = self
            adj_other = other

        # -------------------------------------------
        # Prep for possible column type conversions
        # -------------------------------------------
        self_coltype_conversion_dict = {}
        other_coltype_conversion_dict = {}

        # QUESTION: DO WE NEED TO WORRY ABOUT POTENTIAL keyspace_type INCONSISTENCIES?? [PROBABLY NOT]
        adj_self_coltypes_with_digits = adj_self.get_column_type(adj_self.spaces)
        adj_other_coltypes_with_digits = adj_other.get_column_type(adj_other.spaces)
        # ----------------------------------------------
        #             Process keyspaces
        # ----------------------------------------------
        # Establish tgt_keyspaces as union of
        # all keyspaces (post apply_reflib_multilink)
        # ----------------------------------------------

        tgt_keyspaces = [ks for ks in adj_self.keyspaces]
        # Place self's keyspaces at beginning of tgt_keyspaces list
        for ks in adj_other.keyspaces:
            if ks not in tgt_keyspaces:
                # Here, ks is in adj_other.keyspaces BUT NOT adj_self.keyspaces
                tgt_keyspaces.append(ks)
            else:
                # Here, ks in both adj_self.keyspaces AND adj_other.keyspaces
                # In this case, check for any necessary column type conversions for this ks
                # Compare & record coltype conflicts
                coltype_pair = [
                    adj_self_coltypes_with_digits[ks],
                    adj_other_coltypes_with_digits[ks],
                ]
                resolved_coltypes_with_digits = coltype_resolver(
                    coltype_pair, lower_case=True
                )

                # Does self's coltype need to be resolved?
                # If so, update self_coltype_conversion_dict accordingly
                if (
                    resolved_coltypes_with_digits is not None
                    and resolved_coltypes_with_digits
                    != adj_self_coltypes_with_digits[ks]
                ):
                    self_coltype_conversion_dict[ks] = resolved_coltypes_with_digits

                # Does others's coltype need to be resolved?
                # If so, update other_coltype_conversion_dict accordingly
                if (
                    resolved_coltypes_with_digits is not None
                    and resolved_coltypes_with_digits
                    != adj_other_coltypes_with_digits[ks]
                ):
                    other_coltype_conversion_dict[ks] = resolved_coltypes_with_digits

        # ------------------------
        # Process valuespaces
        # ------------------------
        # We are retaining all adj_self valuespaces w/o renames
        adj_self_valuespace_map = {}
        for vs in adj_self.valuespaces:
            adj_self_valuespace_map[vs] = vs

        # Build a dict containing all adj_other valuespaces to be retained
        # and the respective target valuespace (regardless of whether it is being renamed)
        src_to_updates_valuespace_pair_map = {}
        other_fx_conversion_dict = {}

        if variate_mode == "multi":
            # Place self's valuespaces at beginning of tgt_valuespaces list
            tgt_valuespaces = []

            for vs in adj_self.valuespaces:
                tgt_valuespaces.append(vs)
                if vs in adj_other.valuespaces:
                    src_to_updates_valuespace_pair_map[vs] = vs
                    src_fx1 = adj_self.get_space_info(info_type="fx", space=vs)
                    other_fx1 = adj_other.get_space_info(info_type="fx", space=vs)

                    # Compare & record fx conflicts
                    if (
                        src_fx1 is not None
                        and other_fx1 is not None
                        and src_fx1 != other_fx1
                    ):
                        other_fx_conversion_dict[vs] = src_fx1

                    # Compare & record coltype conflicts
                    coltype_pair = [
                        adj_self_coltypes_with_digits[vs],
                        adj_other_coltypes_with_digits[vs],
                    ]
                    resolved_coltypes_with_digits = coltype_resolver(
                        coltype_pair, lower_case=True
                    )

                    # Does self's coltype need to be resolved?
                    # If so, update self_coltype_conversion_dict accordingly
                    if (
                        resolved_coltypes_with_digits is not None
                        and resolved_coltypes_with_digits
                        != adj_self_coltypes_with_digits[vs]
                    ):
                        self_coltype_conversion_dict[vs] = resolved_coltypes_with_digits

                    # Does others's coltype need to be resolved?
                    # If so, update other_coltype_conversion_dict accordingly
                    if (
                        resolved_coltypes_with_digits is not None
                        and resolved_coltypes_with_digits
                        != adj_other_coltypes_with_digits[vs]
                    ):
                        other_coltype_conversion_dict[vs] = (
                            resolved_coltypes_with_digits
                        )
            # from adj_other to end of tgt_valuespaces
            for vs in adj_other.valuespaces:
                if vs not in tgt_valuespaces:
                    tgt_valuespaces.append(vs)

                if vs not in src_to_updates_valuespace_pair_map:
                    src_to_updates_valuespace_pair_map[vs] = vs
        elif variate_mode == "mixed":
            raise Exception("Unsupported: variate_mode == 'mixed'")
        else:
            # ----------------------------------------------------
            # Validate valuespace arg...
            # ----------------------------------------------------
            # This will be designated "target valuespace"
            # for the univariate merge operation
            # [By default, will be adj_self's primary valuespace]
            # ----------------------------------------------------
            if valuespace == "<valuespace>" and adj_self.is_nonvariate:
                valuespace = None
            else:
                valuespace = adj_self.validate_valuespace(
                    valuespace, grace=False, solo_required=True
                )

            if valuespace is not None and valuespace not in adj_self.valuespaces:
                raise Exception(f"Absent valuespace:{valuespace}")

            # Forcing a copy below to avoid list corruption
            tgt_valuespaces = [vs for vs in adj_self.valuespaces]
            if adj_other.valuespace is not None:
                if valuespace is None:
                    # adj_self does not have a primary valuespace
                    # Inherit adj_other.valuespace as the new primary valuespace of adj_self
                    valuespace = adj_other.valuespace
                    if adj_other.valuespace not in tgt_valuespaces:
                        # Add valuespace to tgt_valuespace (if not already present)
                        tgt_valuespaces.append(adj_other.valuespace)
                elif valuespace not in adj_self.valuespaces:
                    # adj_self does not have the specified valuespace
                    if valuespace not in tgt_valuespaces:
                        # Add specified valuespace to tgt_valuespace (if not already present)
                        tgt_valuespaces.append(valuespace)
                else:
                    # self has a specified valuespace
                    src_to_updates_valuespace_pair_map[valuespace] = (
                        adj_other.valuespace
                    )

                    # Compare & record fx conflicts
                    src_fx1 = adj_self.get_space_info(info_type="fx", space=valuespace)
                    other_fx1 = adj_other.get_space_info(
                        info_type="fx", space=adj_other.valuespace
                    )
                    if (
                        src_fx1 is not None
                        and other_fx1 is not None
                        and src_fx1 != other_fx1
                    ):
                        other_fx_conversion_dict[adj_other.valuespace] = src_fx1

                    # Compare & record coltype conflicts
                    coltype_pair = [
                        adj_self_coltypes_with_digits[valuespace],
                        adj_other_coltypes_with_digits[adj_other.valuespace],
                    ]
                    resolved_coltypes_with_digits = coltype_resolver(
                        coltype_pair, lower_case=True
                    )

                    # Does self's valuespace coltype need to be resolved?
                    # If so, update self_coltype_conversion_dict accordingly
                    if (
                        resolved_coltypes_with_digits is not None
                        and resolved_coltypes_with_digits
                        != adj_self_coltypes_with_digits[valuespace]
                    ):
                        self_coltype_conversion_dict[valuespace] = (
                            resolved_coltypes_with_digits
                        )

                    # Does others's coltype need to be resolved?
                    # If so, update other_coltype_conversion_dict accordingly
                    if (
                        resolved_coltypes_with_digits is not None
                        and resolved_coltypes_with_digits
                        != adj_other_coltypes_with_digits[adj_other.valuespace]
                    ):
                        other_coltype_conversion_dict[adj_other.valuespace] = (
                            resolved_coltypes_with_digits
                        )
        # -----------------------------------------------
        # Impose fx conversions on adj_other as needed
        # -----------------------------------------------
        if len(other_fx_conversion_dict) > 0:
            if auto_fx:
                adj_other = adj_other.convert_fx(
                    fx=other_fx_conversion_dict,
                    valuespace=list(other_fx_conversion_dict.keys()),
                )
            else:
                raise FXConflict(
                    f"Currency FX conflicts present, yet auto_fx:{auto_fx}"
                )
        # -------------------------------------------------------------
        # Impose frequency conversions on adj_other as needed
        # -------------------------------------------------------------
        adj_self_freqs = {}
        adj_other_freqs = {}
        for ks in adj_self.time_keyspaces:  # <-- Arbitrarily using adj_self.keyspaces
            # Is this keyspace present in adj_other?
            if ks not in adj_other.spaces:
                continue
            elif not adj_other.is_time_space(space=ks, grace=True):
                # continue
                raise Exception(
                    f"Merge conflict: keyspace:{ks} is timespace in self but non-timespace in other"
                )

            # Get adj_self & adj_other's frequencies for this keyspace
            adj_self_freqs[ks] = adj_self.get_freq(space=ks)
            adj_other_freqs[ks] = adj_other.get_freq(space=ks)

            # Resolve frequency conflicts according to freq_handling
            if (
                adj_self_freqs[ks] is None
                or adj_other_freqs[ks] is None
                or (adj_self_freqs[ks] == adj_other_freqs[ks])
            ):
                # No frequency conflict here
                pass
            elif auto_convert:
                adj_other = adj_other.asfreq(freq=adj_self_freqs[ks], keyspace=ks)
            else:
                raise FreqConflict(
                    f"Frequency conflicts present, yet auto_convert:{auto_convert}"
                )
        # ----------------------------------------------------
        # Impose coltype conversions on adj_self as needed
        # ----------------------------------------------------
        if len(self_coltype_conversion_dict) > 0:
            if auto_type:
                adj_self = adj_self.change_types(self_coltype_conversion_dict)
            else:
                raise ColTypeConflict(
                    f"Column type conflicts present, yet auto_convert:{auto_convert}"
                )
        # ----------------------------------------------------
        # Impose coltype conversions on adj_other as needed
        # ----------------------------------------------------
        if len(other_coltype_conversion_dict) > 0:
            adj_other = adj_other.change_types(other_coltype_conversion_dict)
        # --------------------------------------------------------------------
        # Are there tgt_keyspaces or tgt_valuespaces that are not in adj_self?
        # If so, expand/adjust adj_self to include extra keyspaces/valuespaces from adj_other
        # [For extra (new) keyspaces, inherit values's keys]
        # [For non-extra (existing) keyspaces, keep adj_self's original keys]
        # --------------------------------------------------------------------
        if any([(ks not in adj_self.keyspaces) for ks in tgt_keyspaces]) or any(
            [(ks not in adj_self.valuespaces) for ks in tgt_valuespaces]
        ):
            if not auto_expand:
                raise Exception(
                    "auto_expand:{0}...cannot insert extra keyspaces:{1}/valuespaces:{2}".format(
                        auto_expand,
                        adj_self.ortho_keyspaces(tgt_keyspaces),
                        adj_self.ortho_valuespaces(tgt_valuespaces),
                    )
                )
            adj_self_valuespace_map1 = {}
            adj_other_valuespace_map1 = {}
            for vs in tgt_valuespaces:
                if vs in adj_self.valuespaces:
                    # Prioriritize adj_self as the preferred valuespace contributor here
                    adj_self_valuespace_map1[vs] = vs
                elif vs in src_to_updates_valuespace_pair_map:
                    # ==> Recall that we are allowing for adj_other's valuespaces
                    # ==> to possibly be renamed here
                    # ==> via src_to_updates_valuespace_pair_map dict
                    other_vs = src_to_updates_valuespace_pair_map[vs]
                    adj_other_valuespace_map1[other_vs] = vs
                else:
                    raise Exception(
                        "Internal inconsistency...vs:{0} not present in adj_self.valuespaces:{1} nor dict values of src_to_updates_valuespace_pair_map:{2}".format(
                            vs, adj_self.valuespaces, src_to_updates_valuespace_pair_map
                        )
                    )

            # Here there are keyspaces or valuespaces in adj_other Quble
            # that are not in adj_self Quble's keyspaces
            # NOTE: we can adj_self.join(adj_other, ....) so that self's valuespaces appear first in result
            adj_self = adj_self.join(
                adj_other,
                keys_join_op="leftmost",
                keyspaces_join_op=tgt_keyspaces,
                valuespaces_join_op=[
                    adj_self_valuespace_map1,
                    adj_other_valuespace_map1,
                ],
            )

            # Re-Check: # Are there tgt_keyspaces that are not in adj_self's keyspaces?
            if any([(ks not in adj_self.keyspaces) for ks in tgt_keyspaces]):
                raise Exception(
                    "Unresolved: following tgt_keyspaces are not in adj_other.keyspaces:{0}".format(
                        adj_other.ortho_keyspaces(self.keyspaces)
                    )
                )
        # -----------------------------------------------------------------
        # At this point adj_self has all tgt_keyspaces & tgt_valuespaces
        # -----------------------------------------------------------------

        # ------------------------------------------------------------------------
        # Are there tgt_keyspaces that are not in adj_other Quble's keyspaces?
        # If so, expand/adjust adj_other to include extra keyspaces from adj_self
        # [For extra (new) keyspaces, inherit adj_self's keys]
        # [For non-extra (existing) keyspaces, keep adj_other's original keys]
        # ------------------------------------------------------------------------
        # if len(adj_other.ortho_keyspaces(tgt_keyspaces)) > 0:
        if any([(ks not in adj_other.keyspaces) for ks in tgt_keyspaces]):
            adj_self_valuespace_map1 = {}
            adj_other_valuespace_map1 = {}
            for tgt_vs in tgt_valuespaces:
                if tgt_vs in list(src_to_updates_valuespace_pair_map.values()):
                    # Prioriritize adj_other as the preferred valuespace contributor here
                    # ==> Recall that we are allowing for adj_other's valuespaces
                    # ==> to possibly be renamed here
                    # ==> via src_to_updates_valuespace_pair_map dict
                    adj_other_valuespace_map1[tgt_vs] = (
                        src_to_updates_valuespace_pair_map[tgt_vs]
                    )
                elif tgt_vs in adj_self.valuespaces:
                    adj_self_valuespace_map1[tgt_vs] = tgt_vs
                else:
                    raise Exception(
                        "Internal inconsistency...tgt_vs:{0} not present in adj_self.valuespaces:{1} nor dict values of src_to_updates_valuespace_pair_map:{2}".format(
                            tgt_vs,
                            adj_self.valuespaces,
                            src_to_updates_valuespace_pair_map,
                        )
                    )

            # Here there keyspaces or valuespaces in adj_self Quble that are not in adj_other Quble's keyspaces
            # NOTE: we can adj_self.join(adj_other, ....) so that self's valuespaces appear first in result
            adj_other = adj_self.join(
                adj_other,
                keys_join_op="rightmost",
                keyspaces_join_op=tgt_keyspaces,  #'union'
                valuespaces_join_op=[
                    adj_self_valuespace_map1,
                    adj_other_valuespace_map1,
                ],
            )
            # Re-Check: Are there tgt_keyspaces that are not in adj_other Quble's keyspaces?
            # if len(adj_self.ortho_keyspaces(tgt_keyspaces)) > 0:
            if any([(ks not in adj_other.keyspaces) for ks in tgt_keyspaces]):
                raise Exception(
                    "Unresolved: following tgt_keyspaces are not in adj_other.keyspaces:{0}".format(
                        adj_self.ortho_keyspaces(tgt_keyspaces)
                    )
                )
        # At this point, the keyspaces (sets) should be the same
        if len(set(adj_self.keyspaces) - set(adj_other.keyspaces)) > 0:
            raise Exception(
                "Non-matching sets...adj_self.keyspaces:{0} & adj_other.keyspaces:{1}".format(
                    adj_self.keyspaces, adj_other.keyspaces
                )
            )
        # But we also need to ensure that ORDERING of keyspaces
        # is the same between adj_self & adj_other
        elif adj_self.keyspaces != adj_other.keyspaces:
            adj_other_columns_reordered = adj_self.keyspaces + adj_other.valuespaces
            adj_other = adj_other.select(column_names=adj_other_columns_reordered)

        # At this point, the keyspaces (AND ORDERING) should be the same

        # -------------------------------------------------------------------
        # For not inplace case, make sure adj_self's table is DIFFERENT than self
        # otherwise make a deep copy (new table) assign adj_self = adj_self.copy()
        # so that the merge query does not directly alter self.table_name
        # -------------------------------------------------------------------
        # If adj_self.table_name != self.table_name here: some operation above has changed adj_self
        # If adj_self.table_name == self.table_name here: adj_self has not yet been adjusted thus far
        # -------------------------------------------------------------------
        if not inplace and adj_self.shares_table_with(self):
            adj_self = adj_self.copy()

        # Are there source valuespaces outside src_to_updates_valuespace_pair_map?
        unmapped_src_valuespaces = []
        for src_vs in adj_self.valuespaces:
            if src_vs not in src_to_updates_valuespace_pair_map:
                unmapped_src_valuespaces.append(src_vs)

        # Handle dual uni/multi scalar case
        dual_scalar_case = False  # <-- initialization
        row_numbers_added = False  # <-- initialization
        if (adj_self.is_scalar or adj_self.is_multiscalar) and (
            adj_other.is_scalar or adj_other.is_multiscalar
        ):
            dual_scalar_case = True
            if len(unmapped_src_valuespaces) > 0:
                row_numbers_added = True
                adj_self = adj_self.add_row_numbers(row_number_keyspace="row_number")
                adj_other = adj_other.add_row_numbers(row_number_keyspace="row_number")

        # Render & execute the merge query (when applicable)
        # ----------------------------------------------------
        if not dual_scalar_case or row_numbers_added:
            sql_template = JINJA_ENV.get_template("merge_tables.j2")
            sql_command = sql_template.render(
                src_table_name=adj_self.table_name,
                updates_table=adj_other.table_name,
                keyspaces=adj_self.keyspaces,  # <-- Arbitrarily using adj_self.keyspaces
                allspaces=adj_self.spaces,
                src_to_updates_valuespace_pair_map=src_to_updates_valuespace_pair_map,
                src_precedence=self_precedence,
                delete_nonupdates=False,  # <-- We choose to keep existing records that are not in updates_table
            )
            execute(sql_command)
        # Here, dual_scalar_case AND not row_numbers_added
        elif self_precedence:
            # Where, we do perform replacement
            pass
        # Render & execute scalar record replacement
        # --------------------------------------------
        else:
            sql_template = JINJA_ENV.get_template("replace_scalar_records.j2")
            sql_command = sql_template.render(
                src_table_name=adj_self.table_name,
                updates_table=adj_other.table_name,
                src_to_updates_valuespace_pair_map=src_to_updates_valuespace_pair_map,
            )
            execute(sql_command)

        # Remove row_number keyspace (when applcable)
        # ---------------------------------------------
        if row_numbers_added:
            if adj_self.num_records != 1:
                raise Exception(
                    "Internal inconsistency...scalar expected yet adj_self.num_records:{0}".format(
                        adj_self.num_records
                    )
                )
            adj_self = adj_self.select(
                column_names=[
                    space for space in adj_self.spaces if space != "row_number"
                ]
            )

        # Clear the num_records_caches for adj_self
        # ------------------------------------------
        adj_self._clear_num_records_caches()
        # Return the result based on inplace arg
        # ------------------------------------------
        if inplace:
            if not adj_self.shares_table_with(self):
                # Swap table so that self Quble inherits adj_self.table_name
                self._swap_table(adj_self)
            return self

        elif adj_self.shares_table_with(self):
            # Make sure not to send self back when inplace=False
            # ==> Rather, we send a copy so that calling context
            # ==> does not unexpectedly alter self subsequently
            return adj_self.copy()

        else:
            return adj_self

    def union_trusted(self, other: list):
        """
        Performs union of records of self with other Quble(s)
        ~see qubles.core.quble.Quble._union_trusted
        """
        return self._union_trusted(other=other, union_op="UNION")

    def union_all_trusted(self, other: list):
        """
        Performs union all of records of self with other Quble(s)
        ~see qubles.core.quble.Quble._union_trusted
        """
        return self._union_trusted(other=other, union_op="UNION ALL")

    def _union_trusted(self, other: list, union_op="UNION"):
        """
        Performs union (or union all) of the records
        for self with the (list/tuple of) other Quble(s) provided

        IMPORTANT: Trusts that all underlying tables are compatible regarding:

           keyspaces, valuespaces, roles, column types, fx, frequency, etc.

        ==> Will inherit column information according to self
        ==> Will throw Exception if any non-undefined table has differing spaces
        ==> Will ignore any undefined tables during union operation

        :param other: (Qubles) to be unioned with self
        :type other: list/tuple of Qubles or Quble

        :param union_op: The union operator...'union','UNION','union all','UNION ALL'
        :type union_op: str

        """
        # Validate union_op arg
        if union_op is None or not isinstance(union_op, str):
            raise Exception(
                f"Invalid union_op...'union','UNION','union all' or 'UNION ALL' expected"
            )

        union_op = union_op.strip().upper()
        if union_op not in ("UNION", "UNION ALL"):
            raise Exception(
                f"Invalid union_op...'union','UNION','union all' or 'UNION ALL' expected"
            )

        # Validate other arg
        # [Should be either a Quble or list/tuple of Qubles]
        if other is None:
            return self.copy()
        elif isinstance(other, Quble):
            other2 = [other]
        elif not isinstance(other, (tuple, list)):
            raise Exception("Invalid other...list/tuple of Qubles or a Quble expected")

        # Validate other entries as Qubles
        for quble_no, q1 in enumerate(other):
            if not isinstance(q1, Quble):
                raise Exception(
                    f"Invalid type(other[{quble_no}]):{type(other[quble_no])}...Quble expected"
                )

        # Drop undefined Qubles from other (list)
        other = [other1 for other1 in other if other.is_defined]
        if len(other) == 0:
            # Handle empty list case
            return self.copy()

        # Handle undefined self
        if self.is_undefined:
            if len(other) == 0:
                return Quble.undefined_instance()
            elif len(other) == 1:
                return other[0]
            else:
                # Apply union operating to remaining qubles
                return other[0]._union_trusted(other[1:], union_op=union_op)

        # Makes sure others have same column names
        # (and same ordering) as self
        for other1 in other:
            if other1.spaces != self.spaces:
                raise Exception(
                    f"Inconsistent columns: self.spaces:{self.spaces} != other1.spaces:{other1.spaces}"
                )

        # Establish reinference_freq_hint dict to identify
        # if/where any time-spaces need re-inference after the union
        # and also denote the associated freq_hint...
        # ==> dict key: time-space where freq re-inference is needed
        # ==> dict value: associated freq_hint for re-inference
        # -----------------------------------------------------------
        reinference_freq_hint = {}
        for space1 in self.time_spaces:
            freq1 = self.get_space_info(info_type="freq", space=space1, grace=True)
            for other1 in other:
                if other1 is None:
                    # Should not happen
                    continue
                elif space1 not in other1.spaces:
                    # Should not happen due to logic above
                    # Could throw an Exception here
                    continue
                elif not other1.is_time_space(space=space1, grace=True):
                    # Ideally should not happen
                    # [hopefully all columns across Quble have consistent types]
                    continue
                freq2 = other1.get_space_info(
                    info_type="freq", space=space1, grace=True
                )
                if freq2 is None:
                    continue
                elif freq1 is None:
                    freq1 = freq2
                elif freq2 != freq1:
                    # Here both freq1 and freq2 are not None
                    # both they do not match
                    # In this case, we should re-infer freq in merged result
                    reinference_freq_hint[space1] = freq1
                    break  # <-- break out of other loop

        # Build comprehensive list of all tables to be unioned
        src_table_names = [self.table_name] + [other1.table_name for other1 in other]

        # Generate target table name
        tgt_table_name = generate_random_table_name()

        # Procure template, then render & execute sql_command
        sql_template = JINJA_ENV.get_template("union_trusted.j2")
        sql_command = sql_template.render(
            tgt_table_name=tgt_table_name,
            src_table_names=src_table_names,
            column_names=self.spaces,
            union_op=union_op,
        )
        execute(sql_command)

        if tgt_table_name == self.table_name:
            result = Quble.from_table(tgt_table_name, time_stamp=self.time_stamp)
        else:
            result = Quble.from_table(
                tgt_table_name,
                col_info=self.get_space_info(
                    info_type=CUSTOM_INFO_TYPES,
                    space=self.spaces,
                    omit_unassigned=True,
                ),
            )

        # Re-infer frequencies where needed [Only needed where frequencies from self and others did not match]
        # ------------------------------------
        for space1 in reinference_freq_hint:
            if space1 not in result.spaces:
                # Should not happen
                continue
            elif not result.is_time_space(space=space1, grace=True):
                # Should not happen
                continue
            result._infer_freq(
                space=space1,
                freq_hint=reinference_freq_hint[space1],
                assign_inferred=True,
                force_reinfer=True,
                grace=True,
            )

        return result

    # ==================================== Export ====================================

    @staticmethod
    @RootLib.lazy_kwargs()
    def string_to_index(
        thestr: str,
        default_keyspace: str = RootLib.lazy_eval("default_keyspace"),
        keyspace_delimiter: str = RootLib.lazy_eval("keyspace_delimiter"),
        index_delimiter: str = RootLib.lazy_eval("index_delimiter"),
        key_delimiter: str = RootLib.lazy_eval("key_delimiter"),
        range_delimiter: str = RootLib.lazy_eval("range_delimiter"),
        complex_indexing_date=RootLib.lazy_eval("complex_indexing_date"),
        datetime64_dtype=RootLib.lazy_eval("datetime64_dtype"),
        context: Quble = None,
        return_type="Quble",
    ) -> Quble:
        """
        Converts a string (or dict of strings) to an index Quble
        with custom column_info (dictionary of dictionaries)
        stored as titles and custom column_info
        The resultant structured array to be used for subsequent Quble construction
        by implementing 'complex_indexing' using delimiters as defined within RootLib controls

        Example:
          'Tickers:IBM,GE|Dates:2018-03-31,4/30/2018-04-30,2018-05-31:Factors:A,B,C'
                 Yields the following 3D (3x5x4) (ordered) dictionary (od)
             -> od = ordered dictionary
            'Tickers'            'Dates'            'Factors'
            ---------  -------------------------   ----------
            'IBM'    '2018-03-31T00:00:00.000'      'A'
            'IBM'    '2018-03-31T00:00:00.000'      'B'
            'IBM'    '2018-03-31T00:00:00.000'      'C'
            'IBM'    '2018-04-30T00:00:00.000'      'A'
            'IBM'    '2018-04-30T00:00:00.000'      'B'
            'IBM'    '2018-04-30T00:00:00.000'      'C'
            'IBM'    '2018-05-31T00:00:00.000'      'A'
            'IBM'    '2018-05-31T00:00:00.000'      'B'
            'IBM'    '2018-05-31T00:00:00.000'      'C'
            'GE'    '2018-03-31T00:00:00.000'      'A'
            'GE'    '2018-03-31T00:00:00.000'      'B'
            'GE'    '2018-03-31T00:00:00.000'      'C'
            'GE'    '2018-04-30T00:00:00.000'      'A'
            'GE'    '2018-04-30T00:00:00.000'      'B'
            'GE'    '2018-04-30T00:00:00.000'      'C'
            'GE'    '2018-05-31T00:00:00.000'      'A'
            'GE'    '2018-05-31T00:00:00.000'      'B'
            'GE'    '2018-05-31T00:00:00.000'      'C'

        Context is an optional Quble with columns (and associated information) that
        may guide behavior

        delimiters:
        index_delimiter: separates dimensional information (typically: index_delimiter='|')
        keyspace_delimiter: separates keyspace from keys for a given dimension (typically: keyspace_delimiter=':')
        range_delimiter: indicates a range of values (typically: range_delimiter='...')

        return_type:
        Quble : Returns a Quble as the output
        PandasDF : Returns an object of PandasDF (derived class) as the output
        pandas_dataframe: Returns an object of standard pandas dataframe class as the output
        """
        # Validating return_type argument
        if return_type not in ("Quble", "PandasDF", "pandas_dataframe"):
            raise Exception("Invalid return_type specified")

        (indices, context_info) = str2indices(
            thestr,
            default_keyspace=default_keyspace,
            keyspace_delimiter=keyspace_delimiter,
            index_delimiter=index_delimiter,
            key_delimiter=key_delimiter,
            range_delimiter=range_delimiter,
            complex_indexing_date=complex_indexing_date,
            datetime64_dtype=datetime64_dtype,
            context=context,
        )

        keyspaces = iter(indices.keys())
        key_lists = []
        names = []
        formats = []
        titles = []

        for ks_no, keyspace in enumerate(keyspaces):
            if not isinstance(keyspace, str):
                raise InvalidIndicesError(f"Invalid keyspace name: {keyspace}")

            keys = indices[keyspace]

            if not isinstance(keys, (list, tuple, np.ndarray)):
                keys = [keys]

            if len(keys) == 0:
                # TODO: Get default dtype from RootLib
                dtype = np.dtype(np.float64)
            else:
                # Try to guard against being provided a non-ndarray
                if not isinstance(keys, np.ndarray):
                    keys = np.array(keys)
                dtype = keys.dtype

                # Try to resolve object dtypes
                if keys.dtype == "O":
                    if len(keys) == 0:
                        raise Exception(
                            "Unsupported object dtype and len==0 prevents introspection"
                        )
                    elif isinstance(keys[0], str):
                        keys = keys.astype("string")
                        dtype = keys.dtype
                    elif isinstance(keys[0], datetime):
                        keys = keys.astype("datetime64")
                        dtype = keys.dtype
                    else:
                        raise Exception(
                            "Introspection failed for object dtype and keys[0]:{0}".format(
                                keys[0]
                            )
                        )

            custom_info_curr_keyspace = {}
            # custom_info_curr_keyspace['type'] = coltype
            custom_info_curr_keyspace[DUMMY_INFO_TYPE_FOR_UNIQUE_NUMPY_TITLES] = (
                keyspace  # <-- just to guarantee titles are unique
            )

            # Also try to incorporate context_info
            if context_info:
                for info_type, info_assignments in context_info.items():
                    if info_assignments and keyspace in info_assignments:
                        custom_info_curr_keyspace[info_type] = info_assignments[
                            keyspace
                        ]

            # Make sure 'role' is in custom_info_curr_keyspace
            if "role" not in custom_info_curr_keyspace:
                custom_info_curr_keyspace["role"] = "keyspace"

            # A DateRange may be provide which has an freq attribute
            if hasattr(keys, "freq"):
                custom_info_curr_keyspace["freq"] = keys.freq

            key_lists.append(keys)
            names.append(keyspace)
            formats.append(dtype.str)
            titles.append(dumps(custom_info_curr_keyspace))

        rows = product(*key_lists)
        rows_tuples = [row for row in rows]
        struct_array = np.core.records.fromrecords(
            rows_tuples, names=names, formats=formats, titles=titles
        )
        if return_type == "PandasDF":
            # deal with custom_col_info_tmp
            return PandasDF(struct_array, space_info=context_info)
        elif return_type == "pandas_dataframe":
            return pd.DataFrame(struct_array)
        else:
            return Quble.from_struct_array(struct_array)

    @RootLib.lazy_kwargs()
    def to_npy(
        self,
        npyfile,
        windows_filename_adjust=True,
        column_names="<all>",
        key_ordering=None,
        clob_export_mode=RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode=RootLib.lazy_eval("blob_export_mode"),
    ):
        """
        Writes Quble to a numpy binary NPY file

        :param npyfile: Path to the npy file to be be created.
        :type npyfile: str

        :param windows_filename_adjust: Adjust the name of the file for windows platforms
        :type windows_filename_adjust: boolean
        """
        # Ensure non-trivial Quble
        if self.is_undefined:
            raise UndefinedQubleError("Undefined Quble (no table)")

        # Return (Throw an error?) if no columns were requested
        if column_names is None or len(column_names) == 0:
            return

        # Adjust npyfile for the windows platform (if applicable)
        if windows_filename_adjust and hasattr(sys, "getwindowsversion"):
            npyfile = npyfile.replace("\\", "\\\\")

        # Update column_info accordingly for empty Quble case
        if self.is_empty:
            # Here, we need to modify column_info,
            # but we do not want to permanently modify
            # the external column_info from the calling program
            # Therefore, make a deepcopy prior to modification here
            column_info = deepcopy(column_info) if column_info is not None else {}
            if DUMMY_INFO_TYPE_FOR_DUMMY_DATA not in column_info:
                column_info[DUMMY_INFO_TYPE_FOR_DUMMY_DATA] = {}
            for column_name in column_names:
                column_info[DUMMY_INFO_TYPE_FOR_DUMMY_DATA][column_name] = True

        struct_array = self.to_struct_array(
            column_names=column_names,
            key_ordering=key_ordering,
            clob_export_mode=clob_export_mode,
            blob_export_mode=blob_export_mode,
        )
        # -------------------------------------------------------
        # Validate file_name and remove (old file if present)
        # -------------------------------------------------------
        filename = npyfile
        if filename is None:
            raise Exception("No filename provided")

        # validate the existence of file_name
        if os.path.exists(filename):
            os.remove(filename)

        # Save the structured array to the designated npy file
        try:
            np.save(filename, struct_array)
        # On failure, try to remove file new then throw an error
        except:
            if os.path.exists(filename):
                os.remove(filename)
            raise Exception("Unable to save to npy file")

    @RootLib.lazy_kwargs()
    def to_csv(
        self,
        csvfile: str,
        pivot_keyspace=None,
        header: bool = True,
        valuespace="<valuespaces>",
        delimiter: str = ",",
        record_separator: str = "\n",
        string_quote: str = '"',
        missing_format: str = "",
        date_format: str = DEFAULT_DATE_FORMAT,
        compress: bool = False,
        key_ordering="asc",
        **fmtparams,
    ):
        r"""Convert Quble to CSV format.

        The output is structured as follows:

        +-------+--------------------+---------------+----------------------------------+
        | ndim  | pivot_keyspace     | valuespace    | result                           |
        +=======+====================+===============+==================================+
        | 0D-mV | None               | <valuespaces> |  m-columns of values             |
        +-------+--------------------+--------------------------------------------------+
        | 0D-mV | specific_ks        | <valuespaces> |  Raises ``QubleCSVError``        |
        +-------+--------------------+--------------------------------------------------+
        | 1D-mV | None               | <valuespaces> | 1 key cols + m value cols        |
        +-------+--------------------+--------------------------------------------------+
        | 1D-mV | None               | specific_vs   | 1 key cols + 1 value col         |
        +-------+--------------------+--------------------------------------------------+
        | 1D-mV | specific_ks        | <valuespaces> | Raises ``QubleCSVError``         |
        +-------+--------------------+--------------------------------------------------+
        | 1D-mV | specific_ks        | specific_vs   | Raises ``QubleCSVError``         |
        +-------+--------------------+--------------------------------------------------+
        | nD-mV | None               | <valuespaces> | n key cols + m value cols        |
        +-------+--------------------+--------------------------------------------------+
        | nD-mV | None               | specific_vs   | n key cols + 1 value col         |
        +-------+--------------------+--------------------------------------------------+
        | nD-mV | specific_ks        | <valuespaces> | Raises ``QubleCSVError``         |
        +-------+--------------------+--------------------------------------------------+
        | nD-mV | specific_ks        | specific_vs   | (n-1) key cols + q distinct keys |
        +-------+--------------------+--------------------------------------------------+

        :type csvfile: file-like object
        :param csvfile:
            Write the Quble to a file-like object. Can be any object with a ``write()``
            method. If *csvfile* is a file object, it must be opened with the 'b' flag
            on platforms where that makes a difference.

        :type pivot_keyspace: str, int or None
        :param pivot_keyspace:
            The keyspace to use for unfolding (if desired)
            [For a folded csv result (no unfolding), use pivot_keyspace=None]

        :type header: bool
        :param header:
            Include a header row in the CSV output.

        :type date_format: str
        :param date_format:
            Format for serializing dates and datetimes. Uses formats accepted by
            Python's ``strftime`` method.

        :type missing_format: str
        :param missing_format:
            Format for serializing missing values. Writes the given string into the
            output when a missing value is encountered.

        :param compress: flag for compressing resultant Quble
        :type compress: bool (True/False*)

        :type min_header_width: int or None
        :param min_header_width: (Optional) minimum header column width

            ==> If min_header_width=None: column types will be inspected
                and min_header_width will be inferred

            ==> If min_header_width!=None: min_header_width should be set
                to integer high enough to accommodate string
                rendering of actual data rows in each column

        :param \*\*fmtparams:
            Optional *fmtparams* keyword arguments can be given to override
            individual default formatting parameters.
            See the Python ``csv`` module for more details.

        """
        if self.is_undefined or self.ndim is None or (self.is_empty and not header):
            return

        # Validate date_format arg
        try:
            datetime.now().strftime(date_format)
        except Exception:
            raise CSVError(f"Invalid date format: {date_format}")

        # Validate Pivot Keyspace arg type
        if (
            isinstance(pivot_keyspace, str)
            or isinstance(pivot_keyspace, int)
            or pivot_keyspace is None
        ):
            pass
        else:
            raise Exception("Invalid arg type for pivot_keyspace")

        # validating key_ordering param
        if key_ordering is not None:
            if isinstance(key_ordering, dict):
                for key, value in key_ordering.items():
                    if not isinstance(key, str) or not isinstance(value, str):
                        raise Exception(
                            "Incorrect key or order datatype provided in key ordering dict"
                        )
                    elif key not in self.keyspaces:
                        raise Exception(
                            f"Column name {key} is not present in Quble's keyspaces"
                        )
                    elif value.lower() not in ["asc", "desc"]:
                        raise Exception(
                            f"Incorrect order {value} provided in key ordering dict for column {key}"
                        )
            elif isinstance(key_ordering, str):
                if key_ordering.lower() not in ["asc", "desc"]:
                    raise Exception("Incorrect order provided in key ordering dict")
            else:
                raise Exception("Incorrect value provided for key ordering parameter")

        # Construct key_ordering dict for key_ordering `str` case
        if isinstance(key_ordering, str):
            key_ordering = dict(
                zip(self.keyspaces, [key_ordering for _ in self.keyspaces])
            )

        # Handle unpivoted/folded cases
        # or 1D case (unpivoted/folded=pivoted/unfolded)
        # Also assign/initialize subject Quble
        # and only reference subject hereafter
        # -------------------------------------
        if (pivot_keyspace is None) or self.ndim <= 1:
            subject = self
        else:
            # -------------------------------------------------
            # For the pivoted/unfolded case w/Quble index
            # we need to create a boolean valuespace
            # -------------------------------------------------
            # ==> pivoted/unfolded format
            #     does not make sense without a valuespace
            # -------------------------------------------------
            if self.is_index:
                subject = self.index_to_bool()
            else:
                subject = self

        # Validate valuespace arg
        valuespaces_to_write = subject.validate_valuespace(
            valuespace=valuespace, grace=False, coerce_to_list=True
        )

        # Establish columns_to_write
        columns_to_write = subject.keyspaces + valuespaces_to_write
        if len(columns_to_write) == 0:
            raise Exception("No columns to be written")

        # --------------------------------------------
        # First, write the unpivoted/folded csv file
        # --------------------------------------------
        # Validate delimiter
        # ----------------------
        if delimiter is None:
            # use comma delimiter format by default
            delimiter = ","
        elif not isinstance(delimiter, str):
            raise CSVError(f"Invalid delimiter:{delimiter}...str expected")
        elif len(delimiter) == 0:
            delimiter = ","
        elif delimiter == "\\n":
            delimiter = "\n"
        elif delimiter == "\\t":
            delimiter = "\t"
        elif delimiter == "\\r\\n":
            delimiter = "\r\n"
        elif delimiter in ("\\n", "\\t", "\\r\\n"):
            pass
        elif len(delimiter) == 2 and delimiter[0] == "\\":
            pass
        elif len(delimiter) > 1:
            raise CSVError(f"Invalid len(delimiter):{len(delimiter)} > 1")

        # Validate record_separator
        # --------------------------
        if record_separator is None:
            # use newline record_separator format by default
            record_separator = "\n"
        elif not isinstance(record_separator, str):
            raise CSVError(
                f"Invalid record_separator:{record_separator}...str expected"
            )
        elif len(record_separator) == 0:
            record_separator = "\n"
        elif record_separator == "\\n":
            record_separator = "\n"
        elif record_separator == "\\t":
            record_separator = "\t"
        elif record_separator == "\\r\\n":
            record_separator = "\r\n"
        elif record_separator in ("\\n", "\\t", "\\r\\n"):
            pass
        elif len(record_separator) == 2 and record_separator[0] == "\\":
            pass
        elif len(record_separator) > 1:
            raise CSVError(f"Invalid len(record_separator):{len(record_separator)} > 1")

        # Validate string_quote
        # --------------------------
        if string_quote:
            pass  # <-- O.K. if no string_quote provided
        elif not isinstance(string_quote, str):
            raise CSVError(f"Invalid string_quote:{string_quote}...str expected")
        elif len(string_quote) > 0:
            raise CSVError(f"Invalid len(string_quote):{len(string_quote)} > 1")

        # Also, create alternate version of csvfile
        # (csvfile) that may contain extra backslashes
        # for sql file path handling on the Windows platform
        # ----------------------------------------------------
        if hasattr(sys, "getwindowsversion"):
            csvfile = csvfile.replace("\\", "\\\\")

        # Execute selections against subject Quble's table
        # --------------------------------------------------
        column_expressions = {}
        for column_name in columns_to_write:
            if date_format is not None and subject.is_time_space(column_name):
                column_expressions[column_name] = (
                    f"to_varchar(\"{column_name}\", '{date_format}')"
                )

        # If missing_format is a list
        # (or comma-delimted string -> list)
        # use the first element
        # --------------------------------
        if missing_format is None:
            # We do this (rather than leaving missing_format=None)
            # otherwise, null may be inserted into csv
            # but will do so in a manner that is not double-quoted
            # which is INCONSISTENT with other fields in the csv result
            missing_format = ""
        elif isinstance(missing_format, (list, tuple)):
            # Take first element (can only use one)
            missing_format = missing_format[0] if len(missing_format) > 0 else ""
        elif isinstance(missing_format, str):
            # If comma-delimited, take first element (can only use one)
            missing_format = missing_format.split(",")[0]

        # --------------------------
        # Make sure missing_format
        # does not contain embdded quotes
        # [These will be added internally here
        # to minimize confusion and for consistentcy
        # with pivot_csv & unpivot_csv functions]
        if (search('"', missing_format) is not None) or (
            search("'", missing_format) is not None
        ):
            raise CSVError(
                "Invalid missing_format:{0}...should not contain embedded quotes".format(
                    missing_format
                )
            )

        # Construct where clause if applicable
        where_clause = None
        if compress:
            for vs in valuespaces_to_write:
                if where_clause is None:
                    where_clause = f'WHERE ("{vs}" IS NOT NONE)'
                else:
                    where_clause += f' OR ("{vs}" IS NOT NONE)'

        # -----------------------------------------------------
        # Now, render and execute the selection query
        # and dump result to io_destination = unpivoted_file2
        # -----------------------------------------------------
        sql_template = JINJA_ENV.get_template("select.j2")
        sql_command = sql_template.render(
            src_table_name=subject.table_name,
            tgt_table_name=None,
            column_names=columns_to_write,
            column_expressions=column_expressions,
            where_clause=where_clause,
            cast_dict=None,
            column_headers=False,
        )
        df = execute_snowalchemy(sql_command)
        df.columns = columns_to_write
        # Getting pivot and value column if pivot keyspace is provided
        if pivot_keyspace is not None:
            # To honour the below case, we need to make sure
            # the valuespace argument is a specific valuespace
            # +-------+--------------------+---------------+----------------------------------+
            # | ndim  | pivot_keyspace     | valuespace    | result                           |
            # +-------+--------------------+---------------+----------------------------------+
            # | nD-mV | specific_ks        | <valuespaces> | Raises ``QubleCSVError``         |
            # +-------+--------------------+---------------+----------------------------------+
            if isinstance(valuespaces_to_write, list) and len(valuespaces_to_write) > 1:
                raise Exception("QubleCSVError : Cannot pivot on multiple valuespaces")

            pivot_column = (
                pivot_keyspace
                if isinstance(pivot_keyspace, str)
                else self.keyspaces[pivot_keyspace]
            )

            if not self.is_index:
                if isinstance(valuespaces_to_write, list):
                    value_column = valuespaces_to_write[0]
                else:
                    value_column = valuespaces_to_write
            else:
                value_column = "Values_"

            # Make sure pivot_keyspace is present in self.keyspaces
            if pivot_column not in self.keyspaces:
                raise Exception("Pivot keyspace not found in Quble's keyspaces")

            # Make sure pivot_column & value_column are distinct
            if value_column == pivot_column:
                raise Exception(
                    "value_column:{0} cannot match pivot_column:{1}".format(
                        value_column, pivot_column
                    )
                )

            non_pivot_columns = []
            for column_name in self.keyspaces:  # Was self.spaces in original code
                if column_name not in [pivot_column, value_column]:
                    non_pivot_columns.append(column_name)

            if len(non_pivot_columns) == 0:
                raise Exception(
                    "Internal inconsistency: No Index columns could be determined"
                )

            # Apply key_ordering
            df.sort_values(
                list(key_ordering.keys()),
                ascending=[
                    True if order == "asc" else False for order in key_ordering.values()
                ],
                inplace=True,
            )
            df = pd.pivot(
                df,
                values=value_column,
                index=non_pivot_columns,
                columns=(
                    [pivot_column]
                    if not isinstance(pivot_column, list)
                    else pivot_column
                ),
            )

            df.columns.name = None
            df = df.reset_index()
            df.to_csv(
                csvfile,
                sep=delimiter,
                lineterminator=record_separator,
                quoting=csv.QUOTE_ALL,
                na_rep=missing_format,
                index=False,
                header=header,
            )
        else:
            df.sort_values(
                list(key_ordering.keys()),
                ascending=[
                    True if order == "asc" else False for order in key_ordering.values()
                ],
                inplace=True,
            )
            df.to_csv(
                csvfile,
                sep=delimiter,
                lineterminator=record_separator,
                quoting=csv.QUOTE_ALL,
                na_rep=missing_format,
                index=False,
                header=header,
            )

        return df

    @RootLib.lazy_kwargs()
    def to_struct_array(
        self,
        column_names="<all>",
        key_ordering=None,
        clob_export_mode: str = RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode: str = RootLib.lazy_eval("blob_export_mode"),
    ) -> np.ndarray:
        """
        Converts Quble to a structured numpy array
        Uses title format to hold column information
        (as a json-string of a dictionary object)

        :param key_ordering: sorts the struct_array as per key_ordering param
        :type key_ordering: string or dictionary
            In case of dictionary, the keys are the column names and values are order to sort (asc or desc)
        """

        array_dict = self.to_array_dict(
            column_names=column_names,
            key_ordering=key_ordering,
            clob_export_mode=clob_export_mode,
            blob_export_mode=blob_export_mode,
        )
        col_info = self.get_space_info(
            info_type=CUSTOM_INFO_TYPES, space="<all>", omit_unassigned=True
        )
        return NumpySA(array_dict, col_info=col_info)

    @RootLib.lazy_kwargs()
    def to_array_dict(
        self,
        column_names="<all>",
        key_ordering=None,
        clob_export_mode: str = RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode: str = RootLib.lazy_eval("blob_export_mode"),
    ) -> dict:
        """
        Converts Quble to a dictionary of comparable length lists
        The dictionary keys correspond to the spaces (column names) of the Quble
        [NOTE: The dictionary will not provide underlying column information]

        :param key_ordering: asc or desc as str
        :type key_ordering: str or dictionary with column names as keys and order (asc/desc) as value

        :param column_names: <all> or column name or list of column names
        :type column_names: string or list of strings

        """
        # Establish column_names
        column_names = self.validate_space(space=column_names, coerce_to_list=True)

        # validating key_ordering
        if key_ordering is not None:
            if isinstance(key_ordering, dict):
                for key, value in key_ordering.items():
                    if not isinstance(key, str) or not isinstance(value, str):
                        raise Exception(
                            "Incorrect key or order datatype provided in key ordering dict"
                        )
                    elif key not in self.keyspaces:
                        raise Exception(
                            f"Column name {key} is not present in Quble's keyspaces"
                        )
                    elif value.lower() not in ["asc", "desc"]:
                        raise Exception(
                            f"Incorrect order {value} provided in key ordering dict for column {key}"
                        )
            elif isinstance(key_ordering, str):
                if key_ordering.lower() not in ["asc", "desc"]:
                    raise Exception("Incorrect order provided in key ordering dict")
            else:
                raise Exception("Incorrect value provided for key ordering parameter")

        self_df = snowflake_table_to_pandas(
            self.table_name, column_names, self.column_info, key_ordering
        )
        # Filter column names
        if column_names != "<all>":
            self_df = self_df.drop(self_df.columns.difference(column_names), axis=1)

        # Applying key ordering
        if key_ordering is not None:
            if isinstance(key_ordering, str):
                self_df.sort_values(
                    column_names,
                    ascending=(
                        [True] * len(column_names)
                        if key_ordering.lower() == "asc"
                        else [False] * len(column_names)
                    ),
                    inplace=True,
                )
            else:
                self_df.sort_values(
                    list(key_ordering.keys()),
                    ascending=[
                        True if v.lower() == "asc" else False
                        for k, v in key_ordering.items()
                    ],
                    inplace=True,
                )

        col_type_dict = {}
        for i, column_name in enumerate(column_names):
            col_type_dict[column_name] = self.get_column_type(column_name)

        # Build missing_value_dict
        # ---------------------------
        missing_value_dict = {}
        date_cols = self_df.select_dtypes(include="datetimetz").columns.tolist()
        for col_name, col_type in col_type_dict.items():
            if col_name in date_cols:
                missing_value_dict[col_name] = pd.Timestamp(
                    coltype_to_missing_value(
                        col_type, clob_export_mode, blob_export_mode
                    )
                ).tz_localize("UTC")
            else:
                missing_value_dict[col_name] = coltype_to_missing_value(
                    col_type, clob_export_mode, blob_export_mode
                )
        # Filling the missing values
        # ----------------------------
        for col_name, value in missing_value_dict.items():
            self_df[col_name].fillna(value, inplace=True)

        return self_df.to_dict(orient="list")

    def to_pandas_df(
        self, column_names="<all>", key_ordering=None, as_derived_class=True
    ):
        """
        Returns a instance of either
        PandasDF (derived class) or pandas DataFrame
        see ~qubles.core.quble.to_struct_array
        """
        if self.is_undefined:
            return PandasDF() if as_derived_class else pd.DataFrame()
        else:
            column_names = self.validate_space(space=column_names, coerce_to_list=True)

            self.data = snowflake_table_to_pandas(
                self.table_name,
                column_names,
                self.column_info,
                key_ordering=key_ordering,
            )

            if as_derived_class:
                return PandasDF(self.data, space_info=self._column_info)
            else:
                return self.data

    def to_snowpark_df(self, profile_name: str = "snowflake"):
        session = SnowparkSessionManager.get_snowpark_session()
        return session.table(dquote_dot(self.table_name))

    # ================================== EXTRACTION ===================================

    def get_hyper_index(
        self,
        hyper_index_format: str = "array_dict",
        contiguous: bool = False,
        tgt_hyper_index=None,
    ):
        """
        Returns Quble's 'unfolded' indices as Python object
        Supports hyper_index_format, contiguous and tgt_hyper_index args

        Output type controlled by hyper_index_format arg
        See :meth:`~qubles.core.quble.Quble.hyper_data`
        """
        _, hyper_index = self.hyper_data(
            hyper_values_format=None,
            hyper_index_format=hyper_index_format,
            contiguous=contiguous,
            tgt_hyper_index=tgt_hyper_index,
        )
        return hyper_index

    @property
    def hyper_index(self):
        """
        Returns Quble's 'unfolded' indices as Python object
        For compatibility with legacy code, implemented as property method

        Internally calls:
           self.get_hyper_index(hyper_index_format='dict')

        See :meth:`~qubles.core.quble.Quble.hyper_data`
        """
        return self.get_hyper_index(hyper_index_format="dict")

    @property
    def hyper_values(self):
        """
        Returns Quble's 'unfolded' values as Python object

        NOTE: Current implementation / defaults to returning
        a non-structured, multi-dimensional numpy array
        providing ONLY the primary valuespace data

        Internally calls:
           self.hyper_data()

        See :meth:`~qubles.core.quble.Quble.hyper_data`
        """
        hyper_values, _ = self.hyper_data()
        return hyper_values

    def hyper_data(
        self,
        hyper_values_format: str = "array",
        hyper_index_format: str = "array_dict",
        valuespace: str = "<valuespace>",
        contiguous: bool = False,
        tgt_hyper_index=None,
    ) -> tuple:
        """
        Returns a two-element tuple containing Quble's values and indices [NOTE: order of return!]
        according to hyper_values_format and hyper_index_format args repectively

        For certain hyper_values_format args, the return hyper_values correspond
        to a specific valuespace as dictated by valuespace argument (defaults to primary valuespace)

        :param hyper_values_format: controls format of hyper_values
        :type hyper_values_format: str ('array', 'array_dict', 'struct_array', None)

            **hyper_values_format**

            'array': returns multi-dim numpy array of values from Quble's specified single valuespace
                     [returns None if no valuespace is present]
            'array_dict': returns dictionary multi-dim numpy arrays
                           where first element is for valuespace and subsequent elements are for auxvalspaces
                           [Here, valuespace arg is ignored, as all valuespaces will be returned]
                           [returns None if no valuespace and no auxvalspaces present]
            'struct_array': returns a structured multi-dim numpy array of values from Quble's valuespaces
                           [[Here, valuespace arg is ignored, as all valuespaces will be returned]
                           [returns None if no valuespaces are present]
            None: NO hyper_values generated (returns None) regardless of state
                   [use this feature (carefully) to reduce overhead / memory
                   when hyper_values will be ignored in calling context]

        :param hyper_index_format: controls format of hyper_index
        :type hyper_index_format: str ('array_dict', 'IndexArray1D_dict', 'list_dict') or None

            **hyper_index_format**

            'dict': returns an instance of dict
            'IndexArray1D_dict': returns dictionary of IndexArray1D
            'array_dict': returns dictionary of (numpy) array of distinct keys (IndexArray1D)
            'list_dict': returns dictionary of lists of distinct keys
            None: NO hyper_index generated (returns None)

            [NOTE: In each case, dict keys are keyspaces (or keygroups)]

        :param valuespace: desired single-valuespace (see comments below)
           ==> valuespace arg ONLY APPLIES when hyper_values_format=='array'
           ==> When hyper_values_format != 'array': valuespace arg is IGNORED
        :type valuespace: str

        :param contiguous: forces contiguous keys for time-keyspaces
        :type contiguous: bool (True/False*)

        :param tgt_hyper_index: (optional) forced hyper_index
            => Provides for control of resultant hyper_index keyspaces & keys
        :type tgt_hyper_index:  dict of IndexArray1D

            **tgt_hyper_index**

                   1) dictionary of IndexArray1D objects or strs/unicodes
                or 2) Indexes

            Warning:
            Be aware that when providing a tgt_hyper_index arg,
            the dimensional ordering of the resultant hyper_values & hyper_index
            will take direction from the keyspaces / ordering in tgt_hyper_index input arg
            and therefore MAY BE INCONSISTENT with the keyspace ordering
            of the underlying Quble!!!

        NOTE: For cases hyper_index_format in 'array_dict',
              each dictionary value / element will be tagged with freq attribute
              through the use of the IndexArray1D class
        keygroups: optional map from keyspaces to keygroups

        :rtype: two-element tuple (hyper_values, hyper_index)
        :returns: (hyper_values, hyper_index) [NOTE: order of return!]
        """
        # ----------------------------------------------
        # HANDLE TRIVIAL (UNDEFINED OR EMPTY) QUBLE
        # ----------------------------------------------
        if self.is_undefined or self.is_empty:
            return (None, None)

        # Validate hyper_index_format arg
        # -----------------------------------
        if hyper_index_format not in (
            "array_dict",
            "IndexArray1D_dict",
            "list_dict",
            "dict",
            None,
        ):
            raise Exception(f"Unsupported hyper_index_format:{hyper_index_format}")

        # --------------------------------------------
        # CASE 0: Handle simple hyper_index only case
        # when tgt_hyper_index is None
        # --------------------------------------------
        if hyper_values_format is None and tgt_hyper_index is None:
            if hyper_index_format is None:
                return (None, None)

            hyper_index = {}
            for ks in self.keyspaces:
                if isinstance(contiguous, dict):
                    contiguous_flag1 = contiguous[ks] if ks in contiguous else False
                else:
                    contiguous_flag1 = contiguous

                hyper_index[ks] = self.distinct_index_array1d(
                    keyspace=ks, contiguous_flag=contiguous_flag1, key_ordering="asc"
                )

            if hyper_index_format == "list_dict":
                # Convert hyper_index from dict of arrays to dict of lists
                for ks in hyper_index:
                    if hyper_index[ks] is not None:
                        # Preserve freq attribute in this case
                        if hasattr(hyper_index[ks], "freq"):
                            freq1 = hyper_index[ks].freq
                            hyper_index[ks] = hyper_index[ks].tolist()
                            hyper_index[ks].freq = freq1
                        else:
                            hyper_index[ks] = hyper_index[ks].tolist()

            return (None, hyper_index)

        # ----------------------------------------
        # Validate valuespace (when applicable)
        # ----------------------------------------
        if hyper_values_format is None:
            valuespaces = []

        elif hyper_values_format in ("array_dict", "struct_array"):
            valuespaces = self.valuespaces

        elif hyper_values_format != "array":
            raise Exception(f"Unsupported hyper_values_format:{hyper_values_format}")

        elif valuespace is None:
            valuespaces = []
        else:
            valuespace = self.validate_valuespace(
                valuespace, grace=False, solo_required=True
            )
            if valuespace is None:
                raise ValuespaceRefError("Could not resolve to a valid valuespace")
            elif isinstance(valuespace, (list, tuple)):
                raise Exception(
                    "Single valuespace required, yet (validated) valuespace:{0}".format(
                        valuespace
                    )
                )
            else:
                valuespaces = [valuespace]

        # Convert self to a structured numpy array
        sa = self.to_struct_array(self.keyspaces + valuespaces)

        # =======================================
        # PART 1: Build preliminary hyper_index
        # =======================================
        # -----------------------------
        # CASE 1A: UNI-SCALAR QUBLES
        # -----------------------------
        if self.is_scalar or self.is_multiscalar:
            if len(sa) != 1:
                raise Exception(
                    f"Scalar qubles should have a single record, yet len(sa):{len(sa)}"
                )

            # Initially build hyper_index as a dictionary of numpy arrays
            hyper_index = {}
        # -----------------------------------------
        # CASE 1B: NON-SCALAR QUBLES W/O TARGET
        # -----------------------------------------
        elif tgt_hyper_index is None:
            # Initially build hyper_index as a dictionary of numpy arrays
            hyper_index = {}
            for ks in self.keyspaces:
                sorted_unique_keys = np.unique(sa[ks])
                freq1 = None
                if self.is_time_space(ks):
                    freq1 = self.get_space_info(
                        info_type="freq",
                        space=ks,
                        grace=True,
                        allow_infer=True,
                        assign_inferred=True,
                    )
                if freq1 is None:
                    hyper_index[ks] = IndexArray1D(sorted_unique_keys, freq=freq1)
                # Handle contiguous arg as bool, dictionary or list
                elif (
                    (contiguous == True)
                    or (
                        isinstance(contiguous, dict)
                        and ks in contiguous
                        and contiguous[ks]
                    )
                    or (isinstance(contiguous, (list, tuple)) and ks in contiguous)
                ):
                    hyper_index[ks] = self.distinct_index_array1d(
                        keyspace=ks, contiguous_flag=True, key_ordering="asc"
                    )
                else:
                    hyper_index[ks] = IndexArray1D(sorted_unique_keys, freq=freq1)
        # ------------------------------------------
        # VALIDATE tgt_hyper_index (WHEN PRESENT)
        # ------------------------------------------
        elif not isinstance(tgt_hyper_index, dict):
            raise Exception(
                "Invalid tgt_hyper_index:{0}...dict or None expected".format(
                    type(tgt_hyper_index)
                )
            )
        # -----------------------------------------
        # CASE 1C: NON-SCALAR QUBLES WITH TARGET
        # -----------------------------------------
        else:
            # We may change elements of tgt_hyper_index below to match sa
            # Therefore, make a deep copy first
            tgt_hyper_index = deepcopy(tgt_hyper_index)

            # Remove records outside of tgt_hyper_index
            # [Then update sa accordingly]
            # --------------------------------------------
            # ================================= START ks LOOP =================================
            valid_records = np.repeat(True, len(tgt_hyper_index) * len(sa)).reshape(
                len(tgt_hyper_index), len(sa)
            )
            for ks_no, ks in enumerate(tgt_hyper_index.keys()):
                # ----------------------------------------------
                # Try to handle unsupported ks...
                # ----------------------------------------------
                # Possible valid cases:
                #   1) tgt_hyper_index[ks] is a struct array
                #      grouping specific keys sets as sub-arrays
                #   2) tgt_hyper_index[ks] is a str
                #      effectively renaming a keyspace
                #   3) tgt_hyper_index[ks] is a list/tuple
                #      where the str elements of list/tuple
                #      correspond to original keyspaces within sa
                #      (Here, tgt_hyper_index[ks] represents a keygroup assignment)
                # ----------------------------------------------
                if ks not in sa.dtype.names:
                    # Handle tgt_hyper_index[ks] as structured numpy array case
                    # Here, each tgt_hyper_index.key (ks) corresponds to a 'keygroup' whereby the underlying numpy
                    # array dtype.names MUST appear in sa.dtype.names but we will require the that the associated structured numpy array
                    if hasattr(tgt_hyper_index[ks], "dtype") and hasattr(
                        tgt_hyper_index[ks].dtype, "names"
                    ):
                        # Are the sub-components compatible with dtypes of sa?
                        dtype_incompatability_flag = False
                        for sub_ks in tgt_hyper_index[ks].dtype.names:
                            if sub_ks not in sa.dtype.names:
                                # Here, sub-array dtypoe names doe not appear in sa.dtype.names
                                # On other words, the keyspaces in this keygroup do not appear in Quble's columns
                                raise Exception(
                                    "sub_ks:{0} is absent from sa.dtype.names:{1}".format(
                                        sub_ks, sa.dtype.names
                                    )
                                )
                            elif tgt_hyper_index[ks][sub_ks].dtype != sa[sub_ks].dtype:
                                dtype_incompatability_flag = True
                                break
                        # Handle incompatibilities
                        if dtype_incompatability_flag:
                            fields = defaultdict(list)
                            for sub_ks in tgt_hyper_index[ks].dtype.names:
                                fields["names"].append(sub_ks)
                                fields["formats"].append(sa[sub_ks].dtype)

                            local_tgt_array = np.zeros(
                                len(tgt_hyper_index[ks]), dtype=dict(fields)
                            )
                            for sub_ks in tgt_hyper_index[ks].dtype.names:
                                local_tgt_array[sub_ks] = np.array(
                                    tgt_hyper_index[ks][sub_ks], dtype=sa[sub_ks].dtype
                                )
                            tgt_hyper_index[ks] = local_tgt_array

                        # Update valid_records[ks_no] via valid_sub_records
                        # NOTE: we need to do this AFTER dtype incompatability resolution
                        valid_sub_records = np.repeat(
                            True, len(tgt_hyper_index[ks].dtype.names) * len(sa)
                        ).reshape(len(tgt_hyper_index[ks].dtype.names), len(sa))
                        for sub_ks_no, sub_ks in enumerate(
                            tgt_hyper_index[ks].dtype.names
                        ):
                            valid_sub_records[sub_ks_no, :] = np.in1d(
                                sa[sub_ks], tgt_hyper_index[ks][sub_ks]
                            )
                        valid_records[ks_no, :] = np.all(valid_sub_records, axis=0)

                    # Perhaps we have been given a keygroup map: keygroup -> sub_keyspace(s)?
                    elif isinstance(tgt_hyper_index[ks], str):
                        # Here, keygroup is simply a 1-to-1 keyspace alias
                        # ==> reassign tgt_hyper_index[ks] as non-structured numpy array
                        # ---------------------------------------------------------------
                        sub_ks = tgt_hyper_index[ks]
                        if sub_ks not in sa.dtype.names:
                            raise Exception(
                                "Invalid tgt_hyper_index...Neither {0} nor tgt_hyper_index[{0}]:{1} are valid keyspaces:{2}".format(
                                    ks, sub_ks, sa.dtype.names
                                )
                            )
                        # NOTE: Here we know: 1) ks != sub_ks, 2) ks not in sa, 3) sub_ks in sa
                        # Here, we are being instructed to rename a keyspace (sub_ks -> ks)
                        # ==> We need to recast sa to support this ks by renaming subarray: sub_ks -> ks
                        tgt_hyper_index[ks] = np.unique(sa[sub_ks])
                        valid_records[ks_no, :] = True
                        fields = defaultdict(list)
                        for old_ks in sa.dtype.names:
                            fields["names"].append(ks if (old_ks == sub_ks) else old_ks)
                            fields["formats"].append(sa[sub_ks].dtype)

                        renamed_sa = np.zeros(len(sa), dtype=dict(fields))
                        for old_ks in sa.dtype.names:
                            renamed_sa[ks if (old_ks == sub_ks) else old_ks] = sa[
                                old_ks
                            ]
                        # Replace sa with renamed_sa
                        sa = renamed_sa
                    # Next, see if tgt_hyper_index[ks] correponds to a list/tuple of strs/unicodes
                    # where each element belongs to a (sub)keyspace of a keygroup. This format represents a desired structured output
                    # In this case, we will replace tgt_hyper_index[ks] (list of keyspaces)
                    # with a structured numpy array of the respective keys from each of the keyspaces
                    # ---------------------------------------------------------------------------------
                    elif not isinstance(tgt_hyper_index[ks], (list, tuple)):
                        raise Exception(
                            "Invalid tgt_hyper_index...{0} absent from keyspaces:{1} and tgt_hyper_index[{0}] not a tuple/list/str".format(
                                ks, sa.dtype.names, tgt_hyper_index[ks]
                            )
                        )
                    elif len(tgt_hyper_index[ks]) == 0:
                        # Empty keygroup...remove this keygroup from tgt_hyper_index
                        tgt_hyper_index.pop(ks)
                        continue  #  <-- process to next ks
                    else:
                        # Complex group ==> reassign tgt_hyper_index[ks] as structured numpy array
                        fields = defaultdict(list)
                        for sub_ks in tgt_hyper_index[ks]:
                            if sub_ks not in sa.dtype.names:
                                raise Exception(
                                    "Invalid tgt_hyper_index...Neither {0} nor tgt_hyper_index[{0}]:{1} are valid keyspaces:{2}".format(
                                        ks, sub_ks, sa.dtype.names
                                    )
                                )
                            fields["names"].append(sub_ks)
                            fields["formats"].append(sa[sub_ks].dtype)

                        local_tgt_array = np.zeros(len(sa[sub_ks]), dtype=dict(fields))
                        for sub_ks in tgt_hyper_index[ks]:
                            local_tgt_array[sub_ks] = sa[sub_ks]
                        # structured array
                        tgt_hyper_index[ks] = np.unique(local_tgt_array)

                # Special Case: When 1) ks in sa AND 2) tgt_hyper_index[ks] in (ks,[ks])
                # ==> ASSUME IN THIS CASE THAT THE USER DESIRES: tgt_hyper_index[ks] = sa[ks]
                # -----------------------------------------------------------------------------
                elif (
                    (isinstance(tgt_hyper_index[ks], str) and tgt_hyper_index[ks] == ks)
                    or (
                        isinstance(tgt_hyper_index[ks], list)
                        and tgt_hyper_index[ks] == [ks]
                    )
                    or (
                        isinstance(tgt_hyper_index[ks], tuple)
                        and tgt_hyper_index[ks] == (ks)
                    )
                    or (
                        isinstance(tgt_hyper_index[ks], np.ndarray)
                        and (
                            np.issubdtype(tgt_hyper_index[ks].dtype, np.unicode_)
                            or np.issubdtype(tgt_hyper_index[ks].dtype, np.string_)
                        )
                        and len(tgt_hyper_index[ks]) == 1
                        and tgt_hyper_index[ks][0] == ks
                    )
                ):
                    tgt_hyper_index[ks] = np.unique(sa[ks])
                # Process tgt_hyper_index[ks]
                # Here, we have confirmed that ks exists in sa
                # ==> ks correponds to a keyspace column in Quble's table
                # --------------------------------------------------------
                elif not hasattr(tgt_hyper_index[ks], "dtype"):
                    # Try to convert to numpy array using sa[ks].dtype as a guide
                    local_tgt_array = np.array(tgt_hyper_index[ks], dtype=sa[ks].dtype)
                    tgt_hyper_index[ks] = np.array(
                        tgt_hyper_index[ks], dtype=sa[ks].dtype
                    )
                    valid_records[ks_no, :] = np.in1d(sa[ks], tgt_hyper_index[ks])
                elif np.issubdtype(sa[ks].dtype, np.datetime64) and not np.issubdtype(
                    tgt_hyper_index[ks].dtype, np.datetime64
                ):
                    # Handle any datetime/datetime64 dtype inconsistencies
                    # Here, tgt_hyper_index[ks] is not a datetime64 numpy array, while sa[ks] is
                    local_tgt_array = np.array(tgt_hyper_index[ks], dtype=sa[ks].dtype)
                    tgt_hyper_index[ks] = np.array(
                        tgt_hyper_index[ks], dtype=sa[ks].dtype
                    )
                    valid_records[ks_no, :] = np.in1d(sa[ks], tgt_hyper_index[ks])
                elif (
                    np.issubdtype(sa[ks].dtype, np.datetime64)
                    and np.issubdtype(tgt_hyper_index[ks].dtype, np.datetime64)
                    and sa[ks].dtype != tgt_hyper_index[ks].dtype
                ):
                    # Handle any datetime/datetime64 dtype inconsistencies
                    # Here, tgt_hyper_index[ks] is not a datetime64 numpy array, while sa[ks] is
                    local_tgt_array = np.array(tgt_hyper_index[ks], dtype=sa[ks].dtype)
                    tgt_hyper_index[ks] = np.array(
                        tgt_hyper_index[ks], dtype=sa[ks].dtype
                    )
                    valid_records[ks_no, :] = np.in1d(sa[ks], tgt_hyper_index[ks])
                else:
                    # Could consider imposing sa[ks].dtype here
                    local_tgt_array = tgt_hyper_index[ks]
                    tgt_hyper_index[ks] = np.array(
                        tgt_hyper_index[ks], dtype=sa[ks].dtype
                    )
                    valid_records[ks_no, :] = np.in1d(sa[ks], tgt_hyper_index[ks])

                # Initially build hyper_index as a dictionary of numpy arrays
                hyper_index = {}
                for ks in list(tgt_hyper_index.keys()):
                    freq1 = None
                    if isinstance(tgt_hyper_index[ks], IndexArray1D):
                        hyper_index[ks] = tgt_hyper_index[ks]
                    else:
                        # Assuming usage of proper frequency here
                        hyper_index[ks] = IndexArray1D(tgt_hyper_index[ks], freq=freq1)

            # =========================== END: ks LOOP =======================================
            # Restrict sa to valid records covered by tgt_hyper_index
            # Require validity across all keyspaces
            valid_records = np.all(valid_records, axis=0)
            sa = sa[valid_records]

        # ================================== END: PART 1 ====================================

        # ================================================================
        # PART 2: Build hyper_values according to hyper_values_format
        # ================================================================
        len_hi = len(hyper_index)
        if len_hi == 0 and not self.is_scalar and not self.is_multiscalar:
            hyper_values = None
        elif hyper_values_format is None:
            hyper_values = None
        elif not hyper_values_format in ("array", "array_dict", "struct_array"):
            raise Exception(
                "Invalid hyper_values_format:{0}", format(hyper_values_format)
            )
        elif (
            hyper_values_format in ("array_dict", "struct_array")
            and len(valuespaces) == 0
        ):
            # Non-variate Quble case
            hyper_values = None
        elif hyper_values_format == "array" and valuespace is None:
            # Do not request info for a valuespace
            hyper_values = None
        elif self.is_scalar or self.is_multiscalar:
            hyper_values = None  # <-- Initialization
            if hyper_values_format is None:
                hyper_values = None  # <-- Initialization
            elif hyper_values_format == "array":
                hyper_values = None
                if valuespace is not None:
                    hyper_values = {}
                    hyper_values = sa[valuespace][0]
            elif hyper_values_format == "struct_array":
                fields = defaultdict(list)
                for vs in valuespaces:
                    fields["names"].append(vs)
                    fields["formats"].append(sa[vs].dtype)

                hyper_values = np.zeros(len(sa), dtype=dict(fields))
                for vs in valuespaces:
                    hyper_values[vs] = np.array(sa[vs], dtype=sa[vs].dtype)
            elif hyper_values_format == "array_dict":
                hyper_values = {}
                for vs in valuespaces:
                    if vs is None:
                        pass
                    else:
                        hyper_values[vs] = sa[vs][0]
            else:
                raise Exception(
                    "Invalid hyper_values_format:{0}", format(hyper_values_format)
                )
        else:
            # Non-scalar Quble case
            # First, use hyper_index to build key_index_maps & id_idx_nos
            id_idx_nos = {}
            shape = []
            for ks_no, ks in enumerate(hyper_index):
                shape.append(len(hyper_index[ks]))
                key_index_map = {}

                if (
                    hasattr(hyper_index[ks], "dtype")
                    and hasattr(hyper_index[ks].dtype, "names")
                    and hyper_index[ks].dtype.names is not None
                ):
                    # For hyper_index[ks] as structured numpy arrays we must convert each key (type numpy void) to a tuple
                    for i, key in enumerate(hyper_index[ks]):
                        key_index_map[tuple(key)] = i

                    # build local_sa (associated structured across sub-keys)
                    fields = defaultdict(list)
                    for sub_ks in hyper_index[ks].dtype.names:
                        fields["names"].append(sub_ks)
                        if sub_ks not in sa.dtype.names:
                            raise Exception(
                                "sub_ks[{0}] absent from sa.dtype.names:{1}".format(
                                    sub_ks, sa.dtype.names
                                )
                            )
                        fields["formats"].append(sa[sub_ks].dtype)

                    local_sa = np.zeros(len(sa), dtype=dict(fields))
                    for sub_ks in tgt_hyper_index[ks].dtype.names:
                        local_sa[sub_ks] = sa[sub_ks]
                    id_idx_nos[ks_no] = [key_index_map[tuple(x)] for x in local_sa]

                else:
                    for i, key in enumerate(hyper_index[ks]):
                        key_index_map[key] = i
                    id_idx_nos[ks_no] = [key_index_map[x] for x in sa[ks]]

            # Build & populate hyper_values_array_dict
            # ------------------------------------------
            hyper_values_array_dict = {}

            for vs in valuespaces:
                if vs is None:
                    continue
                elif self.is_scalar:
                    hyper_values_array_dict[vs] = sa[vs][0]
                else:
                    vs_dtype = sa[vs].dtype
                    missing_value = missing_val_by_dtype(vs_dtype)
                    hyper_values_tmp = np.full(shape, missing_value, vs_dtype)

                    if len_hi == 0:
                        pass
                    elif len_hi == 1:
                        hyper_values_tmp[id_idx_nos[0]] = sa[vs]
                    elif len_hi == 2:
                        hyper_values_tmp[id_idx_nos[0], id_idx_nos[1]] = sa[vs]
                    elif len_hi == 3:
                        hyper_values_tmp[
                            id_idx_nos[0], id_idx_nos[1], id_idx_nos[2]
                        ] = sa[vs]
                    elif len_hi == 4:
                        hyper_values_tmp[
                            id_idx_nos[0], id_idx_nos[1], id_idx_nos[2], id_idx_nos[3]
                        ] = sa[vs]
                    elif len_hi == 5:
                        hyper_values_tmp[
                            id_idx_nos[0],
                            id_idx_nos[1],
                            id_idx_nos[2],
                            id_idx_nos[3],
                            id_idx_nos[4],
                        ] = sa[vs]
                    elif len_hi == 6:
                        hyper_values_tmp[
                            id_idx_nos[0],
                            id_idx_nos[1],
                            id_idx_nos[2],
                            id_idx_nos[3],
                            id_idx_nos[4],
                            id_idx_nos[5],
                        ] = sa[vs]
                    elif len_hi == 7:
                        hyper_values_tmp[
                            id_idx_nos[0],
                            id_idx_nos[1],
                            id_idx_nos[2],
                            id_idx_nos[3],
                            id_idx_nos[4],
                            id_idx_nos[5],
                            id_idx_nos[6],
                        ] = sa[vs]
                    elif len_hi == 8:
                        hyper_values_tmp[
                            id_idx_nos[0],
                            id_idx_nos[1],
                            id_idx_nos[2],
                            id_idx_nos[3],
                            id_idx_nos[4],
                            id_idx_nos[5],
                            id_idx_nos[6],
                            id_idx_nos[7],
                        ] = sa[vs]
                    elif len_hi == 9:
                        hyper_values_tmp[
                            id_idx_nos[0],
                            id_idx_nos[1],
                            id_idx_nos[2],
                            id_idx_nos[3],
                            id_idx_nos[4],
                            id_idx_nos[5],
                            id_idx_nos[6],
                            id_idx_nos[7],
                            id_idx_nos[8],
                        ] = sa[vs]
                    elif len_hi == 10:
                        hyper_values_tmp[
                            id_idx_nos[0],
                            id_idx_nos[1],
                            id_idx_nos[2],
                            id_idx_nos[3],
                            id_idx_nos[4],
                            id_idx_nos[5],
                            id_idx_nos[6],
                            id_idx_nos[7],
                            id_idx_nos[8],
                            id_idx_nos[9],
                        ] = sa[vs]
                    else:
                        raise Exception(f"dimensionality:{len_hi} > max_dimension:10")

                    hyper_values_array_dict[vs] = hyper_values_tmp

            if hyper_values_format == "array_dict":
                hyper_values = hyper_values_array_dict
            elif hyper_values_format == "struct_array":
                fields = defaultdict(list)
                for vs in valuespaces:
                    fields["names"].append(vs)
                    fields["formats"].append(hyper_values_array_dict[vs].dtype)
                # Above we have ensured that len(valuespaces) > 0
                # Also note, hyper_values_array_dict[vs].shape should be the same for all vs so we can choose valuespaces[0] arbitarily here
                shape = hyper_values_array_dict[valuespaces[0]].shape

                hyper_values = np.zeros(shape, dtype=dict(fields))
                for vs in valuespaces:
                    hyper_values[vs] = hyper_values_array_dict[vs]
            elif valuespace is None:
                hyper_values = None
            elif len(hyper_values_array_dict) == 0:
                hyper_values = None
            elif valuespace not in hyper_values_array_dict:
                raise Exception(
                    f"Internal inconsistency: valuespace:{valuespace} absent"
                )
            elif hyper_values_array_dict[valuespace] is None:
                hyper_values = None
            else:
                hyper_values = hyper_values_array_dict[valuespace]

        # ================================================================
        # PART 3: Convert hyper_index according to hyper_index_format
        # ================================================================
        if hyper_index_format is None:
            # Reset to None here (regardless of current state)?
            hyper_index = None
        elif hyper_index is None:
            pass
        elif not isinstance(hyper_index, dict):
            raise Exception("Internal inconsistency...hyper_index is not a dict")
        elif hyper_index_format in ("array_dict", "IndexArray1D_dict"):
            pass
        elif hyper_index_format == "list_dict":
            # Convert hyper_index from dict of arrays to dict of lists
            for ks in hyper_index:
                if hyper_index[ks] is not None:
                    # Preserve freq attribute in this case
                    if hasattr(hyper_index[ks], "freq"):
                        freq1 = hyper_index[ks].freq
                        hyper_index[ks] = hyper_index[ks].tolist()
                        hyper_index[ks].freq = freq1
                    else:
                        hyper_index[ks] = hyper_index[ks].tolist()
        elif hyper_index_format == "dict":
            # Here we need to change the resultant type from dict to dict
            # NOTE: we need to do this step AFTER the hyper_values population
            hyper_index_tmp = dict()
            for ks in hyper_index:
                if not np.issubdtype(hyper_index[ks].dtype, np.datetime64):
                    # Frequency guidance does not apply
                    hyper_index_tmp[ks] = make_index(hyper_index[ks])

                elif (
                    not hasattr(hyper_index[ks], "freq") or hyper_index[ks].freq is None
                ):
                    # Frequency guidance is not available
                    hyper_index_tmp[ks] = make_index(hyper_index[ks])

                elif not RootLib().get_control("datetime64_flag"):
                    # Use frequency guidance from hyper_index[ks].freq
                    # Convert to an array of datetime
                    hyper_index_tmp[ks] = make_index(
                        hyper_index[ks].astype("O"), freq_hint=hyper_index[ks].freq
                    )
                else:
                    # Use frequency guidance from hyper_index[ks].freq
                    # Keep as numpy array of np.datetime64
                    hyper_index_tmp[ks] = make_index(
                        hyper_index[ks], freq_hint=hyper_index[ks].freq
                    )

            hyper_index = hyper_index_tmp
        else:
            raise Exception(
                "Invalid hyper_index_format:{0}", format(hyper_index_format)
            )

        return (hyper_values, hyper_index)  # note order!

    @property
    def valuespace(self) -> str:
        """
        Quble's primary valuespace
        Takes direction from self._valuespace attribute if present
        If absent, will infer primary valuespace using first available valuespace
        """

        return deepcopy(self._valuespace)

    @valuespace.setter
    def valuespace(self, new_valuespace: str):
        """
        (Re)sets the valuespace of the Quble
        by assigning custom info_type='is_valuespace'
        for the relevant columns accordingly

        If new_valuespace=None & CURRENTLY DOES NOT HAVE a valuespace
          ==> returns copy of the original (index-only) Quble++

        If new_valuespace=None & CURRENTLY HAS a (non-trivial) valuespace
          ==> turns Quble into an index-only Quble (drops valuespace column)

        If new_valuespace is not None & CURRENTLY DOES NOT HAVE a valuespace:
          ==> converts column index to boolean

        If new_valuespace is not None & corresponds to an existing space/column:
          ==> appoints the new_valuespace column as the valuespace

        If new_valuespace is not None & NOT corresponds to an existing space/column:
          ==> renames the existing valuespace column to new_valuespace arg
        """
        if self.is_undefined:
            raise UndefinedQubleError("Undefined Quble (no underlying table)")

        spaces = self.spaces
        if not isinstance(spaces, (list, tuple)):
            raise Exception(f"Invalid spaces/colselumns:{spaces}...list/tuple expected")

        if new_valuespace is None:
            if self.valuespace is not None:
                self._valuespace = new_valuespace
            else:
                pass
        elif not isinstance(new_valuespace, str):
            raise Exception(f"new_valuespace arg must be either a string or None")
        elif self._valuespace is None:
            if new_valuespace in spaces:
                # Case: Converting keyspace to valuespace in Index quble
                if (
                    self.get_space_info(
                        space=new_valuespace, info_type="role", grace=True
                    )
                    != "valuespace"
                ):
                    self.set_space_info(
                        space=new_valuespace,
                        info_type="role",
                        info_value="valuespace",
                    )
                    self.remove_space_info(space=new_valuespace, info_type="freq")
                    self._initialize_space_roles(new_valuespace)
            else:
                # Raise exception if new valuepsace not in available cols
                raise Exception(
                    f"The new valuespace {new_valuespace} is not present in table columns"
                )
        else:
            # Case: Rename valuespace
            if new_valuespace not in spaces:
                # Raise exception if new valuepsace not in available cols
                raise Exception(
                    f"The new valuespace {new_valuespace} is not present in table columns"
                )
            else:
                # Case: Promote the aux to primary valuespace
                self.set_space_info(
                    space=new_valuespace, info_type="role", info_value="valuespace"
                )
                self._valuespace = new_valuespace

    @property
    def scalar_value(self):
        """
        Returns the single (Python) value
        from the primary valuespace of a Quble "uniscalar" or "multiscalar"
        """
        if self.is_scalar:
            vs = self.valuespace
            scalar_val = self.to_struct_array(key_ordering=None)[self.valuespace][0]
        elif self.is_multiscalar:
            scalar_values = self.scalar_values
            vs = self.valuespace
            if vs in scalar_values:
                scalar_val = scalar_values[vs]
            else:
                # Could throw an Exception here
                return None
        else:
            raise Exception("Scalar or Multi-Scalar Quble required")

        # Coerce to a literal Python scalar
        if not hasattr(scalar_val, "dtype"):
            return scalar_val
        elif np.issubdtype(scalar_val.dtype, np.integer):
            return int(scalar_val)
        elif np.issubdtype(scalar_val.dtype, np.floating):
            return float(scalar_val)
        elif np.issubdtype(scalar_val.dtype, np.string_):
            col_type = self.get_space_info(info_type="type", space=vs)
            col_type = col_type if col_type is None else col_type.lower()
            if col_type == "blob":
                return bytes(scalar_val)
            else:
                return str(scalar_val)
        elif np.issubdtype(scalar_val.dtype, np.unicode_):
            return str(scalar_val)
        else:
            return scalar_val

    @property
    def scalar_values(self) -> dict:
        """
        Given a "uniscalar" (univariate-scalar)
        or "multiscalar" (multivariate-scalar) Quble,
        returns the the scalar value(s) for each valuespace
        as a dictionary (keyed by valuespace)
        """
        # We cannot return result as a numpy array as the dtypes across the valuespaces may not match
        # Could return a structured single element with valuespace names
        if self.is_scalar or self.is_multiscalar:
            data = self.to_struct_array(key_ordering=None)
            scalar_values = {}
            for vs in self.valuespaces:
                scalar_values[vs] = data[vs][0]
            return scalar_values
        else:
            raise Exception("Scalar or Multi-Scalar Quble required")

    @property
    def sorted_data(self) -> np.ndarray:
        """
        Returns Quble's content as structured numpy array
        with records ordered by keys in ascending order
        """
        return self.to_struct_array(key_ordering="asc")

    @property
    def indices(self) -> np.ndarray:
        """
        Returns Quble's indices (keyspaces only) as structured numpy array
        in existing record order
        """
        return self.to_struct_array(column_names=self.keyspaces, key_ordering=None)

    @property
    def sorted_indices(self) -> np.ndarray:
        """
        Returns Quble's indices (keyspaces only) as structured numpy array
        with records order by keys ascending order
        """
        return self.to_struct_array(column_names=self.keyspaces, key_ordering="asc")

    @property
    def values(self):
        return self.folded_values

    @property
    def folded_values(self) -> np.ndarray:
        """
        Returns Quble's primary values (primary valuespace)
        as structured numpy array
        in existing record order
        """
        if self.valuespace:
            return self.to_struct_array(
                column_names=[self.valuespace], key_ordering=None
            )
        else:
            return None

    @property
    def unfolded_values(self):
        """
        Returns Quble's 'unfolded' values as Python object

        Internally calls property method:
           self.hyper_values

        See :meth:`~qubles.core.quble.Quble.hyper_values`
        """
        return self.hyper_values

    @RootLib.lazy_kwargs()
    def get_all_columns(
        self,
        key_ordering=None,
        remove_rows_any_null_keys: bool = False,
        remove_rows_all_null_values: bool = False,
        as_structured_nparray: bool = False,
        grace: bool = True,
        clob_export_mode: str = RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode: str = RootLib.lazy_eval("blob_export_mode"),
    ):
        """
        [See: :meth:`~qubles.core.quble.Quble.get_columns`]
        """
        return self.get_columns(
            column_names="<all>",
            key_ordering=key_ordering,
            remove_rows_any_null_keys=remove_rows_any_null_keys,
            remove_rows_all_null_values=remove_rows_all_null_values,
            as_structured_nparray=as_structured_nparray,
            grace=grace,
            clob_export_mode=clob_export_mode,
            blob_export_mode=blob_export_mode,
        )

    @RootLib.lazy_kwargs()
    def get_columns(
        self,
        column_names="<all>",
        key_ordering=None,
        remove_rows_any_null_keys: bool = False,
        remove_rows_all_null_values: bool = False,
        as_structured_nparray: bool = False,
        grace: bool = True,
        clob_export_mode: str = RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode: str = RootLib.lazy_eval("blob_export_mode"),
    ):
        """
        Returns all columns as either
        a structured numpy array or a dictionary of numpy arrays

        NOTE: Currently implemented as using row parsing (somewhat slow)
        Consider using Quble.to_struct_array() is a more performance alternative
        """
        # Establish column_names (list/tuple)
        if column_names == "<all>" or column_names is None:
            column_names = self.column_names
        elif isinstance(column_names, (list, tuple)):
            pass
        else:
            column_names = [column_names]

        if column_names is None or len(column_names) == 0:
            if grace:
                return None
            else:
                raise Exception("No column data found")

        keyspaces = self.keyspaces

        # Get column type info
        col_types = []
        for column_name in column_names:
            col_types.append(self.get_column_type(column_name))

        # validate key_ordering
        if key_ordering:
            if not isinstance(key_ordering, str) or (
                key_ordering.lower() not in ("asc", "desc")
            ):
                raise Exception(f"Invalid key_ordering:{key_ordering}")

        # --------------------------------
        # Part #1: Construct the query
        # --------------------------------
        column_expression = {}
        query_command = "SELECT "
        comma_str_select = ""
        any_null_keys_removal_clause = ""
        and_str_all_null_keys_removal = ""
        all_null_values_removal_clause = ""
        or_str_all_null_values_removal = ""
        order_by_clause = ""
        comma_str_order = ""

        for column_no, column_name in enumerate(column_names):
            # date (WITHOUT timezone info)
            if col_types[column_no] in SQL_DATE_TYPES:
                column_expression[column_no] = (
                    f"date_to_str(\"{column_name}\", '%Y-%m-%d')"
                )
            # timestamp (WITHOUT timezone info)
            elif col_types[column_no] in SQL_DATETIME_TYPES:
                column_expression[column_no] = (
                    f"timestamp_to_str(\"{column_name}\", '%Y-%m-%d %H:%M:%S')"
                )
            else:
                column_expression[column_no] = f'"{column_name}"'

            # Update query_command (all columns)
            query_command += (
                comma_str_select
                + column_expression[column_no]
                + ' AS "'
                + column_name
                + '"'
            )
            comma_str_select = ", "

            # Update order_by_clause (keyspaces only)
            if column_name in keyspaces:
                if remove_rows_any_null_keys:
                    any_null_keys_removal_clause += (
                        f'{and_str_all_null_keys_removal}"{column_name}" IS NOT NULL'
                    )
                    and_str_all_null_keys_removal = " AND "

                if key_ordering:
                    if len(order_by_clause) == 0:
                        order_by_clause += " ORDER BY "
                    order_by_clause += (
                        f'{comma_str_order}"{column_name}" {key_ordering}'
                    )
                    comma_str_order = ", "
                else:
                    pass
            # For non-keyspaces (values)
            # Update all_null_values_removal_clause (non-keyspaces aka valuespaces only)
            elif remove_rows_all_null_values:
                all_null_values_removal_clause += (
                    f"{or_str_all_null_values_removal + column_name} IS NOT NULL"
                )
                or_str_all_null_values_removal = " OR "

        # Continue to build query_command
        quoted_table_name = dquote_dot(self.table_name)
        query_command += f" FROM {quoted_table_name}"

        if (
            len(all_null_values_removal_clause) > 0
            and len(any_null_keys_removal_clause) > 0
        ):
            query_command += (
                " WHERE ("
                + all_null_values_removal_clause
                + ") AND ("
                + any_null_keys_removal_clause
                + ")"
            )
        elif len(any_null_keys_removal_clause) > 0:
            query_command += f" WHERE {any_null_keys_removal_clause}"
        elif len(all_null_values_removal_clause) > 0:
            query_command += f" WHERE {all_null_values_removal_clause}"

        query_command += order_by_clause
        query_command += ";"

        # Execute query and fetch results
        column_query_results = execute(query_command, fetch="all")

        # Handle empty column results
        if column_query_results is None and len(column_query_results) == 0:
            return []

        # -----------------------------------------------------------------------------
        # Here, result from fetchall() is a tuple of tuples...
        # The outer tuples are rows, and the inner tuples are columns of a given row.
        # In this case, we are requesting a single column, so the inner tuples will only have one element
        # As such, the inner tuples are unnecessary.
        # Remove the inner tuples and convert the outer tuples to an appropriate numpy array
        # -----------------------------------------------------------------------------

        # ---------------------------------------
        # Part #2: Process the query results
        # ---------------------------------------
        num_records = len(column_query_results)
        result_dict = {}
        dtype_dict = {}
        dtypestr_dict = {}

        for column_no, column_name in enumerate(column_names):
            col_type = col_types[column_no]
            missing_val = coltype_to_missing_value(
                col_type,
                clob_export_mode=clob_export_mode,
                blob_export_mode=blob_export_mode,
            )

            # Trap for bad col_type
            if col_type is None:
                raise Exception(
                    f"Unable to establish column_type for column_name:{column_name}"
                )
            elif not isinstance(col_type, str):
                raise Exception(
                    f"Invalid column_type:{col_type} for column_name:{column_name}"
                )

            col_type = (
                col_type.lower().strip()
            )  # <-- Strip and convert to lower-case for testing below

            # Handle string-related column type
            if col_type in ("varchar", "string", "char", "character", "text"):
                # Convert column_query_results to an list of strings
                # Also, establish the maximum string len:
                obj_list = []
                for row in column_query_results:
                    if row[column_no] is None:
                        obj_list.append(missing_val)
                    else:
                        obj_list.append(row[column_no])

                # Construct the numpy array
                arr = np.array(obj_list)

                # Handle arr.dtype == object accordingly
                if arr.dtype != object:
                    pass
                elif len(arr) > 0 and not isinstance(arr[0], str):
                    pass
                else:
                    arr = arr.astype(np.unicode_)

                result_dict[column_name] = arr
            # Handle character large object (clob) column type
            elif col_type == "clob":
                # Convert column_query_results to an list of strings
                # Also, establish the maximum string len:
                obj_list = []
                for row in column_query_results:
                    if row[column_no] is None:
                        obj_list.append(missing_val)
                    else:
                        obj_list.append(row[column_no])

                # Construct the numpy array
                arr = np.array(obj_list)

                # Handle arr.dtype == object accordingly
                if arr.dtype != object:
                    pass
                elif clob_export_mode is None:
                    pass
                elif clob_export_mode == "object":
                    pass
                elif len(arr) > 0 and not isinstance(arr[0], str):
                    pass
                elif clob_export_mode in ("string", "str"):
                    try:
                        arr = arr.astype(np.string_)
                    except:
                        arr = arr.astype(np.unicode_)
                        arr = unicode_arr_to_string_arr(arr)
                else:
                    arr = arr.astype(np.unicode_)

                result_dict[column_name] = arr
            # Handle binary large object (blob) column type
            elif col_type == "blob":
                # Convert column_query_results to an list of strings
                # Also, establish the maximum string len:
                obj_list = []
                for row in column_query_results:
                    if row[column_no] is None:
                        obj_list.append(missing_val)
                    else:
                        obj_list.append(row[column_no])

                # Handle arr.dtype == object accordingly
                if arr.dtype != object:
                    pass
                elif blob_export_mode is None:
                    pass
                elif blob_export_mode == "object":
                    pass
                elif len(arr) > 0 and not isinstance(arr[0], str):
                    pass
                elif blob_export_mode in ("string", "str"):
                    try:
                        arr = arr.astype(np.string_)
                    except:
                        arr = arr.astype(np.unicode_)
                        arr = unicode_arr_to_string_arr(arr)
                elif blob_export_mode == "unicode":
                    arr = arr.astype(np.unicode_)
                else:
                    pass

                result_dict[column_name] = arr
            # Handle date & timestamp column type
            elif (col_type in SQL_DATE_TYPES) or (col_type in SQL_DATETIME_TYPES):
                obj_list = []
                for row in column_query_results:
                    if row[column_no] is None:
                        obj_list.append(missing_val)
                    else:
                        obj_list.append(row[column_no])

                dtype_dict[column_name] = np.datetime64
                dtypestr_dict[column_name] = (
                    "datetime64[D]" if col_type in SQL_DATE_TYPES else "datetime64[us]"
                )
                result_dict[column_name] = np.array(
                    obj_list, dtype=dtypestr_dict[column_name]
                )
            # Handle standard col_type
            else:
                # Use col_type inside coltype_to_dtype()
                dtype_dict[column_name] = coltype_to_dtype(col_type)

                obj_list = []
                for row in column_query_results:
                    if row[column_no] is None:
                        obj_list.append(missing_val)
                    else:
                        obj_list.append(row[column_no])

                dtypestr_dict[column_name] = DTYPE_TO_DTYPESTR[dtype_dict[column_name]]
                result_dict[column_name] = np.array(
                    obj_list, dtype=dtype_dict[column_name]
                )

        if as_structured_nparray:
            # NOTE: Discovered numpy.zeros() suffers less memory issues than ones()
            result_structured_nparray = np.zeros(
                num_records,
                dtype={"names": column_names, "formats": list(dtypestr_dict.values())},
            )
            for column_name in column_names:
                result_structured_nparray[column_name] = result_dict[column_name]
            return result_structured_nparray
        else:
            return result_dict

    @RootLib.lazy_kwargs()
    def get_column(
        self,
        column_name: str,
        grace: bool = True,
        distinct: bool = False,
        sort_direction: str = None,
        clob_export_mode: str = RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode: str = RootLib.lazy_eval("blob_export_mode"),
    ):
        """
        Gets the records for a specified column_name

        :param column_name: the column name requested
        :type column_name: str

        :param grace: control for handling absent column
        :type grace: bool (True/False)

        :param distinct: control for requesting distinct records
        :type distinct: bool (True/False)

        :param sort_direction: control for specifying sort direction
        :type sort_direction: None (no sorting), or str ('asc','desc')

        """
        # Validate column_name
        if isinstance(column_name, str):
            column_name = column_name.strip()
        elif grace:
            return None
        else:
            raise Exception(f"Absent/invalid column_name:{column_name}")

        # Handle absent column requests
        if column_name not in self.column_names:
            if grace:
                return None
            else:
                raise Exception(f"Absent column_name:{column_name}")

        # Get column type info
        col_type = self.get_column_type(column_name)
        col_type_with_digits = self.get_column_type(column_name)
        # Trap for bad col_type
        if col_type is None or col_type_with_digits is None:
            raise Exception(
                f"Unable to establish column_type for column_name:{column_name}"
            )
        elif not isinstance(col_type, str) or not isinstance(col_type_with_digits, str):
            raise Exception(
                f"Invalid column_type:{col_type} for column_name:{column_name}"
            )

        col_type = (
            col_type.lower().strip()
        )  # <-- Strip and convert to lower-case for testing below
        col_type_with_digits = col_type_with_digits.lower().strip()

        missing_val = coltype_to_missing_value(
            col_type_with_digits,
            clob_export_mode=clob_export_mode,
            blob_export_mode=blob_export_mode,
        )

        # date (WITHOUT timezone info)
        if col_type in SQL_DATE_TYPES:
            column_expression = f"date_to_str(\"{column_name}\", '%Y-%m-%d')"
        # timestamp (WITHOUT timezone info)
        elif col_type in SQL_DATETIME_TYPES:
            column_expression = (
                f"timestamp_to_str(\"{column_name}\", '%Y-%m-%d %H:%M:%S')"
            )
        else:
            column_expression = f'"{column_name}"'

        # Create column_query_command
        if distinct:
            column_query_command = (
                f'SELECT DISTINCT({column_expression}) FROM "{self.table_name}"'
            )
        else:
            column_query_command = (
                f'SELECT {column_expression} FROM "{self.table_name}"'
            )

        # Add sort (if applicable)
        if sort_direction:
            if not isinstance(sort_direction, str) or (
                sort_direction.lower() not in ("asc", "desc")
            ):
                raise Exception(f"Invalid sort_direction:{sort_direction}")
            else:
                column_query_command += f' ORDER BY "{column_name}" {sort_direction}'

        # Add trailing semi-colon
        column_query_command += ";"

        # Execute query and fetch results
        column_query_results = execute(column_query_command, fetch="all")

        # Handle empty column results
        if column_query_results is None and len(column_query_results) == 0:
            return []

        if col_type in ("varchar", "string", "char", "character", "text"):
            obj_list = []
            for row in column_query_results:
                if row[0] is None:
                    obj_list.append(missing_val)
                else:
                    obj_list.append(
                        row[0]
                    )  # <-- The the first (and only) column for the current row

            # Construct the numpy array
            arr = np.array(obj_list)

            # Handle arr.dtype == object accordingly
            if arr.dtype != object:
                return arr
            elif len(arr) > 0 and not isinstance(arr[0], str):
                return arr
            else:
                raise Exception(f"Invalid clob_export_mode:{clob_export_mode}")
        # Handle character large object (clob) column type
        elif col_type == "clob":
            obj_list = []
            for row in column_query_results:
                if row[0] is None:
                    obj_list.append(missing_val)
                else:
                    obj_list.append(
                        row[0]
                    )  # <-- The the first (and only) column for the current row

            # Construct the numpy array
            arr = np.array(obj_list)

            # Handle arr.dtype == object accordingly
            if arr.dtype != object:
                return arr
            elif clob_export_mode is None:
                return arr
            elif clob_export_mode == "object":
                return arr
            elif len(arr) > 0 and not isinstance(arr[0], str):
                return arr
            elif clob_export_mode in ("string", "str"):
                try:
                    return np.array(arr, np.string_)
                except:
                    arr = np.array(arr, np.unicode_)
                    return unicode_arr_to_string_arr(arr)

            elif clob_export_mode == "unicode":
                return np.array(arr, np.unicode_)
            else:
                return arr
        # Handle binary large object (blob) column type
        elif col_type == "blob":
            # Convert column_query_results to an list of strings
            # Also, establish the maximum string len:
            obj_list = []
            for row in column_query_results:
                if row[0] is None:
                    obj_list.append(missing_val)
                else:
                    obj_list.append(row[0])

            # Construct the numpy array
            arr = np.array(obj_list)

            # Handle arr.dtype == object accordingly
            if arr.dtype != object:
                return arr
            elif blob_export_mode is None:
                return arr
            elif blob_export_mode == "object":
                return arr
            elif len(arr) > 0 and not isinstance(arr[0], str):
                return arr
            elif blob_export_mode in ("string", "str"):
                try:
                    return np.array(arr, np.string_)
                except:
                    arr = np.array(arr, np.unicode_)
                    return unicode_arr_to_string_arr(arr)

            elif blob_export_mode == "unicode":
                return np.array(arr, np.unicode_)

            else:  # if blob_export_mode == 'object':
                return arr

        # Handle date & timestamp
        elif (col_type in SQL_DATE_TYPES) or (col_type in SQL_DATETIME_TYPES):
            obj_list = []
            for row in column_query_results:
                if row[0] is None:
                    obj_list.append(missing_val)
                else:
                    obj_list.append(row[0])

            if col_type in SQL_DATE_TYPES:
                return np.array(obj_list, dtype="datetime64[D]")
            else:
                return np.array(obj_list, dtype="datetime64[us]")
        # Handle standard col_type
        else:
            # Use col_type_with_digits inside coltype_to_dtype()
            dtype = coltype_to_dtype(col_type_with_digits)

            obj_list = []
            for row in column_query_results:
                if row[0] is None:
                    obj_list.append(missing_val)
                else:
                    obj_list.append(row[0])
            return np.array(obj_list, dtype=dtype)

    def distinct_valuespace_array1d(
        self, valuespace: str = "<valuespace>"
    ) -> np.ndarray:
        """
        Returns a numpy array of the
        distinct values in the specified Quble's valuespace
        """
        return self.valuespace_array1d(distinct=True, valuespace=valuespace)

    @RootLib.lazy_kwargs()
    def valuespace_array1d(
        self,
        distinct: bool = False,
        valuespace: str = "<valuespace>",
        clob_export_mode: str = RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode: str = RootLib.lazy_eval("blob_export_mode"),
    ) -> np.ndarray:
        """
        Returns a numpy array of the (distinct/non-distinct) values
        in the specified valuespace (single column) of the Quble

        :param keyspace: the keyspace of the desired index
        :type keyspace: string

        :param distinct: flag for distincy key selection
        :type distinct: string or list of strings or '<all>'

        :param key_ordering: (optional) controls row ordering by key
        :type key_ordering: None (no keyspace sorting), 'asc' or 'desc', dict
                 [See: :meth:`~qubles.core.quble.Quble.key_sort`]
        """
        if self.is_undefined:
            raise UndefinedQubleError("undefined Quble")

        valuespace = self.validate_valuespace(
            valuespace=valuespace, solo_required=True, grace=False
        )

        if valuespace is None:
            raise NoValuespaceError("valuespace required")

        return self.get_column(
            column_name=valuespace,
            distinct=distinct,
            sort_direction="asc" if distinct else None,
            clob_export_mode=clob_export_mode,
            blob_export_mode=blob_export_mode,
        )

    def distinct_index(
        self, keyspaces="<keyspaces>", contiguous_flag: bool = False, key_ordering="asc"
    ) -> Quble:
        """
        Returns the distinct (and ordered) index Quble
        Here, we chose to order the distinct key results

        :param keyspaces: keyspace(s) for distinct key selection
        :type keyspaces: string or list of strings or '<all>'

        :param contiguous_flag: (optional) flag to force contiguous dates across time-keyspaces
        :type contiguous_flag: boolean (False*/True)
                 [See: :meth:`~qubles.core.quble.Quble.index`]

        :param key_ordering: (optional) controls row ordering by key
        :type key_ordering: None (no keyspace sorting), 'asc' or 'desc', dict
                 [See: :meth:`~qubles.core.quble.Quble.key_sort`]

        NOTE: the index column lengths & record ordering
              may not match the index columns in underlying table

        :param contiguous_flag: flag for time-key selection WHEN distinct=True
                          (this arg is ignored when distinct=False)
        :type contiguous_flag: boolean (True/False*)

        [See: :meth:`~qubles.core.quble.Quble.index`]
        """
        return self.index(
            keyspaces=keyspaces,
            distinct=True,
            contiguous_flag=contiguous_flag,
            key_ordering=key_ordering,
        )

    def distinct_ortho_index(
        self,
        keyspace,
        contiguous_flag: bool = False,
        key_ordering=None,
        grace: bool = True,
    ) -> Quble:
        """
        Returns an index Quble containing the distinct keys
        across the orthogonal keyspaces (i.e., outside of the specified keyspace(s))
        If there are no orthogonal keyspaces, this method will return an undefined Quble

        :param keyspace: keyspace(s) of the dimension to be excluded
        :type keyspace: str or list of str
                 [See: :meth:`~qubles.core.quble.Quble.validate_keyspace`]

        :param contiguous_flag: (optional) flag to force contiguous dates across time-keyspaces
        :type contiguous_flag: boolean (False*/True)
                 [See: :meth:`~qubles.core.quble.Quble.index`]

        :param key_ordering: (optional) controls row ordering by key
        :type key_ordering: None (no keyspace sorting), 'asc' or 'desc', dict
                 [See: :meth:`~qubles.core.quble.Quble.key_sort`]

        :param grace: Graceful/ungraceful exception handling
        :type grace: boolean (True/False)

        """
        ortho_keyspaces = self.ortho_keyspaces(keyspace, grace=grace)
        if ortho_keyspaces is None or len(ortho_keyspaces) == 0:
            return Quble.undefined_instance()
        else:
            return self.distinct_index(
                keyspaces=ortho_keyspaces,
                contiguous_flag=contiguous_flag,
                key_ordering=key_ordering,
            )

    def unfold(self, contiguous_flag: bool = False, key_ordering=None) -> Quble:
        """
        Creates an 'unfolded' version of the Quble
        supports/exhibits all combinations of
        distinct keys across all keyspaces

        Will implicitly invoke temporal filling if/where applicable

        WARNING: This method may introduce a large number of new records!
        """
        if self.is_undefined:
            return Quble.undefined_instance()
        elif self.is_scalar:
            return self.copy()
        elif self.is_empty:
            return self.copy()

        unfolded_index = self.index(
            keyspaces="<keyspaces>",
            distinct=True,
            contiguous_flag=True,
            key_ordering=key_ordering,
        )

        joined = self.join(
            other=unfolded_index,
            keys_join_op="rightmost",
            keyspaces_join_op="right",
            valuespaces_join_op="left",
        )
        return joined

    def contiguous_distinct_index(
        self, keyspaces="<keyspaces>", key_ordering=None
    ) -> Quble:
        return self.index(
            keyspaces=keyspaces, distinct=True, contiguous_flag=True, key_ordering=None
        )

    # NOTE: using defaults: keyspaces='<keyspaces>', distinct=False, key_ordering=None
    # so that default result will reflect state of index columns in underlying table
    def index(
        self,
        keyspaces="<keyspaces>",
        distinct=False,
        contiguous_flag: bool = False,
        key_ordering=None,
        quble_flag: bool = True,
    ) -> Quble:
        """
        Generates an index (non-valuespace) Quble
        using only the (non-distinct/distinct) keys across the specified keyspaces

        :param keyspaces: keyspace(s) for distinct key selection
        :type keyspaces: string or list of strings or '<keyspaces>', etc.
                 [See: :meth:`~qubles.core.quble.Quble.validate_keyspace`]

        :param distinct: flag for distinct key selection
        :type distinct: boolean

        :param contiguous_flag: flag for time-key selection WHEN distinct=True
                          (this arg is ignored when distinct=False)
        :type contiguous_flag: boolean

        :param key_ordering: (optional) controls row ordering by key
        :type key_ordering: None (no keyspace sorting), 'asc' or 'desc', dict
                 [See: :meth:`~qubles.core.quble.Quble.key_sort`]
        """
        # Validate the distinct keyspace(s)
        # ------------------------------------
        keyspaces = self.validate_keyspace(keyspaces, coerce_to_list=True)

        # Build build_key_ordering_dict when applicable
        if key_ordering is not None and not isinstance(key_ordering, str):
            # NOTE: build ordering dict only for the distinct keyspaces (not self.keyspaces)
            key_ordering = build_key_ordering_dict(key_ordering, keyspaces=keyspaces)

        table_name = generate_random_table_name()

        if distinct and contiguous_flag and self.has_time_keyspaces:
            freqs = {}
            for ks in self.keyspaces:
                if self.is_time_space(ks):
                    freq1 = self.get_space_info(info_type="freq", space=ks)
                    if freq1:
                        freqs[ks] = freq1

            sql_template = JINJA_ENV.get_template("distinct_contiguous_index.j2")
            sql_command = sql_template.render(
                src_table_name=self.table_name,
                tgt_table_name=table_name,
                calendar_table_name=RootLib().get_control("calendar_table_name"),
                keyspaces=keyspaces,
                freqs=freqs,
                key_ordering=key_ordering,
            )
        else:
            sql_template = JINJA_ENV.get_template("index.j2")
            sql_command = sql_template.render(
                src_table_name=self.table_name,
                tgt_table_name=table_name,
                # NOTE: keyspaces in template are only distinct keyspaces (not all keyspaces)
                keyspaces=keyspaces,
                distinct=distinct,
                key_ordering=key_ordering,
            )

        execute(sql_command, format_flag=False)

        if quble_flag:
            return Quble.from_table(
                table_name,
                col_info=self.get_space_info(
                    info_type=CUSTOM_INFO_TYPES,
                    space=keyspaces,
                    omit_unassigned=True,
                ),
            )
        else:
            results = execute(f"SELECT * from {table_name}", fetch="all")
            col_info = desc_table(table_name)
            final_result = {}
            for index in range(0, len(col_info)):
                final_result[col_info[index][0]] = [tup[index] for tup in results]

            return final_result

    def distinct_index_array1d(
        self, keyspace, contiguous_flag: bool = False, key_ordering="asc"
    ) -> Quble:
        """
        Returns a numpy array of the distinct (and ordered) keys in the specified keyspace
        """
        return self.index_array1d(
            keyspace=keyspace,
            distinct=True,
            contiguous_flag=contiguous_flag,
            key_ordering=key_ordering,
        )

    # NOTE: using defaults: distinct=False, key_ordering=None
    # so that default result will reflect state of specified index column in underlying table
    @RootLib.lazy_kwargs()
    def index_array1d(
        self,
        keyspace,
        distinct=False,
        contiguous_flag: bool = False,
        key_ordering=None,
        clob_export_mode=RootLib.lazy_eval("clob_export_mode"),
        blob_export_mode=RootLib.lazy_eval("blob_export_mode"),
        array_format="IndexArray1D",
    ):
        """
        Returns a single index of the (distinct/non-distinct) keys
        in the specified keyspace (column) as a numpy array
        :param keyspace: keyspace (or keygroup) of the desired index
        :type keyspace: string
        :param distinct: flag for distinct key selection
        :type distinct: boolean
        :param key_ordering: (optional) controls row ordering by key
        :type key_ordering: None (no keyspace sorting), 'asc' or 'desc', dict [See: :meth:`~qubles.core.quble.Quble.key_sort`]
        :param contiguous_flag: flag for contiguous time keys (only applies for distinct=True)
        :type contiguous_flag: bool (True/False*)
        :param array_format: format of the resultant index_array object
        'IndexArray1D': returns dictionary of IndexArray1D
        'array': returns numpy array
        'list': returns list of distinct keys
        :type array_format: str
        """
        # Handle trivial array_format arg
        if array_format is None:
            array_format = "IndexArray1D"
        # Apply logic according to state of underlying Quble
        if self.is_undefined:
            # Handle undefined Quble case
            return None
        elif keyspace in self.complex_keygroups:
            # Here, keyspace is a multi-keygroup (multiple underlying keyspaces)
            sub_keyspaces = self.complex_keygroups[keyspace]
            idx = self.index(
                keyspaces=sub_keyspaces,
                distinct=distinct,
                contiguous_flag=contiguous_flag,
                key_ordering=key_ordering,
            )
            sa = idx.to_struct_array(
                column_names="<all>",
                clob_export_mode=clob_export_mode,
                blob_export_mode=blob_export_mode,
            )
            if not is_structured_array(sa):
                raise Exception(
                    f"Quble.to_struct_array returned a non-structured numpy array"
                )
            # Apply multi-dimensional (nested) sorting (if directed)
            if key_ordering is None:
                pass
            elif not isinstance(key_ordering, str):
                raise Exception(
                    f"Invalid key_ordering:{key_ordering}...str ('asc' or 'desc') or None expected"
                )
            else:
                # Convert key_ordering to lower-case string to remove ambiguity
                key_ordering = key_ordering.lower().strip()
                if key_ordering in ("desc", "d"):
                    sa = np.sort(sa, order=sa.dtype.names)[::-1]
                elif key_ordering in ("asc", "a"):
                    sa = np.sort(sa, order=sa.dtype.names)
                else:
                    raise Exception(
                        f"Invalid key_ordering:{key_ordering}...str ('asc' or 'desc') or None expected"
                    )
            freq = None
            # Return results according to array_format arg
            if not isinstance(array_format, str):
                raise Exception(
                    f"Invalid array_format:{array_format}...'IndexArray1D', 'list' or 'array' expected"
                )
            elif array_format.lower() == "indexarray1d":
                return IndexArray1D(sa, freq=freq)
            elif array_format == "list":
                # list format
                if len(self.complex_keygroups) == 1:
                    return sa[self.complex_keygroups[0]].tolist()
                else:
                    raise Exception(
                        f"'list' not supported for len(self.complex_keygroups[{keyspace}]):{len(self.complex_keygroups[keyspace])} != 1"
                    )
            elif array_format.lower() not in ("array", "np", "numpy"):
                raise Exception(
                    f"Invalid array_format:{array_format}...'IndexArray1D', 'list' or 'array' expected"
                )
            else:
                # numpy array format
                return idx_arr
        elif keyspace not in self.keyspaces:
            raise Exception(f"keyspace absent from self.keyspaces:{self.keyspaces}")
        else:
            # Simple single-keyspace request
            if contiguous_flag:
                idx = self.index(
                    keyspaces=keyspace,
                    distinct=distinct,
                    contiguous_flag=contiguous_flag,
                    key_ordering=key_ordering,
                )
                df = idx.select_query(
                    key_ordering=key_ordering,
                    tgt_keyspaces=[keyspace],
                    column_names=[keyspace],
                    return_query_results=True,
                )
            else:
                column_expressions1 = {}
                column_expressions1[keyspace] = (
                    f'DISTINCT "{keyspace}"' if distinct else f'"{keyspace}"'
                )
                df = self.select_query(
                    key_ordering=key_ordering,
                    tgt_keyspaces=[keyspace],
                    column_names=[keyspace],
                    column_expressions=column_expressions1,
                    return_query_results=True,
                )
            # Convert desired pandas dataframe column to numpy array
            idx_arr = df[keyspace].to_numpy()
            # Return results according to array_format arg
            if not isinstance(array_format, str):
                raise Exception(
                    f"Invalid array_format:{array_format}...'IndexArray1D', 'list' or 'array' expected"
                )
            elif array_format.lower() == "indexarray1d":
                if self.is_time_space(space=keyspace, grace=True):
                    freq = self.get_space_info(info_type="freq", space=keyspace)
                else:
                    freq = None
                return IndexArray1D(idx_arr, freq=freq)
            elif array_format == "list":
                # list format
                return idx_arr.tolist()
            elif array_format.lower() not in ("array", "np", "numpy"):
                raise Exception(
                    f"Invalid array_format:{array_format}...'IndexArray1D', 'list' or 'array' expected"
                )
            else:
                # numpy array format
                return idx_arr

    def concate_keys(
        self,
        keygroups="<all>",
        join_delimiter=":",
        null_proxy="NULL",
        date_format: str = "%Y-%m-%d",
        datetime_format: str = "%Y-%m-%d %H:%M:%S",
    ) -> Quble:
        """
        Concatenates keys across the keyspaces in each keygroup
        into a combined string using the specified delimiter

        :param keygroups: The keygroup(s) for concatenation
        :type keygroups: dictionary OR scalar str OR list/tuple/np.array of strings
        dictionary: map from keygroup to keyspaces concatenate
        scalar str: a specific keygroup from self.keygroups
        list/tuple/np.array of strs/unicodes: specific keygroups from self.keygroups
        """
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate keygroup (convert to iterable if needed)
        if keygroups is None:
            return self.copy()
        elif keygroups == "<all>":
            # Need to make a copy here as we may pop some keys below
            keygroups = deepcopy(self.keygroups)
        elif isinstance(keygroups, (dict)):
            # Need to make a copy here as we may pop some keys below
            keygroups = deepcopy(keygroups)
            # Validate keygroups structure provided
            for keygroup in keygroups:
                # Make sure keygroups[keygroup] yields a list/tuple
                if not isinstance(keygroup, str):
                    raise Exception(f"Invalid keygroup:{keygroup}...str required")
                elif not isinstance(keygroups[keygroup], (list, tuple)):
                    raise Exception(
                        f"Invalid keygroups[{keygroup}]...list/tuple required"
                    )

                # Make sure elements of current keygroup list
                # correspond to valid spaces (column names)
                all_kg_elements = []
                for ks_no, ks in enumerate(keygroups[keygroup]):
                    if not isinstance(ks, str):
                        raise Exception(
                            "Invalid keygroups[{0}][{1}]={2}...str required".format(
                                keygroup, ks_no, ks
                            )
                        )
                    elif ks not in self.spaces:
                        raise Exception(
                            "keygroups[{0}][{1}]={2}...absent from self.spaces:{4}".format(
                                keygroup, ks_no, ks, self.spaces
                            )
                        )
                    elif ks in all_kg_elements:
                        raise Exception("ks:{0} assigned to multiple keygroups")
                    else:
                        all_kg_elements.append(ks)

        # keygroup(s) provided (scalar str or list/tuple of strs/unicodes or numpy array of strs/unicodes)
        # where each element is a valid keygroup from self.keygroups
        elif (
            isinstance(keygroups, str)
            or isinstance(keygroups, (tuple, list))
            or (
                isinstance(keygroups, np.ndarray)
                and (
                    np.issubdtype(keygroups.dtype, np.unicode_)
                    or np.issubdtype(keygroups.dtype, np.string_)
                )
            )
        ):
            if isinstance(keygroups, str):
                keygroups = [keygroups]

            # List/tuple of keygroups
            keygroups_dict = {}
            for keygroup in keygroups:
                if keygroup not in self.keygroups:
                    raise Exception(
                        "Invalid keygroup:{0}...valid keygroups:{1}".format(
                            keygroup, list(self.keygroups.keys())
                        )
                    )
                elif len(self.keygroups[keygroup]) == 0:
                    continue
                else:
                    keygroups_dict[keygroup] = self.keygroups[keygroup]
            keygroups = keygroups_dict
        else:
            raise Exception(f"Invalid keygroups:{keygroups}..dictionary expected")

        # Handle trivial group list
        if len(keygroups) == 0:
            return self.copy()

        # Build column_names
        column_names = []
        for space in self.spaces:
            # Recall, keygroup is only list of applicable/requested multi-space keygroups
            space_assigned_to_group = False
            for keygroup1 in keygroups:
                if space in keygroups[keygroup1]:
                    # Current space if part of current multi-keyspace keygroup
                    if keygroup1 not in column_names:
                        column_names.append(keygroup1)
                    space_assigned_to_group = True
                    break
            # Otherwise, space is not part of a multi-keyspace keygroup
            if not space_assigned_to_group and space not in column_names:
                column_names.append(space)

        # Get/validate column types
        col_types = self.get_space_info(info_type="type", space="<all>")
        if col_types is None:
            raise Exception("Unable to procure col_types")
        elif not isinstance(col_types, dict):
            raise Exception(f"Invalid col_types:{col_types}...dict expected")

        # Build column_expressions for each keygroup
        # ==> Handle cases when keyspace values are NULL
        # ==> Include join_delimiter
        column_expressions = {}
        # Loop through thes keygroups
        for keygroup1 in keygroups:
            ks_list = keygroups[keygroup1]

            # Empty keygroup (should ideally not occur)
            if ks_list is None or len(ks_list) == 0:
                continue
            # Here, there is only one keyspace in the current keygroup1
            elif len(ks_list) == 1:
                # Only need column_expressions if we are renaming a column
                # Otherwise, this keyspace wil be covered by the basic select method
                if ks_list[0] not in self.keyspaces:
                    raise Exception(
                        f"ks:{ks_list[0]} absent from keyspaces:{self.keyspaces}"
                    )
                elif ks_list[0] == keygroup1:
                    pass
                elif ks_list[0] in column_expressions:
                    raise Exception(
                        f"ks:{ks_list[0]} already present in column_expressions"
                    )
                else:
                    column_expressions[ks_list[0]] = f'"{ks_list[0]}"'
            # Otherwise, process the multi-space keygroup
            else:
                # Loop through the keyspaces in this keygroup
                for ks_no, ks in enumerate(ks_list):
                    if ks not in self.keyspaces:
                        raise Exception(
                            f"ks:{ks} absent from keyspaces:{self.keyspaces}"
                        )
                    elif ks not in col_types:
                        # Should not happen
                        raise Exception(f"col_types does not contain keyspace:{ks}")
                    # string col_type
                    elif col_types[ks] in SQL_STRING_TYPES:
                        column_as_str = f'"{ks}"'
                    # binary col_type
                    elif col_types[ks] in SQL_BINARY_TYPES:
                        column_as_str = f'"{ks}"'
                    # date
                    elif col_types[ks] in SQL_DATE_TYPES:
                        column_as_str = f"date_to_str(\"{ks}\", '{date_format}')"
                    # timestamp (WITHOUT timezone info)
                    elif col_types[ks] in SQL_DATETIME_TYPES:
                        column_as_str = (
                            f"timestamp_to_str(\"{ks}\", '{datetime_format}')"
                        )
                    # boolean col_type
                    elif col_types[ks] in SQL_BOOL_TYPES:
                        column_as_str = f"CAST(\"{ks}, AS VARCHAR(8)')"
                    # Other col_type (float,int,etc.)
                    else:
                        # column_proxy = "CAST(\"" + ks + ", AS STRING')" # <-- Use of this apprach yields combine VARCHAR(0)
                        column_as_str = f"CAST(\"{ks}, AS VARCHAR(24)')"  # <-- assuming VARCHAR(24) is big enough for most cases

                    sub_expression = (
                        '(CASE WHEN "'
                        + ks
                        + "\" IS NULL THEN '"
                        + null_proxy
                        + "' ELSE "
                        + column_as_str
                        + " END)"
                    )
                    if ks_no < (len(ks_list) - 1):
                        # Augment with trailing join_delimiter (unless processing last keyspace in keygroup)
                        sub_expression = (
                            f"CONCAT( {sub_expression}, '{join_delimiter}' )"
                        )

                    if ks_no == 0:
                        column_expressions[keygroup1] = sub_expression
                    else:
                        column_expressions[keygroup1] = (
                            "CONCAT( "
                            + column_expressions[keygroup1]
                            + ", "
                            + sub_expression
                            + " )"
                        )

        result = self.select(
            column_names=column_names, column_expressions=column_expressions
        )
        return result

    def num_key_instances1d(self, keyspace: str, key) -> int:
        """
        Number of instances of the specified key
        across the specified keyspace/column
        """
        keyspace = self.validate_keyspace(keyspace, solo_required=True, grace=False)
        hyper_key = dict({keyspace: key})
        return self.num_key_instances(hyper_key)

    def num_key_instances(self, hyper_key) -> int:
        """
        Number of instances of the (multi-column) 'hyper_key'
        across the specified keyspaces/columns

        hyper_key: dict/OrderedDict (keyspace->key)
        """
        if self.is_undefined:
            return None

        if hyper_key is None:
            return None
        elif not isinstance(hyper_key, dict):
            raise Exception("Invalid hyper_key...dict expected")

        # Create & edit hyper_key2
        hyper_key2 = {}
        for keyspace, key in hyper_key.items():
            # Validate keyspace
            keyspace2 = self.validate_keyspace(keyspace, grace=False)

            # Modify key for leading/trailing str
            if isinstance(key, str):
                hyper_key2[keyspace2] = f"'{key}'"
            elif isinstance(key, (datetime, date)):
                hyper_key2[keyspace2] = f"'{str(key)}'"
            elif hasattr(key, "dtype") and np.issubdtype(key, np.datetime64):
                hyper_key2[keyspace2] = f"'{str(key)}'"
            else:
                hyper_key2[keyspace2] = key

        sql_template = JINJA_ENV.get_template("num_key_instances.j2")
        sql_command = sql_template.render(
            src_table_name=self.table_name,
            hyper_key=hyper_key2,
        )

        result = execute(sql_command, fetch="all")

        if result is None or len(result) == 0:
            return None
        else:
            return result[0][0]

    def has_key1d(self, keyspace: str, key) -> bool:
        """
        Indicates whether key is present in the specified keyspace/column
        """
        keyspace = self.validate_keyspace(keyspace, solo_required=True, grace=False)
        num_key = self.num_key_instances1d(keyspace, key)
        if num_key is not None and num_key > 0:
            return True
        else:
            return False

    def has_key(self, hyper_key) -> bool:
        """
        Indicates whether a (multi-column) 'hyper_key'
        is present in the specified keyspace/column

        hyper_key: dict/OrderdeDict (keyspace->key)
        """
        num_key = self.num_key_instances(hyper_key)
        if num_key is not None and num_key > 0:
            return True
        else:
            return False

    @property
    def distinct_key_counts(self) -> dict:
        """
        Generates dictionary of distinct key counts
        for each of the keyspaces in a Quble

        Yields a dictionary:
        ==> dictionary keys: keyspaces (str)
        ==> dictionary values: distinct key counts (int) [i.e., number of distinct keys in a given keyspace]

        :param keyspaces: keyspace(s) for distinct key counting
        :type keyspaces: string or list of strings or '<all>'
        """
        if "distinct_key_counts" not in self._cache:
            if self.is_undefined:
                result = {}
            elif self.num_keyspaces == 0:
                result = {}
            else:
                sql_template = JINJA_ENV.get_template("distinct_key_counts.j2")
                sql_command = sql_template.render(
                    src_table_name=self.table_name,
                    # NOTE: keyspaces in template are only requested keyspaces (not all keyspaces)
                    keyspaces=self.keyspaces,
                )
                # Here, we do not yet perform a fetch (but rather access the cursor object)
                # so that we can obtain the query column names as well as the query results below
                result = execute(sql_command, fetch="all")

                if result is None:
                    result = {}
                elif len(result) == 0:
                    # No rows in the query result, throw an Exception
                    raise Exception(f"No query results: len(result):{len(result)}")
                elif len(self.keyspaces) != len(result[0]):
                    # NOTE: query_result[0] yeilds the first/only row of the query results
                    # Does number of query column names match number of self.keyspaces?
                    # If not, throw an Exception
                    raise Exception(
                        f"In distinct_key_counts: len(self.keyspaces):{len(self.keyspaces)} != len(result):{len(result)}"
                    )
                else:
                    # Use the (two-column) query result
                    # to build a dictionary where:
                    #    keys: keyspaces
                    #    values: distinct count
                    # ------------------------------
                    result = dict(zip(self.keyspaces, result[0]))

            # Here, result is a dict to be placed in the Quble._cache for subsquent use
            self._cache["distinct_key_counts"] = result

        # Return the cached dictionary
        return self._cache["distinct_key_counts"]

    def get_distinct_key_counts(self, keyspaces: list = None) -> dict:
        """
        Generates dictionary of distinct key counts for each of the keyspaces in a Quble.

        :param keyspaces: keyspace(s) for distinct key counting
        :type keyspaces: list of strings
        """
        if keyspaces is None:
            keyspaces = self.keyspaces
        elif isinstance(keyspaces, str):
            keyspaces = [keyspaces]
        elif not isinstance(keyspaces, list):
            raise Exception("Keyspaces argument must be a list or str")

        squeeze_candidates = copy.deepcopy(keyspaces)

        if "distinct_key_counts" in self._cache:
            for ks in keyspaces:
                if ks in self._cache["distinct_key_counts"]:
                    squeeze_candidates.remove(ks)
        else:
            self._cache["distinct_key_counts"] = {}

        if len(squeeze_candidates) > 0:
            if self.is_undefined:
                result = {}
            elif self.num_keyspaces == 0:
                result = {}
            else:
                sql_template = JINJA_ENV.get_template("distinct_key_counts.j2")
                sql_command = sql_template.render(
                    src_table_name=self.table_name,
                    keyspaces=squeeze_candidates,
                )
                result = execute(sql_command, fetch="all")

                if result is None:
                    result = {}
                elif len(result) == 0:
                    raise Exception(f"No query results: len(result):{len(result)}")
                elif len(keyspaces) != len(result[0]):
                    raise Exception(
                        f"In distinct_key_counts: len(keyspaces):{len(squeeze_candidates)} != len(result):{len(result)}"
                    )
                else:
                    result = dict(zip(squeeze_candidates, result[0]))

            self._cache["distinct_key_counts"].update(result)
        return self._cache["distinct_key_counts"]

    def distinct_key_count(self, keyspace: str) -> int:
        """
        Returns the distinct key count (int)
        for a specified keyspace
        """
        if self.is_undefined:
            return None

        keyspace = self.validate_keyspace(
            keyspace=keyspace, solo_required=True, grace=False
        )
        distinct_key_counts = self.distinct_key_counts

        if distinct_key_counts is None:
            return None
        elif not isinstance(distinct_key_counts, dict):
            raise Exception(
                "Invalid distinct_key_counts:{0}...dictionary expected".format(
                    distinct_key_counts
                )
            )
        elif keyspace not in distinct_key_counts:
            raise Exception(f"Unsupported keyspace:{keyspace}")
        else:
            return distinct_key_counts[keyspace]

    def distinct_subkey_count(self, keyspace: str) -> int:
        """
        Returns the distinct, coupled (sub) key counts (int)
        across a specified set of keyspace(s) of a Quble

        :params: keyspace: keyspaces(s) for coupled, distinct operation
        :type keyspace: str, or list/tuple of strings or None

        """
        if self.is_undefined:
            return None
        elif keyspace is None:
            return None

        # Validate keyspace arg and coerce to a list
        keyspaces = self.validate_keyspace(
            keyspace=keyspace, coerce_to_list=True, grace=False
        )

        if keyspaces is None or len(keyspaces) == 0:
            return None
        else:
            sql_template = JINJA_ENV.get_template("distinct_subkey_counts.j2")
            sql_command = sql_template.render(
                src_table_name=self.table_name,
                # NOTE: keyspaces in template are only requested keyspaces (not all keyspaces)
                keyspaces=keyspaces,
            )
            result = execute(sql_command, fetch="all")
            if result is None or len(result) == 0:
                return None
            else:
                return result[0][0]

    @property
    def uni_distinct_key_keyspaces(self):
        """
        Provides a list of all keyspaces with only one distinct key
        """
        distinct_key_counts = self.distinct_key_counts

        uni_distinct_key_ks_list = []
        if distinct_key_counts is not None:
            for keyspace in distinct_key_counts:
                if distinct_key_counts[keyspace] == 1:
                    uni_distinct_key_ks_list.append(keyspace)

        return uni_distinct_key_ks_list

    @property
    def multi_distinct_key_keyspaces(self):
        """
        Provides a list of all keyspaces with only multiple distinct keys
        """
        distinct_key_counts = self.distinct_key_counts

        multi_distinct_key_ks_list = []
        if distinct_key_counts is not None:
            for keyspace in distinct_key_counts:
                if distinct_key_counts[keyspace] > 1:
                    multi_distinct_key_ks_list.append(keyspace)

        return multi_distinct_key_ks_list

    def values_fx(self, valuespace="<valuespace>", grace: bool = True):
        """
        Returns the f/x for the valuespace(s) of the associated table

        May return either a scalar or a dict depending on valuespace arg
        """
        valuespace = self.validate_valuespace(valuespace)
        # Here validate_valuespace() may yield scalar or list (depending on valuespace arg)
        return self.get_space_info(info_type="fx", space=valuespace, grace=grace)

    def _column2values_map(self, unfolded: bool = True):
        """
        Builds a map from (folded) columnar value data
        to values (commonly applied to all value columns)
        """
        return None

    @RootLib.lazy_kwargs()
    def normal_pdf(
        self,
        loc=0.0,
        scale=1.0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
    ) -> Quble:
        """
        Computes (element-by-element) normal PDF
        for the specified numeric valuespace(s) of Quble
        See scipy.stats.norm.pdf
        """
        return self._norm_fn_caller(
            norm_fn=norm.pdf, loc=loc, scale=scale, valuespace=valuespace, view=view
        )

    @RootLib.lazy_kwargs()
    def normal_cdf(
        self,
        loc=0.0,
        scale=1.0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
    ) -> Quble:
        """
        Computes (element-by-element) normal CDF
        for the specified numeric valuespace(s) of Quble
        See scipy.stats.norm.cdf
        """
        return self._norm_fn_caller(
            norm_fn=norm.cdf, loc=loc, scale=scale, valuespace=valuespace, view=view
        )

    @RootLib.lazy_kwargs()
    def inv_normal_cdf(
        self,
        loc=0.0,
        scale=1.0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
    ) -> Quble:
        """
        Computes (element-by-element) inverse normal CDF
        of the specified valuespace(s) a Quble
        [Numeric valuespaces required]
        See scipy.stats.norm.ppf
        """
        return self._norm_fn_caller(
            norm_fn=norm.ppf, loc=loc, scale=scale, valuespace=valuespace, view=view
        )

    @RootLib.lazy_kwargs()
    def _norm_fn_caller(
        self,
        norm_fn,
        loc=0.0,
        scale=1.0,
        valuespace="<numeric_valuespaces>",
        view=RootLib.lazy_eval("view"),
    ) -> Quble:
        """
        Computes (element-by-element) normal PDF/CDF/INVCDF
        for the specified numeric valuespace(s) of Quble
        by calling a normal distribution function with following signature:

             norm_fn(np_array, loc, scale)

        where:
               np_array: numpy array of values
               loc: scalar of mean of distribution
               scale: scalar of scale/stddev of distribution

        Examples:

           norm_fn = scipy.stats.norm.pdf
           norm_fn = scipy.stats.norm.cdf
           norm_fn = scipy.stats.norm.ppf
        """
        # Handle trivial cases
        if self.is_undefined:
            return Quble.undefined_instance()

        # Validate valuespace & coerce to list
        valuespace = self.validate_valuespace(
            valuespace, grace=False, coerce_to_list=True, numeric_required=True
        )

        # Restrict Quble to only the valuespace(s) of interest
        # [valuespace arg is validated within sub_variate method]
        # (allow for shallow copy when valuespaces are unchanged)
        # ==> Only refer to subject (not self) hereafter
        # ------------------------------------------------------
        subject = self.sub_variate(valuespace=valuespace, allow_shallow_copy=True)
        if subject.is_nonvariate:
            raise NoValuespaceError("Variate Quble required...No valuespaces present")

        # Apply view to subject
        # ------------------------
        subject = subject.apply_view(view, allow_shallow_copy=True)
        if subject.is_empty:
            return subject.copy() if subject.shares_table_with(self) else subject

        # Make sure only float valuespaces are being used
        # Otherwise, cast ints to floats
        is_int_per_vs = subject.is_int(space=valuespace, grace=True, summarize=None)
        cast_dict = {}
        if isinstance(is_int_per_vs, dict):
            for vs in is_int_per_vs:
                if is_int_per_vs[vs]:
                    cast_dict[vs] = "float"
        elif isinstance(is_int_per_vs, (list, tuple)):
            for vs_no in range(len(is_int_per_vs)):
                if is_int_per_vs[vs_no]:
                    cast_dict[valuespace[vs_no]] = "float"

        # Have we found any int spaces?
        # If so, cast them to float
        if len(cast_dict) > 0:
            subject = subject.select(column_names="<all>", cast_dict=cast_dict)

        # Verify if subject is all floats
        if not subject.is_float(space=valuespace, grace=True, summarize="all"):
            raise Exception("float-valued Quble valuespaces required")
        elif subject.is_empty:
            return subject.copy()

        # Convert Quble to a struct array
        sa = subject.to_struct_array()

        # Access dictionary of missing values keyed by space
        missing_values = subject.missing_values

        # Loop through the applicable valuespaces
        for vs in valuespace:
            orig_values = sa[vs]

            result_values = norm_fn(orig_values, loc=loc, scale=scale)
            result_values[isnull(orig_values, missing_values[vs])] = np.NaN

            # Reassign values of struct array for this valuespace
            sa[vs][:] = result_values

        # Create a new Quble from the modified struct array
        # And promote subject's valuespace as primary
        result = Quble.from_struct_array(struct_array=sa, valuespace=valuespace)
        result.promote_valuespace(subject.valuespace, inplace=True)

        return result

    @RootLib.lazy_kwargs()
    def estimate_ols(
        self,
        yxkeys,
        sample_keyspace: str,
        offset_key: str = None,
        pct_required: float = 0.0,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        ols_method: str = None,
        view=RootLib.lazy_eval("view"),
        fitted_flag: bool = True,
        residual_flag: bool = True,
        detail_keyspace: str = "OLS_DETAIL",
        summary_keyspace: str = "OLS_SUMMARY",
    ) -> tuple:
        """
        Estimates an OLS regression model against sample data Quble (self) provided
        Outputs a tuple of Qubles (ols_details,ols_summary,ols_fitted,ols_resid)
        providing the results of the OLS regression

        Here, sample data (self) MUST contain the sample keyspace
        (ala sample_keyspace) and variable keyspace (ala key & xkeys).
        Any additional keyspaces found in self are considered 'orthogonal' keyspaces

        :param yxkeys: None OR list/tuple/np.array
                OR single-entry dictionary (keys & associated keyspace)
                OR a 1-D index Quble identifying:

            None: Uses all valuespaces of self as regression variables

            list/tuple/np.array: Uses the specified valuespaces of self as regression variables
                [May also include non-trivial offset_key which does not need to be a valuespace]

            (single-key) dictionary: This case only uses primary valuespace!!!
            (single) dict key: variable keyspace/column of self
            dict values: list/tuple/numpy array of variable keys (strings)
            ==> first key: the key for the dependent (y) variable
            ==> latter keys: keys for independent (x) observations
            ==> NOTE: the latter key may contain the non-trivial offset_key 1-D index Quble: attempts to converts Quble to a single-key dict and then treated as above

            .. note::
                Sample data (self) argument should contain the keyspace provided within the yxkeys arg
                (Except for last key when offset_key is not None)
        :type yxkeys: None, list, single-key dictionary or 1-D index Quble

        :param sample_keyspace: The 'sample keyspace' within sample Quble (self)
                                 across which linear regression is to be performed
            The 'sample keyspace' WILL NOT be present in resultant ols_coeffs output Quble

            .. note::
                If list/tuple of keyspaces, 'panel' regression is performed
                by folding these dimensions into a single sample dimension
        :type sample_keyspace: {q_keyspace_type} or list of {q_keyspace_type}

        :param offset_key: variable key for the "offset" (constant) term
                            will be included in the linear regression.
            .. note::
                * If False: yxkeys (hyper index) must all be present in self
                * If True: The last key in the yxkeys (hyper index) arg will be used to hold the offset coefficient
                    Here, to avoid confusion, this last key should NOT be present in sample data (self)
        :type offset_key: str

        ols_method = The OLS method to use. Limited to one of:
            1. Moore-Penrose pseudoinverse (pinv)
            2. QR factorization (qr)
            3. Singular Value Decomposition (svd)
            4. Maximum Likelihood (mle)

            .. note::
                If omitted, the default method for OLS.fit() will be used.

        :param view: Quble indicating conditional elements for which aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :param fitted_flag: flag to generate (suppress) fitted values
        :type fitted_flag: bool (True*/False)

        :param residual_flag: flag to generate (suppress) residual values
        :type residual_flag: bool (True*/False)

        :returns: A tuple containing:
        1. OLS detail Quble (e.g., coefficients, tstats, correlations, std errs, ...)
            keyspaces: ortho_keyspaces + var_keyspace (w/xkeys_all) + detail_keys=dict('OLS_DETAIL: COEFFS, TSTATS, IC, STD_ERRS')
        2. OLS summary Quble (e.g., rsquared, F, n, ...)
            keyspaces: ortho_keyspaces + summary_keys=dict('OLS_SUMMARY: RSQ, RSQ_ADJ, F, F_p, NUM_OBS')
        3. OLS fitted Quble (if fitted_flag==True)
            keyspaces: ortho_keyspaces + sample_keyspace
        4. OLS residuals Quble (if residual_flag==True)
            keyspaces: ortho_keyspaces + sample_keyspace

        .. note::
            In all cases, ortho_keyspaces = self.keyspaces EXCLUDING var_keyspace & sample_keyspace.
        :rtype: tuple of qubles.core.quble.Quble

        Example Syntax
        The following code implements model: Fwd_Return ~ (b1*Factor1 + b2*Factor2 + b3*Factor3 + ConstantTerm)::

            sample_data = Quble(...)
            yxkeys = dict{'Fields':['Fwd_Return','Factor1','Factor2','Factor3','ConstantTerm'])
            (ols_details, ols_summary, ols_fitted, ols_resid) = sample_data.estimate_ols(yxkeys, sample_keyspace='Dates', offset_key='ConstantTerm')

        .. note::
            In this example that sample_data (Quble) should have (at a minimum)
            the following keyspaces: 'Fields' (var_keyspace) & 'Dates' (sample_keyspace).
            Any other keyspaces found in sample data (self) are considered 'orthogonal' keyspaces

        """
        # Call Quble.mestimate_ols() method with periods=None
        # [This call will be treated as as non-rolling estimation]
        return self.mestimate_ols(
            periods=None,
            yxkeys=yxkeys,
            sample_keyspace=sample_keyspace,
            offset_key=offset_key,
            sample_shift=None,
            pct_required=pct_required,
            ignore_missing=ignore_missing,
            ols_method=ols_method,
            view=view,
            fitted_flag=fitted_flag,
            residual_flag=residual_flag,
            detail_keyspace=detail_keyspace,
            summary_keyspace=summary_keyspace,
        )

    @RootLib.lazy_kwargs()
    def mestimate_ols(
        self,
        periods: int,
        yxkeys,
        sample_keyspace: str = "<first_time_keyspace>",
        offset_key: str = None,
        sample_shift: int = None,
        pct_required: float = 0.0,
        ignore_missing: bool = RootLib.lazy_eval("ignore_fn"),
        ols_method: str = None,
        view=RootLib.lazy_eval("view"),
        fitted_flag: bool = True,
        residual_flag: bool = True,
        detail_keyspace: str = "OLS_DETAIL",
        summary_keyspace: str = "OLS_SUMMARY",
    ) -> tuple:
        """
        Moving/rolling estimation of an OLS regression model against sample data Quble (self) provided
        NOTE: Unless yxkeys is a list or None, performs regression on primary valuespace only!

        Outputs a tuple of Qubles (ols_details,ols_summary,ols_fitted,ols_resid)
        providing the results of the rolling OLS regression

        Here, sample data (self) MUST contain the sample keyspace
        (ala sample_keyspace) and variable keyspace (ala key & xkeys).
        Any additional keyspaces found in self are considered 'orthogonal' keyspaces

        :param periods: Trailing window specified in # periods at underlying frequency
        :type periods: int (>0) or None
            ==> IMPORTANT!!...periods=None returns NON-ROLLING estimation result

        :param yxkeys: None OR list/tuple/np.array
                OR single-entry dictionary (keys & associated keyspace)
                OR a 1-D index Quble identifying:

            None: Uses all valuespaces of self as regression variables

            list/tuple/np.array: Uses the specified valuespaces of self as regression variables
                [May also include non-trivial offset_key which does not need to be a valuespace]

            (single-key) dictionary: This case only uses primary valuespace!!!
            (single) dict key: variable keyspace/column of self
            dict values: list/tuple/numpy array of variable keys (strings)
            ==> first key: the key for the dependent (y) variable
            ==> latter keys: keys for independent (x) observations
            ==> NOTE: the latter key may contain the non-trivial offset_key
            1-D index Quble: attempts to converts Quble to a single-key dict and then treated as above

            .. note::
                Sample data (self) argument should contain the keyspace provided within the yxkeys arg
                (Except for last key when offset_key is not None)
        :type yxkeys: None, list, single-key dictionary or 1-D index Quble

        :param sample_keyspace: The 'sample keyspace' within sample Quble (self)
                                 across which linear regression is to be performed
            The 'sample keyspace' WILL NOT be present in resultant ols_coeffs output Quble

            .. note::
                If list/tuple of keyspaces, 'panel' regression is performed
                by folding these dimensions into a single sample dimension
        :type sample_keyspace: str or list of strings

        :param offset_key: variable key for the "offset" (constant) term
                            will be included in the linear regression.
            .. note::
                * If not-None: should be present in values of the yxkeys dictionary
                    Here, to avoid confusion, this offset_key should NOT be present in sample data (self)
        :type offset_key: str

        :param sample_shift: Sampling delay
        :type sample_shift: int (>=0) or None (no sampling delay)

        ols_method = The OLS method to use.
            Limited to one of:
            1. Moore-Penrose pseudoinverse (pinv)
            2. QR factorization (qr)
            3. Singular Value Decomposition (svd)
            4. Maximum Likelihood (mle)

            .. note::
                If omitted, the default method for OLS.fit() will be used.

        :param view: Quble indicating conditional elements for which aggregation will be applied (i.e., participating elements)
        :type view: Quble(dtype=bool or float)

        :param fitted_flag: flag to generate (suppress) fitted values
        :type fitted_flag: bool (True*/False)

        :param residual_flag: flag to generate (suppress) residual values
        :type residual_flag: bool (True*/False)

        :returns: A tuple containing:
        1. OLS detail Quble (e.g., coefficients, tstats, correlations, std errs, ...)
            keyspaces: ortho_keyspaces + var_keyspace (w/xkeys_all) + detail_keys=dict('OLS_DETAIL: COEFFS, TSTATS, IC, STD_ERRS')
        2. OLS summary Quble (e.g., rsquared, F, n, ...)
            keyspaces: ortho_keyspaces + summary_keys=dict('OLS_SUMMARY: RSQ, RSQ_ADJ, F, F_p, NUM_OBS')
        3. OLS fitted Quble (if fitted_flag==True)
            keyspaces: ortho_keyspaces + sample_keyspace
        4. OLS residuals Quble (if residual_flag==True)
            keyspaces: ortho_keyspaces + sample_keyspace

            .. note::
                In all cases, ortho_keyspaces = self.keyspaces EXCLUDING var_keyspace & sample_keyspace.
        :rtype: tuple of qubles.core.quble.Quble

        Example Syntax
        The following code implements model: Fwd_Return ~ (b1*Factor1 + b2*Factor2 + b3*Factor3 + ConstantTerm)::

            sample_data = Quble(...)
            yxkeys = dict{'Fields':['Fwd_Return','Factor1','Factor2','Factor3','ConstantTerm'])
            (ols_details, ols_summary, ols_fitted, ols_resid) = sample_data.estimate_ols(yxkeys, sample_keyspace='Dates', offset_key='ConstantTerm')

        .. note::
            In this example that sample_data (Quble) should have (at a minimum)
            the following keyspaces: 'Fields' (var_keyspace) & 'Dates' (sample_keyspace).
            Any other keyspaces found in sample data (self) are considered 'orthogonal' keyspaces

        """
        # Initialization
        ols_details = Quble.undefined_instance()
        ols_summary = Quble.undefined_instance()
        fitted_values = Quble.undefined_instance()
        resid_values = Quble.undefined_instance()

        # Validate self
        # ---------------
        if self.is_undefined:
            return (ols_details, ols_summary, fitted_values, resid_values)
        elif self.is_empty:
            return (ols_details, ols_summary, fitted_values, resid_values)
        elif self.is_nonvariate:
            raise Exception("variate Quble required")

        # NOTE: Moved "is_numeric" test further down in this method
        # so that we ONLY VALIDATE PARTICIPATING (not all) valuespaces
        # elif not self.is_numeric(space="<valuespaces>", grace=False, summarize="all"):
        #     raise Exception("All valuespaces must be numeric")

        # Validate periods
        if periods is None:
            pass  # <-- Non-moving regression
        elif periods <= 0:
            raise Exception("periods must be positive")

        if (sample_shift is not None) and (sample_shift < 0):
            _logger.warning("sample_shift < 0")

        # Ensure frequencies have been inferred to avoid iteration issues
        self._infer_all_freqs(
            freq_hint="default_freq", assign_inferred=True, force_reinfer=False
        )

        # Otherwise, validate sample_keyspace and convert to sample_ks_list (list/tuple)
        # --------------------------------------------
        sample_ks_list = self.validate_keyspace(
            sample_keyspace,
            coerce_to_list=True,
            grace=False,
            allow_keygroup=True,
            expand_keygroups=True,
        )
        if len(sample_ks_list) == 0:
            return (ols_details, ols_summary, fitted_values, resid_values)

        # Identify rolling_keyspace (if applicable)
        # [Only relevant when periods is not None]
        # ---------------------------------------------
        if periods is None:
            rolling_keyspace = None
        elif periods <= 0:
            raise Exception("Invalid periods:{0}...positive integer (or None) required")
        else:
            rolling_keyspace = self.first_time_keyspace(grace=False)

        # -----------------------------------------------------------
        # Validate yxkeys arg and build following items:
        #
        #    var_keyspace: if None, variables are valuespaces,
        #                  if not None: identifies the variable keyspace
        #    yxkeys_all_list: [ykey] + [xkeys (inclusing possible offset)]
        #
        #          ==> if var_keyspace is None, yxkeys_all_list elements
        #              should corespond to specific valuespaces of self
        #
        #          ==> if var_keyspace is not None, yxkeys_all_list elements
        #              should corespond to keys in var_keyspace
        #
        #    xkeys_all_list: [xkeys (inclusing possible offset)]
        #    ykey: the key for the independent variable
        # -----------------------------------------------------------
        # Acceptable yxkeys input arg entries:
        #
        #   1) None: Treats all valuespaces of self as variables
        #   2) (non-empty) list/ndarray of strings: Identifies specified valuespaces as variables
        #      [entries must be valid valuespaces (except for offset_key entry)]
        #   3) single key dict: for a valid keyspace (dict key),
        #      identifies specific keys within the var_keyspace as variables
        # -----------------------------------------------------------
        if yxkeys is None:
            # Treats valuespaces of self as variable
            # At least one valuespace required (already verified above)
            # Assumes first valuespace corresponds to dependent variable and subsequent valuespaces correpond to independent variables
            var_keyspace = None
            # Forcing a deep copy of valuespaces
            yxkeys_all_list = [vs for vs in self.valuespaces]
        elif isinstance(yxkeys, (list, tuple, np.ndarray)):
            # Here, we are given a list/tuple/np.array of strings
            # [ideally each string element should be unique (no dupes)]
            # Assumes each (string) element corresponds to a valuespace
            # ==> First (string) element represents desired dependent variable
            # ==> Subsequent (string) elements represents desired independent variables
            if len(yxkeys) == 0:
                raise Exception("yxkeys list must not be empty")
            # Make sure each list entry correponds to a valid valuespace (except for offset_key)
            # Also, convention is that first element identifies the independent variable
            for vs in yxkeys:
                if offset_key is not None and vs == offset_key:
                    # Offset key does not need to be present in self.valuspaces
                    pass
                elif vs not in self.valuespaces:
                    raise Exception(
                        f"yxkeys list element:{vs} absent from valuespaces:{self.valuespaces}"
                    )

            var_keyspace = None
            yxkeys_all_list = list(yxkeys)
        elif isinstance(yxkeys, str):
            raise Exception("Invalid yxkeys arg: single-entry dictionary expected")
        elif not isinstance(yxkeys, (dict, Quble)):
            raise Exception(
                "Invalid yxkeys arg: single-entry dictionary or Quble expected"
            )
        else:
            if isinstance(yxkeys, Quble):
                # Try to convert yxkeys Quble to a single-entry dictionary
                if yxkeys.is_empty:
                    return (ols_details, ols_summary, fitted_values, resid_values)
                elif yxkeys.ndim != 1:
                    raise Exception(
                        "Invalid yxkeys arg: single-entry dictionary expected"
                    )
                elif not yxkeys.is_index:
                    raise Exception(
                        "Invalid yxkeys arg: single-entry dictionary expected"
                    )
                else:
                    # Eventually, we may accept 1-D index (non-valued) Quble here
                    # raise Exception('Invalid yxkeys arg: single-entry dictionary expected')
                    yxkeys = {
                        yxkeys.pole_keyspace: yxkeys.index_array1d(
                            keyspace=yxkeys.pole_keyspace
                        )
                    }

            # Verify that yxkeys is now single-key dictionary
            if len(yxkeys) != 1:
                raise Exception("Invalid yxkeys arg: single-entry dictionary expected")

            # Get var_keyspace & orthogonal keys and the associated iterator
            # (excludes sample_ks_list & var_keyspace)
            # -----------------------------------------
            var_keyspace = list(yxkeys.keys())[0]
            if var_keyspace in sample_ks_list:
                raise Exception(
                    "var_keyspace:{0} must not appear in sample_ks_list:{1}".format(
                        var_keyspace, sample_ks_list
                    )
                )

            # -------------------------------------------------------------------------------
            # We assume/require first variable provided is dependent variable (dep_variable)
            # Establish following working variables:
            #    yxkeys_all_list: LIST OF ALL relevant dependent (y) AND independent (x) variables
            #    xkeys_all_list: LIST OF ALL independent (x) variables
            #    yxkeys_xoffset_list: LIST OF ALL relevant dependent (y) AND independent (x) variables EXCLUDING the offset_key
            #    xkeys_xoffset_list: LIST OF ALL independent variables (x) EXCLUDING the offset_key
            #    ykey: dependent variable name (string)
            # -------------------------------------------------------------------------------
            if not isinstance(yxkeys[var_keyspace], (list, tuple, np.ndarray)):
                # Here, the dict value should be a list,tuple or np.ndarray
                raise Exception(
                    f"Invalid type(yxkeys[{var_keyspace}]): {type(yxkeys[var_keyspace])}...list,tuple or np.ndarray expected"
                )

            # Elemental value for the first (and only) key of the yxkeys dictionary
            # Here, yxkeys[var_keyspace] should yield a list/tuple/np.array of strings
            # [ideally each string element should be unique (no dupes)]
            # ==> First (string) element represents desired dependent variable
            # ==> Subsequent (string) elements represents desired independent variables
            yxkeys_all_list = list(yxkeys[var_keyspace])

        # Validate resultant yxkeys_all_list
        if not isinstance(yxkeys_all_list, (list, tuple, np.ndarray)):
            raise Exception(
                f"yxkeys[{list(yxkeys.keys())[0]}] must be a list/tuple/numpy array"
            )
        elif len(yxkeys_all_list) < 2:
            raise Exception(
                f"yxkeys[{var_keyspace}]:{yxkeys_all_list} must contain atleast two elements...dep key (y) & indep key(s) (x and/or offset_key)"
            )
        elif offset_key is None:
            # Assume the first key in yxkeys_all_list is the dependent variable
            yxkeys_xoffset_list = yxkeys_all_list
            xkeys_xoffset_list = yxkeys_all_list[1:]
            # xkeys_xoffset_list can be empty if only offset exists
            if len(xkeys_xoffset_list) == 0:
                raise Exception(
                    "xkeys_xoffset_list can only be empty if offset_key is provided"
                )
        elif offset_key == yxkeys_all_list[0]:
            # The non-trivial offset cannot be used as independent (first) variable
            raise Exception(
                f"Invalid yxkeys_all_list:{yxkeys_all_list} w/offset_key:{offset_key}...first slot reserved for dependent variable"
            )
        elif offset_key not in yxkeys_all_list:
            raise Exception(
                f"offset_key:{offset_key} absent from variable list:{yxkeys_all_list}"
            )
        else:
            # Assume the first key in yxkeys_all_list is the dependent variable
            yxkeys_xoffset_list = []
            xkeys_xoffset_list = []
            for key_no, key1 in enumerate(yxkeys_all_list):
                if key1 == offset_key:
                    if key_no == 0:
                        raise Exception(
                            f"Invalid yxkeys_all_list:{yxkeys_all_list} w/offset_key:{offset_key}...first slot reserved for dependent variable"
                        )
                    continue
                yxkeys_xoffset_list.append(key1)
                if key_no != 0:
                    # Not the dependent variable
                    xkeys_xoffset_list.append(key1)

        # =================================================
        # CASE #1: var_keyspace is None
        # -------------------------------------------------
        # Here, valuespaces represent regression variables
        # =================================================
        xkeys_all_list = yxkeys_all_list[1:]
        ykey = yxkeys_all_list[0]

        if var_keyspace is None:
            if not self.is_numeric(
                space=yxkeys_xoffset_list, grace=False, summarize="all"
            ):
                raise Exception("All participating valuespaces must be numeric")
            regr_data = self

        # ===================================================
        # CASE #2: var_keyspace absent from self.keyspaces
        # ===================================================
        elif var_keyspace not in self.keyspaces:
            raise Exception(
                f"var_keyspace:{var_keyspace} absent from self.keyspaces:{self.keyspaces}"
            )

        # =================================================
        # CASE #3: var_keyspace in self.keyspaces...
        # -------------------------------------------------
        # Here, a variable keyspace column
        # has been designated within source data (self)
        # And only the primary valuespace will be used
        #
        # In this case, we PIVOT on the var_keyspace
        # (against the original primary valuespace)
        # to create a multi-variate Quble where
        # valuespaces correspond to regression vars (yxkeys_all_list)
        # =================================================
        else:
            if not self.is_numeric(space=self.valuespace, grace=False):
                raise Exception("All participating valuespaces must be numeric")

            regr_data = self.pivot(pivot_keyspace=var_keyspace, key_ordering=None)

            # TODO: Remove those records for any key in available_var_keys that are not in yxkeys_xoffset_list
            # (i.e., these are superfluous keys not relevant to regression problem at hand)

        # -------------------------------------------
        # Isolate ONLY the valuespace columns
        # relevant to the required model variables
        # -------------------------------------------
        if regr_data.is_undefined:
            return (ols_details, ols_summary, fitted_values, resid_values)
        elif regr_data.is_empty:
            return (ols_details, ols_summary, fitted_values, resid_values)
        elif regr_data.is_nonvariate:
            # This may happen if the pivot above cannot be properly performed
            return (ols_details, ols_summary, fitted_values, resid_values)
        elif offset_key is not None and offset_key in regr_data.valuespaces:
            # Non-trivial offset_key should not pre-exist in the regression data
            raise Exception(
                f"Non-trivial offset_key:{offset_key} already present in regr_data.valuespaces:{regr_data.valuespaces}"
            )
        elif set(regr_data.valuespaces) == set(yxkeys_xoffset_list):
            pass
        elif set(yxkeys_xoffset_list).issubset(set(regr_data.valuespaces)):
            regr_data = regr_data.sub_variate(yxkeys_xoffset_list)
        else:
            raise Exception(
                f"Not all required variables:{yxkeys_xoffset_list} present in regr_data.valuespaces:{regr_data.valuespaces}"
            )

        # ----------------------------------------
        # Apply view (when applicable) then compress regr_data
        # Only keep records where ALL valuespaces are NOT NULL (summarize='all')
        # ----------------------------------------
        regr_data = regr_data.apply_view(view=view, allow_shallow_copy=True)
        regr_data = regr_data.compress(summarize="all")
        if regr_data.is_empty:
            return (ols_details, ols_summary, fitted_values, resid_values)

        # Loop through the orthogonal keys of regr_data Quble
        # and perform OLS regression for each set of orthogonal keys
        # -----------------------------------------------------------
        ortho_keyspaces = regr_data.ortho_keyspaces(sample_ks_list)
        # For rolling regression, add rolling_keyspace to ortho_keyspaces
        # NOTE: In this case, rolling_keyspace will be in ortho_keyspaces as well as sampling_ks_list
        if rolling_keyspace is not None and periods is not None:
            if rolling_keyspace in ortho_keyspaces:
                raise Exception(
                    f"Internal inconsistency...rolling_keyspace:{rolling_keyspace} present in ortho_keyspaces:{ortho_keyspaces}"
                )
            ortho_keyspaces = ortho_keyspaces + [rolling_keyspace]

        # ------------------------------------------------
        # NOTE: After pivoting, each row of regr_data represents a sample for regressing
        # Also, there should be no null data, as these rows would have been removed by compress above
        # ------------------------------------------------

        # xkeys_all_list includes offset (if present), but excludes ykey
        num_coeffs = len(xkeys_all_list)

        # -----------------------------
        # Create empty placeholders...
        # -----------------------------
        local_missing_details = np.repeat(np.nan, num_coeffs)

        # Initialize coefficient values (np.array) to missing values
        local_coeffs_vals = local_missing_details.copy()

        # Initialize tstat values (np.array) to missing values
        local_tstats_vals = local_missing_details.copy()

        # Initialize information coeffcient (signed correlation) values (np.array) to missing values
        local_ics_vals = local_missing_details.copy()

        # Initialize std err values (np.array) to missing values
        local_bse_vals = local_missing_details.copy()

        # ------------------------
        # Create ortho iterator
        # ------------------------
        if ortho_keyspaces is None or len(ortho_keyspaces) == 0:
            dummy_ortho = True
            ortho_index_iterator = ["dummy"]
        else:
            dummy_ortho = False
            ortho_index_iterator = DistinctOrthoIndexIterator(
                regr_data,
                ortho_keyspaces,
                contiguous_flag=False,
                key_ordering="asc",
                dummy_instance=None,
            )
        # ----------------------------------------
        # Loop through the orthogonal keys...
        # ----------------------------------------
        current_date = None  # <-- Initalization...only applies to rolling_keyspace case
        # ================== START: ortho_index_iterator LOOP ===================
        for ortho_ctr, ortho_index1 in enumerate(ortho_index_iterator):
            if dummy_ortho:
                local_yx = regr_data
            elif rolling_keyspace is not None and periods is not None:
                # Although auto_squeeze=True, rolling_keyspace will REMAIN in resultant local_yx
                # [Since the application of auto_squeeze in get_window1d() only applies to non window/extra keyspaces in ortho_index1]
                if rolling_keyspace not in ortho_index1.keyspaces:
                    raise Exception(
                        f"Internal inconsistency...rolling_keyspace:{rolling_keyspace} absent from ortho_index1.keyspaces:{ortho_index1.keyspaces}"
                    )

                if fitted_flag or residual_flag:
                    current_date_as_nparr = ortho_index1.distinct_index_array1d(
                        rolling_keyspace
                    )
                    if len(current_date_as_nparr) != 1:
                        raise Exception(
                            f"Internal inconsistency...non-unit-length current_date_as_nparr:{current_date_as_nparr}"
                        )
                    elif not np.issubdtype(current_date_as_nparr.dtype, np.datetime64):
                        raise Exception(
                            f"Not np.datetime64...current_date_as_nparr:{current_date_as_nparr}"
                        )
                    elif not np.issubdtype(current_date_as_nparr.dtype, np.datetime64):
                        raise Exception(
                            f"Not np.datetime64...current_date_as_nparr.dtype:{current_date_as_nparr.dtype}"
                        )
                    current_date = current_date_as_nparr[0]
                else:
                    current_date = None  # <-- Not needed in this case

                local_yx = regr_data.get_window1d(
                    periods=periods,
                    key=ortho_index1,
                    space=rolling_keyspace,
                    sample_shift=sample_shift,
                    auto_squeeze=True,
                )
            else:
                local_yx = regr_data.get(ortho_index1, auto_squeeze=True)

            # Proceed to next ortho_index1 if no records exist
            if local_yx.is_undefined or local_yx.is_empty:
                continue

            # -------------------------------------------------
            # Qualify regr_data
            # -------------------------------------------------
            # Empty regr_data suggests no non-null keys exist in var_keyspace column of original Quble...no regression applies
            # -------------------------------------------------
            # Does ykey occur in (pivoted) regression data?
            # If not, ykey will be absent from spaces of local_yx
            # In this case, regression not possible...continue to next ortho_key
            if not set(yxkeys_xoffset_list).issubset(set(local_yx.valuespaces)):
                raise Exception(
                    f"Some yxkeys_xoffset_list:{yxkeys_xoffset_list} ABSENT from local_yx.valuespaces:{local_yx.valuespaces}"
                )

            # Use first element (arbitrary) of
            # local_yx to build dep_vars & indep_vars
            # -----------------------------------------
            if fitted_flag or residual_flag:
                columns_to_extract = local_yx.spaces
            else:
                columns_to_extract = local_yx.valuespaces

            # Only extract the needed columns (to improve performance)
            local_yx_sa = local_yx.to_struct_array(
                column_names=columns_to_extract, key_ordering=None
            )
            dep_vars = local_yx_sa[ykey]

            # When applicable,isolate the samples for the current date
            # [only applies to rolling regression cases]
            if (
                fitted_flag or residual_flag
            ) and rolling_keyspace in local_yx_sa.dtype.names:
                if current_date is None:
                    raise Exception(
                        f"Internal inconsistency...current_date is None yet rolling_keyspace:{rolling_keyspace} in local_yx_sa.dtype.names:{local_yx_sa.dtype.names}"
                    )
                current_date_samples_filter = (
                    local_yx_sa[rolling_keyspace] == current_date
                )
            else:
                current_date_samples_filter = None

            local_num_samples = len(dep_vars)

            # Ensure sufficient number of samples exist to perform regression
            if local_num_samples < num_coeffs:
                continue

            local_fitted_values = np.repeat(np.nan, local_num_samples)
            local_resid_values = np.repeat(np.nan, local_num_samples)

            indep_arr_arr = [local_yx_sa[xkey1] for xkey1 in xkeys_xoffset_list]

            if len(indep_arr_arr) > 0:
                # np.transpose command below does NOT equate to: np.hstack(indep_arr_arr)
                indep_vars = np.transpose(np.vstack(indep_arr_arr))
                if offset_key is not None:
                    indep_vars = models.add_constant(
                        indep_vars, prepend=False, has_constant="add"
                    )
            elif offset_key is None:
                raise Exception(
                    "xkeys_xoffset_list can only be empty if offset_key is not None"
                )
            else:
                indep_vars = np.ones(local_num_samples, dtype=float)

            dep_std = np.std(dep_vars, axis=0)
            ols_model = models.OLS(dep_vars, indep_vars)

            # Execute OLS regression...
            if ols_method is not None:
                ols_results = ols_model.fit(method=ols_method)
            else:
                ols_results = ols_model.fit()  # <-- will invoke the default ols_method

            local_coeffs_vals[:] = ols_results.params[0:num_coeffs]
            local_tstats_vals[:] = ols_results.tvalues[0:num_coeffs]

            if np.isfinite(ols_results.rsquared):
                for x_no in range(num_coeffs):
                    if indep_vars.ndim == 1:
                        # Ostensibly offset only and no indep vars here
                        local_ics_vals[x_no] = (
                            local_coeffs_vals[x_no] * np.std(indep_vars, axis=0)
                        ) / dep_std
                    else:
                        local_ics_vals[x_no] = (
                            local_coeffs_vals[x_no]
                            * np.std(indep_vars[:, x_no], axis=0)
                        ) / dep_std  # <-- Does not work well for multi-variate case

            local_bse_vals[:] = ols_results.bse[0:num_coeffs]

            local_fitted_values[:] = ols_results.fittedvalues
            local_resid_values[:] = ols_results.resid

            # ------------------------------------------------------------
            # Process OLS_DETAIL:
            #    a) INCLUDES var_keyspace
            #    b) EXCLUDES sample_ks_list
            #    c) ADDITIONAL detail_keyspace (e.g., 'OLS_DETAIL')
            #    d) INCLUDES ortho_keyspaces (if present)
            # ------------------------------------------------------------
            if var_keyspace is None:
                detail_array_dict = {}
                detail_array_dict[detail_keyspace] = np.array(
                    ["COEFFS", "TSTATS", "IC", "STD_ERRS"], np.unicode_
                )
                for xkey_no, xkey1 in enumerate(xkeys_all_list):
                    detail_array_dict[xkey1] = np.array(
                        [
                            local_coeffs_vals[xkey_no],
                            local_tstats_vals[xkey_no],
                            local_ics_vals[xkey_no],
                            local_bse_vals[xkey_no],
                        ]
                    )
                # Multi-variate Quble per valuespace
                local_details = Quble(data=detail_array_dict, valuespace=xkeys_all_list)
            else:
                detail_array_dict = {}
                detail_array_dict[var_keyspace] = np.array(
                    xkeys_all_list * 4, np.unicode_
                )
                detail_array_dict[detail_keyspace] = np.array(
                    ["COEFFS"] * num_coeffs
                    + ["TSTATS"] * num_coeffs
                    + ["IC"] * num_coeffs
                    + ["STD_ERRS"] * num_coeffs,
                    np.unicode_,
                )
                detail_array_dict[DEFAULT_VALUESPACE] = np.vstack(
                    (
                        local_coeffs_vals,
                        local_tstats_vals,
                        local_ics_vals,
                        local_bse_vals,
                    )
                ).flatten()
                local_details = Quble(
                    data=detail_array_dict, valuespace=DEFAULT_VALUESPACE
                )

            # Join ortho_index1
            if not dummy_ortho:
                # Put ortho_index1 on left in join so that ortho_keyspaces will appear first
                local_details = ortho_index1.join(
                    local_details,
                    keys_join_op="leftmost",
                    keyspaces_join_op="union",
                    valuespaces_join_op="right",
                )
            if ols_details is None or ols_details.is_empty:
                ols_details = local_details
            else:
                ols_details.merge_inplace(
                    local_details, self_precedence=True, variate_mode="multi"
                )

            # ------------------------------------------------------------
            # Process OLS_SUMMARY:
            #    a) EXCLUDES sample_ks_list & var_keyspace
            #    b) ADDITIONAL summary_keyspace (e.g., 'OLS_SUMMARY')
            #    c) INCLUDES ortho_keyspaces (if present)
            # ------------------------------------------------------------
            summary_array_dict = {}
            summary_array_dict[summary_keyspace] = np.array(
                ["RSQ", "RSQ_ADJ", "F", "F_p", "NUM_OBS"], np.unicode_
            )
            with np.errstate(all="ignore"):
                # Rather than raise a warning for cases like division by zero, we allow division to return +inf/-inf,
                # and then clean that up to np.nan below. This also handles overflow/underflow reasonably.
                summary_array1 = np.array(
                    [
                        ols_results.rsquared,
                        ols_results.rsquared_adj,
                        ols_results.fvalue,
                        ols_results.f_pvalue,
                        ols_results.nobs,
                    ],
                    dtype=float,
                )
            summary_array1[np.isinf(summary_array1)] = np.nan
            summary_array_dict[DEFAULT_VALUESPACE] = summary_array1

            local_summary = Quble(
                data=summary_array_dict, valuespace=DEFAULT_VALUESPACE
            )
            # Join ortho_index1
            if not dummy_ortho:
                # Put ortho_index1 on left in join so that ortho_keyspaces will appear first
                local_summary = ortho_index1.join(
                    local_summary,
                    keys_join_op="leftmost",
                    keyspaces_join_op="union",
                    valuespaces_join_op="right",
                )
            if ols_summary is None or ols_summary.is_empty:
                ols_summary = local_summary
            else:
                ols_summary.merge_inplace(
                    local_summary, self_precedence=True, variate_mode="multi"
                )

            # -------------------------------------------------
            # Process FITTED_VALUES:
            #    a) INCLUDES sample_ks_list
            #       (except for rolling_keyspace when present)
            #    b) EXCLUDES var_keyspace
            #    c) INCLUDES ortho_keyspaces (if present)
            # ------------------------------------------------
            # Process RESID_VALUES:
            #    a) INCLUDES sample_ks_list
            #       (except for rolling_keyspace when present)
            #    b) EXCLUDES var_keyspace
            #    c) INCLUDES ortho_keyspaces (if present)
            # -------------------------------------------------
            if fitted_flag or residual_flag:
                local_array_dict = {}
                if current_date_samples_filter is not None:
                    for sample_ks in sample_ks_list:
                        local_array_dict[sample_ks] = local_yx_sa[sample_ks][
                            current_date_samples_filter
                        ]

                    if fitted_flag:
                        local_array_dict[ykey] = local_fitted_values[
                            current_date_samples_filter
                        ]
                        local_fitted = Quble(data=local_array_dict, valuespace=ykey)

                    if residual_flag:
                        local_array_dict[ykey] = (
                            local_yx_sa[ykey][current_date_samples_filter]
                            - local_fitted_values[current_date_samples_filter]
                        )
                        local_resid = Quble(data=local_array_dict, valuespace=ykey)

                else:
                    for sample_ks in sample_ks_list:
                        local_array_dict[sample_ks] = local_yx_sa[sample_ks]

                    if fitted_flag:
                        local_array_dict[ykey] = local_fitted_values
                        local_fitted = Quble.from_array_dict(
                            local_array_dict, valuespace=ykey
                        )

                    if residual_flag:
                        local_array_dict[ykey] = local_yx_sa[ykey] - local_fitted_values
                        local_resid = Quble.from_array_dict(
                            local_array_dict, valuespace=ykey
                        )

                # Update fitted_values Quble (if applicable)
                if (
                    fitted_flag
                    and local_fitted is not None
                    and not local_fitted.is_undefined
                    and not local_fitted.is_empty
                ):
                    if not dummy_ortho:
                        # Join ortho_index1: Put ortho_index1 on left in join so that ortho_keyspaces will appear first
                        local_fitted = ortho_index1.join(
                            local_fitted,
                            keys_join_op="leftmost",
                            keyspaces_join_op="union",
                            valuespaces_join_op="right",
                        )

                    fitted_values.merge_inplace(
                        local_fitted, self_precedence=True, variate_mode="multi"
                    )

                # Update resid_values Quble (if applicable)
                if (
                    residual_flag
                    and local_resid is not None
                    and not local_resid.is_undefined
                    and not local_resid.is_empty
                ):
                    if not dummy_ortho:
                        # Join ortho_index1: Put ortho_index1 on left in join so that ortho_keyspaces will appear first
                        local_resid = ortho_index1.join(
                            local_resid,
                            keys_join_op="leftmost",
                            keyspaces_join_op="union",
                            valuespaces_join_op="right",
                        )

                    resid_values.merge_inplace(
                        local_resid, self_precedence=True, variate_mode="multi"
                    )

        # =================== END: ortho_index_iterator LOOP ====================
        return (ols_details, ols_summary, fitted_values, resid_values)
